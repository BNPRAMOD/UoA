{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Layer 1: Baseline DeiT environment**"],"metadata":{"id":"A814LG7i7w0a"}},{"cell_type":"markdown","source":["DeiT’s baseline training script expects a teacher model name and distillation settings via CLI flags in main.py (e.g., --teacher-model, --teacher-path, --distillation-type).\n","GitHub\n","+1\n","\n","So the “base environment” Layer 1 must include:\n","\n","DeiT repo (cloned)\n","\n","PyTorch (Colab default) + GPU\n","\n","timm installed (for both student and teacher models)\n","\n","compatibility patches if any (because Colab uses new torch/timm)"],"metadata":{"id":"yZ7gvhPl8OL3"}},{"cell_type":"markdown","source":["Install PyTorch without pinning"],"metadata":{"id":"25JXNJNx7v2f"}},{"cell_type":"code","source":["!pip -q install --upgrade pip\n","!pip -q install torch torchvision torchaudio"],"metadata":{"id":"OZgeujT4qBSQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Verify"],"metadata":{"id":"WWb1brNPqbEs"}},{"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","print(\"CUDA:\", torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2uvYnPeqaBB","executionInfo":{"status":"ok","timestamp":1767457473813,"user_tz":-330,"elapsed":0,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"77d20c33-a355-4f0e-c3d0-7594a3db9d47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cu126\n","CUDA: True\n"]}]},{"cell_type":"markdown","source":["Clone the baseline repo (official DeiT)"],"metadata":{"id":"3awWPnZtp7E6"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7aYSAUqVmQid","executionInfo":{"status":"ok","timestamp":1767457474041,"user_tz":-330,"elapsed":226,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"f5be6134-c022-481b-d23e-fb6868bd8ef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","fatal: destination path 'deit' already exists and is not an empty directory.\n","/content/deit\n"]}],"source":["%cd /content\n","!git clone https://github.com/facebookresearch/deit.git\n","%cd /content/deit\n","!grep -n \"torch\" -n requirements.txt || true"]},{"cell_type":"markdown","source":["Colab Compatibility Fixes\n","\n","1. torch pin removal\n","\n","2. timm API changes\n","\n","3. kwargs popping (pretrained_cfg, cache_dir, etc.)\n","\n"],"metadata":{"id":"fVJsxhJv4Dwu"}},{"cell_type":"markdown","source":["Patch requirements.txt to remove torch pins"],"metadata":{"id":"kHpCHaaDr1u9"}},{"cell_type":"code","source":["%cd /content/deit\n","\n","!python - << 'PY'\n","from pathlib import Path\n","p = Path(\"requirements.txt\")\n","lines = p.read_text().splitlines()\n","\n","filtered = []\n","removed = []\n","for line in lines:\n","    s = line.strip()\n","    if s.startswith(\"torch==\") or s.startswith(\"torchvision==\") or s.startswith(\"torchaudio==\"):\n","        removed.append(line)\n","        continue\n","    filtered.append(line)\n","\n","p.write_text(\"\\n\".join(filtered) + \"\\n\")\n","print(\"✅ Removed these pinned lines:\")\n","for r in removed:\n","    print(\"  -\", r)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3mRQRCcrLmU","executionInfo":{"status":"ok","timestamp":1767457474127,"user_tz":-330,"elapsed":63,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"87ec47b8-3acc-4875-c1ac-33fdae771e4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deit\n","/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n","✅ Removed these pinned lines:\n"]}]},{"cell_type":"markdown","source":["Verify Pins are gone!i.e torch==1.13.1 pin was removed"],"metadata":{"id":"lyODjd5lsAqJ"}},{"cell_type":"code","source":["!grep -nE \"torch|torchvision|torchaudio\" requirements.txt || echo \"✅ No torch pins remain\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7QRJmf7rg6a","executionInfo":{"status":"ok","timestamp":1767457475204,"user_tz":-330,"elapsed":120,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"2422c5b8-acb1-4149-9fd1-010810749a19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ No torch pins remain\n"]}]},{"cell_type":"markdown","source":["Install the baseline dependencies"],"metadata":{"id":"csYbu0BampB9"}},{"cell_type":"code","source":["!pip -q uninstall -y timm\n","!pip -q install -U pip setuptools wheel\n","!pip -q install -U \"timm>=1.0.0\""],"metadata":{"id":"q0Mim13um2k4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Verify"],"metadata":{"id":"llX7-GOnsQQZ"}},{"cell_type":"code","source":["!python -c \"import timm; print('timm:', timm.__version__)\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG39iey7tfMQ","executionInfo":{"status":"ok","timestamp":1767457492691,"user_tz":-330,"elapsed":7996,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"067b148d-a393-40b0-8e22-4ac26850b996"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["timm: 1.0.22\n"]}]},{"cell_type":"code","source":["!python - << 'PY'\n","from pathlib import Path\n","\n","p = Path(\"/usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\")\n","txt = p.read_text()\n","\n","needle = \"OPENAI_CLIP_MEAN\"\n","if needle in txt:\n","    print(\"✅ timm.data already mentions OPENAI_CLIP_MEAN; no patch needed.\")\n","else:\n","    patch = \"\"\"\n","\n","# --- Colab patch: expose CLIP normalization constants for older exports ---\n","try:\n","    from .constants import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD  # timm versions where defined in constants\n","except Exception:\n","    # Standard OpenAI CLIP normalization\n","    OPENAI_CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n","    OPENAI_CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n","# --- end patch ---\n","\"\"\"\n","    p.write_text(txt + patch)\n","    print(\"✅ Patched:\", p)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEsR06SsuQa1","executionInfo":{"status":"ok","timestamp":1767457492895,"user_tz":-330,"elapsed":186,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"71019bbe-42af-4521-c0ff-243423ea6abc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n","✅ Patched: /usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\n"]}]},{"cell_type":"markdown","source":["Runtime → Restart runtime"],"metadata":{"id":"M0ZDDe3uvU2V"}},{"cell_type":"code","source":["!pip -q install timm submitit"],"metadata":{"id":"H3T5zLnQukuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/deit\n","from models import deit_tiny_patch16_224\n","m = deit_tiny_patch16_224()\n","print(\"✅ DeiT model instantiated successfully\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h97jFzzrupzp","executionInfo":{"status":"ok","timestamp":1767457498236,"user_tz":-330,"elapsed":431,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"07e4d25a-6942-439c-9df4-8f47a3f20043"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deit\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n","/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","/content/deit/models.py:62: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:85: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:108: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:131: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:154: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:177: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:200: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:223: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n"]},{"output_type":"stream","name":"stdout","text":["✅ DeiT model instantiated successfully\n"]}]},{"cell_type":"code","source":["import torch, timm\n","print(torch.__version__)\n","print(timm.__version__)\n","print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37b1qcS72uJs","executionInfo":{"status":"ok","timestamp":1767457498273,"user_tz":-330,"elapsed":25,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"920b4130-a09b-4d14-92b9-627bf9853935"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cu126\n","1.0.22\n","True\n"]}]},{"cell_type":"markdown","source":["Download Tiny-ImageNet"],"metadata":{"id":"uu-A5-G7vzTm"}},{"cell_type":"code","source":["%cd /content\n","!wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","!unzip -q tiny-imagenet-200.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IraDkD4vavm","executionInfo":{"status":"ok","timestamp":1767457571456,"user_tz":-330,"elapsed":73180,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"b1c71f84-1f6a-4c01-d42e-91d0bb1d58a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","replace tiny-imagenet-200/words.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","replace tiny-imagenet-200/wnids.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","a\n"]}]},{"cell_type":"markdown","source":["Fix Tiny-ImageNet validation folder"],"metadata":{"id":"qlrZWkYCvyN6"}},{"cell_type":"code","source":["!python - << 'EOF'\n","import shutil\n","from pathlib import Path\n","\n","root = Path(\"/content/tiny-imagenet-200\")\n","val_dir = root/\"val\"\n","img_dir = val_dir/\"images\"\n","ann = val_dir/\"val_annotations.txt\"\n","\n","with ann.open(\"r\") as f:\n","    for line in f:\n","        img, cls = line.strip().split(\"\\t\")[:2]\n","        (val_dir/cls).mkdir(parents=True, exist_ok=True)\n","        src = img_dir/img\n","        dst = val_dir/cls/img\n","        if src.exists():\n","            shutil.move(str(src), str(dst))\n","\n","if img_dir.exists():\n","    shutil.rmtree(img_dir)\n","\n","print(\"✅ Tiny-ImageNet val reorganized into class subfolders.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvYzGeXJwSsy","executionInfo":{"status":"ok","timestamp":1767457572849,"user_tz":-330,"elapsed":1377,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"02c2c7a4-56b7-4569-bccc-86e5e139d236"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n","✅ Tiny-ImageNet val reorganized into class subfolders.\n"]}]},{"cell_type":"code","source":["!find /content/tiny-imagenet-200/val -maxdepth 1 -type d | head"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Bwwo30Qwi0V","executionInfo":{"status":"ok","timestamp":1767457572956,"user_tz":-330,"elapsed":92,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"fe16f295-b12a-4e7b-f17a-4061da5464e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/tiny-imagenet-200/val\n","/content/tiny-imagenet-200/val/n03649909\n","/content/tiny-imagenet-200/val/n03042490\n","/content/tiny-imagenet-200/val/n01629819\n","/content/tiny-imagenet-200/val/n02423022\n","/content/tiny-imagenet-200/val/n02415577\n","/content/tiny-imagenet-200/val/n01910747\n","/content/tiny-imagenet-200/val/n04371430\n","/content/tiny-imagenet-200/val/n03201208\n","/content/tiny-imagenet-200/val/n02883205\n"]}]},{"cell_type":"markdown","source":["Handle timm incompatibilities. Although we can instantiate the model directly, the training script uses timm.create_model(), which injects metadata arguments such as pretrained_cfg and cache_dir.\n","The original DeiT constructors do not support these arguments, so we remove them\n","YOUR NOTEBOOK CALL\n","    |\n","    v\n","deit_tiny_patch16_224()          ✅ works (no kwargs)\n","\n","TRAINING PIPELINE\n","    |\n","    v\n","timm.create_model()\n","    |\n","    v\n","deit_tiny_patch16_224(**kwargs)  ❌ injects extra keys\n"],"metadata":{"id":"Rtyo7rkj3vLq"}},{"cell_type":"markdown","source":["Patch /content/deit/augment.py (safe compatibility fix)"],"metadata":{"id":"mWebMtbWxHi8"}},{"cell_type":"code","source":["%cd /content/deit\n","!python - << 'PY'\n","from pathlib import Path\n","p = Path(\"augment.py\")\n","txt = p.read_text()\n","\n","old = \"from timm.data.transforms import _pil_interp, RandomResizedCropAndInterpolation, ToNumpy, ToTensor\"\n","if old in txt:\n","    txt = txt.replace(\n","        old,\n","        \"from timm.data.transforms import RandomResizedCropAndInterpolation, ToNumpy, ToTensor\\n\"\n","        \"try:\\n\"\n","        \"    from timm.data.transforms import _pil_interp  # older timm\\n\"\n","        \"except Exception:\\n\"\n","        \"    _pil_interp = None  # newer timm doesn't expose this\\n\"\n","    )\n","    p.write_text(txt)\n","    print(\"✅ Patched augment.py for timm compatibility.\")\n","else:\n","    print(\"ℹ️ Expected import line not found; augment.py may already be patched or different.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZwKyJqIxG2d","executionInfo":{"status":"ok","timestamp":1767457573110,"user_tz":-330,"elapsed":152,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"fe1cfb5e-429e-4f4b-ac48-0db60c0db003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deit\n","/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n","ℹ️ Expected import line not found; augment.py may already be patched or different.\n"]}]},{"cell_type":"code","source":["%cd /content/deit\n","!sed -n '1,200p' models.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51Cm_gVMz1-_","executionInfo":{"status":"ok","timestamp":1767457573296,"user_tz":-330,"elapsed":192,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"bf026b1d-3da6-4bed-ecee-d29b806f9aeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deit\n","# Copyright (c) 2015-present, Facebook, Inc.\n","# All rights reserved.\n","import torch\n","import torch.nn as nn\n","from functools import partial\n","\n","from timm.models.vision_transformer import VisionTransformer, _cfg\n","from timm.models.registry import register_model\n","from timm.models.layers import trunc_normal_\n","\n","\n","__all__ = [\n","    'deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224',\n","    'deit_tiny_distilled_patch16_224', 'deit_small_distilled_patch16_224',\n","    'deit_base_distilled_patch16_224', 'deit_base_patch16_384',\n","    'deit_base_distilled_patch16_384',\n","]\n","\n","\n","class DistilledVisionTransformer(VisionTransformer):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.dist_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n","        num_patches = self.patch_embed.num_patches\n","        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.embed_dim))\n","        self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if self.num_classes > 0 else nn.Identity()\n","\n","        trunc_normal_(self.dist_token, std=.02)\n","        trunc_normal_(self.pos_embed, std=.02)\n","        self.head_dist.apply(self._init_weights)\n","\n","    def forward_features(self, x):\n","        # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n","        # with slight modifications to add the dist_token\n","        B = x.shape[0]\n","        x = self.patch_embed(x)\n","\n","        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n","        dist_token = self.dist_token.expand(B, -1, -1)\n","        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n","\n","        x = x + self.pos_embed\n","        x = self.pos_drop(x)\n","\n","        for blk in self.blocks:\n","            x = blk(x)\n","\n","        x = self.norm(x)\n","        return x[:, 0], x[:, 1]\n","\n","    def forward(self, x):\n","        x, x_dist = self.forward_features(x)\n","        x = self.head(x)\n","        x_dist = self.head_dist(x_dist)\n","        if self.training:\n","            return x, x_dist\n","        else:\n","            # during inference, return the average of both classifier predictions\n","            return (x + x_dist) / 2\n","\n","\n","@register_model\n","def deit_tiny_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = VisionTransformer(\n","        patch_size=16, embed_dim=192, depth=12, num_heads=3, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n","def deit_small_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = VisionTransformer(\n","        patch_size=16, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n","def deit_base_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = VisionTransformer(\n","        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n","def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = DistilledVisionTransformer(\n","        patch_size=16, embed_dim=192, depth=12, num_heads=3, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n","def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = DistilledVisionTransformer(\n","        patch_size=16, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n","def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n","    # Drop timm-injected kwargs not supported by DeiT\n","    kwargs.pop('cache_dir', None)\n","    kwargs.pop('hf_hub_id', None)\n","    kwargs.pop('hf_hub_filename', None)\n","    kwargs.pop('hf_hub_revision', None)\n","    kwargs.pop('pretrained_cfg', None)\n","    kwargs.pop('pretrained_cfg_overlay', None)\n","    kwargs.pop('pretrained_cfg_priority', None)\n","    model = DistilledVisionTransformer(\n","        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n","        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n","    model.default_cfg = _cfg()\n","    if pretrained:\n","        checkpoint = torch.hub.load_state_dict_from_url(\n","            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth\",\n","            map_location=\"cpu\", check_hash=True\n","        )\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","\n","@register_model\n"]}]},{"cell_type":"markdown","source":["Before constructing the model, remove those keys from kwargs"],"metadata":{"id":"4sFpztpw00XO"}},{"cell_type":"code","source":["from pathlib import Path\n","\n","p = Path(\"/content/deit/models.py\")\n","lines = p.read_text().splitlines()\n","\n","out = []\n","for line in lines:\n","    out.append(line)\n","    if line.strip().startswith(\"def deit_\") and \"**kwargs\" in line:\n","        out.append(\"    # Drop timm-injected kwargs not supported by DeiT\")\n","        out.append(\"    kwargs.pop('pretrained_cfg', None)\")\n","        out.append(\"    kwargs.pop('pretrained_cfg_overlay', None)\")\n","        out.append(\"    kwargs.pop('pretrained_cfg_priority', None)\")\n","\n","p.write_text(\"\\n\".join(out) + \"\\n\")\n","print(\"✅ models.py patched to drop pretrained_cfg kwargs\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1qywwxV0RS-","executionInfo":{"status":"ok","timestamp":1767457573312,"user_tz":-330,"elapsed":15,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"1c90dd15-fc96-4a43-9a33-7de7f65c7a73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ models.py patched to drop pretrained_cfg kwargs\n"]}]},{"cell_type":"markdown","source":["Verify"],"metadata":{"id":"Yh47-0Pv0-R_"}},{"cell_type":"code","source":["!grep -n \"pretrained_cfg\" /content/deit/models.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxOmdCb90Ymg","executionInfo":{"status":"ok","timestamp":1767457573349,"user_tz":-330,"elapsed":35,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"8d5abf5d-b13f-4d40-c921-2a842fa41b89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["65:    kwargs.pop('pretrained_cfg', None)\n","66:    kwargs.pop('pretrained_cfg_overlay', None)\n","67:    kwargs.pop('pretrained_cfg_priority', None)\n","73:    kwargs.pop('pretrained_cfg', None)\n","74:    kwargs.pop('pretrained_cfg_overlay', None)\n","75:    kwargs.pop('pretrained_cfg_priority', None)\n","92:    kwargs.pop('pretrained_cfg', None)\n","93:    kwargs.pop('pretrained_cfg_overlay', None)\n","94:    kwargs.pop('pretrained_cfg_priority', None)\n","100:    kwargs.pop('pretrained_cfg', None)\n","101:    kwargs.pop('pretrained_cfg_overlay', None)\n","102:    kwargs.pop('pretrained_cfg_priority', None)\n","119:    kwargs.pop('pretrained_cfg', None)\n","120:    kwargs.pop('pretrained_cfg_overlay', None)\n","121:    kwargs.pop('pretrained_cfg_priority', None)\n","127:    kwargs.pop('pretrained_cfg', None)\n","128:    kwargs.pop('pretrained_cfg_overlay', None)\n","129:    kwargs.pop('pretrained_cfg_priority', None)\n","146:    kwargs.pop('pretrained_cfg', None)\n","147:    kwargs.pop('pretrained_cfg_overlay', None)\n","148:    kwargs.pop('pretrained_cfg_priority', None)\n","154:    kwargs.pop('pretrained_cfg', None)\n","155:    kwargs.pop('pretrained_cfg_overlay', None)\n","156:    kwargs.pop('pretrained_cfg_priority', None)\n","173:    kwargs.pop('pretrained_cfg', None)\n","174:    kwargs.pop('pretrained_cfg_overlay', None)\n","175:    kwargs.pop('pretrained_cfg_priority', None)\n","181:    kwargs.pop('pretrained_cfg', None)\n","182:    kwargs.pop('pretrained_cfg_overlay', None)\n","183:    kwargs.pop('pretrained_cfg_priority', None)\n","200:    kwargs.pop('pretrained_cfg', None)\n","201:    kwargs.pop('pretrained_cfg_overlay', None)\n","202:    kwargs.pop('pretrained_cfg_priority', None)\n","208:    kwargs.pop('pretrained_cfg', None)\n","209:    kwargs.pop('pretrained_cfg_overlay', None)\n","210:    kwargs.pop('pretrained_cfg_priority', None)\n","227:    kwargs.pop('pretrained_cfg', None)\n","228:    kwargs.pop('pretrained_cfg_overlay', None)\n","229:    kwargs.pop('pretrained_cfg_priority', None)\n","235:    kwargs.pop('pretrained_cfg', None)\n","236:    kwargs.pop('pretrained_cfg_overlay', None)\n","237:    kwargs.pop('pretrained_cfg_priority', None)\n","254:    kwargs.pop('pretrained_cfg', None)\n","255:    kwargs.pop('pretrained_cfg_overlay', None)\n","256:    kwargs.pop('pretrained_cfg_priority', None)\n","262:    kwargs.pop('pretrained_cfg', None)\n","263:    kwargs.pop('pretrained_cfg_overlay', None)\n","264:    kwargs.pop('pretrained_cfg_priority', None)\n"]}]},{"cell_type":"markdown","source":["Fix: Patch /content/deit/models.py to drop pretrained_cfg=..."],"metadata":{"id":"hfueTM11xy00"}},{"cell_type":"markdown","source":["Patch models.py to also drop cache_dir (and friends)"],"metadata":{"id":"OK2GsetX1ZkS"}},{"cell_type":"code","source":["from pathlib import Path\n","\n","p = Path(\"/content/deit/models.py\")\n","lines = p.read_text().splitlines()\n","\n","# Keys that timm may inject but DeiT constructors don't accept\n","DROP_KEYS = [\n","    \"cache_dir\",\n","    \"hf_hub_id\",\n","    \"hf_hub_filename\",\n","    \"hf_hub_revision\",\n","]\n","\n","out = []\n","for line in lines:\n","    out.append(line)\n","    # Right after the comment line we previously inserted, add more pops once per function\n","    if line.strip() == \"# Drop timm-injected kwargs not supported by DeiT\":\n","        for k in DROP_KEYS:\n","            out.append(f\"    kwargs.pop('{k}', None)\")\n","\n","p.write_text(\"\\n\".join(out) + \"\\n\")\n","print(\"✅ Patched models.py to drop cache_dir/hf_hub* kwargs\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0-XJmyw1aed","executionInfo":{"status":"ok","timestamp":1767457573364,"user_tz":-330,"elapsed":13,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"f87c6e37-c9fc-4169-c1d9-55c401343a6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Patched models.py to drop cache_dir/hf_hub* kwargs\n"]}]},{"cell_type":"markdown","source":["Verify"],"metadata":{"id":"V409XjDO1cdR"}},{"cell_type":"code","source":["!grep -n \"cache_dir\" /content/deit/models.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIFoOP5c1dbu","executionInfo":{"status":"ok","timestamp":1767457573439,"user_tz":-330,"elapsed":77,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"dbdea93e-282b-483f-9126-a9a1f5ed449d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["65:    kwargs.pop('cache_dir', None)\n","73:    kwargs.pop('cache_dir', None)\n","77:    kwargs.pop('cache_dir', None)\n","100:    kwargs.pop('cache_dir', None)\n","108:    kwargs.pop('cache_dir', None)\n","112:    kwargs.pop('cache_dir', None)\n","135:    kwargs.pop('cache_dir', None)\n","143:    kwargs.pop('cache_dir', None)\n","147:    kwargs.pop('cache_dir', None)\n","170:    kwargs.pop('cache_dir', None)\n","178:    kwargs.pop('cache_dir', None)\n","182:    kwargs.pop('cache_dir', None)\n","205:    kwargs.pop('cache_dir', None)\n","213:    kwargs.pop('cache_dir', None)\n","217:    kwargs.pop('cache_dir', None)\n","240:    kwargs.pop('cache_dir', None)\n","248:    kwargs.pop('cache_dir', None)\n","252:    kwargs.pop('cache_dir', None)\n","275:    kwargs.pop('cache_dir', None)\n","283:    kwargs.pop('cache_dir', None)\n","287:    kwargs.pop('cache_dir', None)\n","310:    kwargs.pop('cache_dir', None)\n","318:    kwargs.pop('cache_dir', None)\n","322:    kwargs.pop('cache_dir', None)\n"]}]},{"cell_type":"code","source":["# %cd /content/deit\n","# !python main.py \\\n","#   --model deit_tiny_patch16_224 \\\n","#   --data-path /content/tiny-imagenet-200 \\\n","#   --pretrained \\\n","#   --epochs 1 \\\n","#   --batch-size 64 \\\n","#   --num_workers 2 \\\n","#   --output_dir /content/deit_runs/smoke_test\n","%cd /content/deit\n","!python main.py \\\n","  --model deit_tiny_patch16_224 \\\n","  --data-path /content/tiny-imagenet-200 \\\n","  --epochs 1 \\\n","  --batch-size 128 \\\n","  --num_workers 4 \\\n","  --opt adamw \\\n","  --lr 5e-4 \\\n","  --weight-decay 0.05 \\\n","  --sched cosine \\\n","  --aa rand-m9-mstd0.5 \\\n","  --reprob 0.25 \\\n","  --remode pixel \\\n","  --recount 1 \\\n","  --output_dir /content/deit_runs/tiny_imagenet\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TYvrcwJwlde","executionInfo":{"status":"ok","timestamp":1767458104104,"user_tz":-330,"elapsed":420551,"user":{"displayName":"Pranjal Enchalwar","userId":"08928488842154445235"}},"outputId":"58bb7346-8744-423e-dcbd-1f65bc1fa33b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/deit\n","/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n","/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","/content/deit/models.py:62: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:97: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:132: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:167: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:202: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:237: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:272: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","/content/deit/models.py:307: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  @register_model\n","Not using distributed mode\n","Namespace(batch_size=128, epochs=1, bce_loss=False, unscale_lr=False, model='deit_tiny_patch16_224', input_size=224, drop=0.0, drop_path=0.1, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.3, aa='rand-m9-mstd0.5', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, train_mode=True, ThreeAugment=False, src=False, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety_160', teacher_path='', distillation_type='none', distillation_alpha=0.5, distillation_tau=1.0, cosub=False, finetune='', attn_only=False, data_path='/content/tiny-imagenet-200', data_set='IMNET', inat_category='name', output_dir='/content/deit_runs/tiny_imagenet', device='cuda', seed=0, resume='', start_epoch=0, eval=False, eval_crop_ratio=0.875, dist_eval=False, num_workers=4, pin_mem=True, distributed=False, world_size=1, dist_url='env://')\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Creating model: deit_tiny_patch16_224\n","number of params: 5717416\n","Start training for 1 epochs\n","/content/deit/engine.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","Epoch: [0]  [  0/781]  eta: 1:20:37  lr: 0.000001  loss: 6.9360 (6.9360)  time: 6.1939  data: 1.9188  max mem: 2270\n","Epoch: [0]  [ 10/781]  eta: 0:10:04  lr: 0.000001  loss: 6.9360 (6.9377)  time: 0.7835  data: 0.2090  max mem: 2314\n","Epoch: [0]  [ 20/781]  eta: 0:07:49  lr: 0.000001  loss: 6.9291 (6.9315)  time: 0.3383  data: 0.1250  max mem: 2314\n","Epoch: [0]  [ 30/781]  eta: 0:07:50  lr: 0.000001  loss: 6.9202 (6.9274)  time: 0.5407  data: 0.3061  max mem: 2314\n","Epoch: [0]  [ 40/781]  eta: 0:07:10  lr: 0.000001  loss: 6.9173 (6.9253)  time: 0.5420  data: 0.3046  max mem: 2314\n","Epoch: [0]  [ 50/781]  eta: 0:07:04  lr: 0.000001  loss: 6.9211 (6.9225)  time: 0.5088  data: 0.2765  max mem: 2314\n","Epoch: [0]  [ 60/781]  eta: 0:06:51  lr: 0.000001  loss: 6.9134 (6.9206)  time: 0.5509  data: 0.3246  max mem: 2314\n","Epoch: [0]  [ 70/781]  eta: 0:06:38  lr: 0.000001  loss: 6.8972 (6.9168)  time: 0.5112  data: 0.2932  max mem: 2314\n","Epoch: [0]  [ 80/781]  eta: 0:06:30  lr: 0.000001  loss: 6.8863 (6.9136)  time: 0.5170  data: 0.2802  max mem: 2314\n","Epoch: [0]  [ 90/781]  eta: 0:06:18  lr: 0.000001  loss: 6.8819 (6.9097)  time: 0.5035  data: 0.2684  max mem: 2314\n","Epoch: [0]  [100/781]  eta: 0:06:08  lr: 0.000001  loss: 6.8813 (6.9063)  time: 0.4721  data: 0.2442  max mem: 2314\n","Epoch: [0]  [110/781]  eta: 0:06:02  lr: 0.000001  loss: 6.8734 (6.9036)  time: 0.5031  data: 0.2641  max mem: 2314\n","Epoch: [0]  [120/781]  eta: 0:05:53  lr: 0.000001  loss: 6.8685 (6.9000)  time: 0.5072  data: 0.2719  max mem: 2314\n","Epoch: [0]  [130/781]  eta: 0:05:48  lr: 0.000001  loss: 6.8656 (6.8976)  time: 0.5047  data: 0.2659  max mem: 2314\n","Epoch: [0]  [140/781]  eta: 0:05:42  lr: 0.000001  loss: 6.8611 (6.8945)  time: 0.5331  data: 0.3001  max mem: 2314\n","Epoch: [0]  [150/781]  eta: 0:05:32  lr: 0.000001  loss: 6.8484 (6.8911)  time: 0.4706  data: 0.2375  max mem: 2314\n","Epoch: [0]  [160/781]  eta: 0:05:28  lr: 0.000001  loss: 6.8357 (6.8884)  time: 0.4938  data: 0.2536  max mem: 2314\n","Epoch: [0]  [170/781]  eta: 0:05:20  lr: 0.000001  loss: 6.8357 (6.8850)  time: 0.5096  data: 0.2831  max mem: 2314\n","Epoch: [0]  [180/781]  eta: 0:05:18  lr: 0.000001  loss: 6.8217 (6.8812)  time: 0.5279  data: 0.2935  max mem: 2314\n","Epoch: [0]  [190/781]  eta: 0:05:08  lr: 0.000001  loss: 6.8151 (6.8783)  time: 0.4986  data: 0.2605  max mem: 2314\n","Epoch: [0]  [200/781]  eta: 0:05:02  lr: 0.000001  loss: 6.8207 (6.8752)  time: 0.4442  data: 0.2142  max mem: 2314\n","Epoch: [0]  [210/781]  eta: 0:04:58  lr: 0.000001  loss: 6.8186 (6.8727)  time: 0.5267  data: 0.2806  max mem: 2314\n","Epoch: [0]  [220/781]  eta: 0:04:52  lr: 0.000001  loss: 6.8244 (6.8705)  time: 0.5322  data: 0.2981  max mem: 2314\n","Epoch: [0]  [230/781]  eta: 0:04:46  lr: 0.000001  loss: 6.8229 (6.8681)  time: 0.5037  data: 0.2711  max mem: 2314\n","Epoch: [0]  [240/781]  eta: 0:04:41  lr: 0.000001  loss: 6.8056 (6.8655)  time: 0.4916  data: 0.2541  max mem: 2314\n","Epoch: [0]  [250/781]  eta: 0:04:33  lr: 0.000001  loss: 6.8004 (6.8628)  time: 0.4454  data: 0.2222  max mem: 2314\n","Epoch: [0]  [260/781]  eta: 0:04:30  lr: 0.000001  loss: 6.7968 (6.8601)  time: 0.5230  data: 0.2747  max mem: 2314\n","Epoch: [0]  [270/781]  eta: 0:04:23  lr: 0.000001  loss: 6.7936 (6.8577)  time: 0.5262  data: 0.2771  max mem: 2314\n","Epoch: [0]  [280/781]  eta: 0:04:18  lr: 0.000001  loss: 6.7917 (6.8552)  time: 0.4698  data: 0.2289  max mem: 2314\n","Epoch: [0]  [290/781]  eta: 0:04:12  lr: 0.000001  loss: 6.7785 (6.8528)  time: 0.5041  data: 0.2526  max mem: 2314\n","Epoch: [0]  [300/781]  eta: 0:04:07  lr: 0.000001  loss: 6.7778 (6.8502)  time: 0.4770  data: 0.2404  max mem: 2314\n","Epoch: [0]  [310/781]  eta: 0:04:01  lr: 0.000001  loss: 6.7755 (6.8478)  time: 0.4810  data: 0.2348  max mem: 2314\n","Epoch: [0]  [320/781]  eta: 0:03:55  lr: 0.000001  loss: 6.7675 (6.8452)  time: 0.4829  data: 0.2330  max mem: 2314\n","Epoch: [0]  [330/781]  eta: 0:03:49  lr: 0.000001  loss: 6.7555 (6.8423)  time: 0.4532  data: 0.2210  max mem: 2314\n","Epoch: [0]  [340/781]  eta: 0:03:45  lr: 0.000001  loss: 6.7501 (6.8397)  time: 0.5167  data: 0.2740  max mem: 2314\n","Epoch: [0]  [350/781]  eta: 0:03:39  lr: 0.000001  loss: 6.7582 (6.8376)  time: 0.5147  data: 0.2747  max mem: 2314\n","Epoch: [0]  [360/781]  eta: 0:03:34  lr: 0.000001  loss: 6.7582 (6.8354)  time: 0.4764  data: 0.2423  max mem: 2314\n","Epoch: [0]  [370/781]  eta: 0:03:29  lr: 0.000001  loss: 6.7493 (6.8329)  time: 0.5298  data: 0.2494  max mem: 2314\n","Epoch: [0]  [380/781]  eta: 0:03:23  lr: 0.000001  loss: 6.7427 (6.8306)  time: 0.4712  data: 0.1936  max mem: 2314\n","Epoch: [0]  [390/781]  eta: 0:03:18  lr: 0.000001  loss: 6.7284 (6.8281)  time: 0.4575  data: 0.2110  max mem: 2314\n","Epoch: [0]  [400/781]  eta: 0:03:13  lr: 0.000001  loss: 6.7343 (6.8260)  time: 0.5054  data: 0.2599  max mem: 2314\n","Epoch: [0]  [410/781]  eta: 0:03:08  lr: 0.000001  loss: 6.7354 (6.8237)  time: 0.4898  data: 0.2565  max mem: 2314\n","Epoch: [0]  [420/781]  eta: 0:03:03  lr: 0.000001  loss: 6.7301 (6.8216)  time: 0.5020  data: 0.2582  max mem: 2314\n","Epoch: [0]  [430/781]  eta: 0:02:57  lr: 0.000001  loss: 6.7334 (6.8194)  time: 0.4798  data: 0.2366  max mem: 2314\n","Epoch: [0]  [440/781]  eta: 0:02:53  lr: 0.000001  loss: 6.7288 (6.8172)  time: 0.5244  data: 0.2763  max mem: 2314\n","Epoch: [0]  [450/781]  eta: 0:02:47  lr: 0.000001  loss: 6.7193 (6.8150)  time: 0.5167  data: 0.2665  max mem: 2314\n","Epoch: [0]  [460/781]  eta: 0:02:42  lr: 0.000001  loss: 6.7192 (6.8130)  time: 0.4357  data: 0.2038  max mem: 2314\n","Epoch: [0]  [470/781]  eta: 0:02:37  lr: 0.000001  loss: 6.7166 (6.8109)  time: 0.4880  data: 0.2447  max mem: 2314\n","Epoch: [0]  [480/781]  eta: 0:02:31  lr: 0.000001  loss: 6.7046 (6.8087)  time: 0.5000  data: 0.2525  max mem: 2314\n","Epoch: [0]  [490/781]  eta: 0:02:26  lr: 0.000001  loss: 6.7046 (6.8067)  time: 0.4531  data: 0.2201  max mem: 2314\n","Epoch: [0]  [500/781]  eta: 0:02:22  lr: 0.000001  loss: 6.7014 (6.8046)  time: 0.5263  data: 0.2823  max mem: 2314\n","Epoch: [0]  [510/781]  eta: 0:02:16  lr: 0.000001  loss: 6.6955 (6.8026)  time: 0.5337  data: 0.2894  max mem: 2314\n","Epoch: [0]  [520/781]  eta: 0:02:12  lr: 0.000001  loss: 6.7062 (6.8009)  time: 0.5220  data: 0.2731  max mem: 2314\n","Epoch: [0]  [530/781]  eta: 0:02:06  lr: 0.000001  loss: 6.7088 (6.7990)  time: 0.5061  data: 0.2518  max mem: 2314\n","Epoch: [0]  [540/781]  eta: 0:02:01  lr: 0.000001  loss: 6.6981 (6.7971)  time: 0.4628  data: 0.2224  max mem: 2314\n","Epoch: [0]  [550/781]  eta: 0:01:56  lr: 0.000001  loss: 6.6959 (6.7953)  time: 0.5146  data: 0.2687  max mem: 2314\n","Epoch: [0]  [560/781]  eta: 0:01:51  lr: 0.000001  loss: 6.6947 (6.7935)  time: 0.4818  data: 0.2360  max mem: 2314\n","Epoch: [0]  [570/781]  eta: 0:01:46  lr: 0.000001  loss: 6.6854 (6.7916)  time: 0.4864  data: 0.2389  max mem: 2314\n","Epoch: [0]  [580/781]  eta: 0:01:41  lr: 0.000001  loss: 6.6831 (6.7900)  time: 0.5195  data: 0.2773  max mem: 2314\n","Epoch: [0]  [590/781]  eta: 0:01:36  lr: 0.000001  loss: 6.6889 (6.7882)  time: 0.4754  data: 0.2476  max mem: 2314\n","Epoch: [0]  [600/781]  eta: 0:01:31  lr: 0.000001  loss: 6.6853 (6.7865)  time: 0.4952  data: 0.2479  max mem: 2314\n","Epoch: [0]  [610/781]  eta: 0:01:25  lr: 0.000001  loss: 6.6810 (6.7847)  time: 0.4898  data: 0.2415  max mem: 2314\n","Epoch: [0]  [620/781]  eta: 0:01:20  lr: 0.000001  loss: 6.6794 (6.7831)  time: 0.4415  data: 0.2093  max mem: 2314\n","Epoch: [0]  [630/781]  eta: 0:01:15  lr: 0.000001  loss: 6.6759 (6.7813)  time: 0.4976  data: 0.2543  max mem: 2314\n","Epoch: [0]  [640/781]  eta: 0:01:10  lr: 0.000001  loss: 6.6705 (6.7796)  time: 0.5170  data: 0.2796  max mem: 2314\n","Epoch: [0]  [650/781]  eta: 0:01:05  lr: 0.000001  loss: 6.6636 (6.7779)  time: 0.5005  data: 0.2650  max mem: 2314\n","Epoch: [0]  [660/781]  eta: 0:01:00  lr: 0.000001  loss: 6.6636 (6.7763)  time: 0.5008  data: 0.2577  max mem: 2314\n","Epoch: [0]  [670/781]  eta: 0:00:55  lr: 0.000001  loss: 6.6617 (6.7746)  time: 0.4644  data: 0.2307  max mem: 2314\n","Epoch: [0]  [680/781]  eta: 0:00:50  lr: 0.000001  loss: 6.6569 (6.7730)  time: 0.5077  data: 0.2612  max mem: 2314\n","Epoch: [0]  [690/781]  eta: 0:00:45  lr: 0.000001  loss: 6.6586 (6.7713)  time: 0.5015  data: 0.2517  max mem: 2314\n","Epoch: [0]  [700/781]  eta: 0:00:40  lr: 0.000001  loss: 6.6467 (6.7696)  time: 0.4567  data: 0.2175  max mem: 2314\n","Epoch: [0]  [710/781]  eta: 0:00:35  lr: 0.000001  loss: 6.6535 (6.7681)  time: 0.5031  data: 0.2586  max mem: 2314\n","Epoch: [0]  [720/781]  eta: 0:00:30  lr: 0.000001  loss: 6.6548 (6.7665)  time: 0.4859  data: 0.2511  max mem: 2314\n","Epoch: [0]  [730/781]  eta: 0:00:25  lr: 0.000001  loss: 6.6488 (6.7649)  time: 0.4834  data: 0.2429  max mem: 2314\n","Epoch: [0]  [740/781]  eta: 0:00:20  lr: 0.000001  loss: 6.6446 (6.7632)  time: 0.5184  data: 0.2787  max mem: 2314\n","Epoch: [0]  [750/781]  eta: 0:00:15  lr: 0.000001  loss: 6.6477 (6.7616)  time: 0.4925  data: 0.2630  max mem: 2314\n","Epoch: [0]  [760/781]  eta: 0:00:10  lr: 0.000001  loss: 6.6343 (6.7599)  time: 0.5004  data: 0.2516  max mem: 2314\n","Epoch: [0]  [770/781]  eta: 0:00:05  lr: 0.000001  loss: 6.6403 (6.7584)  time: 0.4749  data: 0.2294  max mem: 2314\n","Epoch: [0]  [780/781]  eta: 0:00:00  lr: 0.000001  loss: 6.6457 (6.7570)  time: 0.3755  data: 0.1619  max mem: 2314\n","Epoch: [0] Total time: 0:06:29 (0.4988 s / it)\n","Averaged stats: lr: 0.000001  loss: 6.6457 (6.7570)\n","/content/deit/engine.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","Test:  [ 0/53]  eta: 0:03:00  loss: 6.4423 (6.4423)  acc1: 0.0000 (0.0000)  acc5: 4.1667 (4.1667)  time: 3.3963  data: 2.7488  max mem: 2314\n","Test:  [10/53]  eta: 0:00:25  loss: 6.5695 (6.5802)  acc1: 0.0000 (0.3314)  acc5: 0.0000 (3.5511)  time: 0.5900  data: 0.4641  max mem: 2314\n","Test:  [20/53]  eta: 0:00:17  loss: 6.5843 (6.5819)  acc1: 0.0000 (0.2232)  acc5: 0.0000 (2.4058)  time: 0.3890  data: 0.3140  max mem: 2314\n","Test:  [30/53]  eta: 0:00:11  loss: 6.5843 (6.5832)  acc1: 0.0000 (1.1257)  acc5: 0.0000 (4.0995)  time: 0.4829  data: 0.3998  max mem: 2314\n","Test:  [40/53]  eta: 0:00:06  loss: 6.5820 (6.5918)  acc1: 0.0000 (0.8765)  acc5: 0.0000 (3.6585)  time: 0.4898  data: 0.4071  max mem: 2314\n","Test:  [50/53]  eta: 0:00:01  loss: 6.5630 (6.5810)  acc1: 0.0000 (0.7455)  acc5: 0.0000 (3.7684)  time: 0.4013  data: 0.3258  max mem: 2314\n","Test:  [52/53]  eta: 0:00:00  loss: 6.5630 (6.5704)  acc1: 0.0000 (0.7300)  acc5: 0.0000 (3.6900)  time: 0.3412  data: 0.2674  max mem: 2314\n","Test: Total time: 0:00:24 (0.4595 s / it)\n","* Acc@1 0.730 Acc@5 3.690 loss 6.570\n","Accuracy of the network on the 10000 test images: 0.7%\n","Max accuracy: 0.73%\n","Training time 0:06:54\n"]}]},{"cell_type":"markdown","source":["# **Layer 2: Base Environment — Teacher Models & Multi-Teacher Adaptations**"],"metadata":{"id":"ck_VO0908kCj"}},{"cell_type":"markdown","source":["Layer 2 extends the baseline DeiT environment to support knowledge distillation from one or more teacher models. This layer is additive: it does not modify the baseline DeiT training loop unless explicitly stated.\n","It includes\n","1. Teacher Model Support (Single & Multiple)\n","2. Teacher Registry / Configuration\n","3. Multi-Teacher Fusion Mechanism (Adaptation Layer)\n","4. Distillation Loss Integration"],"metadata":{"id":"0ZO3MUL88nog"}}]}