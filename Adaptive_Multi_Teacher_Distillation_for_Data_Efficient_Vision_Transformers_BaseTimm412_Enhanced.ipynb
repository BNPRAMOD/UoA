{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 1: Baseline DeiT environment**"
      ],
      "metadata": {
        "id": "A814LG7i7w0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeiT’s baseline training script expects a teacher model name and distillation settings via CLI flags in main.py (e.g., --teacher-model, --teacher-path, --distillation-type).\n",
        "GitHub\n",
        "+1\n",
        "\n",
        "So the “base environment” Layer 1 must include:\n",
        "\n",
        "DeiT repo (cloned)\n",
        "\n",
        "PyTorch (Colab default) + GPU\n",
        "\n",
        "timm installed (for both student and teacher models)\n",
        "\n",
        "compatibility patches if any (because Colab uses new torch/timm)"
      ],
      "metadata": {
        "id": "yZ7gvhPl8OL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install PyTorch without pinning"
      ],
      "metadata": {
        "id": "25JXNJNx7v2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "OZgeujT4qBSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50665055-b729-4bd3-8c3b-250ab9d00fb1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "WWb1brNPqbEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uvYnPeqaBB",
        "outputId": "ad94dde1-99bd-403f-8b12-848e7155a641"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the baseline repo (official DeiT)"
      ],
      "metadata": {
        "id": "3awWPnZtp7E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aYSAUqVmQid",
        "outputId": "bba3247b-088a-40e7-d649-d3cb62ee77c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'deit'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Total 456 (delta 0), reused 0 (delta 0), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 5.73 MiB | 13.34 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n",
            "/content/deit\n",
            "1:torch==1.13.1\n",
            "2:torchvision==0.8.1\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "# Check if 'deit' folder exists → delete it\n",
        "!if [ -d \"deit\" ]; then rm -rf deit; fi\n",
        "\n",
        "!git clone https://github.com/facebookresearch/deit.git\n",
        "%cd /content/deit\n",
        "!grep -n \"torch\" -n requirements.txt || true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab Compatibility Fixes\n",
        "\n",
        "1. torch pin removal\n",
        "\n",
        "2. timm API changes\n",
        "\n",
        "3. kwargs popping (pretrained_cfg, cache_dir, etc.)\n",
        "\n"
      ],
      "metadata": {
        "id": "fVJsxhJv4Dwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch requirements.txt to remove torch pins"
      ],
      "metadata": {
        "id": "kHpCHaaDr1u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"requirements.txt\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "filtered = []\n",
        "removed = []\n",
        "for line in lines:\n",
        "    s = line.strip()\n",
        "    if s.startswith(\"torch==\") or s.startswith(\"torchvision==\") or s.startswith(\"torchaudio==\"):\n",
        "        removed.append(line)\n",
        "        continue\n",
        "    filtered.append(line)\n",
        "\n",
        "p.write_text(\"\\n\".join(filtered) + \"\\n\")\n",
        "print(\"✅ Removed these pinned lines:\")\n",
        "for r in removed:\n",
        "    print(\"  -\", r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3mRQRCcrLmU",
        "outputId": "5245ba37-54e5-4f52-ec4f-6c1b9307a35a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Removed these pinned lines:\n",
            "  - torch==1.13.1\n",
            "  - torchvision==0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Pins are gone!i.e torch==1.13.1 pin was removed"
      ],
      "metadata": {
        "id": "lyODjd5lsAqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -nE \"torch|torchvision|torchaudio\" requirements.txt || echo \"✅ No torch pins remain\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7QRJmf7rg6a",
        "outputId": "26598364-0230-4fab-bb92-884fd477e851"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No torch pins remain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the baseline dependencies"
      ],
      "metadata": {
        "id": "csYbu0BampB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"jedi>=0.16,<0.19\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNoLOzs5xUxa",
        "outputId": "680d1ea4-b6e8-4e9e-c764-cad3cf711a9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi<0.19,>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from jedi<0.19,>=0.16) (0.8.5)\n",
            "Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y timm\n",
        "!pip -q install \"jedi>=0.16,<0.19\"\n",
        "!pip -q install timm==0.6.13 submitit\n",
        "#!pip -q install timm==0.4.12 submitit\n"
      ],
      "metadata": {
        "id": "Xsc3-5Ab2Azw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "llX7-GOnsQQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import timm; print('timm:', timm.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG39iey7tfMQ",
        "outputId": "65a767cd-3cdb-4d3e-94e1-78f9ffff6b37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timm: 0.6.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart the Session**"
      ],
      "metadata": {
        "id": "r3tle6N46b7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "needle = \"OPENAI_CLIP_MEAN\"\n",
        "if needle in txt:\n",
        "    print(\"✅ timm.data already mentions OPENAI_CLIP_MEAN; no patch needed.\")\n",
        "else:\n",
        "    patch = \"\"\"\n",
        "\n",
        "# --- Colab patch: expose CLIP normalization constants for older exports ---\n",
        "try:\n",
        "    from .constants import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD  # timm versions where defined in constants\n",
        "except Exception:\n",
        "    # Standard OpenAI CLIP normalization\n",
        "    OPENAI_CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
        "    OPENAI_CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n",
        "# --- end patch ---\n",
        "\"\"\"\n",
        "    p.write_text(txt + patch)\n",
        "    print(\"✅ Patched:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEsR06SsuQa1",
        "outputId": "fb9d0b5b-1feb-490f-eaf3-08e0da5cd3ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched: /usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "from models import deit_tiny_patch16_224\n",
        "m = deit_tiny_patch16_224()\n",
        "print(\"✅ DeiT model instantiated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h97jFzzrupzp",
        "outputId": "1c9e528d-1821-48a4-b635-a52deb9902fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "✅ DeiT model instantiated successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, timm\n",
        "print(torch.__version__)\n",
        "print(timm.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37b1qcS72uJs",
        "outputId": "64dd339b-2b6c-4efb-a40b-038d948ddfd5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "0.6.13\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Tiny-ImageNet"
      ],
      "metadata": {
        "id": "uu-A5-G7vzTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IraDkD4vavm",
        "outputId": "b9994c60-ec69-49bf-efda-da8934e80363",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix Tiny-ImageNet validation folder"
      ],
      "metadata": {
        "id": "qlrZWkYCvyN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'EOF'\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"/content/tiny-imagenet-200\")\n",
        "val_dir = root/\"val\"\n",
        "img_dir = val_dir/\"images\"\n",
        "ann = val_dir/\"val_annotations.txt\"\n",
        "\n",
        "with ann.open(\"r\") as f:\n",
        "    for line in f:\n",
        "        img, cls = line.strip().split(\"\\t\")[:2]\n",
        "        (val_dir/cls).mkdir(parents=True, exist_ok=True)\n",
        "        src = img_dir/img\n",
        "        dst = val_dir/cls/img\n",
        "        if src.exists():\n",
        "            shutil.move(str(src), str(dst))\n",
        "\n",
        "if img_dir.exists():\n",
        "    shutil.rmtree(img_dir)\n",
        "\n",
        "print(\"✅ Tiny-ImageNet val reorganized into class subfolders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYzGeXJwSsy",
        "outputId": "3567dec6-c174-4e47-99b8-ce6bfeb7e082"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n",
            "✅ Tiny-ImageNet val reorganized into class subfolders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/tiny-imagenet-200/val -maxdepth 1 -type d | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bwwo30Qwi0V",
        "outputId": "a1e3c34d-7201-4d29-af8b-778a1f948855"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tiny-imagenet-200/val\n",
            "/content/tiny-imagenet-200/val/n03854065\n",
            "/content/tiny-imagenet-200/val/n02791270\n",
            "/content/tiny-imagenet-200/val/n01698640\n",
            "/content/tiny-imagenet-200/val/n03670208\n",
            "/content/tiny-imagenet-200/val/n04067472\n",
            "/content/tiny-imagenet-200/val/n02206856\n",
            "/content/tiny-imagenet-200/val/n02129165\n",
            "/content/tiny-imagenet-200/val/n02321529\n",
            "/content/tiny-imagenet-200/val/n02415577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/tiny-imagenet-200 | head"
      ],
      "metadata": {
        "id": "0e-EkPZf6GgG",
        "outputId": "630d397c-2fa9-485e-c88b-58cb5d60021a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.6M\n",
            "drwxrwxr-x   5 root root 4.0K Feb  9  2015 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x   1 root root 4.0K Feb 10 02:22 \u001b[01;34m..\u001b[0m/\n",
            "drwxrwxr-x   3 root root 4.0K Dec 12  2014 \u001b[01;34mtest\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Dec 12  2014 \u001b[01;34mtrain\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Feb 10 02:22 \u001b[01;34mval\u001b[0m/\n",
            "-rw-rw-r--   1 root root 2.0K Feb  9  2015 wnids.txt\n",
            "-rw-------   1 root root 2.6M Feb  9  2015 words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle timm incompatibilities. Although we can instantiate the model directly, the training script uses timm.create_model(), which injects metadata arguments such as pretrained_cfg and cache_dir.\n",
        "The original DeiT constructors do not support these arguments, so we remove them\n",
        "YOUR NOTEBOOK CALL\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224()          ✅ works (no kwargs)\n",
        "\n",
        "TRAINING PIPELINE\n",
        "    |\n",
        "    v\n",
        "timm.create_model()\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224(**kwargs)  ❌ injects extra keys\n"
      ],
      "metadata": {
        "id": "Rtyo7rkj3vLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch /content/deit/augment.py (safe compatibility fix)"
      ],
      "metadata": {
        "id": "mWebMtbWxHi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"augment.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "old = \"from timm.data.transforms import _pil_interp, RandomResizedCropAndInterpolation, ToNumpy, ToTensor\"\n",
        "if old in txt:\n",
        "    txt = txt.replace(\n",
        "        old,\n",
        "        \"from timm.data.transforms import RandomResizedCropAndInterpolation, ToNumpy, ToTensor\\n\"\n",
        "        \"try:\\n\"\n",
        "        \"    from timm.data.transforms import _pil_interp  # older timm\\n\"\n",
        "        \"except Exception:\\n\"\n",
        "        \"    _pil_interp = None  # newer timm doesn't expose this\\n\"\n",
        "    )\n",
        "    p.write_text(txt)\n",
        "    print(\"✅ Patched augment.py for timm compatibility.\")\n",
        "else:\n",
        "    print(\"ℹ️ Expected import line not found; augment.py may already be patched or different.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZwKyJqIxG2d",
        "outputId": "a504f11e-7420-4988-aef1-bf2492ce9d43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched augment.py for timm compatibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!rm -f multiteacher_loss.py\n",
        "!ls -l multiteacher_loss.py || echo \"✅ old file removed\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RizknqA6MBXb",
        "outputId": "9a472101-8a34-4c47-e21d-6a39416cdb42"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "ls: cannot access 'multiteacher_loss.py': No such file or directory\n",
            "✅ old file removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "code = r'''\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Dict, List, Optional\n",
        "import json\n",
        "from pathlib import Path as _Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def normalize_lambdas(lmb: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Normalize teacher weights so they sum to 1 (supports shape (T,) or (B,T)).\n",
        "    \"\"\"\n",
        "    if lmb.dim() == 1:\n",
        "        return lmb / lmb.sum().clamp_min(eps)\n",
        "    return lmb / lmb.sum(dim=-1, keepdim=True).clamp_min(eps)\n",
        "\n",
        "\n",
        "def fuse_logits(\n",
        "    teacher_logits: Dict[str, torch.Tensor],\n",
        "    teacher_order: List[str],\n",
        "    lambdas: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Weighted sum of teacher logits.\n",
        "    teacher_logits[k]: (B,C)\n",
        "    lambdas: (B,T) or (T,)\n",
        "    returns: (B,C)\n",
        "    \"\"\"\n",
        "    logits_list = [teacher_logits[k] for k in teacher_order]\n",
        "    stacked = torch.stack(logits_list, dim=1)  # (B,T,C)\n",
        "\n",
        "    lmb = normalize_lambdas(lambdas).to(stacked.device)\n",
        "    if lmb.dim() == 1:\n",
        "        lmb = lmb.unsqueeze(0).expand(stacked.size(0), -1)  # (B,T)\n",
        "\n",
        "    return (stacked * lmb.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "def kd_soft(student_logits: torch.Tensor, teacher_logits: torch.Tensor, T: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Standard KL-based soft distillation loss with temperature scaling.\n",
        "    \"\"\"\n",
        "    p_t = F.softmax(teacher_logits / T, dim=-1)\n",
        "    log_p_s = F.log_softmax(student_logits / T, dim=-1)\n",
        "    return F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T * T)\n",
        "\n",
        "\n",
        "def kd_hard(student_logits: torch.Tensor, teacher_logits: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Hard distillation: cross-entropy against teacher argmax.\n",
        "    \"\"\"\n",
        "    return F.cross_entropy(student_logits, teacher_logits.argmax(dim=-1))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teachers\n",
        "# -----------------------------\n",
        "class FrozenTeacherEnsemble(nn.Module):\n",
        "    \"\"\"\n",
        "    Loads a list of timm pretrained teachers and freezes them.\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_names: List[str], device: torch.device):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleDict(\n",
        "            {\n",
        "                name: timm.create_model(name, pretrained=True, num_classes=1000).eval().to(device)\n",
        "                for name in teacher_names\n",
        "            }\n",
        "        )\n",
        "        for m in self.models.values():\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad_(False)\n",
        "        self.teacher_order = list(self.models.keys())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        return {k: m(x) for k, m in self.models.items()}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teacher logits mapping: ImageNet-1k -> Tiny-ImageNet (wnid-aligned gather)\n",
        "# -----------------------------\n",
        "def build_tiny_imagenet_im1k_indices(\n",
        "    tiny_root: str,\n",
        "    class_index_json: str = \"/content/imagenet_class_index.json\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns a LongTensor of shape (200,) containing the ImageNet-1k class indices\n",
        "    corresponding to Tiny-ImageNet wnids.txt ordering.\n",
        "\n",
        "    Requires torchvision's imagenet_class_index.json (wnid->index via JSON).\n",
        "    \"\"\"\n",
        "    tiny_root_p = _Path(tiny_root)\n",
        "    wnids_path = tiny_root_p / \"wnids.txt\"\n",
        "    if not wnids_path.exists():\n",
        "        raise FileNotFoundError(f\"Could not find Tiny-ImageNet wnids.txt at: {wnids_path}\")\n",
        "\n",
        "    wnids = wnids_path.read_text().strip().splitlines()\n",
        "\n",
        "    class_index_path = _Path(class_index_json)\n",
        "    if not class_index_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing {class_index_json}. Download it before training.\\n\"\n",
        "            \"Example:\\n\"\n",
        "            \"  !wget -q https://raw.githubusercontent.com/pytorch/vision/main/torchvision/models/imagenet_class_index.json \"\n",
        "            f\"-O {class_index_json}\"\n",
        "        )\n",
        "\n",
        "    class_index = json.loads(class_index_path.read_text())\n",
        "    # class_index: {\"0\": [\"n01440764\", \"tench\"], ...}\n",
        "    wnid_to_idx = {v[0]: int(k) for k, v in class_index.items()}\n",
        "\n",
        "    indices: List[int] = []\n",
        "    missing: List[str] = []\n",
        "    for w in wnids:\n",
        "        if w in wnid_to_idx:\n",
        "            indices.append(wnid_to_idx[w])\n",
        "        else:\n",
        "            missing.append(w)\n",
        "\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            f\"{len(missing)} Tiny-ImageNet wnids were not found in ImageNet-1k mapping. \"\n",
        "            f\"First few missing: {missing[:10]}\"\n",
        "        )\n",
        "\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "\n",
        "class TeacherLogitMapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Maps ImageNet-1k teacher logits (B,1000) -> Tiny-ImageNet logits (B,200)\n",
        "    by selecting the 200 corresponding ImageNet indices (gather/index_select).\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_keys: List[str], im1k_indices: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.teacher_keys = list(teacher_keys)\n",
        "        self.register_buffer(\"im1k_indices\", im1k_indices)  # (200,)\n",
        "\n",
        "    def forward(self, teacher_logits: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        out: Dict[str, torch.Tensor] = {}\n",
        "        idx = self.im1k_indices\n",
        "        for k, v in teacher_logits.items():\n",
        "            # v: (B,1000) -> (B,200)\n",
        "            out[k] = v.index_select(dim=-1, index=idx)\n",
        "        return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# HDTSE confidence weighting\n",
        "# -----------------------------\n",
        "class HDTSEConfidence(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes per-sample teacher weights based on each teacher's confidence\n",
        "    on the (possibly soft) targets.\n",
        "    \"\"\"\n",
        "    def __init__(self, temp: float = 1.0):\n",
        "        super().__init__()\n",
        "        self.temp = float(temp)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(\n",
        "        self,\n",
        "        teacher_logits: Dict[str, torch.Tensor],\n",
        "        teacher_order: List[str],\n",
        "        targets: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        stacked = torch.stack([teacher_logits[k] for k in teacher_order], dim=1)  # (B,T,C)\n",
        "        probs = F.softmax(stacked / self.temp, dim=-1)  # (B,T,C)\n",
        "\n",
        "        # Hard labels: (B,)\n",
        "        if targets.dim() == 1:\n",
        "            idx = targets.to(dtype=torch.long, device=probs.device)\n",
        "            conf = probs.gather(-1, idx[:, None, None]).squeeze(-1)  # (B,T)\n",
        "            return normalize_lambdas(conf)\n",
        "\n",
        "        # Soft labels (mixup/cutmix): (B,C)\n",
        "        tgt = targets.to(dtype=probs.dtype, device=probs.device)\n",
        "        conf = (probs * tgt[:, None, :]).sum(dim=-1)  # (B,T)\n",
        "        return normalize_lambdas(conf)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Multi-teacher distillation loss\n",
        "# -----------------------------\n",
        "class MultiTeacherDistillationLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_criterion,\n",
        "        student_num_classes: int,\n",
        "        teacher_names: List[str],\n",
        "        distillation_type: str = \"soft\",\n",
        "        alpha: float = 0.5,\n",
        "        tau: float = 2.0,\n",
        "        device=None,\n",
        "        use_adapter: bool = True,\n",
        "        hdtse_warmup_epochs: int = 0,\n",
        "        lambda_log: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        base_criterion: supervised loss (CE or soft-target CE when mixup is enabled)\n",
        "        distillation_type: \"soft\" or \"hard\"\n",
        "        alpha: final KD weight\n",
        "        tau: KD temperature\n",
        "        use_adapter: if True, expects Tiny-ImageNet mapping via set_tiny_root() before training\n",
        "        hdtse_warmup_epochs: use uniform lambdas until this epoch (exclusive)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.base_criterion = base_criterion\n",
        "        self.distillation_type = str(distillation_type)\n",
        "        self.tau = float(tau)\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # teachers (frozen)\n",
        "        self.teachers = FrozenTeacherEnsemble(teacher_names, self.device)\n",
        "        self.teacher_order = list(self.teachers.teacher_order)\n",
        "\n",
        "        # teacher->student class mapping (ImageNet-1k -> dataset classes)\n",
        "        self.use_adapter = bool(use_adapter)\n",
        "        self.adapter: Optional[nn.Module] = None  # created by set_tiny_root()\n",
        "\n",
        "        # HDTSE teacher weighting\n",
        "        self.hdtse = HDTSEConfidence()\n",
        "\n",
        "        # epoch state\n",
        "        self.epoch: int = 0\n",
        "        self.hdtse_warmup_epochs = int(hdtse_warmup_epochs)\n",
        "\n",
        "        # alpha schedule (KD weight ramp)\n",
        "        self.alpha_final = float(alpha)\n",
        "        self.alpha_start = 0.0\n",
        "        self.alpha_ramp_epochs = 20  # default ramp duration\n",
        "\n",
        "        # lambda logging (epoch-level)\n",
        "        self.lambda_log = bool(lambda_log)\n",
        "        self._lambda_sum = torch.zeros(len(self.teacher_order), dtype=torch.float32)\n",
        "        self._lambda_count = 0\n",
        "\n",
        "    # ---- Public setters ----\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self.epoch = int(epoch)\n",
        "\n",
        "    def set_alpha_schedule(self, alpha_start: float = 0.0, alpha_ramp_epochs: int = 20):\n",
        "        self.alpha_start = float(alpha_start)\n",
        "        self.alpha_ramp_epochs = int(alpha_ramp_epochs)\n",
        "\n",
        "    def set_tiny_root(self, tiny_root: str, class_index_json: str = \"/content/imagenet_class_index.json\"):\n",
        "        \"\"\"\n",
        "        Call once (from main.py) after constructing this loss, before training starts.\n",
        "        Creates the gather-based teacher logits mapper: (B,1000)->(B,C).\n",
        "        \"\"\"\n",
        "        im1k_indices = build_tiny_imagenet_im1k_indices(tiny_root, class_index_json=class_index_json).to(self.device)\n",
        "        self.adapter = TeacherLogitMapper(self.teacher_order, im1k_indices).to(self.device)\n",
        "\n",
        "    # ---- Logging ----\n",
        "    def pop_lambda_stats(self) -> Optional[Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Returns mean λ per teacher over the epoch, then resets accumulators.\n",
        "        Call once per epoch from main.py.\n",
        "        \"\"\"\n",
        "        if self._lambda_count <= 0:\n",
        "            return None\n",
        "\n",
        "        mean_lmb = (self._lambda_sum / float(self._lambda_count)).tolist()\n",
        "        out = {f\"lambda_{name}\": float(v) for name, v in zip(self.teacher_order, mean_lmb)}\n",
        "\n",
        "        self._lambda_sum.zero_()\n",
        "        self._lambda_count = 0\n",
        "        return out\n",
        "\n",
        "    # ---- Internals ----\n",
        "    def _uniform_lambdas(self, batch_size: int, device: torch.device) -> torch.Tensor:\n",
        "        t = len(self.teacher_order)\n",
        "        return torch.full((batch_size, t), 1.0 / t, device=device, dtype=torch.float32)\n",
        "\n",
        "    def _alpha_effective(self) -> float:\n",
        "        if self.alpha_ramp_epochs <= 0:\n",
        "            return self.alpha_final\n",
        "        t = min(1.0, float(self.epoch) / float(self.alpha_ramp_epochs))\n",
        "        return self.alpha_start + t * (self.alpha_final - self.alpha_start)\n",
        "\n",
        "    # ---- Forward ----\n",
        "    def forward(self, inputs: torch.Tensor, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        inputs: images (B,3,H,W)\n",
        "        outputs: student logits (B,C)\n",
        "        targets: hard labels (B,) or soft labels (B,C) when mixup/cutmix is enabled\n",
        "        \"\"\"\n",
        "        base_loss = self.base_criterion(outputs, targets)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_logits = self.teachers(inputs)  # dict: teacher -> (B,1000)\n",
        "\n",
        "        student_C = outputs.shape[-1]\n",
        "        any_teacher = next(iter(t_logits.values()))\n",
        "        teacher_C = any_teacher.shape[-1]\n",
        "\n",
        "        if teacher_C != student_C:\n",
        "            if self.adapter is None:\n",
        "                raise RuntimeError(\n",
        "                f\"Teacher logits have {teacher_C} classes but student has {student_C}. \"\n",
        "                \"Adapter not initialized. Call criterion.set_tiny_root(args.data_path).\"\n",
        "            )\n",
        "            t_logits = self.adapter(t_logits)  # dict: teacher -> (B,student_C)\n",
        "\n",
        "        # ---- Teacher weights (λ) ----\n",
        "        if self.epoch < self.hdtse_warmup_epochs:\n",
        "            lambdas = self._uniform_lambdas(outputs.size(0), outputs.device)  # (B,T)\n",
        "        else:\n",
        "            lambdas = self.hdtse(t_logits, self.teacher_order, targets)  # (B,T)\n",
        "\n",
        "        # ---- λ logging ----\n",
        "        if self.lambda_log:\n",
        "            batch_mean = lambdas.detach().mean(dim=0).cpu()  # (T,)\n",
        "            self._lambda_sum += batch_mean * outputs.size(0)\n",
        "            self._lambda_count += outputs.size(0)\n",
        "\n",
        "        fused = fuse_logits(t_logits, self.teacher_order, lambdas)  # (B,C)\n",
        "\n",
        "        kd = kd_soft(outputs, fused, self.tau) if self.distillation_type == \"soft\" else kd_hard(outputs, fused)\n",
        "\n",
        "        alpha_eff = self._alpha_effective()\n",
        "        return (1.0 - alpha_eff) * base_loss + alpha_eff * kd\n",
        "'''\n",
        "\n",
        "path = Path(\"multiteacher_loss.py\")\n",
        "path.write_text(code)\n",
        "\n",
        "print(\"File written:\", path)\n",
        "print(\"File size (bytes):\", path.stat().st_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k4jzkzbMHD-",
        "outputId": "9f2e9703-3207-47a9-c09d-8c7c0a10fc34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "File written: multiteacher_loss.py\n",
            "File size (bytes): 11996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re, py_compile\n",
        "\n",
        "MAIN = Path(\"/content/deit/main.py\")\n",
        "txt = MAIN.read_text()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helpers (line-safe insertions to avoid indentation/newline bugs)\n",
        "# ------------------------------------------------------------\n",
        "def fix_broken_import_concatenation():\n",
        "    global txt\n",
        "    # Fix exact failure mode:\n",
        "    txt = txt.replace(\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLossfrom samplers import RASampler\",\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLoss\\nfrom samplers import RASampler\"\n",
        "    )\n",
        "\n",
        "def ensure_line_after(match_line_regex: str, new_line: str):\n",
        "    \"\"\"Insert `new_line` as a full line right AFTER the first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if new_line.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)  # keep line endings\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            # insert after this line\n",
        "            if not new_line.endswith(\"\\n\"):\n",
        "                new_line2 = new_line + \"\\n\"\n",
        "            else:\n",
        "                new_line2 = new_line\n",
        "            lines.insert(i + 1, new_line2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert after: {match_line_regex}\")\n",
        "\n",
        "def ensure_block_after_line(match_line_regex: str, block: str):\n",
        "    \"\"\"Insert a multi-line block after first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    # Heuristic: if first unique token already exists, don't re-add\n",
        "    if \"--teacher-models\" in block and \"--teacher-models\" in txt and \"--hdtse-warmup-epochs\" in txt and \"--lambda-log\" in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            if not block.endswith(\"\\n\"):\n",
        "                block2 = block + \"\\n\"\n",
        "            else:\n",
        "                block2 = block\n",
        "            lines.insert(i + 1, block2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert block after: {match_line_regex}\")\n",
        "\n",
        "def replace_first(pattern: str, repl: str, flags=re.DOTALL):\n",
        "    global txt\n",
        "    m = re.search(pattern, txt, flags)\n",
        "    if not m:\n",
        "        return False\n",
        "    txt = txt[:m.start()] + repl + txt[m.end():]\n",
        "    return True\n",
        "\n",
        "def remove_first_line_matching(line_regex: str):\n",
        "    global txt\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(line_regex, line):\n",
        "            del lines[i]\n",
        "            txt = \"\".join(lines)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Repair if prior patch created the exact SyntaxError\n",
        "# ------------------------------------------------------------\n",
        "fix_broken_import_concatenation()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Ensure MultiTeacherDistillationLoss import (safe line insertion)\n",
        "# Insert after: from losses import DistillationLoss\n",
        "# ------------------------------------------------------------\n",
        "ensure_line_after(\n",
        "    r\"^\\s*from\\s+losses\\s+import\\s+DistillationLoss\\s*$\",\n",
        "    \"from multiteacher_loss import MultiTeacherDistillationLoss\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Ensure CLI args after --teacher-path\n",
        "# ------------------------------------------------------------\n",
        "cli_block = \"\"\"\\\n",
        "    parser.add_argument('--teacher-models', type=str, default='',\n",
        "                        help='Comma-separated timm model names for multi-teacher distillation')\n",
        "    parser.add_argument('--hdtse-warmup-epochs', type=int, default=0,\n",
        "                        help='Use uniform teacher weights for first N epochs, then enable HDTSE weighting')\n",
        "    parser.add_argument('--lambda-log', action='store_true', default=False,\n",
        "                        help='Log mean λ (teacher weights) each epoch for multi-teacher distillation')\n",
        "\"\"\"\n",
        "ensure_block_after_line(r\"^\\s*parser\\.add_argument\\('--teacher-path'\", cli_block)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Allow finetune + distillation ONLY when multi-teacher is used\n",
        "# Base guard is:\n",
        "# if args.distillation_type != 'none' and args.finetune and not args.eval:\n",
        "#     raise NotImplementedError(...)\n",
        "# ------------------------------------------------------------\n",
        "replace_first(\n",
        "    r\"^\\s*if\\s+args\\.distillation_type\\s*!=\\s*'none'\\s+and\\s+args\\.finetune\\s+and\\s+not\\s+args\\.eval\\s*:\\s*\\n\\s*raise\\s+NotImplementedError\\([^\\n]*\\)\\s*$\",\n",
        "    \"    if args.distillation_type != 'none' and args.finetune and not args.eval and not getattr(args, 'teacher_models', ''):\\n\"\n",
        "    \"        raise NotImplementedError(\\\"Finetuning with distillation not yet supported (single-teacher path)\\\")\\n\",\n",
        "    flags=re.MULTILINE\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Move scheduler creation to AFTER adapter param-group add:\n",
        "# Remove early: lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "# ------------------------------------------------------------\n",
        "remove_first_line_matching(r\"^\\s*lr_scheduler,\\s*_\\s*=\\s*create_scheduler\\(\\s*args\\s*,\\s*optimizer\\s*\\)\\s*$\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Unify distillation region (multi-teacher vs single-teacher)\n",
        "# We'll replace from \"teacher_model = None\" up to \"output_dir = Path(args.output_dir)\"\n",
        "# This avoids indentation mistakes and prevents teacher_path='' crash.\n",
        "# ------------------------------------------------------------\n",
        "m_start = re.search(r\"^\\s*teacher_model\\s*=\\s*None\\s*$\", txt, flags=re.MULTILINE)\n",
        "m_end   = re.search(r\"^\\s*output_dir\\s*=\\s*Path\\(args\\.output_dir\\)\\s*$\", txt, flags=re.MULTILINE)\n",
        "if not (m_start and m_end and m_start.start() < m_end.start()):\n",
        "    raise RuntimeError(\"Could not locate distillation region anchors (teacher_model=None ... output_dir=Path(...))\")\n",
        "\n",
        "unified = \"\"\"\\\n",
        "    teacher_model = None\n",
        "\n",
        "    # -------------------------------\n",
        "    # Unified single + multi-teacher distillation\n",
        "    # -------------------------------\n",
        "    teacher_models_str = getattr(args, 'teacher_models', '').strip()\n",
        "\n",
        "    if args.distillation_type != 'none' and teacher_models_str:\n",
        "        teacher_names = [t.strip() for t in teacher_models_str.split(',') if t.strip()]\n",
        "        print(f\"✅ Multi-teacher distillation enabled. Teachers: {teacher_names}\")\n",
        "\n",
        "        criterion = MultiTeacherDistillationLoss(\n",
        "            base_criterion=criterion,\n",
        "            student_num_classes=args.nb_classes,\n",
        "            teacher_names=teacher_names,\n",
        "            distillation_type=args.distillation_type,\n",
        "            alpha=args.distillation_alpha,\n",
        "            tau=args.distillation_tau,\n",
        "            device=device,\n",
        "            use_adapter=True,\n",
        "            hdtse_warmup_epochs=getattr(args, 'hdtse_warmup_epochs', 0),\n",
        "            lambda_log=getattr(args, 'lambda_log', False),\n",
        "        )\n",
        "\n",
        "        # Initialize Tiny-ImageNet wnid -> ImageNet-1k index mapping for teacher logits\n",
        "        if hasattr(criterion, \"set_tiny_root\"):\n",
        "            criterion.set_tiny_root(args.data_path)\n",
        "\n",
        "        # Optional: alpha ramp if you add args later\n",
        "        if hasattr(criterion, \"set_alpha_schedule\") and hasattr(args, \"alpha_ramp_epochs\"):\n",
        "            criterion.set_alpha_schedule(\n",
        "                alpha_start=getattr(args, \"alpha_start\", 0.0),\n",
        "                alpha_ramp_epochs=getattr(args, \"alpha_ramp_epochs\", 20),\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        if args.distillation_type != 'none':\n",
        "            assert args.teacher_path, 'need to specify teacher-path when using single-teacher distillation'\n",
        "            print(f\"Creating teacher model: {args.teacher_model}\")\n",
        "            teacher_model = create_model(\n",
        "                args.teacher_model,\n",
        "                pretrained=False,\n",
        "                num_classes=args.nb_classes,\n",
        "                global_pool='avg',\n",
        "            )\n",
        "            if args.teacher_path.startswith('https'):\n",
        "                checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                    args.teacher_path, map_location='cpu', check_hash=True)\n",
        "            else:\n",
        "                checkpoint = torch.load(args.teacher_path, map_location='cpu')\n",
        "            teacher_model.load_state_dict(checkpoint['model'])\n",
        "            teacher_model.to(device)\n",
        "            teacher_model.eval()\n",
        "\n",
        "        criterion = DistillationLoss(\n",
        "            criterion, teacher_model, args.distillation_type, args.distillation_alpha, args.distillation_tau\n",
        "        )\n",
        "\n",
        "    # Scheduler must be created AFTER all optimizer param groups are finalized\n",
        "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "\"\"\"\n",
        "\n",
        "txt = txt[:m_start.start()] + unified + \"\\n    output_dir = Path(args.output_dir)\\n\" + txt[m_end.end():]\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Ensure loss call uses (samples, outputs, targets)\n",
        "# ----------------------------\n",
        "# Patch ONLY the simple 2-arg form if present.\n",
        "if \"criterion(samples, outputs, targets)\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"loss\\s*=\\s*criterion\\(\\s*outputs\\s*,\\s*targets\\s*\\)\",\n",
        "        r\"loss = criterion(samples, outputs, targets)\",\n",
        "        txt\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Insert criterion.set_epoch(epoch) before train_one_epoch\n",
        "# We add it inside the epoch loop, after sampler.set_epoch if present.\n",
        "# ------------------------------------------------------------\n",
        "if \"criterion.set_epoch(epoch)\" not in txt:\n",
        "    # If distributed block exists, insert after it\n",
        "    if re.search(r\"^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$\", txt, flags=re.MULTILINE):\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "    else:\n",
        "        # Otherwise put at top of loop\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*for\\s+epoch\\s+in\\s+range\\(args\\.start_epoch,\\s*args\\.epochs\\)\\s*:\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Per-epoch λ logging after train_one_epoch call\n",
        "# ------------------------------------------------------------\n",
        "if \"print('λ means:'\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"(train_stats\\s*=\\s*train_one_epoch\\([\\s\\S]*?\\)\\s*)\\n\",\n",
        "        r\"\\1\\n\\n\"\n",
        "        r\"        # Optional: log mean λ per teacher (multi-teacher only)\\n\"\n",
        "        r\"        if getattr(args, 'lambda_log', False) and hasattr(criterion, 'pop_lambda_stats'):\\n\"\n",
        "        r\"            lambda_means = criterion.pop_lambda_stats()\\n\"\n",
        "        r\"            if lambda_means:\\n\"\n",
        "        r\"                print('λ means:', lambda_means)\\n\",\n",
        "        txt,\n",
        "        count=1\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Write + compile check\n",
        "# ------------------------------------------------------------\n",
        "MAIN.write_text(txt)\n",
        "py_compile.compile(str(MAIN), doraise=True)\n",
        "print(\"✅ Patched main.py written and compiles:\", MAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUdJZ4F-NoE-",
        "outputId": "214aa364-4a21-45df-d378-5016b9517fd8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched main.py written and compiles: /content/deit/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidated patcher for /content/deit/main.py\n",
        "# Adds: Cosine α schedule CLI args + per-epoch α update (works for DistillationLoss + MultiTeacherDistillationLoss)\n",
        "#\n",
        "# Base file reference (as you shared): :contentReference[oaicite:0]{index=0}\n",
        "\n",
        "from pathlib import Path\n",
        "import re, py_compile\n",
        "\n",
        "MAIN = Path(\"/content/deit/main.py\")\n",
        "txt = MAIN.read_text()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helpers (line-safe insertions to avoid indentation/newline bugs)\n",
        "# ------------------------------------------------------------\n",
        "def ensure_import(module_name: str):\n",
        "    \"\"\"Ensure `import <module_name>` exists near the top-level imports.\"\"\"\n",
        "    global txt\n",
        "    pat = rf\"^\\s*import\\s+{re.escape(module_name)}\\s*$\"\n",
        "    if re.search(pat, txt, flags=re.MULTILINE):\n",
        "        return\n",
        "    # Insert after \"import time\" if present, else after argparse\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r\"^\\s*import\\s+time\\s*$\", line):\n",
        "            lines.insert(i + 1, f\"import {module_name}\\n\")\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r\"^\\s*import\\s+argparse\\s*$\", line):\n",
        "            lines.insert(i + 1, f\"import {module_name}\\n\")\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    # fallback: very top\n",
        "    txt = f\"import {module_name}\\n\" + txt\n",
        "\n",
        "def ensure_line_after(match_line_regex: str, new_line: str):\n",
        "    \"\"\"Insert `new_line` as a full line RIGHT AFTER the first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if new_line.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            lines.insert(i + 1, (new_line if new_line.endswith(\"\\n\") else new_line + \"\\n\"))\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert after: {match_line_regex}\")\n",
        "\n",
        "def ensure_block_after_line(match_line_regex: str, block: str, unique_guard: str = None):\n",
        "    \"\"\"Insert a multi-line block after first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if unique_guard and unique_guard in txt:\n",
        "        return\n",
        "    if (not unique_guard) and block.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            lines.insert(i + 1, (block if block.endswith(\"\\n\") else block + \"\\n\"))\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert block after: {match_line_regex}\")\n",
        "\n",
        "def replace_first(pattern: str, repl: str, flags=re.DOTALL):\n",
        "    global txt\n",
        "    m = re.search(pattern, txt, flags)\n",
        "    if not m:\n",
        "        return False\n",
        "    txt = txt[:m.start()] + repl + txt[m.end():]\n",
        "    return True\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Ensure `import math` (needed for cosine schedule)\n",
        "# ------------------------------------------------------------\n",
        "ensure_import(\"math\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Add CLI args for alpha scheduling (after distillation params)\n",
        "#    Insert right after: parser.add_argument('--distillation-tau' ...)\n",
        "# ------------------------------------------------------------\n",
        "alpha_cli_block = \"\"\"\\\n",
        "    # ---- Distillation alpha scheduling (epoch-level) ----\n",
        "    parser.add_argument('--alpha-schedule', default='none',\n",
        "                        choices=['none', 'cosine'],\n",
        "                        type=str, help=\"Schedule distillation alpha across epochs.\")\n",
        "    parser.add_argument('--alpha-start', default=0.05, type=float,\n",
        "                        help=\"Starting alpha for alpha schedule (ignored if alpha-schedule=none).\")\n",
        "    parser.add_argument('--alpha-end', default=0.7, type=float,\n",
        "                        help=\"Final alpha for alpha schedule (ignored if alpha-schedule=none).\")\n",
        "\"\"\"\n",
        "ensure_block_after_line(\n",
        "    r\"^\\s*parser\\.add_argument\\('--distillation-tau'.*\\)\\s*$\",\n",
        "    alpha_cli_block,\n",
        "    unique_guard=\"--alpha-schedule\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Add helper function for cosine schedule (module-level, before main())\n",
        "#    Insert right after get_args_parser() returns `parser`\n",
        "# ------------------------------------------------------------\n",
        "alpha_fn_block = \"\"\"\\\n",
        "\n",
        "def _cosine_alpha(epoch: int, total_epochs: int, alpha_start: float, alpha_end: float) -> float:\n",
        "    # Smoothly increases alpha from alpha_start to alpha_end over training.\n",
        "    total_epochs = int(total_epochs)\n",
        "    if total_epochs <= 1:\n",
        "        return alpha_end\n",
        "\n",
        "    progress = float(epoch) / float(total_epochs-1)\n",
        "    progress = min(max(progress, 0.0), 1.0)\n",
        "    cosine = 0.5 * (1.0 - math.cos(math.pi * progress))\n",
        "    return alpha_start + cosine * (alpha_end - alpha_start)\n",
        "\"\"\"\n",
        "# Insert after the \"return parser\" line inside get_args_parser()\n",
        "ensure_block_after_line(\n",
        "    r\"^\\s*return\\s+parser\\s*$\",\n",
        "    alpha_fn_block,\n",
        "    unique_guard=\"def _cosine_alpha\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Update α each epoch BEFORE train_one_epoch call, and push into criterion\n",
        "#    Key detail: DistillationLoss() captures alpha at init in this base main.py,\n",
        "#    so we must update criterion.alpha (or criterion.set_alpha) per epoch.\n",
        "# ------------------------------------------------------------\n",
        "epoch_hook_block = \"\"\"\\\n",
        "        # ---- Cosine α schedule (distillation weight) ----\n",
        "        if args.distillation_type != 'none' and getattr(args, 'alpha_schedule', 'none') == 'cosine':\n",
        "            args.distillation_alpha = _cosine_alpha(\n",
        "                epoch=epoch,\n",
        "                total_epochs=args.epochs,\n",
        "                alpha_start=getattr(args, 'alpha_start', 0.05),\n",
        "                alpha_end=getattr(args, 'alpha_end', 0.7),\n",
        "            )\n",
        "            # Propagate into the actual loss wrapper (DistillationLoss / MultiTeacherDistillationLoss)\n",
        "            if hasattr(criterion, \"alpha\"):\n",
        "                criterion.alpha = args.distillation_alpha\n",
        "            elif hasattr(criterion, \"set_alpha\"):\n",
        "                criterion.set_alpha(args.distillation_alpha)\n",
        "\n",
        "            if (not getattr(args, \"distributed\", False)) or getattr(args, \"rank\", 0) == 0:\n",
        "                print(f\"[alpha-schedule=cosine] epoch={epoch} distillation_alpha={args.distillation_alpha:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "# Insert this block after the distributed sampler epoch set (if present),\n",
        "# otherwise right after the for-loop line.\n",
        "if \"alpha-schedule=cosine\" not in txt:\n",
        "    # Case A: distributed sampler.set_epoch exists\n",
        "    if re.search(\n",
        "        r\"^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$\",\n",
        "        txt,\n",
        "        flags=re.MULTILINE\n",
        "    ):\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$)\",\n",
        "            r\"\\1\\n\\n\" + epoch_hook_block.rstrip(\"\\n\"),\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "    else:\n",
        "        # Case B: no distributed stanza → insert at top of loop\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*for\\s+epoch\\s+in\\s+range\\(args\\.start_epoch,\\s*args\\.epochs\\)\\s*:\\s*$)\",\n",
        "            r\"\\1\\n\" + epoch_hook_block.rstrip(\"\\n\"),\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Write + compile check\n",
        "# ------------------------------------------------------------\n",
        "MAIN.write_text(txt)\n",
        "py_compile.compile(str(MAIN), doraise=True)\n",
        "print(\"✅ Patched main.py written and compiles:\", MAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcHzSlpfe-Ap",
        "outputId": "721a12af-481a-44a9-ea09-f9eacff668e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched main.py written and compiles: /content/deit/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before constructing the model, remove those keys from kwargs"
      ],
      "metadata": {
        "id": "4sFpztpw00XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    if line.strip().startswith(\"def deit_\") and \"**kwargs\" in line:\n",
        "        out.append(\"    # Drop timm-injected kwargs not supported by DeiT\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_overlay', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_priority', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ models.py patched to drop pretrained_cfg kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1qywwxV0RS-",
        "outputId": "26059395-35a9-4548-9fc8-018ecfe71bea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ models.py patched to drop pretrained_cfg kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "Yh47-0Pv0-R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix: Patch /content/deit/models.py to drop pretrained_cfg=..."
      ],
      "metadata": {
        "id": "hfueTM11xy00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch models.py to also drop cache_dir (and friends)"
      ],
      "metadata": {
        "id": "OK2GsetX1ZkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "# Keys that timm may inject but DeiT constructors don't accept\n",
        "DROP_KEYS = [\n",
        "    \"cache_dir\",\n",
        "    \"hf_hub_id\",\n",
        "    \"hf_hub_filename\",\n",
        "    \"hf_hub_revision\",\n",
        "]\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    # Right after the comment line we previously inserted, add more pops once per function\n",
        "    if line.strip() == \"# Drop timm-injected kwargs not supported by DeiT\":\n",
        "        for k in DROP_KEYS:\n",
        "            out.append(f\"    kwargs.pop('{k}', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ Patched models.py to drop cache_dir/hf_hub* kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0-XJmyw1aed",
        "outputId": "dc840bca-7a7c-4b10-fefa-5faba7a43ef6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched models.py to drop cache_dir/hf_hub* kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/imagenet_class_index.json\n",
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json \\\n",
        "  -O /content/imagenet_class_index.json\n",
        "\n",
        "!python - <<'PY'\n",
        "import json\n",
        "p=\"/content/imagenet_class_index.json\"\n",
        "with open(p,\"r\",encoding=\"utf-8\") as f:\n",
        "    obj=json.load(f)\n",
        "print(\"Loaded OK. Entries:\", len(obj))\n",
        "print(\"Example 0:\", obj[\"0\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAeUxFOQMFrE",
        "outputId": "aa5ef694-b554-4275-8554-afa65e5ced28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-10 02:22:40--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.207.235, 54.231.234.208, 3.5.8.206, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.207.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/octet-stream]\n",
            "Saving to: ‘/content/imagenet_class_index.json’\n",
            "\n",
            "/content/imagenet_c 100%[===================>]  34.53K   160KB/s    in 0.2s    \n",
            "\n",
            "2026-02-10 02:22:42 (160 KB/s) - ‘/content/imagenet_class_index.json’ saved [35363/35363]\n",
            "\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "Loaded OK. Entries: 1000\n",
            "Example 0: ['n01440764', 'tench']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --pretrained \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 64 \\\n",
        "#   --num_workers 2 \\\n",
        "#   --output_dir /content/deit_runs/smoke_test\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 128 \\\n",
        "#   --num_workers 4 \\\n",
        "#   --input-size 224 \\\n",
        "#   --opt adamw \\\n",
        "#   --lr 5e-4 \\\n",
        "#   --weight-decay 0.05 \\\n",
        "#   --sched cosine \\\n",
        "#   --aa rand-m9-mstd0.5 \\\n",
        "#   --reprob 0.25 \\\n",
        "#   --remode pixel \\\n",
        "#   --recount 1 \\\n",
        "#   --output_dir /content/deit_runs/tiny_imagenet\n",
        "### correct one\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 3e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_5ep\n",
        "%cd /content/deit\n",
        "!python main.py \\\n",
        " --model deit_tiny_patch16_224 \\\n",
        " --data-path /content/tiny-imagenet-200 \\\n",
        " --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        " --epochs 120 \\\n",
        " --batch-size 128 \\\n",
        " --num_workers 4 \\\n",
        " --input-size 224 \\\n",
        " --opt adamw \\\n",
        " --lr 2.5e-4 \\\n",
        " --weight-decay 0.05 \\\n",
        " --sched cosine \\\n",
        " --warmup-epochs 4 \\\n",
        " --smoothing 0.1 \\\n",
        " --aa rand-m6-mstd0.5 \\\n",
        " --reprob 0.2 \\\n",
        " --model-ema \\\n",
        " --model-ema-decay 0.9999 \\\n",
        " --drop-path 0.05 \\\n",
        " --mixup 0.2 \\\n",
        " --cutmix 0.0 \\\n",
        " --mixup-prob 0.5 \\\n",
        " --distillation-type soft \\\n",
        " --alpha-schedule cosine --alpha-start 0.1 --alpha-end 0.6 \\\n",
        " --distillation-alpha 0.5 \\\n",
        " --distillation-tau 3.5 \\\n",
        " --hdtse-warmup-epochs 8 \\\n",
        " --lambda-log \\\n",
        " --output_dir /content/deit_runs/tiny_imagenet \\\n",
        " --teacher-models \"swin_base_patch4_window7_224,convnext_base,tf_efficientnetv2_l\"\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 2.5e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --distillation-type hard \\\n",
        "# --teacher-model regnety_160 \\\n",
        "# --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_10ep\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_distilled_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 7e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.0 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.0 \\\n",
        "#  --distillation-type hard \\\n",
        "#  --distillation-alpha 0.7 \\\n",
        "#  --teacher-model regnety_160 \\\n",
        "#  --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/deit_tiny_distilled_10ep\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TYvrcwJwlde",
        "outputId": "970f2ee8-9d29-4732-f289-9d8eb67d908d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [53]  [570/781]  eta: 0:01:10  lr: 0.000042  loss: 1.4762 (1.6044)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [580/781]  eta: 0:01:07  lr: 0.000042  loss: 1.4328 (1.6004)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [590/781]  eta: 0:01:03  lr: 0.000042  loss: 1.4626 (1.6019)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [600/781]  eta: 0:01:00  lr: 0.000042  loss: 1.5058 (1.6018)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [610/781]  eta: 0:00:57  lr: 0.000042  loss: 1.4106 (1.6006)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [620/781]  eta: 0:00:53  lr: 0.000042  loss: 1.4151 (1.6009)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [630/781]  eta: 0:00:50  lr: 0.000042  loss: 1.4908 (1.6039)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [640/781]  eta: 0:00:47  lr: 0.000042  loss: 1.4449 (1.6058)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [650/781]  eta: 0:00:43  lr: 0.000042  loss: 1.4274 (1.6078)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [660/781]  eta: 0:00:40  lr: 0.000042  loss: 1.3913 (1.6078)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [670/781]  eta: 0:00:37  lr: 0.000042  loss: 1.4123 (1.6086)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [680/781]  eta: 0:00:33  lr: 0.000042  loss: 1.4961 (1.6096)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [690/781]  eta: 0:00:30  lr: 0.000042  loss: 1.4240 (1.6074)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [700/781]  eta: 0:00:27  lr: 0.000042  loss: 1.4240 (1.6084)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [710/781]  eta: 0:00:23  lr: 0.000042  loss: 1.4787 (1.6121)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [720/781]  eta: 0:00:20  lr: 0.000042  loss: 1.5237 (1.6122)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [730/781]  eta: 0:00:17  lr: 0.000042  loss: 1.4824 (1.6141)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [740/781]  eta: 0:00:13  lr: 0.000042  loss: 1.4324 (1.6129)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [750/781]  eta: 0:00:10  lr: 0.000042  loss: 1.4324 (1.6135)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [760/781]  eta: 0:00:07  lr: 0.000042  loss: 1.4250 (1.6134)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [770/781]  eta: 0:00:03  lr: 0.000042  loss: 1.4116 (1.6111)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [780/781]  eta: 0:00:00  lr: 0.000042  loss: 1.3848 (1.6084)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [53] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000042  loss: 1.3848 (1.6084)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3246634900569916, 'lambda_convnext_base': 0.2560904920101166, 'lambda_tf_efficientnetv2_l': 0.4192460775375366}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7794 (0.7794)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8291  data: 0.7981  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8936 (0.9981)  acc1: 82.8125 (80.9186)  acc5: 94.7917 (93.1345)  time: 0.1709  data: 0.1402  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0537 (1.0667)  acc1: 78.6458 (79.5635)  acc5: 93.2292 (92.4851)  time: 0.1247  data: 0.0940  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1475 (1.1168)  acc1: 78.1250 (78.9147)  acc5: 91.1458 (91.9859)  time: 0.1270  data: 0.0963  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2592 (1.1651)  acc1: 77.6042 (77.8836)  acc5: 90.6250 (91.5269)  time: 0.1263  data: 0.0956  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1044 (1.1627)  acc1: 77.0833 (77.6859)  acc5: 92.1875 (91.7382)  time: 0.1287  data: 0.0980  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1138 (1.1744)  acc1: 77.0833 (77.5500)  acc5: 92.1875 (91.7500)  time: 0.1114  data: 0.0817  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1335 s / it)\n",
            "* Acc@1 77.550 Acc@5 91.750 loss 1.174\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=54 distillation_alpha=0.3566\n",
            "Epoch: [54]  [  0/781]  eta: 0:17:26  lr: 0.000041  loss: 1.3412 (1.3412)  time: 1.3403  data: 0.9887  max mem: 6459\n",
            "Epoch: [54]  [ 10/781]  eta: 0:05:37  lr: 0.000041  loss: 1.3688 (1.6022)  time: 0.4381  data: 0.0902  max mem: 6459\n",
            "Epoch: [54]  [ 20/781]  eta: 0:04:55  lr: 0.000041  loss: 1.3707 (1.5505)  time: 0.3404  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 30/781]  eta: 0:04:38  lr: 0.000041  loss: 1.4068 (1.5737)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 40/781]  eta: 0:04:27  lr: 0.000041  loss: 1.4447 (1.5795)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 50/781]  eta: 0:04:19  lr: 0.000041  loss: 1.3899 (1.5544)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 60/781]  eta: 0:04:13  lr: 0.000041  loss: 1.3850 (1.5704)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 70/781]  eta: 0:04:08  lr: 0.000041  loss: 1.3818 (1.5435)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 80/781]  eta: 0:04:03  lr: 0.000041  loss: 1.3583 (1.5383)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 90/781]  eta: 0:03:58  lr: 0.000041  loss: 1.3833 (1.5539)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [100/781]  eta: 0:03:54  lr: 0.000041  loss: 1.4220 (1.5527)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [110/781]  eta: 0:03:50  lr: 0.000041  loss: 1.4273 (1.5714)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [120/781]  eta: 0:03:46  lr: 0.000041  loss: 1.3858 (1.5666)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [130/781]  eta: 0:03:42  lr: 0.000041  loss: 1.3715 (1.5681)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [140/781]  eta: 0:03:38  lr: 0.000041  loss: 1.4308 (1.5762)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [150/781]  eta: 0:03:34  lr: 0.000041  loss: 1.4034 (1.5654)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [160/781]  eta: 0:03:31  lr: 0.000041  loss: 1.4099 (1.5636)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [170/781]  eta: 0:03:27  lr: 0.000041  loss: 1.4099 (1.5581)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [180/781]  eta: 0:03:23  lr: 0.000041  loss: 1.3887 (1.5708)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [190/781]  eta: 0:03:20  lr: 0.000041  loss: 1.8689 (1.5881)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [200/781]  eta: 0:03:16  lr: 0.000041  loss: 1.4355 (1.5844)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [210/781]  eta: 0:03:13  lr: 0.000041  loss: 1.3925 (1.5788)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [220/781]  eta: 0:03:09  lr: 0.000041  loss: 1.4055 (1.5895)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [230/781]  eta: 0:03:06  lr: 0.000041  loss: 1.4455 (1.5960)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [240/781]  eta: 0:03:02  lr: 0.000041  loss: 1.4208 (1.5982)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [250/781]  eta: 0:02:59  lr: 0.000041  loss: 1.4290 (1.5984)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [260/781]  eta: 0:02:55  lr: 0.000041  loss: 1.4375 (1.5975)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [270/781]  eta: 0:02:52  lr: 0.000041  loss: 1.4353 (1.5910)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [280/781]  eta: 0:02:48  lr: 0.000041  loss: 1.4233 (1.5938)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [290/781]  eta: 0:02:45  lr: 0.000041  loss: 1.4700 (1.5893)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [300/781]  eta: 0:02:42  lr: 0.000041  loss: 1.4289 (1.5892)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [310/781]  eta: 0:02:38  lr: 0.000041  loss: 1.4289 (1.5931)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [320/781]  eta: 0:02:35  lr: 0.000041  loss: 1.4606 (1.5929)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [330/781]  eta: 0:02:31  lr: 0.000041  loss: 1.4606 (1.6032)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [340/781]  eta: 0:02:28  lr: 0.000041  loss: 1.4417 (1.6053)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [350/781]  eta: 0:02:24  lr: 0.000041  loss: 1.4243 (1.6074)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [360/781]  eta: 0:02:21  lr: 0.000041  loss: 1.4256 (1.6056)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [370/781]  eta: 0:02:18  lr: 0.000041  loss: 1.4000 (1.6044)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [380/781]  eta: 0:02:14  lr: 0.000041  loss: 1.4031 (1.6061)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [390/781]  eta: 0:02:11  lr: 0.000041  loss: 1.5259 (1.6062)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [400/781]  eta: 0:02:07  lr: 0.000041  loss: 1.4066 (1.6010)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [410/781]  eta: 0:02:04  lr: 0.000041  loss: 1.4066 (1.6046)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [420/781]  eta: 0:02:01  lr: 0.000041  loss: 1.4465 (1.6073)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [430/781]  eta: 0:01:57  lr: 0.000041  loss: 1.4465 (1.6079)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [440/781]  eta: 0:01:54  lr: 0.000041  loss: 1.4269 (1.6033)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [450/781]  eta: 0:01:51  lr: 0.000041  loss: 1.4277 (1.6063)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [460/781]  eta: 0:01:47  lr: 0.000041  loss: 1.4277 (1.6065)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [470/781]  eta: 0:01:44  lr: 0.000041  loss: 1.3763 (1.6029)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [480/781]  eta: 0:01:40  lr: 0.000041  loss: 1.3886 (1.6037)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [490/781]  eta: 0:01:37  lr: 0.000041  loss: 1.4375 (1.6047)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [500/781]  eta: 0:01:34  lr: 0.000041  loss: 1.4792 (1.6072)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [510/781]  eta: 0:01:30  lr: 0.000041  loss: 1.4590 (1.6072)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [520/781]  eta: 0:01:27  lr: 0.000041  loss: 1.3987 (1.6050)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [530/781]  eta: 0:01:24  lr: 0.000041  loss: 1.4012 (1.6048)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [540/781]  eta: 0:01:20  lr: 0.000041  loss: 1.4078 (1.6013)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [550/781]  eta: 0:01:17  lr: 0.000041  loss: 1.4078 (1.5982)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [560/781]  eta: 0:01:14  lr: 0.000041  loss: 1.3596 (1.5984)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [570/781]  eta: 0:01:10  lr: 0.000041  loss: 1.3596 (1.5994)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [580/781]  eta: 0:01:07  lr: 0.000041  loss: 1.4540 (1.5989)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [590/781]  eta: 0:01:03  lr: 0.000041  loss: 1.5845 (1.6040)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [600/781]  eta: 0:01:00  lr: 0.000041  loss: 1.7734 (1.6066)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [610/781]  eta: 0:00:57  lr: 0.000041  loss: 1.5505 (1.6084)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [620/781]  eta: 0:00:53  lr: 0.000041  loss: 1.5057 (1.6100)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [630/781]  eta: 0:00:50  lr: 0.000041  loss: 1.3845 (1.6072)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [640/781]  eta: 0:00:47  lr: 0.000041  loss: 1.3544 (1.6050)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [650/781]  eta: 0:00:43  lr: 0.000041  loss: 1.3791 (1.6069)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [660/781]  eta: 0:00:40  lr: 0.000041  loss: 1.4416 (1.6084)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [670/781]  eta: 0:00:37  lr: 0.000041  loss: 1.4318 (1.6087)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [680/781]  eta: 0:00:33  lr: 0.000041  loss: 1.4112 (1.6093)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [690/781]  eta: 0:00:30  lr: 0.000041  loss: 1.4258 (1.6120)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [700/781]  eta: 0:00:27  lr: 0.000041  loss: 1.4297 (1.6121)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [710/781]  eta: 0:00:23  lr: 0.000041  loss: 1.4227 (1.6112)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [720/781]  eta: 0:00:20  lr: 0.000041  loss: 1.4134 (1.6108)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [730/781]  eta: 0:00:17  lr: 0.000041  loss: 1.4201 (1.6134)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [740/781]  eta: 0:00:13  lr: 0.000041  loss: 1.4759 (1.6148)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [750/781]  eta: 0:00:10  lr: 0.000041  loss: 1.4480 (1.6144)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [760/781]  eta: 0:00:07  lr: 0.000041  loss: 1.4062 (1.6123)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [770/781]  eta: 0:00:03  lr: 0.000041  loss: 1.4243 (1.6130)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [780/781]  eta: 0:00:00  lr: 0.000041  loss: 1.5074 (1.6166)  time: 0.3329  data: 0.0005  max mem: 6459\n",
            "Epoch: [54] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000041  loss: 1.5074 (1.6166)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3246678113937378, 'lambda_convnext_base': 0.25625982880592346, 'lambda_tf_efficientnetv2_l': 0.41907188296318054}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8606 (0.8606)  acc1: 82.2917 (82.2917)  acc5: 93.2292 (93.2292)  time: 0.8556  data: 0.8246  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9093 (0.9880)  acc1: 82.2917 (80.6345)  acc5: 94.2708 (93.6553)  time: 0.1669  data: 0.1362  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0866 (1.0607)  acc1: 76.5625 (79.3651)  acc5: 92.1875 (92.6091)  time: 0.1217  data: 0.0910  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2068 (1.1207)  acc1: 75.0000 (78.3266)  acc5: 90.6250 (92.1539)  time: 0.1257  data: 0.0950  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2187 (1.1667)  acc1: 74.4792 (77.4136)  acc5: 89.5833 (91.6286)  time: 0.1248  data: 0.0941  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1125 (1.1620)  acc1: 76.5625 (77.2263)  acc5: 91.1458 (91.7484)  time: 0.1218  data: 0.0912  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1325 (1.1710)  acc1: 75.0000 (77.1400)  acc5: 92.1875 (91.7800)  time: 0.1019  data: 0.0723  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1297 s / it)\n",
            "* Acc@1 77.140 Acc@5 91.780 loss 1.171\n",
            "Accuracy of the network on the 10000 test images: 77.1%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=55 distillation_alpha=0.3644\n",
            "Epoch: [55]  [  0/781]  eta: 0:14:20  lr: 0.000040  loss: 1.3425 (1.3425)  time: 1.1015  data: 0.7607  max mem: 6459\n",
            "Epoch: [55]  [ 10/781]  eta: 0:05:10  lr: 0.000040  loss: 1.4240 (1.6425)  time: 0.4028  data: 0.0694  max mem: 6459\n",
            "Epoch: [55]  [ 20/781]  eta: 0:04:41  lr: 0.000040  loss: 1.4240 (1.5780)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 30/781]  eta: 0:04:28  lr: 0.000040  loss: 1.4257 (1.6656)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 40/781]  eta: 0:04:20  lr: 0.000040  loss: 1.4003 (1.6050)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 50/781]  eta: 0:04:14  lr: 0.000040  loss: 1.4139 (1.6527)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 60/781]  eta: 0:04:09  lr: 0.000040  loss: 1.4845 (1.6720)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 70/781]  eta: 0:04:04  lr: 0.000040  loss: 1.3834 (1.6317)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 80/781]  eta: 0:04:00  lr: 0.000040  loss: 1.3738 (1.6198)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 90/781]  eta: 0:03:56  lr: 0.000040  loss: 1.3738 (1.6133)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [100/781]  eta: 0:03:52  lr: 0.000040  loss: 1.3945 (1.6035)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [110/781]  eta: 0:03:48  lr: 0.000040  loss: 1.4739 (1.6215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [120/781]  eta: 0:03:44  lr: 0.000040  loss: 1.4527 (1.6171)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [130/781]  eta: 0:03:40  lr: 0.000040  loss: 1.4207 (1.6225)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [140/781]  eta: 0:03:37  lr: 0.000040  loss: 1.4087 (1.6249)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [150/781]  eta: 0:03:33  lr: 0.000040  loss: 1.4087 (1.6172)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [160/781]  eta: 0:03:29  lr: 0.000040  loss: 1.3575 (1.6103)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [170/781]  eta: 0:03:26  lr: 0.000040  loss: 1.3575 (1.6138)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [180/781]  eta: 0:03:22  lr: 0.000040  loss: 1.4920 (1.6147)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [190/781]  eta: 0:03:19  lr: 0.000040  loss: 1.4920 (1.6224)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [200/781]  eta: 0:03:15  lr: 0.000040  loss: 1.5415 (1.6312)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [210/781]  eta: 0:03:12  lr: 0.000040  loss: 1.5127 (1.6352)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [220/781]  eta: 0:03:08  lr: 0.000040  loss: 1.4430 (1.6337)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [230/781]  eta: 0:03:05  lr: 0.000040  loss: 1.4412 (1.6366)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [240/781]  eta: 0:03:02  lr: 0.000040  loss: 1.4429 (1.6373)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [250/781]  eta: 0:02:58  lr: 0.000040  loss: 1.4480 (1.6363)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [260/781]  eta: 0:02:55  lr: 0.000040  loss: 1.4188 (1.6282)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [270/781]  eta: 0:02:51  lr: 0.000040  loss: 1.4051 (1.6284)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [280/781]  eta: 0:02:48  lr: 0.000040  loss: 1.3577 (1.6221)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [290/781]  eta: 0:02:44  lr: 0.000040  loss: 1.3946 (1.6172)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [300/781]  eta: 0:02:41  lr: 0.000040  loss: 1.4285 (1.6160)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [310/781]  eta: 0:02:38  lr: 0.000040  loss: 1.4285 (1.6101)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [320/781]  eta: 0:02:34  lr: 0.000040  loss: 1.3987 (1.6087)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [330/781]  eta: 0:02:31  lr: 0.000040  loss: 1.3987 (1.6072)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [340/781]  eta: 0:02:27  lr: 0.000040  loss: 1.4412 (1.6129)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [350/781]  eta: 0:02:24  lr: 0.000040  loss: 1.4530 (1.6128)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [360/781]  eta: 0:02:21  lr: 0.000040  loss: 1.3819 (1.6145)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [370/781]  eta: 0:02:17  lr: 0.000040  loss: 1.3851 (1.6135)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [380/781]  eta: 0:02:14  lr: 0.000040  loss: 1.3997 (1.6126)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [390/781]  eta: 0:02:11  lr: 0.000040  loss: 1.4020 (1.6076)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [400/781]  eta: 0:02:07  lr: 0.000040  loss: 1.4250 (1.6101)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [410/781]  eta: 0:02:04  lr: 0.000040  loss: 1.3999 (1.6084)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [420/781]  eta: 0:02:00  lr: 0.000040  loss: 1.3999 (1.6138)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [430/781]  eta: 0:01:57  lr: 0.000040  loss: 1.4171 (1.6109)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [440/781]  eta: 0:01:54  lr: 0.000040  loss: 1.4171 (1.6131)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [450/781]  eta: 0:01:50  lr: 0.000040  loss: 1.5308 (1.6158)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [460/781]  eta: 0:01:47  lr: 0.000040  loss: 1.4365 (1.6155)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [470/781]  eta: 0:01:44  lr: 0.000040  loss: 1.4152 (1.6150)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [480/781]  eta: 0:01:40  lr: 0.000040  loss: 1.3989 (1.6121)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [490/781]  eta: 0:01:37  lr: 0.000040  loss: 1.4179 (1.6130)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [500/781]  eta: 0:01:34  lr: 0.000040  loss: 1.4266 (1.6123)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [510/781]  eta: 0:01:30  lr: 0.000040  loss: 1.4052 (1.6112)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [520/781]  eta: 0:01:27  lr: 0.000040  loss: 1.3654 (1.6106)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [530/781]  eta: 0:01:23  lr: 0.000040  loss: 1.3942 (1.6128)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [540/781]  eta: 0:01:20  lr: 0.000040  loss: 1.5112 (1.6157)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [550/781]  eta: 0:01:17  lr: 0.000040  loss: 1.4412 (1.6162)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [560/781]  eta: 0:01:13  lr: 0.000040  loss: 1.4373 (1.6166)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [570/781]  eta: 0:01:10  lr: 0.000040  loss: 1.4494 (1.6178)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [580/781]  eta: 0:01:07  lr: 0.000040  loss: 1.4393 (1.6159)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [590/781]  eta: 0:01:03  lr: 0.000040  loss: 1.4038 (1.6158)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [600/781]  eta: 0:01:00  lr: 0.000040  loss: 1.4285 (1.6159)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [610/781]  eta: 0:00:57  lr: 0.000040  loss: 1.3733 (1.6138)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [620/781]  eta: 0:00:53  lr: 0.000040  loss: 1.3997 (1.6132)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [630/781]  eta: 0:00:50  lr: 0.000040  loss: 1.4240 (1.6118)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [640/781]  eta: 0:00:47  lr: 0.000040  loss: 1.4240 (1.6125)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [650/781]  eta: 0:00:43  lr: 0.000040  loss: 1.4612 (1.6145)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [660/781]  eta: 0:00:40  lr: 0.000040  loss: 1.4143 (1.6146)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [670/781]  eta: 0:00:37  lr: 0.000040  loss: 1.4147 (1.6157)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [680/781]  eta: 0:00:33  lr: 0.000040  loss: 1.4728 (1.6169)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [690/781]  eta: 0:00:30  lr: 0.000040  loss: 1.4757 (1.6168)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [700/781]  eta: 0:00:27  lr: 0.000040  loss: 1.3494 (1.6157)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [710/781]  eta: 0:00:23  lr: 0.000040  loss: 1.3494 (1.6154)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [720/781]  eta: 0:00:20  lr: 0.000040  loss: 1.4185 (1.6178)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [730/781]  eta: 0:00:17  lr: 0.000040  loss: 1.4526 (1.6167)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [740/781]  eta: 0:00:13  lr: 0.000040  loss: 1.4222 (1.6163)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [750/781]  eta: 0:00:10  lr: 0.000040  loss: 1.4674 (1.6182)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [760/781]  eta: 0:00:07  lr: 0.000040  loss: 1.4566 (1.6163)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [770/781]  eta: 0:00:03  lr: 0.000040  loss: 1.3536 (1.6161)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [780/781]  eta: 0:00:00  lr: 0.000040  loss: 1.3770 (1.6152)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [55] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000040  loss: 1.3770 (1.6152)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3241780996322632, 'lambda_convnext_base': 0.25659605860710144, 'lambda_tf_efficientnetv2_l': 0.4192259609699249}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7968 (0.7968)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8511  data: 0.8203  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9420 (1.0012)  acc1: 80.7292 (80.3977)  acc5: 94.7917 (93.5606)  time: 0.1714  data: 0.1408  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0261 (1.0645)  acc1: 77.6042 (79.4891)  acc5: 93.7500 (92.5843)  time: 0.1222  data: 0.0916  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2031 (1.1232)  acc1: 77.0833 (78.4946)  acc5: 90.6250 (91.9187)  time: 0.1211  data: 0.0905  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2714 (1.1701)  acc1: 75.5208 (77.4390)  acc5: 89.5833 (91.4634)  time: 0.1207  data: 0.0900  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1498 (1.1605)  acc1: 76.0417 (77.4408)  acc5: 91.6667 (91.6871)  time: 0.1239  data: 0.0932  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1864 (1.1763)  acc1: 75.5208 (77.3000)  acc5: 91.6667 (91.7100)  time: 0.1054  data: 0.0757  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1297 s / it)\n",
            "* Acc@1 77.300 Acc@5 91.710 loss 1.176\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=56 distillation_alpha=0.3723\n",
            "Epoch: [56]  [  0/781]  eta: 0:14:37  lr: 0.000040  loss: 1.3821 (1.3821)  time: 1.1236  data: 0.7765  max mem: 6459\n",
            "Epoch: [56]  [ 10/781]  eta: 0:05:12  lr: 0.000040  loss: 1.4131 (1.4922)  time: 0.4047  data: 0.0708  max mem: 6459\n",
            "Epoch: [56]  [ 20/781]  eta: 0:04:41  lr: 0.000040  loss: 1.3586 (1.4659)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 30/781]  eta: 0:04:29  lr: 0.000040  loss: 1.3586 (1.4956)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 40/781]  eta: 0:04:20  lr: 0.000040  loss: 1.3628 (1.5325)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 50/781]  eta: 0:04:14  lr: 0.000040  loss: 1.3993 (1.5658)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 60/781]  eta: 0:04:09  lr: 0.000040  loss: 1.4670 (1.5807)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 70/781]  eta: 0:04:04  lr: 0.000040  loss: 1.4050 (1.5762)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 80/781]  eta: 0:04:00  lr: 0.000040  loss: 1.4132 (1.5835)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 90/781]  eta: 0:03:55  lr: 0.000040  loss: 1.4776 (1.5967)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [100/781]  eta: 0:03:52  lr: 0.000040  loss: 1.4815 (1.6004)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [110/781]  eta: 0:03:48  lr: 0.000040  loss: 1.4564 (1.6062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [120/781]  eta: 0:03:44  lr: 0.000040  loss: 1.4430 (1.5985)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [130/781]  eta: 0:03:40  lr: 0.000040  loss: 1.4042 (1.5960)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [140/781]  eta: 0:03:36  lr: 0.000040  loss: 1.4592 (1.6079)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [150/781]  eta: 0:03:33  lr: 0.000040  loss: 1.4597 (1.5984)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [160/781]  eta: 0:03:29  lr: 0.000040  loss: 1.4028 (1.5917)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [170/781]  eta: 0:03:26  lr: 0.000040  loss: 1.4085 (1.5898)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [180/781]  eta: 0:03:22  lr: 0.000040  loss: 1.3589 (1.5850)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [190/781]  eta: 0:03:19  lr: 0.000040  loss: 1.3966 (1.5887)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [200/781]  eta: 0:03:15  lr: 0.000040  loss: 1.4737 (1.5979)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [210/781]  eta: 0:03:12  lr: 0.000040  loss: 1.4194 (1.5908)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [220/781]  eta: 0:03:08  lr: 0.000040  loss: 1.3808 (1.5874)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [230/781]  eta: 0:03:05  lr: 0.000040  loss: 1.3821 (1.5831)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [240/781]  eta: 0:03:01  lr: 0.000040  loss: 1.3917 (1.5895)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [250/781]  eta: 0:02:58  lr: 0.000040  loss: 1.3957 (1.5834)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [260/781]  eta: 0:02:54  lr: 0.000040  loss: 1.3957 (1.5859)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [270/781]  eta: 0:02:51  lr: 0.000040  loss: 1.3789 (1.5821)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [280/781]  eta: 0:02:48  lr: 0.000040  loss: 1.3532 (1.5823)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [290/781]  eta: 0:02:44  lr: 0.000040  loss: 1.4302 (1.5869)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [300/781]  eta: 0:02:41  lr: 0.000040  loss: 1.4324 (1.5842)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [310/781]  eta: 0:02:37  lr: 0.000040  loss: 1.4136 (1.5833)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [320/781]  eta: 0:02:34  lr: 0.000040  loss: 1.3997 (1.5808)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [330/781]  eta: 0:02:31  lr: 0.000040  loss: 1.3997 (1.5820)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [340/781]  eta: 0:02:27  lr: 0.000040  loss: 1.4386 (1.5868)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [350/781]  eta: 0:02:24  lr: 0.000040  loss: 1.4176 (1.5832)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [360/781]  eta: 0:02:21  lr: 0.000040  loss: 1.4077 (1.5816)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [370/781]  eta: 0:02:17  lr: 0.000040  loss: 1.4611 (1.5846)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [380/781]  eta: 0:02:14  lr: 0.000040  loss: 1.4421 (1.5818)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [390/781]  eta: 0:02:10  lr: 0.000040  loss: 1.4421 (1.5889)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [400/781]  eta: 0:02:07  lr: 0.000040  loss: 1.4445 (1.5878)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [410/781]  eta: 0:02:04  lr: 0.000040  loss: 1.3893 (1.5852)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [420/781]  eta: 0:02:00  lr: 0.000040  loss: 1.4189 (1.5896)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [430/781]  eta: 0:01:57  lr: 0.000040  loss: 1.4699 (1.5883)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [440/781]  eta: 0:01:54  lr: 0.000040  loss: 1.3960 (1.5875)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [450/781]  eta: 0:01:50  lr: 0.000040  loss: 1.4186 (1.5882)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [460/781]  eta: 0:01:47  lr: 0.000040  loss: 1.4541 (1.5910)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [470/781]  eta: 0:01:44  lr: 0.000040  loss: 1.3983 (1.5898)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [480/781]  eta: 0:01:40  lr: 0.000040  loss: 1.3792 (1.5911)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [490/781]  eta: 0:01:37  lr: 0.000040  loss: 1.3716 (1.5886)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [500/781]  eta: 0:01:33  lr: 0.000040  loss: 1.3593 (1.5910)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [510/781]  eta: 0:01:30  lr: 0.000040  loss: 1.4650 (1.5933)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [520/781]  eta: 0:01:27  lr: 0.000040  loss: 1.4507 (1.5936)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [530/781]  eta: 0:01:23  lr: 0.000040  loss: 1.3771 (1.5912)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [540/781]  eta: 0:01:20  lr: 0.000040  loss: 1.4101 (1.5934)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [550/781]  eta: 0:01:17  lr: 0.000040  loss: 1.4121 (1.5892)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [560/781]  eta: 0:01:13  lr: 0.000040  loss: 1.4107 (1.5887)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [570/781]  eta: 0:01:10  lr: 0.000040  loss: 1.4449 (1.5882)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [580/781]  eta: 0:01:07  lr: 0.000040  loss: 1.3746 (1.5901)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [590/781]  eta: 0:01:03  lr: 0.000040  loss: 1.3879 (1.5923)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [600/781]  eta: 0:01:00  lr: 0.000040  loss: 1.4263 (1.5920)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [610/781]  eta: 0:00:57  lr: 0.000040  loss: 1.4255 (1.5917)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [620/781]  eta: 0:00:53  lr: 0.000040  loss: 1.3995 (1.5901)  time: 0.3441  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [630/781]  eta: 0:00:50  lr: 0.000040  loss: 1.4103 (1.5905)  time: 0.3439  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [640/781]  eta: 0:00:47  lr: 0.000040  loss: 1.4327 (1.5908)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [650/781]  eta: 0:00:43  lr: 0.000040  loss: 1.4191 (1.5893)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [660/781]  eta: 0:00:40  lr: 0.000040  loss: 1.3920 (1.5882)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [670/781]  eta: 0:00:37  lr: 0.000040  loss: 1.4152 (1.5897)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [680/781]  eta: 0:00:33  lr: 0.000040  loss: 1.4300 (1.5898)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [690/781]  eta: 0:00:30  lr: 0.000040  loss: 1.3784 (1.5876)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [700/781]  eta: 0:00:27  lr: 0.000040  loss: 1.4218 (1.5884)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [710/781]  eta: 0:00:23  lr: 0.000040  loss: 1.4169 (1.5868)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [720/781]  eta: 0:00:20  lr: 0.000040  loss: 1.3726 (1.5887)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [730/781]  eta: 0:00:17  lr: 0.000040  loss: 1.4220 (1.5895)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [740/781]  eta: 0:00:13  lr: 0.000040  loss: 1.3871 (1.5893)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [750/781]  eta: 0:00:10  lr: 0.000040  loss: 1.3721 (1.5863)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [760/781]  eta: 0:00:07  lr: 0.000040  loss: 1.3972 (1.5870)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [770/781]  eta: 0:00:03  lr: 0.000040  loss: 1.4286 (1.5873)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [780/781]  eta: 0:00:00  lr: 0.000040  loss: 1.4685 (1.5894)  time: 0.3332  data: 0.0005  max mem: 6459\n",
            "Epoch: [56] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000040  loss: 1.4685 (1.5894)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32378798723220825, 'lambda_convnext_base': 0.2554614841938019, 'lambda_tf_efficientnetv2_l': 0.42075085639953613}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8220 (0.8220)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8115  data: 0.7806  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9382 (0.9979)  acc1: 82.2917 (80.1610)  acc5: 94.2708 (93.5133)  time: 0.1719  data: 0.1412  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0668 (1.0718)  acc1: 77.0833 (78.8691)  acc5: 92.7083 (92.2867)  time: 0.1202  data: 0.0896  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1558 (1.1185)  acc1: 76.5625 (78.3434)  acc5: 91.6667 (91.7843)  time: 0.1265  data: 0.0959  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2159 (1.1555)  acc1: 76.5625 (77.5534)  acc5: 91.1458 (91.5904)  time: 0.1230  data: 0.0923  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1712 (1.1561)  acc1: 75.5208 (77.2978)  acc5: 92.1875 (91.8709)  time: 0.1247  data: 0.0941  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1719 (1.1708)  acc1: 73.9583 (77.1700)  acc5: 92.1875 (91.8800)  time: 0.1132  data: 0.0835  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1321 s / it)\n",
            "* Acc@1 77.170 Acc@5 91.880 loss 1.171\n",
            "Accuracy of the network on the 10000 test images: 77.2%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=57 distillation_alpha=0.3802\n",
            "Epoch: [57]  [  0/781]  eta: 0:14:59  lr: 0.000039  loss: 1.3434 (1.3434)  time: 1.1522  data: 0.8071  max mem: 6459\n",
            "Epoch: [57]  [ 10/781]  eta: 0:05:14  lr: 0.000039  loss: 1.3504 (1.4331)  time: 0.4074  data: 0.0737  max mem: 6459\n",
            "Epoch: [57]  [ 20/781]  eta: 0:04:43  lr: 0.000039  loss: 1.3789 (1.4727)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 30/781]  eta: 0:04:29  lr: 0.000039  loss: 1.4389 (1.5358)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 40/781]  eta: 0:04:21  lr: 0.000039  loss: 1.3958 (1.5176)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 50/781]  eta: 0:04:15  lr: 0.000039  loss: 1.3642 (1.5293)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 60/781]  eta: 0:04:09  lr: 0.000039  loss: 1.4068 (1.5159)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 70/781]  eta: 0:04:04  lr: 0.000039  loss: 1.4068 (1.5193)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 80/781]  eta: 0:04:00  lr: 0.000039  loss: 1.4023 (1.5339)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 90/781]  eta: 0:03:56  lr: 0.000039  loss: 1.3739 (1.5360)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [100/781]  eta: 0:03:52  lr: 0.000039  loss: 1.3746 (1.5239)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [110/781]  eta: 0:03:48  lr: 0.000039  loss: 1.3923 (1.5387)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [120/781]  eta: 0:03:44  lr: 0.000039  loss: 1.4095 (1.5499)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [130/781]  eta: 0:03:40  lr: 0.000039  loss: 1.3885 (1.5532)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [140/781]  eta: 0:03:37  lr: 0.000039  loss: 1.3885 (1.5620)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [150/781]  eta: 0:03:33  lr: 0.000039  loss: 1.3997 (1.5708)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [160/781]  eta: 0:03:29  lr: 0.000039  loss: 1.3880 (1.5708)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [170/781]  eta: 0:03:26  lr: 0.000039  loss: 1.3723 (1.5654)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [180/781]  eta: 0:03:22  lr: 0.000039  loss: 1.3615 (1.5607)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [190/781]  eta: 0:03:19  lr: 0.000039  loss: 1.3430 (1.5659)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [200/781]  eta: 0:03:15  lr: 0.000039  loss: 1.4610 (1.5747)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [210/781]  eta: 0:03:12  lr: 0.000039  loss: 1.4610 (1.5748)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [220/781]  eta: 0:03:08  lr: 0.000039  loss: 1.4598 (1.5754)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [230/781]  eta: 0:03:05  lr: 0.000039  loss: 1.4478 (1.5735)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [240/781]  eta: 0:03:01  lr: 0.000039  loss: 1.3828 (1.5711)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [250/781]  eta: 0:02:58  lr: 0.000039  loss: 1.3546 (1.5704)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [260/781]  eta: 0:02:55  lr: 0.000039  loss: 1.4094 (1.5737)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [270/781]  eta: 0:02:51  lr: 0.000039  loss: 1.4094 (1.5703)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [280/781]  eta: 0:02:48  lr: 0.000039  loss: 1.4043 (1.5672)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [290/781]  eta: 0:02:44  lr: 0.000039  loss: 1.4043 (1.5701)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [300/781]  eta: 0:02:41  lr: 0.000039  loss: 1.3748 (1.5685)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [310/781]  eta: 0:02:38  lr: 0.000039  loss: 1.3235 (1.5665)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [320/781]  eta: 0:02:34  lr: 0.000039  loss: 1.3491 (1.5711)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [330/781]  eta: 0:02:31  lr: 0.000039  loss: 1.3860 (1.5687)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [340/781]  eta: 0:02:27  lr: 0.000039  loss: 1.3369 (1.5683)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [350/781]  eta: 0:02:24  lr: 0.000039  loss: 1.3958 (1.5687)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [360/781]  eta: 0:02:21  lr: 0.000039  loss: 1.4358 (1.5771)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [370/781]  eta: 0:02:17  lr: 0.000039  loss: 1.4415 (1.5790)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [380/781]  eta: 0:02:14  lr: 0.000039  loss: 1.4275 (1.5826)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [390/781]  eta: 0:02:11  lr: 0.000039  loss: 1.4431 (1.5827)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [400/781]  eta: 0:02:07  lr: 0.000039  loss: 1.4417 (1.5807)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [410/781]  eta: 0:02:04  lr: 0.000039  loss: 1.4054 (1.5762)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [420/781]  eta: 0:02:00  lr: 0.000039  loss: 1.4054 (1.5720)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [430/781]  eta: 0:01:57  lr: 0.000039  loss: 1.4188 (1.5717)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [440/781]  eta: 0:01:54  lr: 0.000039  loss: 1.4066 (1.5691)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [450/781]  eta: 0:01:50  lr: 0.000039  loss: 1.3540 (1.5649)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [460/781]  eta: 0:01:47  lr: 0.000039  loss: 1.4354 (1.5691)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [470/781]  eta: 0:01:44  lr: 0.000039  loss: 1.4367 (1.5679)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [480/781]  eta: 0:01:40  lr: 0.000039  loss: 1.3692 (1.5666)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [490/781]  eta: 0:01:37  lr: 0.000039  loss: 1.3912 (1.5639)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [500/781]  eta: 0:01:34  lr: 0.000039  loss: 1.4215 (1.5650)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [510/781]  eta: 0:01:30  lr: 0.000039  loss: 1.4043 (1.5640)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [520/781]  eta: 0:01:27  lr: 0.000039  loss: 1.3779 (1.5645)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [530/781]  eta: 0:01:23  lr: 0.000039  loss: 1.3779 (1.5641)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [540/781]  eta: 0:01:20  lr: 0.000039  loss: 1.3662 (1.5653)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [550/781]  eta: 0:01:17  lr: 0.000039  loss: 1.4167 (1.5659)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [560/781]  eta: 0:01:13  lr: 0.000039  loss: 1.4105 (1.5636)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [570/781]  eta: 0:01:10  lr: 0.000039  loss: 1.4220 (1.5666)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [580/781]  eta: 0:01:07  lr: 0.000039  loss: 1.4248 (1.5665)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [590/781]  eta: 0:01:03  lr: 0.000039  loss: 1.3727 (1.5647)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [600/781]  eta: 0:01:00  lr: 0.000039  loss: 1.3894 (1.5663)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [610/781]  eta: 0:00:57  lr: 0.000039  loss: 1.4128 (1.5683)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [620/781]  eta: 0:00:53  lr: 0.000039  loss: 1.4320 (1.5691)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [630/781]  eta: 0:00:50  lr: 0.000039  loss: 1.4000 (1.5679)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [640/781]  eta: 0:00:47  lr: 0.000039  loss: 1.3798 (1.5729)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [650/781]  eta: 0:00:43  lr: 0.000039  loss: 1.5199 (1.5710)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [660/781]  eta: 0:00:40  lr: 0.000039  loss: 1.4286 (1.5710)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [670/781]  eta: 0:00:37  lr: 0.000039  loss: 1.4038 (1.5706)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [680/781]  eta: 0:00:33  lr: 0.000039  loss: 1.4025 (1.5712)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [690/781]  eta: 0:00:30  lr: 0.000039  loss: 1.3978 (1.5703)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [700/781]  eta: 0:00:27  lr: 0.000039  loss: 1.4322 (1.5707)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [710/781]  eta: 0:00:23  lr: 0.000039  loss: 1.4334 (1.5694)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [720/781]  eta: 0:00:20  lr: 0.000039  loss: 1.4060 (1.5701)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [730/781]  eta: 0:00:17  lr: 0.000039  loss: 1.4282 (1.5735)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [740/781]  eta: 0:00:13  lr: 0.000039  loss: 1.4227 (1.5741)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [750/781]  eta: 0:00:10  lr: 0.000039  loss: 1.4071 (1.5753)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [760/781]  eta: 0:00:07  lr: 0.000039  loss: 1.4352 (1.5771)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [770/781]  eta: 0:00:03  lr: 0.000039  loss: 1.3743 (1.5755)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [780/781]  eta: 0:00:00  lr: 0.000039  loss: 1.3720 (1.5763)  time: 0.3332  data: 0.0005  max mem: 6459\n",
            "Epoch: [57] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000039  loss: 1.3720 (1.5763)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3243657648563385, 'lambda_convnext_base': 0.2542813718318939, 'lambda_tf_efficientnetv2_l': 0.42135289311408997}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8149 (0.8149)  acc1: 81.7708 (81.7708)  acc5: 95.8333 (95.8333)  time: 0.8423  data: 0.8114  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9426 (0.9868)  acc1: 81.7708 (80.3977)  acc5: 94.7917 (93.7027)  time: 0.1668  data: 0.1361  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9763 (1.0561)  acc1: 78.6458 (79.4395)  acc5: 93.2292 (92.6339)  time: 0.1202  data: 0.0895  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2567 (1.1262)  acc1: 75.5208 (78.2090)  acc5: 90.6250 (91.8179)  time: 0.1229  data: 0.0922  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2719 (1.1651)  acc1: 75.5208 (77.4644)  acc5: 90.1042 (91.4634)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1397 (1.1574)  acc1: 79.1667 (77.4510)  acc5: 91.1458 (91.6667)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1491 (1.1642)  acc1: 79.1667 (77.3900)  acc5: 91.6667 (91.6900)  time: 0.1074  data: 0.0776  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1299 s / it)\n",
            "* Acc@1 77.390 Acc@5 91.690 loss 1.164\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=58 distillation_alpha=0.3881\n",
            "Epoch: [58]  [  0/781]  eta: 0:13:29  lr: 0.000038  loss: 1.2467 (1.2467)  time: 1.0362  data: 0.6933  max mem: 6459\n",
            "Epoch: [58]  [ 10/781]  eta: 0:05:06  lr: 0.000038  loss: 1.3844 (1.4794)  time: 0.3972  data: 0.0633  max mem: 6459\n",
            "Epoch: [58]  [ 20/781]  eta: 0:04:38  lr: 0.000038  loss: 1.3844 (1.4462)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 30/781]  eta: 0:04:27  lr: 0.000038  loss: 1.3581 (1.4500)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 40/781]  eta: 0:04:19  lr: 0.000038  loss: 1.4114 (1.4852)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 50/781]  eta: 0:04:13  lr: 0.000038  loss: 1.3679 (1.4823)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 60/781]  eta: 0:04:08  lr: 0.000038  loss: 1.3317 (1.4655)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 70/781]  eta: 0:04:03  lr: 0.000038  loss: 1.3654 (1.4807)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 80/781]  eta: 0:03:59  lr: 0.000038  loss: 1.3654 (1.4996)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 90/781]  eta: 0:03:55  lr: 0.000038  loss: 1.3698 (1.5046)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [100/781]  eta: 0:03:51  lr: 0.000038  loss: 1.3349 (1.4874)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [110/781]  eta: 0:03:47  lr: 0.000038  loss: 1.3291 (1.5005)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [120/781]  eta: 0:03:44  lr: 0.000038  loss: 1.4260 (1.5192)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [130/781]  eta: 0:03:40  lr: 0.000038  loss: 1.3641 (1.5124)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [140/781]  eta: 0:03:36  lr: 0.000038  loss: 1.3134 (1.5172)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [150/781]  eta: 0:03:33  lr: 0.000038  loss: 1.3662 (1.5211)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [160/781]  eta: 0:03:29  lr: 0.000038  loss: 1.3819 (1.5274)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [170/781]  eta: 0:03:26  lr: 0.000038  loss: 1.3819 (1.5390)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [180/781]  eta: 0:03:22  lr: 0.000038  loss: 1.3807 (1.5337)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [190/781]  eta: 0:03:18  lr: 0.000038  loss: 1.4223 (1.5328)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [200/781]  eta: 0:03:15  lr: 0.000038  loss: 1.4383 (1.5339)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [210/781]  eta: 0:03:12  lr: 0.000038  loss: 1.3970 (1.5428)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [220/781]  eta: 0:03:08  lr: 0.000038  loss: 1.3968 (1.5405)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [230/781]  eta: 0:03:05  lr: 0.000038  loss: 1.3776 (1.5429)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [240/781]  eta: 0:03:01  lr: 0.000038  loss: 1.4244 (1.5581)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [250/781]  eta: 0:02:58  lr: 0.000038  loss: 1.4244 (1.5602)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [260/781]  eta: 0:02:54  lr: 0.000038  loss: 1.4154 (1.5709)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [270/781]  eta: 0:02:51  lr: 0.000038  loss: 1.4311 (1.5651)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [280/781]  eta: 0:02:48  lr: 0.000038  loss: 1.3847 (1.5638)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [290/781]  eta: 0:02:44  lr: 0.000038  loss: 1.3301 (1.5551)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [300/781]  eta: 0:02:41  lr: 0.000038  loss: 1.3540 (1.5563)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [310/781]  eta: 0:02:37  lr: 0.000038  loss: 1.3939 (1.5557)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [320/781]  eta: 0:02:34  lr: 0.000038  loss: 1.4178 (1.5568)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [330/781]  eta: 0:02:31  lr: 0.000038  loss: 1.3958 (1.5568)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [340/781]  eta: 0:02:27  lr: 0.000038  loss: 1.3958 (1.5643)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [350/781]  eta: 0:02:24  lr: 0.000038  loss: 1.4393 (1.5663)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [360/781]  eta: 0:02:21  lr: 0.000038  loss: 1.4393 (1.5728)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [370/781]  eta: 0:02:17  lr: 0.000038  loss: 1.3664 (1.5668)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [380/781]  eta: 0:02:14  lr: 0.000038  loss: 1.3657 (1.5752)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [390/781]  eta: 0:02:10  lr: 0.000038  loss: 1.4173 (1.5721)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [400/781]  eta: 0:02:07  lr: 0.000038  loss: 1.3773 (1.5692)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [410/781]  eta: 0:02:04  lr: 0.000038  loss: 1.3451 (1.5678)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [420/781]  eta: 0:02:00  lr: 0.000038  loss: 1.4127 (1.5771)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [430/781]  eta: 0:01:57  lr: 0.000038  loss: 1.6906 (1.5795)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [440/781]  eta: 0:01:54  lr: 0.000038  loss: 1.4349 (1.5808)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [450/781]  eta: 0:01:50  lr: 0.000038  loss: 1.4067 (1.5799)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [460/781]  eta: 0:01:47  lr: 0.000038  loss: 1.4067 (1.5813)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [470/781]  eta: 0:01:44  lr: 0.000038  loss: 1.3957 (1.5823)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [480/781]  eta: 0:01:40  lr: 0.000038  loss: 1.3600 (1.5836)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [490/781]  eta: 0:01:37  lr: 0.000038  loss: 1.3667 (1.5850)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [500/781]  eta: 0:01:33  lr: 0.000038  loss: 1.3939 (1.5805)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [510/781]  eta: 0:01:30  lr: 0.000038  loss: 1.3677 (1.5846)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [520/781]  eta: 0:01:27  lr: 0.000038  loss: 1.3660 (1.5828)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [530/781]  eta: 0:01:23  lr: 0.000038  loss: 1.4383 (1.5843)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [540/781]  eta: 0:01:20  lr: 0.000038  loss: 1.4790 (1.5837)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [550/781]  eta: 0:01:17  lr: 0.000038  loss: 1.4039 (1.5831)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [560/781]  eta: 0:01:13  lr: 0.000038  loss: 1.4017 (1.5833)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [570/781]  eta: 0:01:10  lr: 0.000038  loss: 1.4268 (1.5819)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [580/781]  eta: 0:01:07  lr: 0.000038  loss: 1.4257 (1.5791)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [590/781]  eta: 0:01:03  lr: 0.000038  loss: 1.4257 (1.5835)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [600/781]  eta: 0:01:00  lr: 0.000038  loss: 1.4727 (1.5840)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [610/781]  eta: 0:00:57  lr: 0.000038  loss: 1.4135 (1.5859)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [620/781]  eta: 0:00:53  lr: 0.000038  loss: 1.4025 (1.5835)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [630/781]  eta: 0:00:50  lr: 0.000038  loss: 1.3808 (1.5828)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [640/781]  eta: 0:00:47  lr: 0.000038  loss: 1.3905 (1.5818)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [650/781]  eta: 0:00:43  lr: 0.000038  loss: 1.3905 (1.5835)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [660/781]  eta: 0:00:40  lr: 0.000038  loss: 1.4373 (1.5824)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [670/781]  eta: 0:00:37  lr: 0.000038  loss: 1.4014 (1.5810)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [680/781]  eta: 0:00:33  lr: 0.000038  loss: 1.3866 (1.5799)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [690/781]  eta: 0:00:30  lr: 0.000038  loss: 1.3837 (1.5795)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [700/781]  eta: 0:00:27  lr: 0.000038  loss: 1.3827 (1.5764)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [710/781]  eta: 0:00:23  lr: 0.000038  loss: 1.3794 (1.5754)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [720/781]  eta: 0:00:20  lr: 0.000038  loss: 1.3862 (1.5727)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [730/781]  eta: 0:00:17  lr: 0.000038  loss: 1.4022 (1.5723)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [740/781]  eta: 0:00:13  lr: 0.000038  loss: 1.4359 (1.5733)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [750/781]  eta: 0:00:10  lr: 0.000038  loss: 1.4625 (1.5751)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [760/781]  eta: 0:00:07  lr: 0.000038  loss: 1.4065 (1.5742)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [770/781]  eta: 0:00:03  lr: 0.000038  loss: 1.3664 (1.5731)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [780/781]  eta: 0:00:00  lr: 0.000038  loss: 1.4129 (1.5710)  time: 0.3338  data: 0.0006  max mem: 6459\n",
            "Epoch: [58] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000038  loss: 1.4129 (1.5710)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3249524235725403, 'lambda_convnext_base': 0.2559131979942322, 'lambda_tf_efficientnetv2_l': 0.4191341698169708}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.9099 (0.9099)  acc1: 79.6875 (79.6875)  acc5: 94.2708 (94.2708)  time: 0.8682  data: 0.8373  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0379 (0.9880)  acc1: 80.7292 (80.3030)  acc5: 94.2708 (93.2765)  time: 0.1729  data: 0.1422  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0897 (1.0651)  acc1: 78.1250 (78.9187)  acc5: 93.2292 (92.3115)  time: 0.1222  data: 0.0916  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1821 (1.1281)  acc1: 75.0000 (78.0242)  acc5: 91.1458 (91.7339)  time: 0.1202  data: 0.0895  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2876 (1.1638)  acc1: 74.4792 (77.2104)  acc5: 89.5833 (91.4634)  time: 0.1208  data: 0.0901  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1350 (1.1607)  acc1: 75.5208 (77.1548)  acc5: 92.7083 (91.6054)  time: 0.1238  data: 0.0932  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1862 (1.1703)  acc1: 75.5208 (77.0300)  acc5: 92.7083 (91.6400)  time: 0.1045  data: 0.0747  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1298 s / it)\n",
            "* Acc@1 77.030 Acc@5 91.640 loss 1.170\n",
            "Accuracy of the network on the 10000 test images: 77.0%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=59 distillation_alpha=0.3960\n",
            "Epoch: [59]  [  0/781]  eta: 0:14:18  lr: 0.000038  loss: 1.4131 (1.4131)  time: 1.0991  data: 0.7537  max mem: 6459\n",
            "Epoch: [59]  [ 10/781]  eta: 0:05:10  lr: 0.000038  loss: 1.4037 (1.4709)  time: 0.4030  data: 0.0688  max mem: 6459\n",
            "Epoch: [59]  [ 20/781]  eta: 0:04:41  lr: 0.000038  loss: 1.4037 (1.6339)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 30/781]  eta: 0:04:29  lr: 0.000038  loss: 1.4416 (1.6892)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 40/781]  eta: 0:04:21  lr: 0.000038  loss: 1.8285 (1.7281)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 50/781]  eta: 0:04:14  lr: 0.000038  loss: 1.5190 (1.7078)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 60/781]  eta: 0:04:09  lr: 0.000038  loss: 1.4151 (1.7116)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 70/781]  eta: 0:04:04  lr: 0.000038  loss: 1.3551 (1.6712)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 80/781]  eta: 0:04:00  lr: 0.000038  loss: 1.3551 (1.6402)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 90/781]  eta: 0:03:56  lr: 0.000038  loss: 1.4517 (1.6503)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [100/781]  eta: 0:03:52  lr: 0.000038  loss: 1.4226 (1.6326)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [110/781]  eta: 0:03:48  lr: 0.000038  loss: 1.3398 (1.6233)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [120/781]  eta: 0:03:44  lr: 0.000038  loss: 1.4135 (1.6469)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [130/781]  eta: 0:03:40  lr: 0.000038  loss: 1.4455 (1.6469)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [140/781]  eta: 0:03:37  lr: 0.000038  loss: 1.3990 (1.6533)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [150/781]  eta: 0:03:33  lr: 0.000038  loss: 1.3983 (1.6505)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [160/781]  eta: 0:03:29  lr: 0.000038  loss: 1.4028 (1.6591)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [170/781]  eta: 0:03:26  lr: 0.000038  loss: 1.4415 (1.6628)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [180/781]  eta: 0:03:22  lr: 0.000038  loss: 1.4279 (1.6618)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [190/781]  eta: 0:03:19  lr: 0.000038  loss: 1.4279 (1.6629)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [200/781]  eta: 0:03:15  lr: 0.000038  loss: 1.3642 (1.6485)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [210/781]  eta: 0:03:12  lr: 0.000038  loss: 1.3649 (1.6422)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [220/781]  eta: 0:03:08  lr: 0.000038  loss: 1.4221 (1.6460)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [230/781]  eta: 0:03:05  lr: 0.000038  loss: 1.4024 (1.6391)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [240/781]  eta: 0:03:01  lr: 0.000038  loss: 1.3641 (1.6386)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [250/781]  eta: 0:02:58  lr: 0.000038  loss: 1.4594 (1.6412)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [260/781]  eta: 0:02:55  lr: 0.000038  loss: 1.4481 (1.6414)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [270/781]  eta: 0:02:51  lr: 0.000038  loss: 1.3964 (1.6365)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [280/781]  eta: 0:02:48  lr: 0.000038  loss: 1.3964 (1.6342)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [290/781]  eta: 0:02:44  lr: 0.000038  loss: 1.3812 (1.6284)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [300/781]  eta: 0:02:41  lr: 0.000038  loss: 1.4228 (1.6315)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [310/781]  eta: 0:02:37  lr: 0.000038  loss: 1.4280 (1.6334)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [320/781]  eta: 0:02:34  lr: 0.000038  loss: 1.4217 (1.6315)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [330/781]  eta: 0:02:31  lr: 0.000038  loss: 1.5151 (1.6340)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [340/781]  eta: 0:02:27  lr: 0.000038  loss: 1.5389 (1.6385)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [350/781]  eta: 0:02:24  lr: 0.000038  loss: 1.4234 (1.6414)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [360/781]  eta: 0:02:21  lr: 0.000038  loss: 1.4056 (1.6386)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [370/781]  eta: 0:02:17  lr: 0.000038  loss: 1.4056 (1.6372)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [380/781]  eta: 0:02:14  lr: 0.000038  loss: 1.3646 (1.6297)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [390/781]  eta: 0:02:10  lr: 0.000038  loss: 1.3748 (1.6259)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [400/781]  eta: 0:02:07  lr: 0.000038  loss: 1.4350 (1.6264)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [410/781]  eta: 0:02:04  lr: 0.000038  loss: 1.4368 (1.6260)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [420/781]  eta: 0:02:00  lr: 0.000038  loss: 1.4733 (1.6296)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [430/781]  eta: 0:01:57  lr: 0.000038  loss: 1.4936 (1.6311)  time: 0.3425  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [440/781]  eta: 0:01:54  lr: 0.000038  loss: 1.3969 (1.6280)  time: 0.3424  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [450/781]  eta: 0:01:50  lr: 0.000038  loss: 1.3514 (1.6220)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [460/781]  eta: 0:01:47  lr: 0.000038  loss: 1.3671 (1.6239)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [470/781]  eta: 0:01:44  lr: 0.000038  loss: 1.3851 (1.6250)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [480/781]  eta: 0:01:40  lr: 0.000038  loss: 1.3901 (1.6250)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [490/781]  eta: 0:01:37  lr: 0.000038  loss: 1.4353 (1.6241)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [500/781]  eta: 0:01:34  lr: 0.000038  loss: 1.4094 (1.6277)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [510/781]  eta: 0:01:30  lr: 0.000038  loss: 1.3691 (1.6250)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [520/781]  eta: 0:01:27  lr: 0.000038  loss: 1.3691 (1.6227)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [530/781]  eta: 0:01:24  lr: 0.000038  loss: 1.3651 (1.6197)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [540/781]  eta: 0:01:20  lr: 0.000038  loss: 1.3862 (1.6228)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [550/781]  eta: 0:01:17  lr: 0.000038  loss: 1.3871 (1.6202)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [560/781]  eta: 0:01:13  lr: 0.000038  loss: 1.3625 (1.6189)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [570/781]  eta: 0:01:10  lr: 0.000038  loss: 1.4030 (1.6201)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [580/781]  eta: 0:01:07  lr: 0.000038  loss: 1.4253 (1.6180)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [590/781]  eta: 0:01:03  lr: 0.000038  loss: 1.4341 (1.6192)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [600/781]  eta: 0:01:00  lr: 0.000038  loss: 1.4129 (1.6164)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [610/781]  eta: 0:00:57  lr: 0.000038  loss: 1.3637 (1.6153)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [620/781]  eta: 0:00:53  lr: 0.000038  loss: 1.4027 (1.6136)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [630/781]  eta: 0:00:50  lr: 0.000038  loss: 1.4027 (1.6142)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [640/781]  eta: 0:00:47  lr: 0.000038  loss: 1.4353 (1.6157)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [650/781]  eta: 0:00:43  lr: 0.000038  loss: 1.4320 (1.6158)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [660/781]  eta: 0:00:40  lr: 0.000038  loss: 1.3256 (1.6157)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [670/781]  eta: 0:00:37  lr: 0.000038  loss: 1.3686 (1.6156)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [680/781]  eta: 0:00:33  lr: 0.000038  loss: 1.4015 (1.6149)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [690/781]  eta: 0:00:30  lr: 0.000038  loss: 1.4481 (1.6199)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [700/781]  eta: 0:00:27  lr: 0.000038  loss: 1.4026 (1.6182)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [710/781]  eta: 0:00:23  lr: 0.000038  loss: 1.3769 (1.6169)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [720/781]  eta: 0:00:20  lr: 0.000038  loss: 1.4037 (1.6147)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [730/781]  eta: 0:00:17  lr: 0.000038  loss: 1.4075 (1.6120)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [740/781]  eta: 0:00:13  lr: 0.000038  loss: 1.4163 (1.6127)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [750/781]  eta: 0:00:10  lr: 0.000038  loss: 1.4602 (1.6131)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [760/781]  eta: 0:00:07  lr: 0.000038  loss: 1.3647 (1.6105)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [770/781]  eta: 0:00:03  lr: 0.000038  loss: 1.4086 (1.6141)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [780/781]  eta: 0:00:00  lr: 0.000038  loss: 1.5342 (1.6133)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [59] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000038  loss: 1.5342 (1.6133)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3242844045162201, 'lambda_convnext_base': 0.2556512951850891, 'lambda_tf_efficientnetv2_l': 0.42006421089172363}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8576 (0.8576)  acc1: 82.8125 (82.8125)  acc5: 94.7917 (94.7917)  time: 0.8547  data: 0.8239  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8576 (0.9935)  acc1: 82.8125 (80.9186)  acc5: 94.7917 (93.5606)  time: 0.1733  data: 0.1426  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0330 (1.0739)  acc1: 79.1667 (79.2659)  acc5: 93.2292 (92.5843)  time: 0.1227  data: 0.0921  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2436 (1.1436)  acc1: 75.5208 (77.8226)  acc5: 91.6667 (91.8851)  time: 0.1215  data: 0.0909  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3425 (1.1865)  acc1: 75.0000 (77.1087)  acc5: 89.5833 (91.4507)  time: 0.1255  data: 0.0948  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1493 (1.1815)  acc1: 77.0833 (76.8893)  acc5: 91.6667 (91.6769)  time: 0.1245  data: 0.0938  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1736 (1.1990)  acc1: 76.0417 (76.7700)  acc5: 91.6667 (91.6800)  time: 0.1046  data: 0.0750  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1306 s / it)\n",
            "* Acc@1 76.770 Acc@5 91.680 loss 1.199\n",
            "Accuracy of the network on the 10000 test images: 76.8%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=60 distillation_alpha=0.4040\n",
            "Epoch: [60]  [  0/781]  eta: 0:14:46  lr: 0.000037  loss: 1.3042 (1.3042)  time: 1.1348  data: 0.7925  max mem: 6459\n",
            "Epoch: [60]  [ 10/781]  eta: 0:05:12  lr: 0.000037  loss: 1.4019 (1.5546)  time: 0.4057  data: 0.0723  max mem: 6459\n",
            "Epoch: [60]  [ 20/781]  eta: 0:04:42  lr: 0.000037  loss: 1.4068 (1.5024)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 30/781]  eta: 0:04:29  lr: 0.000037  loss: 1.4068 (1.5026)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 40/781]  eta: 0:04:21  lr: 0.000037  loss: 1.4033 (1.5473)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 50/781]  eta: 0:04:14  lr: 0.000037  loss: 1.3880 (1.5390)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 60/781]  eta: 0:04:09  lr: 0.000037  loss: 1.3880 (1.5530)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 70/781]  eta: 0:04:04  lr: 0.000037  loss: 1.3607 (1.5571)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 80/781]  eta: 0:04:00  lr: 0.000037  loss: 1.4091 (1.5757)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 90/781]  eta: 0:03:56  lr: 0.000037  loss: 1.4016 (1.5601)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [100/781]  eta: 0:03:52  lr: 0.000037  loss: 1.4180 (1.5612)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [110/781]  eta: 0:03:48  lr: 0.000037  loss: 1.3716 (1.5413)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [120/781]  eta: 0:03:44  lr: 0.000037  loss: 1.3071 (1.5373)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [130/781]  eta: 0:03:40  lr: 0.000037  loss: 1.3994 (1.5454)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [140/781]  eta: 0:03:36  lr: 0.000037  loss: 1.4229 (1.5480)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [150/781]  eta: 0:03:33  lr: 0.000037  loss: 1.3702 (1.5424)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [160/781]  eta: 0:03:29  lr: 0.000037  loss: 1.3302 (1.5308)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [170/781]  eta: 0:03:26  lr: 0.000037  loss: 1.3716 (1.5368)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [180/781]  eta: 0:03:22  lr: 0.000037  loss: 1.3828 (1.5405)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [190/781]  eta: 0:03:19  lr: 0.000037  loss: 1.3819 (1.5417)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [200/781]  eta: 0:03:15  lr: 0.000037  loss: 1.3796 (1.5504)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [210/781]  eta: 0:03:12  lr: 0.000037  loss: 1.4705 (1.5579)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [220/781]  eta: 0:03:08  lr: 0.000037  loss: 1.4705 (1.5651)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [230/781]  eta: 0:03:05  lr: 0.000037  loss: 1.3805 (1.5653)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [240/781]  eta: 0:03:01  lr: 0.000037  loss: 1.4292 (1.5700)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [250/781]  eta: 0:02:58  lr: 0.000037  loss: 1.4106 (1.5679)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [260/781]  eta: 0:02:55  lr: 0.000037  loss: 1.3666 (1.5637)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [270/781]  eta: 0:02:51  lr: 0.000037  loss: 1.4036 (1.5700)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [280/781]  eta: 0:02:48  lr: 0.000037  loss: 1.8336 (1.5820)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [290/781]  eta: 0:02:44  lr: 0.000037  loss: 1.6299 (1.5845)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [300/781]  eta: 0:02:41  lr: 0.000037  loss: 1.3683 (1.5796)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [310/781]  eta: 0:02:37  lr: 0.000037  loss: 1.3476 (1.5812)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [320/781]  eta: 0:02:34  lr: 0.000037  loss: 1.3817 (1.5851)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [330/781]  eta: 0:02:31  lr: 0.000037  loss: 1.4290 (1.5846)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [340/781]  eta: 0:02:27  lr: 0.000037  loss: 1.3920 (1.5808)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [350/781]  eta: 0:02:24  lr: 0.000037  loss: 1.3823 (1.5826)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [360/781]  eta: 0:02:21  lr: 0.000037  loss: 1.4270 (1.5858)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [370/781]  eta: 0:02:17  lr: 0.000037  loss: 1.4461 (1.5893)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [380/781]  eta: 0:02:14  lr: 0.000037  loss: 1.4224 (1.5882)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [390/781]  eta: 0:02:10  lr: 0.000037  loss: 1.3390 (1.5818)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [400/781]  eta: 0:02:07  lr: 0.000037  loss: 1.3390 (1.5793)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [410/781]  eta: 0:02:04  lr: 0.000037  loss: 1.4418 (1.5846)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [420/781]  eta: 0:02:00  lr: 0.000037  loss: 1.4406 (1.5840)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [430/781]  eta: 0:01:57  lr: 0.000037  loss: 1.3611 (1.5786)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [440/781]  eta: 0:01:54  lr: 0.000037  loss: 1.3669 (1.5789)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [450/781]  eta: 0:01:50  lr: 0.000037  loss: 1.4449 (1.5812)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [460/781]  eta: 0:01:47  lr: 0.000037  loss: 1.3653 (1.5772)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [470/781]  eta: 0:01:44  lr: 0.000037  loss: 1.3701 (1.5748)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [480/781]  eta: 0:01:40  lr: 0.000037  loss: 1.3827 (1.5748)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [490/781]  eta: 0:01:37  lr: 0.000037  loss: 1.3949 (1.5721)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [500/781]  eta: 0:01:33  lr: 0.000037  loss: 1.4342 (1.5742)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [510/781]  eta: 0:01:30  lr: 0.000037  loss: 1.4457 (1.5754)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [520/781]  eta: 0:01:27  lr: 0.000037  loss: 1.3910 (1.5795)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [530/781]  eta: 0:01:23  lr: 0.000037  loss: 1.3810 (1.5782)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [540/781]  eta: 0:01:20  lr: 0.000037  loss: 1.3554 (1.5764)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [550/781]  eta: 0:01:17  lr: 0.000037  loss: 1.3820 (1.5788)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [560/781]  eta: 0:01:13  lr: 0.000037  loss: 1.4120 (1.5805)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [570/781]  eta: 0:01:10  lr: 0.000037  loss: 1.3758 (1.5806)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [580/781]  eta: 0:01:07  lr: 0.000037  loss: 1.4356 (1.5859)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [590/781]  eta: 0:01:03  lr: 0.000037  loss: 1.4367 (1.5845)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [600/781]  eta: 0:01:00  lr: 0.000037  loss: 1.3915 (1.5843)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [610/781]  eta: 0:00:57  lr: 0.000037  loss: 1.3725 (1.5857)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [620/781]  eta: 0:00:53  lr: 0.000037  loss: 1.3939 (1.5855)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [630/781]  eta: 0:00:50  lr: 0.000037  loss: 1.4299 (1.5888)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [640/781]  eta: 0:00:47  lr: 0.000037  loss: 1.4827 (1.5875)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [650/781]  eta: 0:00:43  lr: 0.000037  loss: 1.4198 (1.5850)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [660/781]  eta: 0:00:40  lr: 0.000037  loss: 1.4085 (1.5877)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [670/781]  eta: 0:00:37  lr: 0.000037  loss: 1.4430 (1.5878)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [680/781]  eta: 0:00:33  lr: 0.000037  loss: 1.4430 (1.5876)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [690/781]  eta: 0:00:30  lr: 0.000037  loss: 1.4246 (1.5887)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [700/781]  eta: 0:00:27  lr: 0.000037  loss: 1.3613 (1.5885)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [710/781]  eta: 0:00:23  lr: 0.000037  loss: 1.3613 (1.5856)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [720/781]  eta: 0:00:20  lr: 0.000037  loss: 1.3872 (1.5866)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [730/781]  eta: 0:00:17  lr: 0.000037  loss: 1.4080 (1.5849)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [740/781]  eta: 0:00:13  lr: 0.000037  loss: 1.3745 (1.5843)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [750/781]  eta: 0:00:10  lr: 0.000037  loss: 1.3705 (1.5817)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [760/781]  eta: 0:00:07  lr: 0.000037  loss: 1.4247 (1.5833)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [770/781]  eta: 0:00:03  lr: 0.000037  loss: 1.4422 (1.5839)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [780/781]  eta: 0:00:00  lr: 0.000037  loss: 1.4236 (1.5835)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [60] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000037  loss: 1.4236 (1.5835)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3245265483856201, 'lambda_convnext_base': 0.2558853328227997, 'lambda_tf_efficientnetv2_l': 0.4195888042449951}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8517 (0.8517)  acc1: 83.3333 (83.3333)  acc5: 93.2292 (93.2292)  time: 0.8523  data: 0.8213  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0166 (1.0069)  acc1: 81.7708 (80.4451)  acc5: 93.7500 (93.5133)  time: 0.1685  data: 0.1378  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1315 (1.0974)  acc1: 77.6042 (78.7698)  acc5: 92.7083 (92.4603)  time: 0.1209  data: 0.0902  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2127 (1.1421)  acc1: 75.0000 (77.9738)  acc5: 91.1458 (91.8515)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3011 (1.1820)  acc1: 74.4792 (77.2104)  acc5: 90.6250 (91.4380)  time: 0.1231  data: 0.0925  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1509 (1.1808)  acc1: 76.5625 (77.0425)  acc5: 92.1875 (91.6054)  time: 0.1233  data: 0.0927  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1576 (1.1942)  acc1: 75.5208 (76.9100)  acc5: 92.1875 (91.6100)  time: 0.1035  data: 0.0738  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1296 s / it)\n",
            "* Acc@1 76.910 Acc@5 91.610 loss 1.194\n",
            "Accuracy of the network on the 10000 test images: 76.9%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=61 distillation_alpha=0.4119\n",
            "Epoch: [61]  [  0/781]  eta: 0:14:44  lr: 0.000036  loss: 1.4057 (1.4057)  time: 1.1329  data: 0.7944  max mem: 6459\n",
            "Epoch: [61]  [ 10/781]  eta: 0:05:12  lr: 0.000036  loss: 1.4719 (1.7135)  time: 0.4057  data: 0.0725  max mem: 6459\n",
            "Epoch: [61]  [ 20/781]  eta: 0:04:42  lr: 0.000036  loss: 1.5937 (1.7164)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 30/781]  eta: 0:04:29  lr: 0.000036  loss: 1.4272 (1.6801)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 40/781]  eta: 0:04:21  lr: 0.000036  loss: 1.3868 (1.6544)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 50/781]  eta: 0:04:14  lr: 0.000036  loss: 1.3957 (1.6512)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 60/781]  eta: 0:04:09  lr: 0.000036  loss: 1.3378 (1.5919)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 70/781]  eta: 0:04:04  lr: 0.000036  loss: 1.3350 (1.5840)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 80/781]  eta: 0:04:00  lr: 0.000036  loss: 1.3671 (1.5756)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 90/781]  eta: 0:03:56  lr: 0.000036  loss: 1.4332 (1.5943)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [100/781]  eta: 0:03:52  lr: 0.000036  loss: 1.3864 (1.5992)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [110/781]  eta: 0:03:48  lr: 0.000036  loss: 1.3864 (1.5902)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [120/781]  eta: 0:03:44  lr: 0.000036  loss: 1.4109 (1.5823)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [130/781]  eta: 0:03:40  lr: 0.000036  loss: 1.4067 (1.5864)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [140/781]  eta: 0:03:36  lr: 0.000036  loss: 1.4227 (1.5949)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [150/781]  eta: 0:03:33  lr: 0.000036  loss: 1.4118 (1.5850)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [160/781]  eta: 0:03:29  lr: 0.000036  loss: 1.3324 (1.5886)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [170/781]  eta: 0:03:26  lr: 0.000036  loss: 1.3862 (1.5913)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [180/781]  eta: 0:03:22  lr: 0.000036  loss: 1.3850 (1.5883)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [190/781]  eta: 0:03:19  lr: 0.000036  loss: 1.3494 (1.5839)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [200/781]  eta: 0:03:15  lr: 0.000036  loss: 1.3642 (1.5840)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [210/781]  eta: 0:03:12  lr: 0.000036  loss: 1.3642 (1.5782)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [220/781]  eta: 0:03:08  lr: 0.000036  loss: 1.3844 (1.5875)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [230/781]  eta: 0:03:05  lr: 0.000036  loss: 1.3941 (1.5873)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [240/781]  eta: 0:03:01  lr: 0.000036  loss: 1.4026 (1.5813)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [250/781]  eta: 0:02:58  lr: 0.000036  loss: 1.4113 (1.5810)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [260/781]  eta: 0:02:54  lr: 0.000036  loss: 1.3364 (1.5783)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [270/781]  eta: 0:02:51  lr: 0.000036  loss: 1.3875 (1.5798)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [280/781]  eta: 0:02:48  lr: 0.000036  loss: 1.3995 (1.5821)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [290/781]  eta: 0:02:44  lr: 0.000036  loss: 1.3919 (1.5772)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [300/781]  eta: 0:02:41  lr: 0.000036  loss: 1.3919 (1.5827)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [310/781]  eta: 0:02:37  lr: 0.000036  loss: 1.4562 (1.5857)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [320/781]  eta: 0:02:34  lr: 0.000036  loss: 1.4290 (1.5861)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [330/781]  eta: 0:02:31  lr: 0.000036  loss: 1.3720 (1.5805)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [340/781]  eta: 0:02:27  lr: 0.000036  loss: 1.3891 (1.5801)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [350/781]  eta: 0:02:24  lr: 0.000036  loss: 1.4020 (1.5840)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [360/781]  eta: 0:02:21  lr: 0.000036  loss: 1.3826 (1.5827)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [370/781]  eta: 0:02:17  lr: 0.000036  loss: 1.3931 (1.5824)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [380/781]  eta: 0:02:14  lr: 0.000036  loss: 1.3931 (1.5848)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [390/781]  eta: 0:02:10  lr: 0.000036  loss: 1.3985 (1.5822)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [400/781]  eta: 0:02:07  lr: 0.000036  loss: 1.4011 (1.5881)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [410/781]  eta: 0:02:04  lr: 0.000036  loss: 1.3981 (1.5918)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [420/781]  eta: 0:02:00  lr: 0.000036  loss: 1.6573 (1.5983)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [430/781]  eta: 0:01:57  lr: 0.000036  loss: 1.4892 (1.5957)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [440/781]  eta: 0:01:54  lr: 0.000036  loss: 1.3572 (1.5929)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [450/781]  eta: 0:01:50  lr: 0.000036  loss: 1.3591 (1.5913)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [460/781]  eta: 0:01:47  lr: 0.000036  loss: 1.3746 (1.5863)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [470/781]  eta: 0:01:44  lr: 0.000036  loss: 1.3746 (1.5870)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [480/781]  eta: 0:01:40  lr: 0.000036  loss: 1.3897 (1.5852)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [490/781]  eta: 0:01:37  lr: 0.000036  loss: 1.3898 (1.5849)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [500/781]  eta: 0:01:33  lr: 0.000036  loss: 1.3797 (1.5832)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [510/781]  eta: 0:01:30  lr: 0.000036  loss: 1.3488 (1.5814)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [520/781]  eta: 0:01:27  lr: 0.000036  loss: 1.3739 (1.5810)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [530/781]  eta: 0:01:23  lr: 0.000036  loss: 1.4232 (1.5801)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [540/781]  eta: 0:01:20  lr: 0.000036  loss: 1.4038 (1.5799)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [550/781]  eta: 0:01:17  lr: 0.000036  loss: 1.3787 (1.5769)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [560/781]  eta: 0:01:13  lr: 0.000036  loss: 1.3856 (1.5761)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [570/781]  eta: 0:01:10  lr: 0.000036  loss: 1.4007 (1.5747)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [580/781]  eta: 0:01:07  lr: 0.000036  loss: 1.4279 (1.5764)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [590/781]  eta: 0:01:03  lr: 0.000036  loss: 1.3815 (1.5747)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [600/781]  eta: 0:01:00  lr: 0.000036  loss: 1.3967 (1.5749)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [610/781]  eta: 0:00:57  lr: 0.000036  loss: 1.4034 (1.5741)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [620/781]  eta: 0:00:53  lr: 0.000036  loss: 1.4072 (1.5767)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [630/781]  eta: 0:00:50  lr: 0.000036  loss: 1.3266 (1.5758)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [640/781]  eta: 0:00:47  lr: 0.000036  loss: 1.3556 (1.5757)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [650/781]  eta: 0:00:43  lr: 0.000036  loss: 1.4092 (1.5760)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [660/781]  eta: 0:00:40  lr: 0.000036  loss: 1.3881 (1.5740)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [670/781]  eta: 0:00:37  lr: 0.000036  loss: 1.3430 (1.5723)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [680/781]  eta: 0:00:33  lr: 0.000036  loss: 1.3500 (1.5718)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [690/781]  eta: 0:00:30  lr: 0.000036  loss: 1.4114 (1.5726)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [700/781]  eta: 0:00:27  lr: 0.000036  loss: 1.4040 (1.5720)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [710/781]  eta: 0:00:23  lr: 0.000036  loss: 1.4106 (1.5741)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [720/781]  eta: 0:00:20  lr: 0.000036  loss: 1.4107 (1.5743)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [730/781]  eta: 0:00:17  lr: 0.000036  loss: 1.3718 (1.5739)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [740/781]  eta: 0:00:13  lr: 0.000036  loss: 1.4023 (1.5744)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [750/781]  eta: 0:00:10  lr: 0.000036  loss: 1.4023 (1.5733)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [760/781]  eta: 0:00:07  lr: 0.000036  loss: 1.3657 (1.5734)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [770/781]  eta: 0:00:03  lr: 0.000036  loss: 1.3843 (1.5749)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [780/781]  eta: 0:00:00  lr: 0.000036  loss: 1.3664 (1.5722)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [61] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000036  loss: 1.3664 (1.5722)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32447177171707153, 'lambda_convnext_base': 0.25553053617477417, 'lambda_tf_efficientnetv2_l': 0.4199972450733185}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.9178 (0.9178)  acc1: 80.7292 (80.7292)  acc5: 93.2292 (93.2292)  time: 0.8132  data: 0.7823  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9178 (1.0152)  acc1: 81.2500 (80.5398)  acc5: 93.7500 (93.4659)  time: 0.1726  data: 0.1419  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0764 (1.0865)  acc1: 77.6042 (79.2907)  acc5: 93.7500 (92.5347)  time: 0.1255  data: 0.0948  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2484 (1.1466)  acc1: 73.9583 (78.2090)  acc5: 90.6250 (91.7171)  time: 0.1225  data: 0.0918  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3357 (1.1789)  acc1: 74.4792 (77.4644)  acc5: 89.5833 (91.5015)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1204 (1.1678)  acc1: 76.0417 (77.4510)  acc5: 91.6667 (91.6973)  time: 0.1212  data: 0.0905  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2261 (1.1892)  acc1: 75.0000 (77.2800)  acc5: 92.1875 (91.7200)  time: 0.1030  data: 0.0733  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1300 s / it)\n",
            "* Acc@1 77.280 Acc@5 91.720 loss 1.189\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=62 distillation_alpha=0.4198\n",
            "Epoch: [62]  [  0/781]  eta: 0:13:50  lr: 0.000036  loss: 2.4055 (2.4055)  time: 1.0635  data: 0.7121  max mem: 6459\n",
            "Epoch: [62]  [ 10/781]  eta: 0:05:07  lr: 0.000036  loss: 1.4091 (1.7371)  time: 0.3990  data: 0.0650  max mem: 6459\n",
            "Epoch: [62]  [ 20/781]  eta: 0:04:39  lr: 0.000036  loss: 1.3765 (1.5783)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 30/781]  eta: 0:04:27  lr: 0.000036  loss: 1.3361 (1.5715)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 40/781]  eta: 0:04:19  lr: 0.000036  loss: 1.3924 (1.5548)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 50/781]  eta: 0:04:13  lr: 0.000036  loss: 1.4214 (1.5819)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 60/781]  eta: 0:04:08  lr: 0.000036  loss: 1.3338 (1.5629)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 70/781]  eta: 0:04:03  lr: 0.000036  loss: 1.3391 (1.5579)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 80/781]  eta: 0:03:59  lr: 0.000036  loss: 1.3802 (1.5771)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 90/781]  eta: 0:03:55  lr: 0.000036  loss: 1.3859 (1.5719)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [100/781]  eta: 0:03:51  lr: 0.000036  loss: 1.3901 (1.5748)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [110/781]  eta: 0:03:47  lr: 0.000036  loss: 1.4204 (1.5799)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [120/781]  eta: 0:03:43  lr: 0.000036  loss: 1.4043 (1.5740)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [130/781]  eta: 0:03:40  lr: 0.000036  loss: 1.3632 (1.5830)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [140/781]  eta: 0:03:36  lr: 0.000036  loss: 1.4339 (1.5912)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [150/781]  eta: 0:03:33  lr: 0.000036  loss: 1.4023 (1.5760)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [160/781]  eta: 0:03:29  lr: 0.000036  loss: 1.3917 (1.5750)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [170/781]  eta: 0:03:25  lr: 0.000036  loss: 1.3917 (1.5784)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [180/781]  eta: 0:03:22  lr: 0.000036  loss: 1.3390 (1.5702)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [190/781]  eta: 0:03:18  lr: 0.000036  loss: 1.3390 (1.5661)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [200/781]  eta: 0:03:15  lr: 0.000036  loss: 1.4663 (1.5768)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [210/781]  eta: 0:03:12  lr: 0.000036  loss: 1.4229 (1.5708)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [220/781]  eta: 0:03:08  lr: 0.000036  loss: 1.3509 (1.5648)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [230/781]  eta: 0:03:05  lr: 0.000036  loss: 1.3833 (1.5694)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [240/781]  eta: 0:03:01  lr: 0.000036  loss: 1.4024 (1.5628)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [250/781]  eta: 0:02:58  lr: 0.000036  loss: 1.3247 (1.5576)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [260/781]  eta: 0:02:55  lr: 0.000036  loss: 1.3304 (1.5525)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [270/781]  eta: 0:02:51  lr: 0.000036  loss: 1.4098 (1.5529)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [280/781]  eta: 0:02:48  lr: 0.000036  loss: 1.4349 (1.5572)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [290/781]  eta: 0:02:44  lr: 0.000036  loss: 1.3744 (1.5498)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [300/781]  eta: 0:02:41  lr: 0.000036  loss: 1.3720 (1.5546)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [310/781]  eta: 0:02:38  lr: 0.000036  loss: 1.5137 (1.5593)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [320/781]  eta: 0:02:34  lr: 0.000036  loss: 1.4868 (1.5632)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [330/781]  eta: 0:02:31  lr: 0.000036  loss: 1.4095 (1.5658)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [340/781]  eta: 0:02:27  lr: 0.000036  loss: 1.3842 (1.5661)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [350/781]  eta: 0:02:24  lr: 0.000036  loss: 1.3699 (1.5661)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [360/781]  eta: 0:02:21  lr: 0.000036  loss: 1.3904 (1.5663)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [370/781]  eta: 0:02:17  lr: 0.000036  loss: 1.4386 (1.5725)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [380/781]  eta: 0:02:14  lr: 0.000036  loss: 1.5152 (1.5731)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [390/781]  eta: 0:02:11  lr: 0.000036  loss: 1.4121 (1.5780)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [400/781]  eta: 0:02:07  lr: 0.000036  loss: 1.4087 (1.5766)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [410/781]  eta: 0:02:04  lr: 0.000036  loss: 1.4087 (1.5774)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [420/781]  eta: 0:02:00  lr: 0.000036  loss: 1.3274 (1.5740)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [430/781]  eta: 0:01:57  lr: 0.000036  loss: 1.3393 (1.5711)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [440/781]  eta: 0:01:54  lr: 0.000036  loss: 1.3897 (1.5720)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [450/781]  eta: 0:01:50  lr: 0.000036  loss: 1.3437 (1.5706)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [460/781]  eta: 0:01:47  lr: 0.000036  loss: 1.3299 (1.5675)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [470/781]  eta: 0:01:44  lr: 0.000036  loss: 1.4087 (1.5742)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [480/781]  eta: 0:01:40  lr: 0.000036  loss: 1.4032 (1.5726)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [490/781]  eta: 0:01:37  lr: 0.000036  loss: 1.3802 (1.5720)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [500/781]  eta: 0:01:34  lr: 0.000036  loss: 1.4090 (1.5735)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [510/781]  eta: 0:01:30  lr: 0.000036  loss: 1.4525 (1.5770)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [520/781]  eta: 0:01:27  lr: 0.000036  loss: 1.4525 (1.5775)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [530/781]  eta: 0:01:23  lr: 0.000036  loss: 1.3902 (1.5770)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [540/781]  eta: 0:01:20  lr: 0.000036  loss: 1.3677 (1.5759)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [550/781]  eta: 0:01:17  lr: 0.000036  loss: 1.3533 (1.5748)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [560/781]  eta: 0:01:13  lr: 0.000036  loss: 1.3533 (1.5759)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [570/781]  eta: 0:01:10  lr: 0.000036  loss: 1.3738 (1.5757)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [580/781]  eta: 0:01:07  lr: 0.000036  loss: 1.3496 (1.5729)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [590/781]  eta: 0:01:03  lr: 0.000036  loss: 1.3438 (1.5710)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [600/781]  eta: 0:01:00  lr: 0.000036  loss: 1.3869 (1.5735)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [610/781]  eta: 0:00:57  lr: 0.000036  loss: 1.4000 (1.5733)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [620/781]  eta: 0:00:53  lr: 0.000036  loss: 1.3927 (1.5708)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [630/781]  eta: 0:00:50  lr: 0.000036  loss: 1.3717 (1.5674)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [640/781]  eta: 0:00:47  lr: 0.000036  loss: 1.3664 (1.5687)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [650/781]  eta: 0:00:43  lr: 0.000036  loss: 1.3664 (1.5664)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [660/781]  eta: 0:00:40  lr: 0.000036  loss: 1.4041 (1.5668)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [670/781]  eta: 0:00:37  lr: 0.000036  loss: 1.4315 (1.5679)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [680/781]  eta: 0:00:33  lr: 0.000036  loss: 1.4321 (1.5695)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [690/781]  eta: 0:00:30  lr: 0.000036  loss: 1.4192 (1.5704)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [700/781]  eta: 0:00:27  lr: 0.000036  loss: 1.3726 (1.5682)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [710/781]  eta: 0:00:23  lr: 0.000036  loss: 1.3423 (1.5686)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [720/781]  eta: 0:00:20  lr: 0.000036  loss: 1.4191 (1.5724)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [730/781]  eta: 0:00:17  lr: 0.000036  loss: 1.4177 (1.5722)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [740/781]  eta: 0:00:13  lr: 0.000036  loss: 1.3800 (1.5763)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [750/781]  eta: 0:00:10  lr: 0.000036  loss: 1.6000 (1.5765)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [760/781]  eta: 0:00:07  lr: 0.000036  loss: 1.6000 (1.5798)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [770/781]  eta: 0:00:03  lr: 0.000036  loss: 1.4700 (1.5803)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [780/781]  eta: 0:00:00  lr: 0.000036  loss: 1.3898 (1.5816)  time: 0.3332  data: 0.0005  max mem: 6459\n",
            "Epoch: [62] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000036  loss: 1.3898 (1.5816)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32444074749946594, 'lambda_convnext_base': 0.2558528482913971, 'lambda_tf_efficientnetv2_l': 0.4197066128253937}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8201 (0.8201)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8523  data: 0.8215  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0205 (1.0051)  acc1: 79.6875 (81.1553)  acc5: 93.2292 (93.3239)  time: 0.1699  data: 0.1392  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1014 (1.0837)  acc1: 77.0833 (79.4147)  acc5: 92.7083 (92.3115)  time: 0.1183  data: 0.0877  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2078 (1.1337)  acc1: 75.5208 (78.4274)  acc5: 91.1458 (91.9691)  time: 0.1225  data: 0.0918  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2111 (1.1785)  acc1: 75.5208 (77.4517)  acc5: 91.1458 (91.7175)  time: 0.1246  data: 0.0939  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1851 (1.1754)  acc1: 75.5208 (77.3284)  acc5: 91.6667 (91.7484)  time: 0.1242  data: 0.0935  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2009 (1.1867)  acc1: 75.5208 (77.1700)  acc5: 92.1875 (91.7900)  time: 0.1058  data: 0.0761  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1302 s / it)\n",
            "* Acc@1 77.170 Acc@5 91.790 loss 1.187\n",
            "Accuracy of the network on the 10000 test images: 77.2%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=63 distillation_alpha=0.4277\n",
            "Epoch: [63]  [  0/781]  eta: 0:15:19  lr: 0.000035  loss: 1.2548 (1.2548)  time: 1.1768  data: 0.8364  max mem: 6459\n",
            "Epoch: [63]  [ 10/781]  eta: 0:05:15  lr: 0.000035  loss: 1.3587 (1.6004)  time: 0.4095  data: 0.0763  max mem: 6459\n",
            "Epoch: [63]  [ 20/781]  eta: 0:04:43  lr: 0.000035  loss: 1.3664 (1.5998)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 30/781]  eta: 0:04:30  lr: 0.000035  loss: 1.4326 (1.6533)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 40/781]  eta: 0:04:21  lr: 0.000035  loss: 1.4326 (1.6337)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 50/781]  eta: 0:04:15  lr: 0.000035  loss: 1.4050 (1.6515)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 60/781]  eta: 0:04:09  lr: 0.000035  loss: 1.4204 (1.6780)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 70/781]  eta: 0:04:04  lr: 0.000035  loss: 1.4204 (1.6775)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 80/781]  eta: 0:04:00  lr: 0.000035  loss: 1.4272 (1.6886)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 90/781]  eta: 0:03:56  lr: 0.000035  loss: 1.3854 (1.6631)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [100/781]  eta: 0:03:52  lr: 0.000035  loss: 1.3999 (1.6796)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [110/781]  eta: 0:03:48  lr: 0.000035  loss: 1.5551 (1.6827)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [120/781]  eta: 0:03:44  lr: 0.000035  loss: 1.4495 (1.6812)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [130/781]  eta: 0:03:40  lr: 0.000035  loss: 1.4411 (1.6901)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [140/781]  eta: 0:03:37  lr: 0.000035  loss: 1.3897 (1.6723)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [150/781]  eta: 0:03:33  lr: 0.000035  loss: 1.3625 (1.6670)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [160/781]  eta: 0:03:29  lr: 0.000035  loss: 1.3216 (1.6463)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [170/781]  eta: 0:03:26  lr: 0.000035  loss: 1.3216 (1.6506)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [180/781]  eta: 0:03:22  lr: 0.000035  loss: 1.3910 (1.6501)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [190/781]  eta: 0:03:19  lr: 0.000035  loss: 1.3981 (1.6492)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [200/781]  eta: 0:03:15  lr: 0.000035  loss: 1.4068 (1.6522)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [210/781]  eta: 0:03:12  lr: 0.000035  loss: 1.3632 (1.6396)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [220/781]  eta: 0:03:08  lr: 0.000035  loss: 1.3573 (1.6349)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [230/781]  eta: 0:03:05  lr: 0.000035  loss: 1.4060 (1.6452)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [240/781]  eta: 0:03:01  lr: 0.000035  loss: 2.1101 (1.6547)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [250/781]  eta: 0:02:58  lr: 0.000035  loss: 1.4217 (1.6511)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [260/781]  eta: 0:02:55  lr: 0.000035  loss: 1.4217 (1.6528)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [270/781]  eta: 0:02:51  lr: 0.000035  loss: 1.3853 (1.6459)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [280/781]  eta: 0:02:48  lr: 0.000035  loss: 1.3353 (1.6351)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [290/781]  eta: 0:02:44  lr: 0.000035  loss: 1.3414 (1.6298)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [300/781]  eta: 0:02:41  lr: 0.000035  loss: 1.4282 (1.6316)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [310/781]  eta: 0:02:38  lr: 0.000035  loss: 1.4175 (1.6248)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [320/781]  eta: 0:02:34  lr: 0.000035  loss: 1.3744 (1.6229)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [330/781]  eta: 0:02:31  lr: 0.000035  loss: 1.3802 (1.6190)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [340/781]  eta: 0:02:27  lr: 0.000035  loss: 1.3814 (1.6201)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [350/781]  eta: 0:02:24  lr: 0.000035  loss: 1.3814 (1.6177)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [360/781]  eta: 0:02:21  lr: 0.000035  loss: 1.3882 (1.6185)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [370/781]  eta: 0:02:17  lr: 0.000035  loss: 1.3536 (1.6160)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [380/781]  eta: 0:02:14  lr: 0.000035  loss: 1.3424 (1.6095)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [390/781]  eta: 0:02:10  lr: 0.000035  loss: 1.3737 (1.6087)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [400/781]  eta: 0:02:07  lr: 0.000035  loss: 1.3456 (1.6062)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [410/781]  eta: 0:02:04  lr: 0.000035  loss: 1.3838 (1.6076)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [420/781]  eta: 0:02:00  lr: 0.000035  loss: 1.4596 (1.6083)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [430/781]  eta: 0:01:57  lr: 0.000035  loss: 1.4217 (1.6084)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [440/781]  eta: 0:01:54  lr: 0.000035  loss: 1.3950 (1.6106)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [450/781]  eta: 0:01:50  lr: 0.000035  loss: 1.3883 (1.6055)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [460/781]  eta: 0:01:47  lr: 0.000035  loss: 1.3830 (1.6035)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [470/781]  eta: 0:01:44  lr: 0.000035  loss: 1.3742 (1.6019)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [480/781]  eta: 0:01:40  lr: 0.000035  loss: 1.3642 (1.5993)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [490/781]  eta: 0:01:37  lr: 0.000035  loss: 1.3683 (1.5985)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [500/781]  eta: 0:01:33  lr: 0.000035  loss: 1.3706 (1.6006)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [510/781]  eta: 0:01:30  lr: 0.000035  loss: 1.3580 (1.5969)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [520/781]  eta: 0:01:27  lr: 0.000035  loss: 1.3851 (1.5999)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [530/781]  eta: 0:01:23  lr: 0.000035  loss: 1.4365 (1.6003)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [540/781]  eta: 0:01:20  lr: 0.000035  loss: 1.3699 (1.5989)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [550/781]  eta: 0:01:17  lr: 0.000035  loss: 1.3531 (1.5994)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [560/781]  eta: 0:01:13  lr: 0.000035  loss: 1.3462 (1.5966)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [570/781]  eta: 0:01:10  lr: 0.000035  loss: 1.3613 (1.5941)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [580/781]  eta: 0:01:07  lr: 0.000035  loss: 1.3868 (1.5913)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [590/781]  eta: 0:01:03  lr: 0.000035  loss: 1.3868 (1.5945)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [600/781]  eta: 0:01:00  lr: 0.000035  loss: 1.3778 (1.5930)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [610/781]  eta: 0:00:57  lr: 0.000035  loss: 1.3658 (1.5907)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [620/781]  eta: 0:00:53  lr: 0.000035  loss: 1.3818 (1.5915)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [630/781]  eta: 0:00:50  lr: 0.000035  loss: 1.3715 (1.5897)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [640/781]  eta: 0:00:47  lr: 0.000035  loss: 1.3695 (1.5930)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [650/781]  eta: 0:00:43  lr: 0.000035  loss: 1.3666 (1.5914)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [660/781]  eta: 0:00:40  lr: 0.000035  loss: 1.3666 (1.5953)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [670/781]  eta: 0:00:37  lr: 0.000035  loss: 1.3912 (1.5948)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [680/781]  eta: 0:00:33  lr: 0.000035  loss: 1.3770 (1.5942)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [690/781]  eta: 0:00:30  lr: 0.000035  loss: 1.4104 (1.5951)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [700/781]  eta: 0:00:27  lr: 0.000035  loss: 1.3975 (1.5932)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [710/781]  eta: 0:00:23  lr: 0.000035  loss: 1.4191 (1.5906)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [720/781]  eta: 0:00:20  lr: 0.000035  loss: 1.3759 (1.5884)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [730/781]  eta: 0:00:17  lr: 0.000035  loss: 1.3459 (1.5877)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [740/781]  eta: 0:00:13  lr: 0.000035  loss: 1.3506 (1.5845)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [750/781]  eta: 0:00:10  lr: 0.000035  loss: 1.3590 (1.5823)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [760/781]  eta: 0:00:07  lr: 0.000035  loss: 1.3954 (1.5819)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [770/781]  eta: 0:00:03  lr: 0.000035  loss: 1.3913 (1.5800)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [780/781]  eta: 0:00:00  lr: 0.000035  loss: 1.3843 (1.5809)  time: 0.3327  data: 0.0006  max mem: 6459\n",
            "Epoch: [63] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000035  loss: 1.3843 (1.5809)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3247182369232178, 'lambda_convnext_base': 0.25580671429634094, 'lambda_tf_efficientnetv2_l': 0.4194749593734741}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.9010 (0.9010)  acc1: 81.2500 (81.2500)  acc5: 93.2292 (93.2292)  time: 0.8340  data: 0.8031  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0510 (1.0029)  acc1: 80.7292 (80.8239)  acc5: 93.2292 (93.1345)  time: 0.1703  data: 0.1396  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0510 (1.0688)  acc1: 79.6875 (79.5139)  acc5: 92.7083 (92.4107)  time: 0.1235  data: 0.0928  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1944 (1.1176)  acc1: 77.0833 (78.6290)  acc5: 90.6250 (91.7843)  time: 0.1281  data: 0.0974  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2156 (1.1576)  acc1: 76.5625 (77.7566)  acc5: 90.1042 (91.4761)  time: 0.1272  data: 0.0965  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1321 (1.1509)  acc1: 77.6042 (77.6757)  acc5: 91.6667 (91.6871)  time: 0.1276  data: 0.0969  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1363 (1.1596)  acc1: 76.0417 (77.5100)  acc5: 92.1875 (91.7100)  time: 0.1105  data: 0.0807  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1336 s / it)\n",
            "* Acc@1 77.510 Acc@5 91.710 loss 1.160\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=64 distillation_alpha=0.4356\n",
            "Epoch: [64]  [  0/781]  eta: 0:14:44  lr: 0.000034  loss: 1.2281 (1.2281)  time: 1.1320  data: 0.7862  max mem: 6459\n",
            "Epoch: [64]  [ 10/781]  eta: 0:05:12  lr: 0.000034  loss: 1.3983 (1.5588)  time: 0.4059  data: 0.0718  max mem: 6459\n",
            "Epoch: [64]  [ 20/781]  eta: 0:04:42  lr: 0.000034  loss: 1.3741 (1.5918)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 30/781]  eta: 0:04:29  lr: 0.000034  loss: 1.4366 (1.6126)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 40/781]  eta: 0:04:21  lr: 0.000034  loss: 1.4366 (1.6141)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 50/781]  eta: 0:04:15  lr: 0.000034  loss: 1.3611 (1.6116)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 60/781]  eta: 0:04:09  lr: 0.000034  loss: 1.3833 (1.6064)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 70/781]  eta: 0:04:05  lr: 0.000034  loss: 1.3783 (1.6029)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 80/781]  eta: 0:04:00  lr: 0.000034  loss: 1.3297 (1.5780)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 90/781]  eta: 0:03:56  lr: 0.000034  loss: 1.3867 (1.5943)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [100/781]  eta: 0:03:52  lr: 0.000034  loss: 1.4339 (1.5991)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [110/781]  eta: 0:03:48  lr: 0.000034  loss: 1.4295 (1.6155)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [120/781]  eta: 0:03:44  lr: 0.000034  loss: 1.5112 (1.6215)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [130/781]  eta: 0:03:40  lr: 0.000034  loss: 1.5112 (1.6192)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [140/781]  eta: 0:03:37  lr: 0.000034  loss: 1.4260 (1.6138)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [150/781]  eta: 0:03:33  lr: 0.000034  loss: 1.3745 (1.6006)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [160/781]  eta: 0:03:29  lr: 0.000034  loss: 1.3328 (1.5968)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [170/781]  eta: 0:03:26  lr: 0.000034  loss: 1.3328 (1.5882)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [180/781]  eta: 0:03:22  lr: 0.000034  loss: 1.4000 (1.5934)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [190/781]  eta: 0:03:19  lr: 0.000034  loss: 1.3942 (1.5868)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [200/781]  eta: 0:03:15  lr: 0.000034  loss: 1.3810 (1.5891)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [210/781]  eta: 0:03:12  lr: 0.000034  loss: 1.3781 (1.5905)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [220/781]  eta: 0:03:08  lr: 0.000034  loss: 1.3733 (1.5870)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [230/781]  eta: 0:03:05  lr: 0.000034  loss: 1.3686 (1.5773)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [240/781]  eta: 0:03:01  lr: 0.000034  loss: 1.3912 (1.5805)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [250/781]  eta: 0:02:58  lr: 0.000034  loss: 1.4031 (1.5814)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [260/781]  eta: 0:02:55  lr: 0.000034  loss: 1.3822 (1.5783)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [270/781]  eta: 0:02:51  lr: 0.000034  loss: 1.3822 (1.5781)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [280/781]  eta: 0:02:48  lr: 0.000034  loss: 1.3570 (1.5803)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [290/781]  eta: 0:02:44  lr: 0.000034  loss: 1.3799 (1.5822)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [300/781]  eta: 0:02:41  lr: 0.000034  loss: 1.3799 (1.5792)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [310/781]  eta: 0:02:37  lr: 0.000034  loss: 1.4018 (1.5812)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [320/781]  eta: 0:02:34  lr: 0.000034  loss: 1.4084 (1.5844)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [330/781]  eta: 0:02:31  lr: 0.000034  loss: 1.4334 (1.5828)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [340/781]  eta: 0:02:27  lr: 0.000034  loss: 1.3766 (1.5808)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [350/781]  eta: 0:02:24  lr: 0.000034  loss: 1.3376 (1.5788)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [360/781]  eta: 0:02:21  lr: 0.000034  loss: 1.3629 (1.5755)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [370/781]  eta: 0:02:17  lr: 0.000034  loss: 1.3969 (1.5728)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [380/781]  eta: 0:02:14  lr: 0.000034  loss: 1.3727 (1.5690)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [390/781]  eta: 0:02:10  lr: 0.000034  loss: 1.3883 (1.5750)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [400/781]  eta: 0:02:07  lr: 0.000034  loss: 1.8951 (1.5812)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [410/781]  eta: 0:02:04  lr: 0.000034  loss: 1.4943 (1.5828)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [420/781]  eta: 0:02:00  lr: 0.000034  loss: 1.4229 (1.5810)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [430/781]  eta: 0:01:57  lr: 0.000034  loss: 1.4135 (1.5825)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [440/781]  eta: 0:01:54  lr: 0.000034  loss: 1.3380 (1.5795)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [450/781]  eta: 0:01:50  lr: 0.000034  loss: 1.3693 (1.5828)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [460/781]  eta: 0:01:47  lr: 0.000034  loss: 1.3968 (1.5851)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [470/781]  eta: 0:01:44  lr: 0.000034  loss: 1.3950 (1.5860)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [480/781]  eta: 0:01:40  lr: 0.000034  loss: 1.3660 (1.5847)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [490/781]  eta: 0:01:37  lr: 0.000034  loss: 1.4103 (1.5864)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [500/781]  eta: 0:01:33  lr: 0.000034  loss: 1.4694 (1.5883)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [510/781]  eta: 0:01:30  lr: 0.000034  loss: 1.4716 (1.5883)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [520/781]  eta: 0:01:27  lr: 0.000034  loss: 1.4716 (1.5932)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [530/781]  eta: 0:01:23  lr: 0.000034  loss: 1.4290 (1.5937)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [540/781]  eta: 0:01:20  lr: 0.000034  loss: 1.3727 (1.5934)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [550/781]  eta: 0:01:17  lr: 0.000034  loss: 1.3841 (1.5933)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [560/781]  eta: 0:01:13  lr: 0.000034  loss: 1.3679 (1.5939)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [570/781]  eta: 0:01:10  lr: 0.000034  loss: 1.3679 (1.5921)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [580/781]  eta: 0:01:07  lr: 0.000034  loss: 1.4022 (1.5937)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [590/781]  eta: 0:01:03  lr: 0.000034  loss: 1.6651 (1.5977)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [600/781]  eta: 0:01:00  lr: 0.000034  loss: 1.4374 (1.5968)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [610/781]  eta: 0:00:57  lr: 0.000034  loss: 1.4106 (1.5988)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [620/781]  eta: 0:00:53  lr: 0.000034  loss: 1.4106 (1.5988)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [630/781]  eta: 0:00:50  lr: 0.000034  loss: 1.3533 (1.5950)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [640/781]  eta: 0:00:47  lr: 0.000034  loss: 1.3508 (1.5940)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [650/781]  eta: 0:00:43  lr: 0.000034  loss: 1.3392 (1.5935)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [660/781]  eta: 0:00:40  lr: 0.000034  loss: 1.3134 (1.5897)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [670/781]  eta: 0:00:37  lr: 0.000034  loss: 1.3432 (1.5924)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [680/781]  eta: 0:00:33  lr: 0.000034  loss: 1.4157 (1.5935)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [690/781]  eta: 0:00:30  lr: 0.000034  loss: 1.4080 (1.5933)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [700/781]  eta: 0:00:27  lr: 0.000034  loss: 1.3420 (1.5934)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [710/781]  eta: 0:00:23  lr: 0.000034  loss: 1.3374 (1.5938)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [720/781]  eta: 0:00:20  lr: 0.000034  loss: 1.3584 (1.5926)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [730/781]  eta: 0:00:17  lr: 0.000034  loss: 1.4027 (1.5936)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [740/781]  eta: 0:00:13  lr: 0.000034  loss: 1.4142 (1.5950)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [750/781]  eta: 0:00:10  lr: 0.000034  loss: 1.3554 (1.5950)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [760/781]  eta: 0:00:07  lr: 0.000034  loss: 1.3502 (1.5928)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [770/781]  eta: 0:00:03  lr: 0.000034  loss: 1.3846 (1.5955)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [780/781]  eta: 0:00:00  lr: 0.000034  loss: 1.5309 (1.5972)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [64] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000034  loss: 1.5309 (1.5972)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3238149583339691, 'lambda_convnext_base': 0.25578242540359497, 'lambda_tf_efficientnetv2_l': 0.42040249705314636}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8233 (0.8233)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8317  data: 0.8008  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0048 (1.0187)  acc1: 82.8125 (80.1136)  acc5: 94.2708 (93.4659)  time: 0.1708  data: 0.1401  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0832 (1.0647)  acc1: 76.5625 (79.0923)  acc5: 93.7500 (92.4851)  time: 0.1153  data: 0.0846  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1504 (1.1108)  acc1: 77.6042 (78.4106)  acc5: 91.6667 (91.9187)  time: 0.1154  data: 0.0847  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2292 (1.1542)  acc1: 77.0833 (77.7058)  acc5: 91.1458 (91.5650)  time: 0.1169  data: 0.0862  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1413 (1.1534)  acc1: 77.0833 (77.4408)  acc5: 92.7083 (91.7688)  time: 0.1168  data: 0.0861  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1515 (1.1634)  acc1: 76.0417 (77.3500)  acc5: 92.7083 (91.7900)  time: 0.1005  data: 0.0707  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1250 s / it)\n",
            "* Acc@1 77.350 Acc@5 91.790 loss 1.163\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=65 distillation_alpha=0.4434\n",
            "Epoch: [65]  [  0/781]  eta: 0:14:28  lr: 0.000034  loss: 2.3133 (2.3133)  time: 1.1119  data: 0.7734  max mem: 6459\n",
            "Epoch: [65]  [ 10/781]  eta: 0:05:11  lr: 0.000034  loss: 1.4010 (1.5304)  time: 0.4037  data: 0.0706  max mem: 6459\n",
            "Epoch: [65]  [ 20/781]  eta: 0:04:41  lr: 0.000034  loss: 1.3902 (1.5456)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 30/781]  eta: 0:04:34  lr: 0.000034  loss: 1.4340 (1.5898)  time: 0.3438  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 40/781]  eta: 0:04:24  lr: 0.000034  loss: 1.6142 (1.6493)  time: 0.3437  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 50/781]  eta: 0:04:17  lr: 0.000034  loss: 1.4744 (1.6530)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 60/781]  eta: 0:04:11  lr: 0.000034  loss: 1.3777 (1.6413)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 70/781]  eta: 0:04:06  lr: 0.000034  loss: 1.3302 (1.6240)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 80/781]  eta: 0:04:01  lr: 0.000034  loss: 1.3486 (1.6116)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 90/781]  eta: 0:03:57  lr: 0.000034  loss: 1.3486 (1.6036)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [100/781]  eta: 0:03:53  lr: 0.000034  loss: 1.3650 (1.5943)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [110/781]  eta: 0:03:49  lr: 0.000034  loss: 1.3694 (1.5809)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [120/781]  eta: 0:03:45  lr: 0.000034  loss: 1.3425 (1.5650)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [130/781]  eta: 0:03:41  lr: 0.000034  loss: 1.3428 (1.5638)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [140/781]  eta: 0:03:37  lr: 0.000034  loss: 1.3913 (1.5695)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [150/781]  eta: 0:03:34  lr: 0.000034  loss: 1.3751 (1.5658)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [160/781]  eta: 0:03:30  lr: 0.000034  loss: 1.3602 (1.5581)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [170/781]  eta: 0:03:26  lr: 0.000034  loss: 1.3603 (1.5623)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [180/781]  eta: 0:03:23  lr: 0.000034  loss: 1.3867 (1.5674)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [190/781]  eta: 0:03:19  lr: 0.000034  loss: 1.3867 (1.5687)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [200/781]  eta: 0:03:16  lr: 0.000034  loss: 1.3596 (1.5750)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [210/781]  eta: 0:03:12  lr: 0.000034  loss: 1.3768 (1.5704)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [220/781]  eta: 0:03:09  lr: 0.000034  loss: 1.3403 (1.5602)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [230/781]  eta: 0:03:05  lr: 0.000034  loss: 1.3403 (1.5607)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [240/781]  eta: 0:03:02  lr: 0.000034  loss: 1.3181 (1.5573)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [250/781]  eta: 0:02:58  lr: 0.000034  loss: 1.3181 (1.5567)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [260/781]  eta: 0:02:55  lr: 0.000034  loss: 1.3578 (1.5561)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [270/781]  eta: 0:02:51  lr: 0.000034  loss: 1.4051 (1.5556)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [280/781]  eta: 0:02:48  lr: 0.000034  loss: 1.4162 (1.5599)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [290/781]  eta: 0:02:45  lr: 0.000034  loss: 1.4442 (1.5649)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [300/781]  eta: 0:02:41  lr: 0.000034  loss: 1.4247 (1.5638)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [310/781]  eta: 0:02:38  lr: 0.000034  loss: 1.3584 (1.5598)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [320/781]  eta: 0:02:34  lr: 0.000034  loss: 1.3517 (1.5614)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [330/781]  eta: 0:02:31  lr: 0.000034  loss: 1.3863 (1.5575)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [340/781]  eta: 0:02:28  lr: 0.000034  loss: 1.3863 (1.5614)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [350/781]  eta: 0:02:24  lr: 0.000034  loss: 1.3644 (1.5599)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [360/781]  eta: 0:02:21  lr: 0.000034  loss: 1.3644 (1.5595)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [370/781]  eta: 0:02:17  lr: 0.000034  loss: 1.3682 (1.5584)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [380/781]  eta: 0:02:14  lr: 0.000034  loss: 1.3669 (1.5583)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [390/781]  eta: 0:02:11  lr: 0.000034  loss: 1.3633 (1.5559)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [400/781]  eta: 0:02:07  lr: 0.000034  loss: 1.4240 (1.5577)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [410/781]  eta: 0:02:04  lr: 0.000034  loss: 1.3981 (1.5573)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [420/781]  eta: 0:02:01  lr: 0.000034  loss: 1.4036 (1.5615)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [430/781]  eta: 0:01:57  lr: 0.000034  loss: 1.3903 (1.5587)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [440/781]  eta: 0:01:54  lr: 0.000034  loss: 1.3482 (1.5580)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [450/781]  eta: 0:01:50  lr: 0.000034  loss: 1.3627 (1.5578)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [460/781]  eta: 0:01:47  lr: 0.000034  loss: 1.3769 (1.5545)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [470/781]  eta: 0:01:44  lr: 0.000034  loss: 1.4361 (1.5586)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [480/781]  eta: 0:01:40  lr: 0.000034  loss: 1.3914 (1.5554)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [490/781]  eta: 0:01:37  lr: 0.000034  loss: 1.3793 (1.5576)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [500/781]  eta: 0:01:34  lr: 0.000034  loss: 1.4072 (1.5585)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [510/781]  eta: 0:01:30  lr: 0.000034  loss: 1.4482 (1.5602)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [520/781]  eta: 0:01:27  lr: 0.000034  loss: 1.4808 (1.5641)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [530/781]  eta: 0:01:24  lr: 0.000034  loss: 1.3687 (1.5642)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [540/781]  eta: 0:01:20  lr: 0.000034  loss: 1.3507 (1.5626)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [550/781]  eta: 0:01:17  lr: 0.000034  loss: 1.3709 (1.5631)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [560/781]  eta: 0:01:13  lr: 0.000034  loss: 1.3998 (1.5608)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [570/781]  eta: 0:01:10  lr: 0.000034  loss: 1.3977 (1.5603)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [580/781]  eta: 0:01:07  lr: 0.000034  loss: 1.3641 (1.5605)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [590/781]  eta: 0:01:03  lr: 0.000034  loss: 1.3995 (1.5587)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [600/781]  eta: 0:01:00  lr: 0.000034  loss: 1.3995 (1.5625)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [610/781]  eta: 0:00:57  lr: 0.000034  loss: 1.3563 (1.5598)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [620/781]  eta: 0:00:53  lr: 0.000034  loss: 1.3193 (1.5580)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [630/781]  eta: 0:00:50  lr: 0.000034  loss: 1.3619 (1.5580)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [640/781]  eta: 0:00:47  lr: 0.000034  loss: 1.3925 (1.5590)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [650/781]  eta: 0:00:43  lr: 0.000034  loss: 1.3710 (1.5583)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [660/781]  eta: 0:00:40  lr: 0.000034  loss: 1.3439 (1.5568)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [670/781]  eta: 0:00:37  lr: 0.000034  loss: 1.3227 (1.5564)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [680/781]  eta: 0:00:33  lr: 0.000034  loss: 1.3932 (1.5574)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [690/781]  eta: 0:00:30  lr: 0.000034  loss: 1.3932 (1.5595)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [700/781]  eta: 0:00:27  lr: 0.000034  loss: 1.4067 (1.5606)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [710/781]  eta: 0:00:23  lr: 0.000034  loss: 1.4067 (1.5611)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [720/781]  eta: 0:00:20  lr: 0.000034  loss: 1.4012 (1.5627)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [730/781]  eta: 0:00:17  lr: 0.000034  loss: 1.3985 (1.5632)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [740/781]  eta: 0:00:13  lr: 0.000034  loss: 1.3543 (1.5623)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [750/781]  eta: 0:00:10  lr: 0.000034  loss: 1.3519 (1.5594)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [760/781]  eta: 0:00:07  lr: 0.000034  loss: 1.3571 (1.5574)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [770/781]  eta: 0:00:03  lr: 0.000034  loss: 1.3869 (1.5594)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [780/781]  eta: 0:00:00  lr: 0.000034  loss: 1.4239 (1.5591)  time: 0.3327  data: 0.0005  max mem: 6459\n",
            "Epoch: [65] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000034  loss: 1.4239 (1.5591)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3249085545539856, 'lambda_convnext_base': 0.2553040087223053, 'lambda_tf_efficientnetv2_l': 0.41978776454925537}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8114 (0.8114)  acc1: 81.7708 (81.7708)  acc5: 95.3125 (95.3125)  time: 0.8223  data: 0.7879  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0535 (1.0157)  acc1: 81.2500 (80.3504)  acc5: 93.2292 (93.1818)  time: 0.1654  data: 0.1344  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1313 (1.0854)  acc1: 76.0417 (78.7946)  acc5: 92.7083 (92.3363)  time: 0.1229  data: 0.0923  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1893 (1.1336)  acc1: 76.0417 (77.9906)  acc5: 91.6667 (91.8347)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2469 (1.1725)  acc1: 76.5625 (77.3374)  acc5: 90.1042 (91.5396)  time: 0.1234  data: 0.0928  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1190 (1.1700)  acc1: 76.0417 (77.1140)  acc5: 92.7083 (91.7688)  time: 0.1233  data: 0.0926  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2231 (1.1771)  acc1: 75.5208 (76.9900)  acc5: 92.7083 (91.7900)  time: 0.1037  data: 0.0740  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1299 s / it)\n",
            "* Acc@1 76.990 Acc@5 91.790 loss 1.177\n",
            "Accuracy of the network on the 10000 test images: 77.0%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=66 distillation_alpha=0.4512\n",
            "Epoch: [66]  [  0/781]  eta: 0:14:21  lr: 0.000033  loss: 1.4034 (1.4034)  time: 1.1026  data: 0.7585  max mem: 6459\n",
            "Epoch: [66]  [ 10/781]  eta: 0:05:10  lr: 0.000033  loss: 1.3515 (1.4370)  time: 0.4032  data: 0.0692  max mem: 6459\n",
            "Epoch: [66]  [ 20/781]  eta: 0:04:41  lr: 0.000033  loss: 1.3368 (1.4515)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 30/781]  eta: 0:04:28  lr: 0.000033  loss: 1.3883 (1.5061)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 40/781]  eta: 0:04:20  lr: 0.000033  loss: 1.3710 (1.4766)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 50/781]  eta: 0:04:14  lr: 0.000033  loss: 1.3620 (1.5279)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 60/781]  eta: 0:04:09  lr: 0.000033  loss: 1.4040 (1.5406)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 70/781]  eta: 0:04:04  lr: 0.000033  loss: 1.3313 (1.5327)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 80/781]  eta: 0:03:59  lr: 0.000033  loss: 1.3200 (1.5243)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 90/781]  eta: 0:03:55  lr: 0.000033  loss: 1.3073 (1.5202)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [100/781]  eta: 0:03:51  lr: 0.000033  loss: 1.3318 (1.5274)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [110/781]  eta: 0:03:47  lr: 0.000033  loss: 1.3542 (1.5344)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [120/781]  eta: 0:03:44  lr: 0.000033  loss: 1.3542 (1.5441)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [130/781]  eta: 0:03:40  lr: 0.000033  loss: 1.4639 (1.5553)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [140/781]  eta: 0:03:36  lr: 0.000033  loss: 1.5360 (1.5680)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [150/781]  eta: 0:03:33  lr: 0.000033  loss: 1.4126 (1.5697)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [160/781]  eta: 0:03:29  lr: 0.000033  loss: 1.3888 (1.5642)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [170/781]  eta: 0:03:26  lr: 0.000033  loss: 1.4236 (1.5840)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [180/781]  eta: 0:03:22  lr: 0.000033  loss: 1.5018 (1.5866)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [190/781]  eta: 0:03:19  lr: 0.000033  loss: 1.3873 (1.5917)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [200/781]  eta: 0:03:15  lr: 0.000033  loss: 1.4277 (1.5933)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [210/781]  eta: 0:03:12  lr: 0.000033  loss: 1.4277 (1.5898)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [220/781]  eta: 0:03:08  lr: 0.000033  loss: 1.3835 (1.5885)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [230/781]  eta: 0:03:05  lr: 0.000033  loss: 1.3953 (1.5861)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [240/781]  eta: 0:03:01  lr: 0.000033  loss: 1.4081 (1.5816)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [250/781]  eta: 0:02:58  lr: 0.000033  loss: 1.3814 (1.5784)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [260/781]  eta: 0:02:54  lr: 0.000033  loss: 1.4089 (1.5819)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [270/781]  eta: 0:02:51  lr: 0.000033  loss: 1.3779 (1.5755)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [280/781]  eta: 0:02:48  lr: 0.000033  loss: 1.3552 (1.5763)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [290/781]  eta: 0:02:44  lr: 0.000033  loss: 1.3919 (1.5729)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [300/781]  eta: 0:02:41  lr: 0.000033  loss: 1.3715 (1.5714)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [310/781]  eta: 0:02:37  lr: 0.000033  loss: 1.3715 (1.5714)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [320/781]  eta: 0:02:34  lr: 0.000033  loss: 1.3562 (1.5659)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [330/781]  eta: 0:02:31  lr: 0.000033  loss: 1.3621 (1.5684)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [340/781]  eta: 0:02:27  lr: 0.000033  loss: 1.3890 (1.5679)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [350/781]  eta: 0:02:24  lr: 0.000033  loss: 1.3751 (1.5646)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [360/781]  eta: 0:02:21  lr: 0.000033  loss: 1.3901 (1.5661)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [370/781]  eta: 0:02:17  lr: 0.000033  loss: 1.3956 (1.5653)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [380/781]  eta: 0:02:14  lr: 0.000033  loss: 1.3654 (1.5635)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [390/781]  eta: 0:02:10  lr: 0.000033  loss: 1.3733 (1.5660)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [400/781]  eta: 0:02:07  lr: 0.000033  loss: 1.3733 (1.5644)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [410/781]  eta: 0:02:04  lr: 0.000033  loss: 1.3265 (1.5639)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [420/781]  eta: 0:02:00  lr: 0.000033  loss: 1.4268 (1.5611)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [430/781]  eta: 0:01:57  lr: 0.000033  loss: 1.4337 (1.5622)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [440/781]  eta: 0:01:54  lr: 0.000033  loss: 1.4272 (1.5590)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [450/781]  eta: 0:01:50  lr: 0.000033  loss: 1.2923 (1.5542)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [460/781]  eta: 0:01:47  lr: 0.000033  loss: 1.2887 (1.5547)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [470/781]  eta: 0:01:44  lr: 0.000033  loss: 1.3427 (1.5558)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [480/781]  eta: 0:01:40  lr: 0.000033  loss: 1.3229 (1.5587)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [490/781]  eta: 0:01:37  lr: 0.000033  loss: 1.3554 (1.5600)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [500/781]  eta: 0:01:33  lr: 0.000033  loss: 1.3843 (1.5615)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [510/781]  eta: 0:01:30  lr: 0.000033  loss: 1.4096 (1.5637)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [520/781]  eta: 0:01:27  lr: 0.000033  loss: 1.3943 (1.5626)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [530/781]  eta: 0:01:23  lr: 0.000033  loss: 1.3526 (1.5626)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [540/781]  eta: 0:01:20  lr: 0.000033  loss: 1.3863 (1.5649)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [550/781]  eta: 0:01:17  lr: 0.000033  loss: 1.5251 (1.5696)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [560/781]  eta: 0:01:13  lr: 0.000033  loss: 1.4316 (1.5691)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [570/781]  eta: 0:01:10  lr: 0.000033  loss: 1.3795 (1.5691)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [580/781]  eta: 0:01:07  lr: 0.000033  loss: 1.3831 (1.5673)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [590/781]  eta: 0:01:03  lr: 0.000033  loss: 1.3781 (1.5666)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [600/781]  eta: 0:01:00  lr: 0.000033  loss: 1.3781 (1.5661)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [610/781]  eta: 0:00:57  lr: 0.000033  loss: 1.4098 (1.5659)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [620/781]  eta: 0:00:53  lr: 0.000033  loss: 1.3732 (1.5645)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [630/781]  eta: 0:00:50  lr: 0.000033  loss: 1.3893 (1.5653)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [640/781]  eta: 0:00:47  lr: 0.000033  loss: 1.3898 (1.5656)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [650/781]  eta: 0:00:43  lr: 0.000033  loss: 1.3536 (1.5656)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [660/781]  eta: 0:00:40  lr: 0.000033  loss: 1.3430 (1.5631)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [670/781]  eta: 0:00:37  lr: 0.000033  loss: 1.3615 (1.5652)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [680/781]  eta: 0:00:33  lr: 0.000033  loss: 1.3850 (1.5630)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [690/781]  eta: 0:00:30  lr: 0.000033  loss: 1.3655 (1.5643)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [700/781]  eta: 0:00:27  lr: 0.000033  loss: 1.4268 (1.5662)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [710/781]  eta: 0:00:23  lr: 0.000033  loss: 1.3722 (1.5637)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [720/781]  eta: 0:00:20  lr: 0.000033  loss: 1.3006 (1.5625)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [730/781]  eta: 0:00:17  lr: 0.000033  loss: 1.3692 (1.5624)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [740/781]  eta: 0:00:13  lr: 0.000033  loss: 1.3720 (1.5629)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [750/781]  eta: 0:00:10  lr: 0.000033  loss: 1.3689 (1.5639)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [760/781]  eta: 0:00:07  lr: 0.000033  loss: 1.4587 (1.5666)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [770/781]  eta: 0:00:03  lr: 0.000033  loss: 1.3772 (1.5651)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [780/781]  eta: 0:00:00  lr: 0.000033  loss: 1.3600 (1.5628)  time: 0.3328  data: 0.0005  max mem: 6459\n",
            "Epoch: [66] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000033  loss: 1.3600 (1.5628)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3249739408493042, 'lambda_convnext_base': 0.2559063136577606, 'lambda_tf_efficientnetv2_l': 0.419119656085968}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7575 (0.7575)  acc1: 83.3333 (83.3333)  acc5: 96.3542 (96.3542)  time: 0.8515  data: 0.8206  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9538 (0.9969)  acc1: 81.2500 (80.3977)  acc5: 94.7917 (93.4659)  time: 0.1699  data: 0.1392  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0637 (1.0850)  acc1: 80.7292 (78.7946)  acc5: 92.7083 (92.1379)  time: 0.1253  data: 0.0946  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1820 (1.1250)  acc1: 77.0833 (78.3602)  acc5: 91.1458 (91.7171)  time: 0.1260  data: 0.0953  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1820 (1.1593)  acc1: 76.0417 (77.7185)  acc5: 90.1042 (91.5015)  time: 0.1206  data: 0.0899  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0882 (1.1506)  acc1: 78.6458 (77.6144)  acc5: 92.1875 (91.7382)  time: 0.1217  data: 0.0911  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1297 (1.1629)  acc1: 75.0000 (77.4800)  acc5: 92.1875 (91.7400)  time: 0.1036  data: 0.0740  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1304 s / it)\n",
            "* Acc@1 77.480 Acc@5 91.740 loss 1.163\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=67 distillation_alpha=0.4590\n",
            "Epoch: [67]  [  0/781]  eta: 0:14:30  lr: 0.000032  loss: 1.3137 (1.3137)  time: 1.1149  data: 0.7714  max mem: 6459\n",
            "Epoch: [67]  [ 10/781]  eta: 0:05:11  lr: 0.000032  loss: 1.8052 (1.7150)  time: 0.4042  data: 0.0704  max mem: 6459\n",
            "Epoch: [67]  [ 20/781]  eta: 0:04:41  lr: 0.000032  loss: 1.3374 (1.5954)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 30/781]  eta: 0:04:28  lr: 0.000032  loss: 1.3272 (1.5976)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 40/781]  eta: 0:04:20  lr: 0.000032  loss: 1.3339 (1.5480)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 50/781]  eta: 0:04:14  lr: 0.000032  loss: 1.3825 (1.5856)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 60/781]  eta: 0:04:09  lr: 0.000032  loss: 1.3794 (1.5599)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 70/781]  eta: 0:04:04  lr: 0.000032  loss: 1.3794 (1.5611)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 80/781]  eta: 0:04:00  lr: 0.000032  loss: 1.3755 (1.5537)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 90/781]  eta: 0:03:55  lr: 0.000032  loss: 1.3482 (1.5458)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [100/781]  eta: 0:03:51  lr: 0.000032  loss: 1.3493 (1.5621)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [110/781]  eta: 0:03:47  lr: 0.000032  loss: 1.3493 (1.5661)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [120/781]  eta: 0:03:44  lr: 0.000032  loss: 1.3412 (1.5612)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [130/781]  eta: 0:03:40  lr: 0.000032  loss: 1.3589 (1.5801)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [140/781]  eta: 0:03:36  lr: 0.000032  loss: 1.3208 (1.5599)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [150/781]  eta: 0:03:33  lr: 0.000032  loss: 1.3614 (1.5629)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [160/781]  eta: 0:03:29  lr: 0.000032  loss: 1.3684 (1.5491)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [170/781]  eta: 0:03:26  lr: 0.000032  loss: 1.3459 (1.5482)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [180/781]  eta: 0:03:22  lr: 0.000032  loss: 1.3761 (1.5424)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [190/781]  eta: 0:03:19  lr: 0.000032  loss: 1.3946 (1.5536)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [200/781]  eta: 0:03:15  lr: 0.000032  loss: 1.3680 (1.5507)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [210/781]  eta: 0:03:12  lr: 0.000032  loss: 1.3302 (1.5441)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [220/781]  eta: 0:03:08  lr: 0.000032  loss: 1.3847 (1.5543)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [230/781]  eta: 0:03:05  lr: 0.000032  loss: 1.4332 (1.5583)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [240/781]  eta: 0:03:01  lr: 0.000032  loss: 1.3634 (1.5561)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [250/781]  eta: 0:02:58  lr: 0.000032  loss: 1.3116 (1.5535)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [260/781]  eta: 0:02:54  lr: 0.000032  loss: 1.4105 (1.5573)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [270/781]  eta: 0:02:51  lr: 0.000032  loss: 1.3821 (1.5534)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [280/781]  eta: 0:02:48  lr: 0.000032  loss: 1.3379 (1.5570)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [290/781]  eta: 0:02:44  lr: 0.000032  loss: 1.3379 (1.5519)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [300/781]  eta: 0:02:41  lr: 0.000032  loss: 1.3235 (1.5442)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [310/781]  eta: 0:02:37  lr: 0.000032  loss: 1.3826 (1.5472)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [320/781]  eta: 0:02:34  lr: 0.000032  loss: 1.3793 (1.5463)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [330/781]  eta: 0:02:31  lr: 0.000032  loss: 1.3742 (1.5503)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [340/781]  eta: 0:02:27  lr: 0.000032  loss: 1.4008 (1.5508)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [350/781]  eta: 0:02:24  lr: 0.000032  loss: 1.3980 (1.5555)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [360/781]  eta: 0:02:20  lr: 0.000032  loss: 1.4070 (1.5590)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [370/781]  eta: 0:02:17  lr: 0.000032  loss: 1.4112 (1.5653)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [380/781]  eta: 0:02:14  lr: 0.000032  loss: 1.3653 (1.5633)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [390/781]  eta: 0:02:10  lr: 0.000032  loss: 1.3342 (1.5604)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [400/781]  eta: 0:02:07  lr: 0.000032  loss: 1.3376 (1.5612)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [410/781]  eta: 0:02:04  lr: 0.000032  loss: 1.3463 (1.5617)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [420/781]  eta: 0:02:00  lr: 0.000032  loss: 1.3388 (1.5597)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [430/781]  eta: 0:01:57  lr: 0.000032  loss: 1.3055 (1.5584)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [440/781]  eta: 0:01:54  lr: 0.000032  loss: 1.3409 (1.5579)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [450/781]  eta: 0:01:50  lr: 0.000032  loss: 1.3311 (1.5545)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [460/781]  eta: 0:01:47  lr: 0.000032  loss: 1.3286 (1.5532)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [470/781]  eta: 0:01:43  lr: 0.000032  loss: 1.3771 (1.5571)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [480/781]  eta: 0:01:40  lr: 0.000032  loss: 1.4019 (1.5606)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [490/781]  eta: 0:01:37  lr: 0.000032  loss: 1.4019 (1.5631)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [500/781]  eta: 0:01:33  lr: 0.000032  loss: 1.3915 (1.5642)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [510/781]  eta: 0:01:30  lr: 0.000032  loss: 1.3551 (1.5610)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [520/781]  eta: 0:01:27  lr: 0.000032  loss: 1.3221 (1.5617)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [530/781]  eta: 0:01:23  lr: 0.000032  loss: 1.3727 (1.5608)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [540/781]  eta: 0:01:20  lr: 0.000032  loss: 1.3913 (1.5617)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [550/781]  eta: 0:01:17  lr: 0.000032  loss: 1.3754 (1.5598)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [560/781]  eta: 0:01:13  lr: 0.000032  loss: 1.3355 (1.5614)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [570/781]  eta: 0:01:10  lr: 0.000032  loss: 1.3917 (1.5627)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [580/781]  eta: 0:01:07  lr: 0.000032  loss: 1.3917 (1.5648)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [590/781]  eta: 0:01:03  lr: 0.000032  loss: 1.4089 (1.5640)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [600/781]  eta: 0:01:00  lr: 0.000032  loss: 1.4089 (1.5641)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [610/781]  eta: 0:00:57  lr: 0.000032  loss: 1.4027 (1.5648)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [620/781]  eta: 0:00:53  lr: 0.000032  loss: 1.4027 (1.5646)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [630/781]  eta: 0:00:50  lr: 0.000032  loss: 1.3666 (1.5630)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [640/781]  eta: 0:00:47  lr: 0.000032  loss: 1.3580 (1.5615)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [650/781]  eta: 0:00:43  lr: 0.000032  loss: 1.3475 (1.5617)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [660/781]  eta: 0:00:40  lr: 0.000032  loss: 1.3757 (1.5611)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [670/781]  eta: 0:00:37  lr: 0.000032  loss: 1.3893 (1.5622)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [680/781]  eta: 0:00:33  lr: 0.000032  loss: 1.4109 (1.5660)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [690/781]  eta: 0:00:30  lr: 0.000032  loss: 1.5044 (1.5697)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [700/781]  eta: 0:00:27  lr: 0.000032  loss: 1.3657 (1.5698)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [710/781]  eta: 0:00:23  lr: 0.000032  loss: 1.4240 (1.5714)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [720/781]  eta: 0:00:20  lr: 0.000032  loss: 1.3415 (1.5684)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [730/781]  eta: 0:00:17  lr: 0.000032  loss: 1.3315 (1.5657)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [740/781]  eta: 0:00:13  lr: 0.000032  loss: 1.3847 (1.5659)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [750/781]  eta: 0:00:10  lr: 0.000032  loss: 1.3408 (1.5639)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [760/781]  eta: 0:00:07  lr: 0.000032  loss: 1.3192 (1.5624)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [770/781]  eta: 0:00:03  lr: 0.000032  loss: 1.3674 (1.5623)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [780/781]  eta: 0:00:00  lr: 0.000032  loss: 1.4003 (1.5631)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [67] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000032  loss: 1.4003 (1.5631)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32541632652282715, 'lambda_convnext_base': 0.25601726770401, 'lambda_tf_efficientnetv2_l': 0.41856640577316284}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7921 (0.7921)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8502  data: 0.8192  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9826 (1.0001)  acc1: 82.8125 (80.7765)  acc5: 94.7917 (93.6553)  time: 0.1724  data: 0.1418  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0407 (1.0541)  acc1: 79.1667 (79.3403)  acc5: 92.7083 (92.7083)  time: 0.1204  data: 0.0897  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1595 (1.1140)  acc1: 75.5208 (78.3098)  acc5: 91.6667 (92.0867)  time: 0.1195  data: 0.0888  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2801 (1.1611)  acc1: 75.5208 (77.4263)  acc5: 89.0625 (91.5777)  time: 0.1187  data: 0.0880  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1709 (1.1629)  acc1: 74.4792 (77.1242)  acc5: 91.1458 (91.6871)  time: 0.1210  data: 0.0903  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2018 (1.1706)  acc1: 74.4792 (77.0400)  acc5: 92.1875 (91.7200)  time: 0.1037  data: 0.0740  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1284 s / it)\n",
            "* Acc@1 77.040 Acc@5 91.720 loss 1.171\n",
            "Accuracy of the network on the 10000 test images: 77.0%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=68 distillation_alpha=0.4668\n",
            "Epoch: [68]  [  0/781]  eta: 0:14:06  lr: 0.000031  loss: 1.2675 (1.2675)  time: 1.0835  data: 0.7352  max mem: 6459\n",
            "Epoch: [68]  [ 10/781]  eta: 0:05:09  lr: 0.000031  loss: 1.3386 (1.5189)  time: 0.4017  data: 0.0671  max mem: 6459\n",
            "Epoch: [68]  [ 20/781]  eta: 0:04:40  lr: 0.000031  loss: 1.3386 (1.5300)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 30/781]  eta: 0:04:28  lr: 0.000031  loss: 1.3261 (1.5381)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 40/781]  eta: 0:04:20  lr: 0.000031  loss: 1.3366 (1.5389)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 50/781]  eta: 0:04:14  lr: 0.000031  loss: 1.3736 (1.5383)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 60/781]  eta: 0:04:09  lr: 0.000031  loss: 1.3672 (1.5290)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 70/781]  eta: 0:04:04  lr: 0.000031  loss: 1.3477 (1.5474)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 80/781]  eta: 0:04:00  lr: 0.000031  loss: 1.3322 (1.5352)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 90/781]  eta: 0:03:55  lr: 0.000031  loss: 1.3877 (1.5289)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [100/781]  eta: 0:03:52  lr: 0.000031  loss: 1.3671 (1.5250)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [110/781]  eta: 0:03:48  lr: 0.000031  loss: 1.3598 (1.5281)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [120/781]  eta: 0:03:44  lr: 0.000031  loss: 1.4132 (1.5310)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [130/781]  eta: 0:03:40  lr: 0.000031  loss: 1.4221 (1.5418)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [140/781]  eta: 0:03:37  lr: 0.000031  loss: 1.4189 (1.5474)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [150/781]  eta: 0:03:33  lr: 0.000031  loss: 1.3905 (1.5430)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [160/781]  eta: 0:03:29  lr: 0.000031  loss: 1.3802 (1.5453)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [170/781]  eta: 0:03:26  lr: 0.000031  loss: 1.4206 (1.5551)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [180/781]  eta: 0:03:22  lr: 0.000031  loss: 1.4135 (1.5443)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [190/781]  eta: 0:03:19  lr: 0.000031  loss: 1.3368 (1.5369)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [200/781]  eta: 0:03:15  lr: 0.000031  loss: 1.3514 (1.5421)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [210/781]  eta: 0:03:12  lr: 0.000031  loss: 1.4158 (1.5461)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [220/781]  eta: 0:03:08  lr: 0.000031  loss: 1.4305 (1.5487)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [230/781]  eta: 0:03:05  lr: 0.000031  loss: 1.3835 (1.5450)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [240/781]  eta: 0:03:01  lr: 0.000031  loss: 1.3289 (1.5409)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [250/781]  eta: 0:02:58  lr: 0.000031  loss: 1.3640 (1.5384)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [260/781]  eta: 0:02:55  lr: 0.000031  loss: 1.4001 (1.5435)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [270/781]  eta: 0:02:51  lr: 0.000031  loss: 1.4434 (1.5394)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [280/781]  eta: 0:02:48  lr: 0.000031  loss: 1.3851 (1.5380)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [290/781]  eta: 0:02:44  lr: 0.000031  loss: 1.3706 (1.5364)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [300/781]  eta: 0:02:41  lr: 0.000031  loss: 1.3949 (1.5384)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [310/781]  eta: 0:02:38  lr: 0.000031  loss: 1.3437 (1.5315)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [320/781]  eta: 0:02:34  lr: 0.000031  loss: 1.3388 (1.5280)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [330/781]  eta: 0:02:31  lr: 0.000031  loss: 1.3636 (1.5277)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [340/781]  eta: 0:02:27  lr: 0.000031  loss: 1.3829 (1.5321)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [350/781]  eta: 0:02:24  lr: 0.000031  loss: 1.3244 (1.5252)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [360/781]  eta: 0:02:21  lr: 0.000031  loss: 1.2999 (1.5234)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [370/781]  eta: 0:02:17  lr: 0.000031  loss: 1.3151 (1.5255)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [380/781]  eta: 0:02:14  lr: 0.000031  loss: 1.3279 (1.5252)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [390/781]  eta: 0:02:11  lr: 0.000031  loss: 1.3806 (1.5285)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [400/781]  eta: 0:02:07  lr: 0.000031  loss: 1.3806 (1.5264)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [410/781]  eta: 0:02:04  lr: 0.000031  loss: 1.3105 (1.5204)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [420/781]  eta: 0:02:00  lr: 0.000031  loss: 1.2792 (1.5191)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [430/781]  eta: 0:01:57  lr: 0.000031  loss: 1.3083 (1.5214)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [440/781]  eta: 0:01:54  lr: 0.000031  loss: 1.3287 (1.5201)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [450/781]  eta: 0:01:50  lr: 0.000031  loss: 1.3592 (1.5269)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [460/781]  eta: 0:01:47  lr: 0.000031  loss: 1.4998 (1.5310)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [470/781]  eta: 0:01:44  lr: 0.000031  loss: 1.4242 (1.5324)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [480/781]  eta: 0:01:40  lr: 0.000031  loss: 1.3496 (1.5323)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [490/781]  eta: 0:01:37  lr: 0.000031  loss: 1.3489 (1.5323)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [500/781]  eta: 0:01:34  lr: 0.000031  loss: 1.3725 (1.5289)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [510/781]  eta: 0:01:30  lr: 0.000031  loss: 1.3574 (1.5280)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [520/781]  eta: 0:01:27  lr: 0.000031  loss: 1.3401 (1.5262)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [530/781]  eta: 0:01:23  lr: 0.000031  loss: 1.4036 (1.5265)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [540/781]  eta: 0:01:20  lr: 0.000031  loss: 1.4856 (1.5309)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [550/781]  eta: 0:01:17  lr: 0.000031  loss: 1.3379 (1.5290)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [560/781]  eta: 0:01:13  lr: 0.000031  loss: 1.3379 (1.5290)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [570/781]  eta: 0:01:10  lr: 0.000031  loss: 1.3788 (1.5283)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [580/781]  eta: 0:01:07  lr: 0.000031  loss: 1.3647 (1.5267)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [590/781]  eta: 0:01:03  lr: 0.000031  loss: 1.3697 (1.5270)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [600/781]  eta: 0:01:00  lr: 0.000031  loss: 1.4227 (1.5289)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [610/781]  eta: 0:00:57  lr: 0.000031  loss: 1.4237 (1.5295)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [620/781]  eta: 0:00:53  lr: 0.000031  loss: 1.3999 (1.5296)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [630/781]  eta: 0:00:50  lr: 0.000031  loss: 1.3606 (1.5282)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [640/781]  eta: 0:00:47  lr: 0.000031  loss: 1.3959 (1.5315)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [650/781]  eta: 0:00:43  lr: 0.000031  loss: 1.3570 (1.5314)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [660/781]  eta: 0:00:40  lr: 0.000031  loss: 1.3372 (1.5329)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [670/781]  eta: 0:00:37  lr: 0.000031  loss: 1.3691 (1.5343)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [680/781]  eta: 0:00:33  lr: 0.000031  loss: 1.3412 (1.5319)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [690/781]  eta: 0:00:30  lr: 0.000031  loss: 1.3171 (1.5300)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [700/781]  eta: 0:00:27  lr: 0.000031  loss: 1.3378 (1.5313)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [710/781]  eta: 0:00:23  lr: 0.000031  loss: 1.3556 (1.5303)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [720/781]  eta: 0:00:20  lr: 0.000031  loss: 1.3556 (1.5311)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [730/781]  eta: 0:00:17  lr: 0.000031  loss: 1.3736 (1.5326)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [740/781]  eta: 0:00:13  lr: 0.000031  loss: 1.3987 (1.5353)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [750/781]  eta: 0:00:10  lr: 0.000031  loss: 1.3987 (1.5348)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [760/781]  eta: 0:00:07  lr: 0.000031  loss: 1.3761 (1.5345)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [770/781]  eta: 0:00:03  lr: 0.000031  loss: 1.3611 (1.5347)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [780/781]  eta: 0:00:00  lr: 0.000031  loss: 1.3930 (1.5348)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [68] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000031  loss: 1.3930 (1.5348)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3244205415248871, 'lambda_convnext_base': 0.2555934190750122, 'lambda_tf_efficientnetv2_l': 0.4199860095977783}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8257 (0.8257)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8566  data: 0.8257  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9350 (0.9887)  acc1: 82.8125 (81.2027)  acc5: 94.7917 (93.8447)  time: 0.1716  data: 0.1409  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1376 (1.0636)  acc1: 77.0833 (79.7123)  acc5: 93.2292 (92.7083)  time: 0.1226  data: 0.0919  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2234 (1.1168)  acc1: 76.0417 (78.5114)  acc5: 90.6250 (92.1539)  time: 0.1258  data: 0.0951  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2256 (1.1579)  acc1: 75.0000 (77.8074)  acc5: 90.6250 (91.7429)  time: 0.1256  data: 0.0949  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1418 (1.1570)  acc1: 75.0000 (77.5531)  acc5: 92.1875 (91.8505)  time: 0.1225  data: 0.0919  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1865 (1.1685)  acc1: 75.0000 (77.4600)  acc5: 92.1875 (91.8800)  time: 0.1028  data: 0.0731  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1311 s / it)\n",
            "* Acc@1 77.460 Acc@5 91.880 loss 1.168\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=69 distillation_alpha=0.4745\n",
            "Epoch: [69]  [  0/781]  eta: 0:14:49  lr: 0.000031  loss: 1.2784 (1.2784)  time: 1.1393  data: 0.7939  max mem: 6459\n",
            "Epoch: [69]  [ 10/781]  eta: 0:05:12  lr: 0.000031  loss: 1.3324 (1.3487)  time: 0.4059  data: 0.0724  max mem: 6459\n",
            "Epoch: [69]  [ 20/781]  eta: 0:04:42  lr: 0.000031  loss: 1.3921 (1.4372)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 30/781]  eta: 0:04:29  lr: 0.000031  loss: 1.3368 (1.4259)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 40/781]  eta: 0:04:21  lr: 0.000031  loss: 1.3110 (1.4363)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 50/781]  eta: 0:04:14  lr: 0.000031  loss: 1.3110 (1.4497)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 60/781]  eta: 0:04:09  lr: 0.000031  loss: 1.3297 (1.4364)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 70/781]  eta: 0:04:04  lr: 0.000031  loss: 1.3414 (1.4552)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 80/781]  eta: 0:04:00  lr: 0.000031  loss: 1.4038 (1.4810)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 90/781]  eta: 0:03:56  lr: 0.000031  loss: 1.3880 (1.4866)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [100/781]  eta: 0:03:52  lr: 0.000031  loss: 1.4517 (1.5027)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [110/781]  eta: 0:03:48  lr: 0.000031  loss: 1.4517 (1.5086)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [120/781]  eta: 0:03:44  lr: 0.000031  loss: 1.3987 (1.5141)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [130/781]  eta: 0:03:40  lr: 0.000031  loss: 1.3532 (1.5148)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [140/781]  eta: 0:03:37  lr: 0.000031  loss: 1.3402 (1.5214)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [150/781]  eta: 0:03:33  lr: 0.000031  loss: 1.3646 (1.5350)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [160/781]  eta: 0:03:29  lr: 0.000031  loss: 1.3553 (1.5270)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [170/781]  eta: 0:03:26  lr: 0.000031  loss: 1.3374 (1.5232)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [180/781]  eta: 0:03:22  lr: 0.000031  loss: 1.4150 (1.5306)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [190/781]  eta: 0:03:19  lr: 0.000031  loss: 1.3797 (1.5280)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [200/781]  eta: 0:03:15  lr: 0.000031  loss: 1.2960 (1.5262)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [210/781]  eta: 0:03:12  lr: 0.000031  loss: 1.3233 (1.5333)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [220/781]  eta: 0:03:08  lr: 0.000031  loss: 1.3337 (1.5349)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [230/781]  eta: 0:03:05  lr: 0.000031  loss: 1.3337 (1.5290)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [240/781]  eta: 0:03:01  lr: 0.000031  loss: 1.3822 (1.5274)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [250/781]  eta: 0:02:58  lr: 0.000031  loss: 1.3557 (1.5220)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [260/781]  eta: 0:02:55  lr: 0.000031  loss: 1.3023 (1.5212)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [270/781]  eta: 0:02:51  lr: 0.000031  loss: 1.3534 (1.5225)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [280/781]  eta: 0:02:48  lr: 0.000031  loss: 1.3897 (1.5262)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [290/781]  eta: 0:02:44  lr: 0.000031  loss: 1.3897 (1.5318)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [300/781]  eta: 0:02:41  lr: 0.000031  loss: 1.3384 (1.5359)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [310/781]  eta: 0:02:37  lr: 0.000031  loss: 1.3384 (1.5353)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [320/781]  eta: 0:02:34  lr: 0.000031  loss: 1.3753 (1.5401)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [330/781]  eta: 0:02:31  lr: 0.000031  loss: 1.3952 (1.5437)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [340/781]  eta: 0:02:27  lr: 0.000031  loss: 1.4272 (1.5453)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [350/781]  eta: 0:02:24  lr: 0.000031  loss: 1.3693 (1.5419)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [360/781]  eta: 0:02:21  lr: 0.000031  loss: 1.3144 (1.5397)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [370/781]  eta: 0:02:17  lr: 0.000031  loss: 1.3144 (1.5370)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [380/781]  eta: 0:02:14  lr: 0.000031  loss: 1.3478 (1.5358)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [390/781]  eta: 0:02:10  lr: 0.000031  loss: 1.3572 (1.5361)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [400/781]  eta: 0:02:07  lr: 0.000031  loss: 1.3918 (1.5363)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [410/781]  eta: 0:02:04  lr: 0.000031  loss: 1.4014 (1.5374)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [420/781]  eta: 0:02:00  lr: 0.000031  loss: 1.3341 (1.5345)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [430/781]  eta: 0:01:57  lr: 0.000031  loss: 1.3341 (1.5347)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [440/781]  eta: 0:01:54  lr: 0.000031  loss: 1.3816 (1.5350)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [450/781]  eta: 0:01:50  lr: 0.000031  loss: 1.3571 (1.5345)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [460/781]  eta: 0:01:47  lr: 0.000031  loss: 1.3338 (1.5363)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [470/781]  eta: 0:01:44  lr: 0.000031  loss: 1.3348 (1.5384)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [480/781]  eta: 0:01:40  lr: 0.000031  loss: 1.8710 (1.5480)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [490/781]  eta: 0:01:37  lr: 0.000031  loss: 1.8460 (1.5485)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [500/781]  eta: 0:01:33  lr: 0.000031  loss: 1.3482 (1.5476)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [510/781]  eta: 0:01:30  lr: 0.000031  loss: 1.3474 (1.5500)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [520/781]  eta: 0:01:27  lr: 0.000031  loss: 1.3959 (1.5538)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [530/781]  eta: 0:01:23  lr: 0.000031  loss: 1.4454 (1.5578)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [540/781]  eta: 0:01:20  lr: 0.000031  loss: 1.3727 (1.5616)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [550/781]  eta: 0:01:17  lr: 0.000031  loss: 1.4296 (1.5626)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [560/781]  eta: 0:01:13  lr: 0.000031  loss: 1.3929 (1.5611)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [570/781]  eta: 0:01:10  lr: 0.000031  loss: 1.3475 (1.5576)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [580/781]  eta: 0:01:07  lr: 0.000031  loss: 1.3365 (1.5590)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [590/781]  eta: 0:01:03  lr: 0.000031  loss: 1.3711 (1.5618)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [600/781]  eta: 0:01:00  lr: 0.000031  loss: 1.4031 (1.5612)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [610/781]  eta: 0:00:57  lr: 0.000031  loss: 1.4031 (1.5619)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [620/781]  eta: 0:00:53  lr: 0.000031  loss: 1.3311 (1.5612)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [630/781]  eta: 0:00:50  lr: 0.000031  loss: 1.3771 (1.5610)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [640/781]  eta: 0:00:47  lr: 0.000031  loss: 1.3844 (1.5618)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [650/781]  eta: 0:00:43  lr: 0.000031  loss: 1.3867 (1.5619)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [660/781]  eta: 0:00:40  lr: 0.000031  loss: 1.3867 (1.5618)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [670/781]  eta: 0:00:37  lr: 0.000031  loss: 1.4439 (1.5679)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [680/781]  eta: 0:00:33  lr: 0.000031  loss: 1.4281 (1.5670)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [690/781]  eta: 0:00:30  lr: 0.000031  loss: 1.3100 (1.5636)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [700/781]  eta: 0:00:27  lr: 0.000031  loss: 1.3100 (1.5616)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [710/781]  eta: 0:00:23  lr: 0.000031  loss: 1.3825 (1.5617)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [720/781]  eta: 0:00:20  lr: 0.000031  loss: 1.4448 (1.5640)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [730/781]  eta: 0:00:17  lr: 0.000031  loss: 1.4170 (1.5641)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [740/781]  eta: 0:00:13  lr: 0.000031  loss: 1.3661 (1.5645)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [750/781]  eta: 0:00:10  lr: 0.000031  loss: 1.4031 (1.5659)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [760/781]  eta: 0:00:07  lr: 0.000031  loss: 1.4024 (1.5657)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [770/781]  eta: 0:00:03  lr: 0.000031  loss: 1.3237 (1.5624)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [780/781]  eta: 0:00:00  lr: 0.000031  loss: 1.3237 (1.5635)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [69] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000031  loss: 1.3237 (1.5635)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3243100345134735, 'lambda_convnext_base': 0.2557351291179657, 'lambda_tf_efficientnetv2_l': 0.4199548661708832}\n",
            "Test:  [ 0/53]  eta: 0:00:41  loss: 0.7924 (0.7924)  acc1: 84.8958 (84.8958)  acc5: 95.3125 (95.3125)  time: 0.7885  data: 0.7575  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9766 (1.0009)  acc1: 80.2083 (81.1080)  acc5: 94.2708 (93.1818)  time: 0.1667  data: 0.1360  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0244 (1.0830)  acc1: 79.6875 (79.0179)  acc5: 93.2292 (92.2867)  time: 0.1239  data: 0.0932  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2708 (1.1405)  acc1: 74.4792 (78.1082)  acc5: 90.6250 (91.8347)  time: 0.1274  data: 0.0968  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2988 (1.1787)  acc1: 74.4792 (77.6931)  acc5: 90.1042 (91.3745)  time: 0.1281  data: 0.0974  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1321 (1.1700)  acc1: 76.0417 (77.6859)  acc5: 92.1875 (91.6565)  time: 0.1306  data: 0.0999  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1447 (1.1799)  acc1: 75.0000 (77.5500)  acc5: 92.7083 (91.6900)  time: 0.1122  data: 0.0825  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1336 s / it)\n",
            "* Acc@1 77.550 Acc@5 91.690 loss 1.180\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.55%\n",
            "[alpha-schedule=cosine] epoch=70 distillation_alpha=0.4821\n",
            "Epoch: [70]  [  0/781]  eta: 0:14:49  lr: 0.000030  loss: 1.3592 (1.3592)  time: 1.1386  data: 0.7812  max mem: 6459\n",
            "Epoch: [70]  [ 10/781]  eta: 0:05:13  lr: 0.000030  loss: 1.3592 (1.3514)  time: 0.4067  data: 0.0713  max mem: 6459\n",
            "Epoch: [70]  [ 20/781]  eta: 0:04:42  lr: 0.000030  loss: 1.3584 (1.5418)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 30/781]  eta: 0:04:29  lr: 0.000030  loss: 1.3728 (1.5688)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 40/781]  eta: 0:04:21  lr: 0.000030  loss: 1.3826 (1.5823)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 50/781]  eta: 0:04:14  lr: 0.000030  loss: 1.3821 (1.5756)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 60/781]  eta: 0:04:09  lr: 0.000030  loss: 1.3626 (1.5569)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 70/781]  eta: 0:04:04  lr: 0.000030  loss: 1.3627 (1.5608)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 80/781]  eta: 0:04:00  lr: 0.000030  loss: 1.4238 (1.5668)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 90/781]  eta: 0:03:56  lr: 0.000030  loss: 1.3974 (1.5701)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [100/781]  eta: 0:03:52  lr: 0.000030  loss: 1.3278 (1.5542)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [110/781]  eta: 0:03:48  lr: 0.000030  loss: 1.3479 (1.5605)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [120/781]  eta: 0:03:44  lr: 0.000030  loss: 1.3750 (1.5567)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [130/781]  eta: 0:03:40  lr: 0.000030  loss: 1.3526 (1.5540)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [140/781]  eta: 0:03:37  lr: 0.000030  loss: 1.3408 (1.5363)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [150/781]  eta: 0:03:33  lr: 0.000030  loss: 1.3408 (1.5342)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [160/781]  eta: 0:03:29  lr: 0.000030  loss: 1.3769 (1.5399)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [170/781]  eta: 0:03:26  lr: 0.000030  loss: 1.3995 (1.5398)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [180/781]  eta: 0:03:22  lr: 0.000030  loss: 1.3777 (1.5381)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [190/781]  eta: 0:03:19  lr: 0.000030  loss: 1.3338 (1.5298)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [200/781]  eta: 0:03:15  lr: 0.000030  loss: 1.3338 (1.5270)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [210/781]  eta: 0:03:12  lr: 0.000030  loss: 1.3561 (1.5253)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [220/781]  eta: 0:03:08  lr: 0.000030  loss: 1.4147 (1.5372)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [230/781]  eta: 0:03:05  lr: 0.000030  loss: 1.4037 (1.5289)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [240/781]  eta: 0:03:01  lr: 0.000030  loss: 1.3914 (1.5274)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [250/781]  eta: 0:02:58  lr: 0.000030  loss: 1.4030 (1.5330)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [260/781]  eta: 0:02:55  lr: 0.000030  loss: 1.3827 (1.5306)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [270/781]  eta: 0:02:51  lr: 0.000030  loss: 1.3282 (1.5284)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [280/781]  eta: 0:02:48  lr: 0.000030  loss: 1.3217 (1.5214)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [290/781]  eta: 0:02:44  lr: 0.000030  loss: 1.3319 (1.5202)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [300/781]  eta: 0:02:41  lr: 0.000030  loss: 1.3538 (1.5142)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [310/781]  eta: 0:02:38  lr: 0.000030  loss: 1.3627 (1.5211)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [320/781]  eta: 0:02:34  lr: 0.000030  loss: 1.4281 (1.5167)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [330/781]  eta: 0:02:31  lr: 0.000030  loss: 1.4383 (1.5237)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [340/781]  eta: 0:02:27  lr: 0.000030  loss: 1.4017 (1.5197)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [350/781]  eta: 0:02:24  lr: 0.000030  loss: 1.3262 (1.5182)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [360/781]  eta: 0:02:21  lr: 0.000030  loss: 1.3539 (1.5192)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [370/781]  eta: 0:02:17  lr: 0.000030  loss: 1.3754 (1.5167)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [380/781]  eta: 0:02:14  lr: 0.000030  loss: 1.3774 (1.5207)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [390/781]  eta: 0:02:10  lr: 0.000030  loss: 1.3286 (1.5180)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [400/781]  eta: 0:02:07  lr: 0.000030  loss: 1.3272 (1.5160)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [410/781]  eta: 0:02:04  lr: 0.000030  loss: 1.3372 (1.5176)  time: 0.3436  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [420/781]  eta: 0:02:01  lr: 0.000030  loss: 1.4052 (1.5198)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [430/781]  eta: 0:01:57  lr: 0.000030  loss: 1.4980 (1.5279)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [440/781]  eta: 0:01:54  lr: 0.000030  loss: 1.3619 (1.5263)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [450/781]  eta: 0:01:50  lr: 0.000030  loss: 1.3487 (1.5341)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [460/781]  eta: 0:01:47  lr: 0.000030  loss: 1.3441 (1.5338)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [470/781]  eta: 0:01:44  lr: 0.000030  loss: 1.3305 (1.5368)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [480/781]  eta: 0:01:40  lr: 0.000030  loss: 1.3450 (1.5366)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [490/781]  eta: 0:01:37  lr: 0.000030  loss: 1.3706 (1.5369)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [500/781]  eta: 0:01:34  lr: 0.000030  loss: 1.3706 (1.5354)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [510/781]  eta: 0:01:30  lr: 0.000030  loss: 1.3638 (1.5376)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [520/781]  eta: 0:01:27  lr: 0.000030  loss: 1.3326 (1.5350)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [530/781]  eta: 0:01:24  lr: 0.000030  loss: 1.3326 (1.5346)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [540/781]  eta: 0:01:20  lr: 0.000030  loss: 1.3181 (1.5314)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [550/781]  eta: 0:01:17  lr: 0.000030  loss: 1.2836 (1.5271)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [560/781]  eta: 0:01:13  lr: 0.000030  loss: 1.2853 (1.5248)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [570/781]  eta: 0:01:10  lr: 0.000030  loss: 1.3043 (1.5221)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [580/781]  eta: 0:01:07  lr: 0.000030  loss: 1.2698 (1.5183)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [590/781]  eta: 0:01:03  lr: 0.000030  loss: 1.3241 (1.5181)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [600/781]  eta: 0:01:00  lr: 0.000030  loss: 1.3435 (1.5177)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [610/781]  eta: 0:00:57  lr: 0.000030  loss: 1.3236 (1.5163)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [620/781]  eta: 0:00:53  lr: 0.000030  loss: 1.3734 (1.5205)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [630/781]  eta: 0:00:50  lr: 0.000030  loss: 1.3843 (1.5214)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [640/781]  eta: 0:00:47  lr: 0.000030  loss: 1.3834 (1.5254)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [650/781]  eta: 0:00:43  lr: 0.000030  loss: 1.3832 (1.5258)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [660/781]  eta: 0:00:40  lr: 0.000030  loss: 1.4642 (1.5278)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [670/781]  eta: 0:00:37  lr: 0.000030  loss: 1.5204 (1.5291)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [680/781]  eta: 0:00:33  lr: 0.000030  loss: 1.3796 (1.5290)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [690/781]  eta: 0:00:30  lr: 0.000030  loss: 1.3646 (1.5263)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [700/781]  eta: 0:00:27  lr: 0.000030  loss: 1.3656 (1.5316)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [710/781]  eta: 0:00:23  lr: 0.000030  loss: 1.5616 (1.5319)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [720/781]  eta: 0:00:20  lr: 0.000030  loss: 1.3368 (1.5304)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [730/781]  eta: 0:00:17  lr: 0.000030  loss: 1.3485 (1.5333)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [740/781]  eta: 0:00:13  lr: 0.000030  loss: 1.3984 (1.5349)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [750/781]  eta: 0:00:10  lr: 0.000030  loss: 1.3446 (1.5359)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [760/781]  eta: 0:00:07  lr: 0.000030  loss: 1.3564 (1.5382)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [770/781]  eta: 0:00:03  lr: 0.000030  loss: 1.3859 (1.5379)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [780/781]  eta: 0:00:00  lr: 0.000030  loss: 1.3625 (1.5387)  time: 0.3327  data: 0.0005  max mem: 6459\n",
            "Epoch: [70] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000030  loss: 1.3625 (1.5387)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3250306248664856, 'lambda_convnext_base': 0.2554782032966614, 'lambda_tf_efficientnetv2_l': 0.41949158906936646}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8562 (0.8562)  acc1: 80.7292 (80.7292)  acc5: 94.7917 (94.7917)  time: 0.8506  data: 0.8197  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9698 (0.9830)  acc1: 82.2917 (81.7708)  acc5: 94.2708 (93.2765)  time: 0.1706  data: 0.1400  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0803 (1.0399)  acc1: 77.6042 (80.5060)  acc5: 93.2292 (92.6091)  time: 0.1209  data: 0.0903  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1618 (1.1090)  acc1: 76.0417 (79.2171)  acc5: 90.6250 (91.8347)  time: 0.1232  data: 0.0925  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2913 (1.1555)  acc1: 75.0000 (78.4045)  acc5: 90.1042 (91.3618)  time: 0.1249  data: 0.0943  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1132 (1.1518)  acc1: 77.0833 (78.0637)  acc5: 92.1875 (91.6156)  time: 0.1259  data: 0.0953  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1573 (1.1633)  acc1: 73.9583 (77.9300)  acc5: 92.1875 (91.6400)  time: 0.1062  data: 0.0766  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1310 s / it)\n",
            "* Acc@1 77.930 Acc@5 91.640 loss 1.163\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.93%\n",
            "[alpha-schedule=cosine] epoch=71 distillation_alpha=0.4897\n",
            "Epoch: [71]  [  0/781]  eta: 0:14:05  lr: 0.000029  loss: 1.3350 (1.3350)  time: 1.0823  data: 0.7277  max mem: 6459\n",
            "Epoch: [71]  [ 10/781]  eta: 0:05:09  lr: 0.000029  loss: 1.3154 (1.3925)  time: 0.4015  data: 0.0664  max mem: 6459\n",
            "Epoch: [71]  [ 20/781]  eta: 0:04:40  lr: 0.000029  loss: 1.3544 (1.4806)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 30/781]  eta: 0:04:28  lr: 0.000029  loss: 1.3897 (1.5261)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 40/781]  eta: 0:04:20  lr: 0.000029  loss: 1.3359 (1.5341)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 50/781]  eta: 0:04:14  lr: 0.000029  loss: 1.3348 (1.5267)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 60/781]  eta: 0:04:08  lr: 0.000029  loss: 1.3923 (1.5532)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 70/781]  eta: 0:04:04  lr: 0.000029  loss: 1.3923 (1.5549)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 80/781]  eta: 0:03:59  lr: 0.000029  loss: 1.3215 (1.5364)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 90/781]  eta: 0:03:55  lr: 0.000029  loss: 1.3719 (1.5425)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [100/781]  eta: 0:03:51  lr: 0.000029  loss: 1.4188 (1.5433)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [110/781]  eta: 0:03:47  lr: 0.000029  loss: 1.3551 (1.5369)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [120/781]  eta: 0:03:44  lr: 0.000029  loss: 1.3456 (1.5317)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [130/781]  eta: 0:03:40  lr: 0.000029  loss: 1.3533 (1.5249)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [140/781]  eta: 0:03:36  lr: 0.000029  loss: 1.3931 (1.5376)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [150/781]  eta: 0:03:33  lr: 0.000029  loss: 1.6404 (1.5516)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [160/781]  eta: 0:03:29  lr: 0.000029  loss: 1.5238 (1.5568)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [170/781]  eta: 0:03:26  lr: 0.000029  loss: 1.3787 (1.5506)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [180/781]  eta: 0:03:22  lr: 0.000029  loss: 1.3675 (1.5446)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [190/781]  eta: 0:03:19  lr: 0.000029  loss: 1.3443 (1.5417)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [200/781]  eta: 0:03:15  lr: 0.000029  loss: 1.3569 (1.5507)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [210/781]  eta: 0:03:12  lr: 0.000029  loss: 1.4060 (1.5615)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [220/781]  eta: 0:03:08  lr: 0.000029  loss: 1.8175 (1.5698)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [230/781]  eta: 0:03:05  lr: 0.000029  loss: 1.3804 (1.5731)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [240/781]  eta: 0:03:01  lr: 0.000029  loss: 1.3603 (1.5666)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [250/781]  eta: 0:02:58  lr: 0.000029  loss: 1.3509 (1.5678)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [260/781]  eta: 0:02:54  lr: 0.000029  loss: 1.3509 (1.5659)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [270/781]  eta: 0:02:51  lr: 0.000029  loss: 1.2915 (1.5598)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [280/781]  eta: 0:02:48  lr: 0.000029  loss: 1.3311 (1.5614)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [290/781]  eta: 0:02:44  lr: 0.000029  loss: 1.3909 (1.5652)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [300/781]  eta: 0:02:41  lr: 0.000029  loss: 1.3417 (1.5655)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [310/781]  eta: 0:02:37  lr: 0.000029  loss: 1.4259 (1.5732)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [320/781]  eta: 0:02:34  lr: 0.000029  loss: 1.4259 (1.5716)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [330/781]  eta: 0:02:31  lr: 0.000029  loss: 1.3758 (1.5738)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [340/781]  eta: 0:02:27  lr: 0.000029  loss: 1.3814 (1.5733)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [350/781]  eta: 0:02:24  lr: 0.000029  loss: 1.3690 (1.5730)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [360/781]  eta: 0:02:21  lr: 0.000029  loss: 1.3093 (1.5693)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [370/781]  eta: 0:02:17  lr: 0.000029  loss: 1.3236 (1.5671)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [380/781]  eta: 0:02:14  lr: 0.000029  loss: 1.3790 (1.5677)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [390/781]  eta: 0:02:10  lr: 0.000029  loss: 1.3790 (1.5678)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [400/781]  eta: 0:02:07  lr: 0.000029  loss: 1.3647 (1.5683)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [410/781]  eta: 0:02:04  lr: 0.000029  loss: 1.3496 (1.5714)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [420/781]  eta: 0:02:00  lr: 0.000029  loss: 1.3496 (1.5728)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [430/781]  eta: 0:01:57  lr: 0.000029  loss: 1.3227 (1.5691)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [440/781]  eta: 0:01:54  lr: 0.000029  loss: 1.3560 (1.5719)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [450/781]  eta: 0:01:50  lr: 0.000029  loss: 1.3642 (1.5669)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [460/781]  eta: 0:01:47  lr: 0.000029  loss: 1.3194 (1.5660)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [470/781]  eta: 0:01:44  lr: 0.000029  loss: 1.3308 (1.5635)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [480/781]  eta: 0:01:40  lr: 0.000029  loss: 1.3308 (1.5616)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [490/781]  eta: 0:01:37  lr: 0.000029  loss: 1.3446 (1.5606)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [500/781]  eta: 0:01:33  lr: 0.000029  loss: 1.3446 (1.5614)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [510/781]  eta: 0:01:30  lr: 0.000029  loss: 1.4391 (1.5635)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [520/781]  eta: 0:01:27  lr: 0.000029  loss: 1.3700 (1.5614)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [530/781]  eta: 0:01:23  lr: 0.000029  loss: 1.3356 (1.5596)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [540/781]  eta: 0:01:20  lr: 0.000029  loss: 1.3450 (1.5577)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [550/781]  eta: 0:01:17  lr: 0.000029  loss: 1.3311 (1.5565)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [560/781]  eta: 0:01:13  lr: 0.000029  loss: 1.3347 (1.5580)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [570/781]  eta: 0:01:10  lr: 0.000029  loss: 1.3622 (1.5604)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [580/781]  eta: 0:01:07  lr: 0.000029  loss: 1.3506 (1.5607)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [590/781]  eta: 0:01:03  lr: 0.000029  loss: 1.3357 (1.5600)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [600/781]  eta: 0:01:00  lr: 0.000029  loss: 1.3439 (1.5574)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [610/781]  eta: 0:00:57  lr: 0.000029  loss: 1.3749 (1.5587)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [620/781]  eta: 0:00:53  lr: 0.000029  loss: 1.4129 (1.5586)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [630/781]  eta: 0:00:50  lr: 0.000029  loss: 1.3759 (1.5613)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [640/781]  eta: 0:00:47  lr: 0.000029  loss: 1.4233 (1.5626)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [650/781]  eta: 0:00:43  lr: 0.000029  loss: 1.3478 (1.5592)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [660/781]  eta: 0:00:40  lr: 0.000029  loss: 1.3419 (1.5599)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [670/781]  eta: 0:00:37  lr: 0.000029  loss: 1.3776 (1.5613)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [680/781]  eta: 0:00:33  lr: 0.000029  loss: 1.3625 (1.5624)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [690/781]  eta: 0:00:30  lr: 0.000029  loss: 1.3637 (1.5611)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [700/781]  eta: 0:00:27  lr: 0.000029  loss: 1.3826 (1.5609)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [710/781]  eta: 0:00:23  lr: 0.000029  loss: 1.4099 (1.5652)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [720/781]  eta: 0:00:20  lr: 0.000029  loss: 1.3776 (1.5645)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [730/781]  eta: 0:00:17  lr: 0.000029  loss: 1.3776 (1.5664)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [740/781]  eta: 0:00:13  lr: 0.000029  loss: 1.4397 (1.5662)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [750/781]  eta: 0:00:10  lr: 0.000029  loss: 1.3807 (1.5679)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [760/781]  eta: 0:00:07  lr: 0.000029  loss: 1.3684 (1.5670)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [770/781]  eta: 0:00:03  lr: 0.000029  loss: 1.3870 (1.5690)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [780/781]  eta: 0:00:00  lr: 0.000029  loss: 1.5268 (1.5701)  time: 0.3333  data: 0.0006  max mem: 6459\n",
            "Epoch: [71] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000029  loss: 1.5268 (1.5701)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3238790035247803, 'lambda_convnext_base': 0.25599005818367004, 'lambda_tf_efficientnetv2_l': 0.42013096809387207}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8363 (0.8363)  acc1: 82.8125 (82.8125)  acc5: 95.8333 (95.8333)  time: 0.8507  data: 0.8199  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9080 (0.9786)  acc1: 83.3333 (81.9602)  acc5: 94.7917 (93.6080)  time: 0.1754  data: 0.1447  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0471 (1.0574)  acc1: 80.7292 (80.5308)  acc5: 92.7083 (92.5347)  time: 0.1287  data: 0.0981  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2012 (1.1162)  acc1: 75.5208 (79.4019)  acc5: 90.6250 (91.9523)  time: 0.1298  data: 0.0991  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2305 (1.1624)  acc1: 75.5208 (78.3918)  acc5: 90.6250 (91.5523)  time: 0.1303  data: 0.0997  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1325 (1.1595)  acc1: 77.0833 (78.0637)  acc5: 91.6667 (91.7484)  time: 0.1271  data: 0.0964  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1553 (1.1690)  acc1: 75.5208 (77.9600)  acc5: 92.1875 (91.8100)  time: 0.1063  data: 0.0766  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1349 s / it)\n",
            "* Acc@1 77.960 Acc@5 91.810 loss 1.169\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=72 distillation_alpha=0.4972\n",
            "Epoch: [72]  [  0/781]  eta: 0:14:41  lr: 0.000029  loss: 1.1995 (1.1995)  time: 1.1288  data: 0.7885  max mem: 6459\n",
            "Epoch: [72]  [ 10/781]  eta: 0:05:12  lr: 0.000029  loss: 1.3957 (1.6059)  time: 0.4053  data: 0.0720  max mem: 6459\n",
            "Epoch: [72]  [ 20/781]  eta: 0:04:42  lr: 0.000029  loss: 1.3180 (1.5102)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 30/781]  eta: 0:04:29  lr: 0.000029  loss: 1.3166 (1.5061)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 40/781]  eta: 0:04:21  lr: 0.000029  loss: 1.4193 (1.5647)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 50/781]  eta: 0:04:15  lr: 0.000029  loss: 1.4053 (1.5424)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 60/781]  eta: 0:04:09  lr: 0.000029  loss: 1.3940 (1.5480)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 70/781]  eta: 0:04:04  lr: 0.000029  loss: 1.3569 (1.5604)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 80/781]  eta: 0:04:00  lr: 0.000029  loss: 1.3879 (1.5708)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 90/781]  eta: 0:03:56  lr: 0.000029  loss: 1.3879 (1.5776)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [100/781]  eta: 0:03:52  lr: 0.000029  loss: 1.3670 (1.5740)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [110/781]  eta: 0:03:48  lr: 0.000029  loss: 1.3309 (1.5548)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [120/781]  eta: 0:03:44  lr: 0.000029  loss: 1.3742 (1.5597)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [130/781]  eta: 0:03:40  lr: 0.000029  loss: 1.4150 (1.5753)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [140/781]  eta: 0:03:37  lr: 0.000029  loss: 1.3405 (1.5810)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [150/781]  eta: 0:03:33  lr: 0.000029  loss: 1.3211 (1.5718)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [160/781]  eta: 0:03:29  lr: 0.000029  loss: 1.3353 (1.5642)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [170/781]  eta: 0:03:26  lr: 0.000029  loss: 1.3339 (1.5538)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [180/781]  eta: 0:03:22  lr: 0.000029  loss: 1.3339 (1.5713)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [190/781]  eta: 0:03:19  lr: 0.000029  loss: 1.3303 (1.5629)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [200/781]  eta: 0:03:15  lr: 0.000029  loss: 1.2989 (1.5575)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [210/781]  eta: 0:03:12  lr: 0.000029  loss: 1.3743 (1.5596)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [220/781]  eta: 0:03:08  lr: 0.000029  loss: 1.3763 (1.5614)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [230/781]  eta: 0:03:05  lr: 0.000029  loss: 1.3164 (1.5540)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [240/781]  eta: 0:03:02  lr: 0.000029  loss: 1.2740 (1.5476)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [250/781]  eta: 0:02:58  lr: 0.000029  loss: 1.3014 (1.5442)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [260/781]  eta: 0:02:55  lr: 0.000029  loss: 1.3473 (1.5435)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [270/781]  eta: 0:02:51  lr: 0.000029  loss: 1.3295 (1.5382)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [280/781]  eta: 0:02:48  lr: 0.000029  loss: 1.3376 (1.5337)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [290/781]  eta: 0:02:44  lr: 0.000029  loss: 1.3509 (1.5384)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [300/781]  eta: 0:02:41  lr: 0.000029  loss: 1.3567 (1.5421)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [310/781]  eta: 0:02:38  lr: 0.000029  loss: 1.3626 (1.5430)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [320/781]  eta: 0:02:34  lr: 0.000029  loss: 1.3626 (1.5452)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [330/781]  eta: 0:02:31  lr: 0.000029  loss: 1.3340 (1.5426)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [340/781]  eta: 0:02:27  lr: 0.000029  loss: 1.3457 (1.5400)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [350/781]  eta: 0:02:24  lr: 0.000029  loss: 1.4042 (1.5478)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [360/781]  eta: 0:02:21  lr: 0.000029  loss: 1.3810 (1.5448)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [370/781]  eta: 0:02:17  lr: 0.000029  loss: 1.3647 (1.5423)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [380/781]  eta: 0:02:14  lr: 0.000029  loss: 1.3908 (1.5446)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [390/781]  eta: 0:02:11  lr: 0.000029  loss: 1.3658 (1.5465)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [400/781]  eta: 0:02:07  lr: 0.000029  loss: 1.3402 (1.5479)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [410/781]  eta: 0:02:04  lr: 0.000029  loss: 1.3647 (1.5479)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [420/781]  eta: 0:02:00  lr: 0.000029  loss: 1.3553 (1.5426)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [430/781]  eta: 0:01:57  lr: 0.000029  loss: 1.3279 (1.5426)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [440/781]  eta: 0:01:54  lr: 0.000029  loss: 1.4066 (1.5494)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [450/781]  eta: 0:01:50  lr: 0.000029  loss: 1.4477 (1.5524)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [460/781]  eta: 0:01:47  lr: 0.000029  loss: 1.4567 (1.5566)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [470/781]  eta: 0:01:44  lr: 0.000029  loss: 1.4020 (1.5585)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [480/781]  eta: 0:01:40  lr: 0.000029  loss: 1.3621 (1.5576)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [490/781]  eta: 0:01:37  lr: 0.000029  loss: 1.3389 (1.5567)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [500/781]  eta: 0:01:34  lr: 0.000029  loss: 1.3527 (1.5617)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [510/781]  eta: 0:01:30  lr: 0.000029  loss: 1.3911 (1.5609)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [520/781]  eta: 0:01:27  lr: 0.000029  loss: 1.3911 (1.5608)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [530/781]  eta: 0:01:23  lr: 0.000029  loss: 1.3760 (1.5591)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [540/781]  eta: 0:01:20  lr: 0.000029  loss: 1.3760 (1.5601)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [550/781]  eta: 0:01:17  lr: 0.000029  loss: 1.4444 (1.5645)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [560/781]  eta: 0:01:13  lr: 0.000029  loss: 1.4444 (1.5663)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [570/781]  eta: 0:01:10  lr: 0.000029  loss: 1.3690 (1.5631)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [580/781]  eta: 0:01:07  lr: 0.000029  loss: 1.3720 (1.5626)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [590/781]  eta: 0:01:03  lr: 0.000029  loss: 1.4041 (1.5665)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [600/781]  eta: 0:01:00  lr: 0.000029  loss: 1.4618 (1.5705)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [610/781]  eta: 0:00:57  lr: 0.000029  loss: 1.3805 (1.5688)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [620/781]  eta: 0:00:53  lr: 0.000029  loss: 1.3805 (1.5687)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [630/781]  eta: 0:00:50  lr: 0.000029  loss: 1.4294 (1.5720)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [640/781]  eta: 0:00:47  lr: 0.000029  loss: 1.4054 (1.5710)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [650/781]  eta: 0:00:43  lr: 0.000029  loss: 1.3528 (1.5695)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [660/781]  eta: 0:00:40  lr: 0.000029  loss: 1.3813 (1.5710)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [670/781]  eta: 0:00:37  lr: 0.000029  loss: 1.3390 (1.5688)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [680/781]  eta: 0:00:33  lr: 0.000029  loss: 1.3390 (1.5680)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [690/781]  eta: 0:00:30  lr: 0.000029  loss: 1.3686 (1.5674)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [700/781]  eta: 0:00:27  lr: 0.000029  loss: 1.4073 (1.5685)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [710/781]  eta: 0:00:23  lr: 0.000029  loss: 1.3702 (1.5658)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [720/781]  eta: 0:00:20  lr: 0.000029  loss: 1.3237 (1.5680)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [730/781]  eta: 0:00:17  lr: 0.000029  loss: 1.3583 (1.5692)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [740/781]  eta: 0:00:13  lr: 0.000029  loss: 1.4173 (1.5727)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [750/781]  eta: 0:00:10  lr: 0.000029  loss: 1.4049 (1.5721)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [760/781]  eta: 0:00:07  lr: 0.000029  loss: 1.3374 (1.5696)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [770/781]  eta: 0:00:03  lr: 0.000029  loss: 1.3512 (1.5708)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [780/781]  eta: 0:00:00  lr: 0.000029  loss: 1.3799 (1.5700)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [72] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000029  loss: 1.3799 (1.5700)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32400643825531006, 'lambda_convnext_base': 0.2559318542480469, 'lambda_tf_efficientnetv2_l': 0.4200621545314789}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7854 (0.7854)  acc1: 84.8958 (84.8958)  acc5: 95.3125 (95.3125)  time: 0.8268  data: 0.7959  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9840 (1.0171)  acc1: 81.7708 (80.8712)  acc5: 93.7500 (93.1818)  time: 0.1694  data: 0.1387  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0117 (1.0763)  acc1: 79.6875 (79.7123)  acc5: 92.7083 (92.2123)  time: 0.1253  data: 0.0946  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2044 (1.1228)  acc1: 75.5208 (78.7970)  acc5: 91.6667 (91.6499)  time: 0.1277  data: 0.0971  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2627 (1.1699)  acc1: 75.5208 (77.9853)  acc5: 90.6250 (91.2348)  time: 0.1272  data: 0.0966  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1406 (1.1732)  acc1: 77.6042 (77.7063)  acc5: 92.1875 (91.2990)  time: 0.1266  data: 0.0959  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2325 (1.1834)  acc1: 75.5208 (77.6000)  acc5: 92.1875 (91.3300)  time: 0.1064  data: 0.0767  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1327 s / it)\n",
            "* Acc@1 77.600 Acc@5 91.330 loss 1.183\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=73 distillation_alpha=0.5047\n",
            "Epoch: [73]  [  0/781]  eta: 0:14:40  lr: 0.000028  loss: 1.2788 (1.2788)  time: 1.1277  data: 0.7848  max mem: 6459\n",
            "Epoch: [73]  [ 10/781]  eta: 0:05:12  lr: 0.000028  loss: 1.3401 (1.4968)  time: 0.4052  data: 0.0716  max mem: 6459\n",
            "Epoch: [73]  [ 20/781]  eta: 0:04:42  lr: 0.000028  loss: 1.4074 (1.5898)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 30/781]  eta: 0:04:29  lr: 0.000028  loss: 1.4074 (1.6008)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 40/781]  eta: 0:04:21  lr: 0.000028  loss: 1.3653 (1.6008)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 50/781]  eta: 0:04:14  lr: 0.000028  loss: 1.3936 (1.6022)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 60/781]  eta: 0:04:09  lr: 0.000028  loss: 1.3269 (1.5701)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 70/781]  eta: 0:04:04  lr: 0.000028  loss: 1.3185 (1.5615)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 80/781]  eta: 0:04:00  lr: 0.000028  loss: 1.3149 (1.5553)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 90/781]  eta: 0:03:56  lr: 0.000028  loss: 1.2953 (1.5348)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [100/781]  eta: 0:03:52  lr: 0.000028  loss: 1.3036 (1.5496)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [110/781]  eta: 0:03:48  lr: 0.000028  loss: 1.4327 (1.5625)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [120/781]  eta: 0:03:44  lr: 0.000028  loss: 1.4846 (1.5624)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [130/781]  eta: 0:03:40  lr: 0.000028  loss: 1.3336 (1.5544)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [140/781]  eta: 0:03:37  lr: 0.000028  loss: 1.3126 (1.5565)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [150/781]  eta: 0:03:34  lr: 0.000028  loss: 1.3237 (1.5556)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [160/781]  eta: 0:03:30  lr: 0.000028  loss: 1.3761 (1.5632)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [170/781]  eta: 0:03:27  lr: 0.000028  loss: 1.3596 (1.5572)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [180/781]  eta: 0:03:23  lr: 0.000028  loss: 1.3390 (1.5505)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [190/781]  eta: 0:03:19  lr: 0.000028  loss: 1.3711 (1.5546)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [200/781]  eta: 0:03:16  lr: 0.000028  loss: 1.3711 (1.5552)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [210/781]  eta: 0:03:12  lr: 0.000028  loss: 1.3392 (1.5591)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [220/781]  eta: 0:03:09  lr: 0.000028  loss: 1.3324 (1.5547)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [230/781]  eta: 0:03:05  lr: 0.000028  loss: 1.3898 (1.5569)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [240/781]  eta: 0:03:02  lr: 0.000028  loss: 1.3898 (1.5635)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [250/781]  eta: 0:02:58  lr: 0.000028  loss: 1.3202 (1.5577)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [260/781]  eta: 0:02:55  lr: 0.000028  loss: 1.3202 (1.5533)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [270/781]  eta: 0:02:52  lr: 0.000028  loss: 1.3807 (1.5583)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [280/781]  eta: 0:02:48  lr: 0.000028  loss: 1.3984 (1.5570)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [290/781]  eta: 0:02:45  lr: 0.000028  loss: 1.3434 (1.5531)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [300/781]  eta: 0:02:41  lr: 0.000028  loss: 1.3798 (1.5592)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [310/781]  eta: 0:02:38  lr: 0.000028  loss: 1.3857 (1.5574)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [320/781]  eta: 0:02:34  lr: 0.000028  loss: 1.3910 (1.5701)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [330/781]  eta: 0:02:31  lr: 0.000028  loss: 1.7865 (1.5735)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [340/781]  eta: 0:02:28  lr: 0.000028  loss: 1.4543 (1.5786)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [350/781]  eta: 0:02:24  lr: 0.000028  loss: 1.4490 (1.5831)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [360/781]  eta: 0:02:21  lr: 0.000028  loss: 1.6245 (1.5904)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [370/781]  eta: 0:02:17  lr: 0.000028  loss: 1.4292 (1.5894)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [380/781]  eta: 0:02:14  lr: 0.000028  loss: 1.4159 (1.5950)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [390/781]  eta: 0:02:11  lr: 0.000028  loss: 1.4699 (1.5963)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [400/781]  eta: 0:02:07  lr: 0.000028  loss: 1.3722 (1.5994)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [410/781]  eta: 0:02:04  lr: 0.000028  loss: 1.3807 (1.5998)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [420/781]  eta: 0:02:01  lr: 0.000028  loss: 1.3548 (1.5973)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [430/781]  eta: 0:01:57  lr: 0.000028  loss: 1.3174 (1.5941)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [440/781]  eta: 0:01:54  lr: 0.000028  loss: 1.3560 (1.5895)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [450/781]  eta: 0:01:50  lr: 0.000028  loss: 1.3069 (1.5834)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [460/781]  eta: 0:01:47  lr: 0.000028  loss: 1.3085 (1.5819)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [470/781]  eta: 0:01:44  lr: 0.000028  loss: 1.3513 (1.5813)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [480/781]  eta: 0:01:40  lr: 0.000028  loss: 1.3781 (1.5789)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [490/781]  eta: 0:01:37  lr: 0.000028  loss: 1.3475 (1.5766)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [500/781]  eta: 0:01:34  lr: 0.000028  loss: 1.3459 (1.5766)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [510/781]  eta: 0:01:30  lr: 0.000028  loss: 1.4416 (1.5815)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [520/781]  eta: 0:01:27  lr: 0.000028  loss: 1.7566 (1.5855)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [530/781]  eta: 0:01:24  lr: 0.000028  loss: 1.7566 (1.5884)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [540/781]  eta: 0:01:20  lr: 0.000028  loss: 1.3378 (1.5868)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [550/781]  eta: 0:01:17  lr: 0.000028  loss: 1.3041 (1.5863)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [560/781]  eta: 0:01:13  lr: 0.000028  loss: 1.3156 (1.5842)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [570/781]  eta: 0:01:10  lr: 0.000028  loss: 1.4098 (1.5846)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [580/781]  eta: 0:01:07  lr: 0.000028  loss: 1.4101 (1.5872)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [590/781]  eta: 0:01:03  lr: 0.000028  loss: 1.3880 (1.5854)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [600/781]  eta: 0:01:00  lr: 0.000028  loss: 1.3689 (1.5826)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [610/781]  eta: 0:00:57  lr: 0.000028  loss: 1.3462 (1.5805)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [620/781]  eta: 0:00:53  lr: 0.000028  loss: 1.3462 (1.5811)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [630/781]  eta: 0:00:50  lr: 0.000028  loss: 1.3840 (1.5821)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [640/781]  eta: 0:00:47  lr: 0.000028  loss: 1.4119 (1.5868)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [650/781]  eta: 0:00:43  lr: 0.000028  loss: 1.5105 (1.5878)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [660/781]  eta: 0:00:40  lr: 0.000028  loss: 1.3779 (1.5865)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [670/781]  eta: 0:00:37  lr: 0.000028  loss: 1.3106 (1.5846)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [680/781]  eta: 0:00:33  lr: 0.000028  loss: 1.3203 (1.5848)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [690/781]  eta: 0:00:30  lr: 0.000028  loss: 1.3463 (1.5835)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [700/781]  eta: 0:00:27  lr: 0.000028  loss: 1.3312 (1.5839)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [710/781]  eta: 0:00:23  lr: 0.000028  loss: 1.3500 (1.5813)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [720/781]  eta: 0:00:20  lr: 0.000028  loss: 1.3455 (1.5796)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [730/781]  eta: 0:00:17  lr: 0.000028  loss: 1.3500 (1.5811)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [740/781]  eta: 0:00:13  lr: 0.000028  loss: 1.5274 (1.5851)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [750/781]  eta: 0:00:10  lr: 0.000028  loss: 1.4838 (1.5854)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [760/781]  eta: 0:00:07  lr: 0.000028  loss: 1.3483 (1.5854)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [770/781]  eta: 0:00:03  lr: 0.000028  loss: 1.3401 (1.5855)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [780/781]  eta: 0:00:00  lr: 0.000028  loss: 1.3572 (1.5822)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [73] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000028  loss: 1.3572 (1.5822)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3245777189731598, 'lambda_convnext_base': 0.2554013133049011, 'lambda_tf_efficientnetv2_l': 0.4200206696987152}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7661 (0.7661)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8835  data: 0.8527  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0772 (0.9905)  acc1: 81.2500 (81.4867)  acc5: 94.7917 (93.7027)  time: 0.1722  data: 0.1415  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0772 (1.0567)  acc1: 79.1667 (79.9355)  acc5: 93.2292 (92.6835)  time: 0.1169  data: 0.0862  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1521 (1.1031)  acc1: 77.0833 (79.0995)  acc5: 91.6667 (92.2547)  time: 0.1270  data: 0.0963  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1926 (1.1523)  acc1: 77.0833 (78.2647)  acc5: 91.1458 (91.7302)  time: 0.1174  data: 0.0861  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1444 (1.1523)  acc1: 76.0417 (77.9208)  acc5: 92.7083 (91.8505)  time: 0.1298  data: 0.0986  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1580 (1.1647)  acc1: 76.0417 (77.8100)  acc5: 92.7083 (91.8500)  time: 0.1251  data: 0.0948  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1346 s / it)\n",
            "* Acc@1 77.810 Acc@5 91.850 loss 1.165\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=74 distillation_alpha=0.5121\n",
            "Epoch: [74]  [  0/781]  eta: 0:14:06  lr: 0.000027  loss: 1.6066 (1.6066)  time: 1.0845  data: 0.7410  max mem: 6459\n",
            "Epoch: [74]  [ 10/781]  eta: 0:05:09  lr: 0.000027  loss: 1.3788 (1.5730)  time: 0.4012  data: 0.0676  max mem: 6459\n",
            "Epoch: [74]  [ 20/781]  eta: 0:04:40  lr: 0.000027  loss: 1.3286 (1.5705)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 30/781]  eta: 0:04:28  lr: 0.000027  loss: 1.3256 (1.5897)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 40/781]  eta: 0:04:20  lr: 0.000027  loss: 1.3152 (1.5524)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 50/781]  eta: 0:04:14  lr: 0.000027  loss: 1.3066 (1.5275)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 60/781]  eta: 0:04:08  lr: 0.000027  loss: 1.3626 (1.5446)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 70/781]  eta: 0:04:04  lr: 0.000027  loss: 1.3905 (1.5396)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 80/781]  eta: 0:03:59  lr: 0.000027  loss: 1.3295 (1.5162)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 90/781]  eta: 0:03:55  lr: 0.000027  loss: 1.3248 (1.5368)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [100/781]  eta: 0:03:51  lr: 0.000027  loss: 1.3211 (1.5429)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [110/781]  eta: 0:03:48  lr: 0.000027  loss: 1.3725 (1.5424)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [120/781]  eta: 0:03:44  lr: 0.000027  loss: 1.3700 (1.5463)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [130/781]  eta: 0:03:40  lr: 0.000027  loss: 1.3451 (1.5560)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [140/781]  eta: 0:03:36  lr: 0.000027  loss: 1.3652 (1.5690)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [150/781]  eta: 0:03:33  lr: 0.000027  loss: 1.4316 (1.5851)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [160/781]  eta: 0:03:29  lr: 0.000027  loss: 1.3789 (1.5819)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [170/781]  eta: 0:03:26  lr: 0.000027  loss: 1.3283 (1.5797)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [180/781]  eta: 0:03:22  lr: 0.000027  loss: 1.5434 (1.5943)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [190/781]  eta: 0:03:19  lr: 0.000027  loss: 1.7520 (1.5993)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [200/781]  eta: 0:03:15  lr: 0.000027  loss: 1.3907 (1.6021)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [210/781]  eta: 0:03:12  lr: 0.000027  loss: 1.3890 (1.6009)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [220/781]  eta: 0:03:08  lr: 0.000027  loss: 1.3305 (1.6023)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [230/781]  eta: 0:03:05  lr: 0.000027  loss: 1.3305 (1.5977)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [240/781]  eta: 0:03:01  lr: 0.000027  loss: 1.3351 (1.5894)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [250/781]  eta: 0:02:58  lr: 0.000027  loss: 1.3422 (1.5826)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [260/781]  eta: 0:02:54  lr: 0.000027  loss: 1.3799 (1.5792)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [270/781]  eta: 0:02:51  lr: 0.000027  loss: 1.3799 (1.5797)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [280/781]  eta: 0:02:48  lr: 0.000027  loss: 1.3756 (1.5782)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [290/781]  eta: 0:02:44  lr: 0.000027  loss: 1.3203 (1.5724)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [300/781]  eta: 0:02:41  lr: 0.000027  loss: 1.3312 (1.5720)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [310/781]  eta: 0:02:37  lr: 0.000027  loss: 1.3435 (1.5740)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [320/781]  eta: 0:02:34  lr: 0.000027  loss: 1.3030 (1.5669)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [330/781]  eta: 0:02:31  lr: 0.000027  loss: 1.3030 (1.5650)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [340/781]  eta: 0:02:27  lr: 0.000027  loss: 1.3270 (1.5602)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [350/781]  eta: 0:02:24  lr: 0.000027  loss: 1.3479 (1.5583)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [360/781]  eta: 0:02:21  lr: 0.000027  loss: 1.3640 (1.5612)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [370/781]  eta: 0:02:17  lr: 0.000027  loss: 1.3985 (1.5629)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [380/781]  eta: 0:02:14  lr: 0.000027  loss: 1.3423 (1.5588)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [390/781]  eta: 0:02:10  lr: 0.000027  loss: 1.3155 (1.5570)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [400/781]  eta: 0:02:07  lr: 0.000027  loss: 1.3155 (1.5544)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [410/781]  eta: 0:02:04  lr: 0.000027  loss: 1.3148 (1.5503)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [420/781]  eta: 0:02:00  lr: 0.000027  loss: 1.3099 (1.5511)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [430/781]  eta: 0:01:57  lr: 0.000027  loss: 1.3223 (1.5481)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [440/781]  eta: 0:01:54  lr: 0.000027  loss: 1.3224 (1.5486)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [450/781]  eta: 0:01:50  lr: 0.000027  loss: 1.3513 (1.5469)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [460/781]  eta: 0:01:47  lr: 0.000027  loss: 1.3324 (1.5461)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [470/781]  eta: 0:01:44  lr: 0.000027  loss: 1.4021 (1.5468)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [480/781]  eta: 0:01:40  lr: 0.000027  loss: 1.4124 (1.5463)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [490/781]  eta: 0:01:37  lr: 0.000027  loss: 1.3828 (1.5460)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [500/781]  eta: 0:01:33  lr: 0.000027  loss: 1.3320 (1.5450)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [510/781]  eta: 0:01:30  lr: 0.000027  loss: 1.2953 (1.5409)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [520/781]  eta: 0:01:27  lr: 0.000027  loss: 1.3223 (1.5421)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [530/781]  eta: 0:01:23  lr: 0.000027  loss: 1.3274 (1.5432)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [540/781]  eta: 0:01:20  lr: 0.000027  loss: 1.3274 (1.5407)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [550/781]  eta: 0:01:17  lr: 0.000027  loss: 1.3442 (1.5388)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [560/781]  eta: 0:01:13  lr: 0.000027  loss: 1.3744 (1.5406)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [570/781]  eta: 0:01:10  lr: 0.000027  loss: 1.3230 (1.5372)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [580/781]  eta: 0:01:07  lr: 0.000027  loss: 1.2726 (1.5366)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [590/781]  eta: 0:01:03  lr: 0.000027  loss: 1.3329 (1.5381)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [600/781]  eta: 0:01:00  lr: 0.000027  loss: 1.3479 (1.5380)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [610/781]  eta: 0:00:57  lr: 0.000027  loss: 1.5296 (1.5448)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [620/781]  eta: 0:00:53  lr: 0.000027  loss: 1.4018 (1.5425)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [630/781]  eta: 0:00:50  lr: 0.000027  loss: 1.3612 (1.5436)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [640/781]  eta: 0:00:47  lr: 0.000027  loss: 1.3612 (1.5424)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [650/781]  eta: 0:00:43  lr: 0.000027  loss: 1.3412 (1.5462)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [660/781]  eta: 0:00:40  lr: 0.000027  loss: 1.3400 (1.5470)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [670/781]  eta: 0:00:37  lr: 0.000027  loss: 1.3406 (1.5478)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [680/781]  eta: 0:00:33  lr: 0.000027  loss: 1.3517 (1.5488)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [690/781]  eta: 0:00:30  lr: 0.000027  loss: 1.3720 (1.5496)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [700/781]  eta: 0:00:27  lr: 0.000027  loss: 1.3231 (1.5487)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [710/781]  eta: 0:00:23  lr: 0.000027  loss: 1.3329 (1.5489)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [720/781]  eta: 0:00:20  lr: 0.000027  loss: 1.3316 (1.5471)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [730/781]  eta: 0:00:17  lr: 0.000027  loss: 1.3316 (1.5477)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [740/781]  eta: 0:00:13  lr: 0.000027  loss: 1.3754 (1.5487)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [750/781]  eta: 0:00:10  lr: 0.000027  loss: 1.3563 (1.5463)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [760/781]  eta: 0:00:07  lr: 0.000027  loss: 1.3476 (1.5474)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [770/781]  eta: 0:00:03  lr: 0.000027  loss: 1.3307 (1.5443)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [780/781]  eta: 0:00:00  lr: 0.000027  loss: 1.3307 (1.5454)  time: 0.3332  data: 0.0005  max mem: 6459\n",
            "Epoch: [74] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000027  loss: 1.3307 (1.5454)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32418739795684814, 'lambda_convnext_base': 0.25586748123168945, 'lambda_tf_efficientnetv2_l': 0.41994571685791016}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8478 (0.8478)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8365  data: 0.8056  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9745 (0.9974)  acc1: 82.8125 (81.4394)  acc5: 94.2708 (93.2765)  time: 0.1734  data: 0.1427  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1163 (1.0525)  acc1: 76.5625 (79.9355)  acc5: 93.2292 (92.5595)  time: 0.1248  data: 0.0942  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1806 (1.1122)  acc1: 73.9583 (78.7466)  acc5: 91.6667 (91.9187)  time: 0.1267  data: 0.0961  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2168 (1.1596)  acc1: 75.5208 (78.1504)  acc5: 90.6250 (91.3872)  time: 0.1313  data: 0.1006  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1441 (1.1546)  acc1: 77.0833 (77.9208)  acc5: 91.6667 (91.5850)  time: 0.1300  data: 0.0994  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1666 (1.1615)  acc1: 76.0417 (77.7800)  acc5: 92.1875 (91.6200)  time: 0.1119  data: 0.0822  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1345 s / it)\n",
            "* Acc@1 77.780 Acc@5 91.620 loss 1.161\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=75 distillation_alpha=0.5194\n",
            "Epoch: [75]  [  0/781]  eta: 0:14:40  lr: 0.000027  loss: 2.3885 (2.3885)  time: 1.1273  data: 0.7825  max mem: 6459\n",
            "Epoch: [75]  [ 10/781]  eta: 0:05:12  lr: 0.000027  loss: 1.4823 (1.6693)  time: 0.4052  data: 0.0714  max mem: 6459\n",
            "Epoch: [75]  [ 20/781]  eta: 0:04:42  lr: 0.000027  loss: 1.3598 (1.5510)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 30/781]  eta: 0:04:29  lr: 0.000027  loss: 1.3146 (1.4781)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 40/781]  eta: 0:04:21  lr: 0.000027  loss: 1.3483 (1.5615)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 50/781]  eta: 0:04:14  lr: 0.000027  loss: 1.3530 (1.5262)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 60/781]  eta: 0:04:09  lr: 0.000027  loss: 1.3118 (1.5225)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 70/781]  eta: 0:04:04  lr: 0.000027  loss: 1.3668 (1.5543)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 80/781]  eta: 0:04:00  lr: 0.000027  loss: 1.3542 (1.5420)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 90/781]  eta: 0:03:56  lr: 0.000027  loss: 1.3552 (1.5571)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [100/781]  eta: 0:03:52  lr: 0.000027  loss: 1.3314 (1.5495)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [110/781]  eta: 0:03:48  lr: 0.000027  loss: 1.3343 (1.5480)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [120/781]  eta: 0:03:44  lr: 0.000027  loss: 1.3769 (1.5439)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [130/781]  eta: 0:03:40  lr: 0.000027  loss: 1.3774 (1.5521)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [140/781]  eta: 0:03:36  lr: 0.000027  loss: 1.3774 (1.5500)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [150/781]  eta: 0:03:33  lr: 0.000027  loss: 1.3505 (1.5501)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [160/781]  eta: 0:03:29  lr: 0.000027  loss: 1.2886 (1.5446)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [170/781]  eta: 0:03:26  lr: 0.000027  loss: 1.3271 (1.5508)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [180/781]  eta: 0:03:22  lr: 0.000027  loss: 1.3656 (1.5562)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [190/781]  eta: 0:03:19  lr: 0.000027  loss: 1.3652 (1.5533)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [200/781]  eta: 0:03:15  lr: 0.000027  loss: 1.3450 (1.5543)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [210/781]  eta: 0:03:12  lr: 0.000027  loss: 1.3568 (1.5531)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [220/781]  eta: 0:03:08  lr: 0.000027  loss: 1.3584 (1.5466)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [230/781]  eta: 0:03:05  lr: 0.000027  loss: 1.3794 (1.5482)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [240/781]  eta: 0:03:01  lr: 0.000027  loss: 1.3451 (1.5426)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [250/781]  eta: 0:02:58  lr: 0.000027  loss: 1.2840 (1.5344)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [260/781]  eta: 0:02:55  lr: 0.000027  loss: 1.2933 (1.5291)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [270/781]  eta: 0:02:51  lr: 0.000027  loss: 1.3524 (1.5308)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [280/781]  eta: 0:02:48  lr: 0.000027  loss: 1.3106 (1.5243)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [290/781]  eta: 0:02:44  lr: 0.000027  loss: 1.2653 (1.5237)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [300/781]  eta: 0:02:41  lr: 0.000027  loss: 1.3369 (1.5223)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [310/781]  eta: 0:02:38  lr: 0.000027  loss: 1.2907 (1.5191)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [320/781]  eta: 0:02:34  lr: 0.000027  loss: 1.3556 (1.5247)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [330/781]  eta: 0:02:31  lr: 0.000027  loss: 1.3896 (1.5241)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [340/781]  eta: 0:02:27  lr: 0.000027  loss: 1.3801 (1.5278)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [350/781]  eta: 0:02:24  lr: 0.000027  loss: 1.3746 (1.5269)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [360/781]  eta: 0:02:21  lr: 0.000027  loss: 1.3306 (1.5233)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [370/781]  eta: 0:02:17  lr: 0.000027  loss: 1.3735 (1.5281)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [380/781]  eta: 0:02:14  lr: 0.000027  loss: 1.3373 (1.5265)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [390/781]  eta: 0:02:10  lr: 0.000027  loss: 1.3026 (1.5250)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [400/781]  eta: 0:02:07  lr: 0.000027  loss: 1.3008 (1.5268)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [410/781]  eta: 0:02:04  lr: 0.000027  loss: 1.3530 (1.5235)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [420/781]  eta: 0:02:00  lr: 0.000027  loss: 1.3536 (1.5266)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [430/781]  eta: 0:01:57  lr: 0.000027  loss: 1.3696 (1.5258)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [440/781]  eta: 0:01:54  lr: 0.000027  loss: 1.3179 (1.5281)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [450/781]  eta: 0:01:50  lr: 0.000027  loss: 1.3446 (1.5303)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [460/781]  eta: 0:01:47  lr: 0.000027  loss: 1.3665 (1.5309)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [470/781]  eta: 0:01:44  lr: 0.000027  loss: 1.3534 (1.5332)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [480/781]  eta: 0:01:40  lr: 0.000027  loss: 1.3214 (1.5287)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [490/781]  eta: 0:01:37  lr: 0.000027  loss: 1.3029 (1.5299)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [500/781]  eta: 0:01:33  lr: 0.000027  loss: 1.3376 (1.5289)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [510/781]  eta: 0:01:30  lr: 0.000027  loss: 1.2817 (1.5250)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [520/781]  eta: 0:01:27  lr: 0.000027  loss: 1.3037 (1.5238)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [530/781]  eta: 0:01:23  lr: 0.000027  loss: 1.3565 (1.5230)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [540/781]  eta: 0:01:20  lr: 0.000027  loss: 1.3722 (1.5256)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [550/781]  eta: 0:01:17  lr: 0.000027  loss: 1.3722 (1.5251)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [560/781]  eta: 0:01:13  lr: 0.000027  loss: 1.3378 (1.5246)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [570/781]  eta: 0:01:10  lr: 0.000027  loss: 1.2985 (1.5227)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [580/781]  eta: 0:01:07  lr: 0.000027  loss: 1.3240 (1.5211)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [590/781]  eta: 0:01:03  lr: 0.000027  loss: 1.3480 (1.5204)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [600/781]  eta: 0:01:00  lr: 0.000027  loss: 1.3490 (1.5192)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [610/781]  eta: 0:00:57  lr: 0.000027  loss: 1.3541 (1.5195)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [620/781]  eta: 0:00:53  lr: 0.000027  loss: 1.3409 (1.5179)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [630/781]  eta: 0:00:50  lr: 0.000027  loss: 1.2876 (1.5159)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [640/781]  eta: 0:00:47  lr: 0.000027  loss: 1.2876 (1.5150)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [650/781]  eta: 0:00:43  lr: 0.000027  loss: 1.3563 (1.5158)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [660/781]  eta: 0:00:40  lr: 0.000027  loss: 1.3681 (1.5180)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [670/781]  eta: 0:00:37  lr: 0.000027  loss: 1.3170 (1.5158)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [680/781]  eta: 0:00:33  lr: 0.000027  loss: 1.3262 (1.5144)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [690/781]  eta: 0:00:30  lr: 0.000027  loss: 1.3536 (1.5139)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [700/781]  eta: 0:00:27  lr: 0.000027  loss: 1.3821 (1.5148)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [710/781]  eta: 0:00:23  lr: 0.000027  loss: 1.3991 (1.5187)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [720/781]  eta: 0:00:20  lr: 0.000027  loss: 1.5290 (1.5221)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [730/781]  eta: 0:00:17  lr: 0.000027  loss: 1.3315 (1.5228)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [740/781]  eta: 0:00:13  lr: 0.000027  loss: 1.3157 (1.5246)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [750/781]  eta: 0:00:10  lr: 0.000027  loss: 1.2938 (1.5247)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [760/781]  eta: 0:00:07  lr: 0.000027  loss: 1.3245 (1.5242)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [770/781]  eta: 0:00:03  lr: 0.000027  loss: 1.3937 (1.5251)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [780/781]  eta: 0:00:00  lr: 0.000027  loss: 1.3937 (1.5243)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [75] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000027  loss: 1.3937 (1.5243)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32511332631111145, 'lambda_convnext_base': 0.2559373378753662, 'lambda_tf_efficientnetv2_l': 0.4189494550228119}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8388 (0.8388)  acc1: 82.8125 (82.8125)  acc5: 94.2708 (94.2708)  time: 0.8378  data: 0.8070  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9240 (1.0254)  acc1: 82.2917 (80.4451)  acc5: 94.2708 (93.3712)  time: 0.1741  data: 0.1435  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0432 (1.0651)  acc1: 79.1667 (79.4891)  acc5: 93.2292 (92.5843)  time: 0.1260  data: 0.0954  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1861 (1.1229)  acc1: 75.0000 (78.6290)  acc5: 91.6667 (91.9859)  time: 0.1268  data: 0.0961  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2266 (1.1682)  acc1: 75.0000 (77.9472)  acc5: 91.1458 (91.6159)  time: 0.1303  data: 0.0996  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1023 (1.1628)  acc1: 75.0000 (77.7369)  acc5: 92.1875 (91.7586)  time: 0.1300  data: 0.0994  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2323 (1.1757)  acc1: 73.4375 (77.6100)  acc5: 92.1875 (91.7800)  time: 0.1091  data: 0.0794  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1350 s / it)\n",
            "* Acc@1 77.610 Acc@5 91.780 loss 1.176\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=76 distillation_alpha=0.5266\n",
            "Epoch: [76]  [  0/781]  eta: 0:13:55  lr: 0.000026  loss: 1.2418 (1.2418)  time: 1.0696  data: 0.7257  max mem: 6459\n",
            "Epoch: [76]  [ 10/781]  eta: 0:05:08  lr: 0.000026  loss: 1.3172 (1.4076)  time: 0.3999  data: 0.0663  max mem: 6459\n",
            "Epoch: [76]  [ 20/781]  eta: 0:04:39  lr: 0.000026  loss: 1.3345 (1.4557)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 30/781]  eta: 0:04:27  lr: 0.000026  loss: 1.3620 (1.4914)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 40/781]  eta: 0:04:19  lr: 0.000026  loss: 1.3381 (1.4877)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 50/781]  eta: 0:04:13  lr: 0.000026  loss: 1.3582 (1.5481)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 60/781]  eta: 0:04:08  lr: 0.000026  loss: 1.3582 (1.5266)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 70/781]  eta: 0:04:03  lr: 0.000026  loss: 1.3396 (1.5170)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 80/781]  eta: 0:03:59  lr: 0.000026  loss: 1.3509 (1.5185)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 90/781]  eta: 0:03:55  lr: 0.000026  loss: 1.2942 (1.5067)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [100/781]  eta: 0:03:51  lr: 0.000026  loss: 1.3118 (1.4993)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [110/781]  eta: 0:03:47  lr: 0.000026  loss: 1.3927 (1.5159)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [120/781]  eta: 0:03:44  lr: 0.000026  loss: 1.4836 (1.5317)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [130/781]  eta: 0:03:40  lr: 0.000026  loss: 1.3946 (1.5306)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [140/781]  eta: 0:03:36  lr: 0.000026  loss: 1.4062 (1.5323)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [150/781]  eta: 0:03:33  lr: 0.000026  loss: 1.4300 (1.5385)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [160/781]  eta: 0:03:29  lr: 0.000026  loss: 1.3581 (1.5455)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [170/781]  eta: 0:03:26  lr: 0.000026  loss: 1.3059 (1.5502)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [180/781]  eta: 0:03:22  lr: 0.000026  loss: 1.3787 (1.5486)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [190/781]  eta: 0:03:19  lr: 0.000026  loss: 1.3637 (1.5560)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [200/781]  eta: 0:03:15  lr: 0.000026  loss: 1.3473 (1.5549)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [210/781]  eta: 0:03:12  lr: 0.000026  loss: 1.3383 (1.5531)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [220/781]  eta: 0:03:08  lr: 0.000026  loss: 1.3306 (1.5535)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [230/781]  eta: 0:03:05  lr: 0.000026  loss: 1.3346 (1.5498)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [240/781]  eta: 0:03:01  lr: 0.000026  loss: 1.3309 (1.5453)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [250/781]  eta: 0:02:58  lr: 0.000026  loss: 1.3268 (1.5431)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [260/781]  eta: 0:02:54  lr: 0.000026  loss: 1.3268 (1.5421)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [270/781]  eta: 0:02:51  lr: 0.000026  loss: 1.3231 (1.5367)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [280/781]  eta: 0:02:48  lr: 0.000026  loss: 1.3059 (1.5343)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [290/781]  eta: 0:02:44  lr: 0.000026  loss: 1.3225 (1.5350)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [300/781]  eta: 0:02:41  lr: 0.000026  loss: 1.3160 (1.5316)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [310/781]  eta: 0:02:37  lr: 0.000026  loss: 1.3317 (1.5336)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [320/781]  eta: 0:02:34  lr: 0.000026  loss: 1.3530 (1.5334)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [330/781]  eta: 0:02:31  lr: 0.000026  loss: 1.3666 (1.5350)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [340/781]  eta: 0:02:27  lr: 0.000026  loss: 1.3666 (1.5328)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [350/781]  eta: 0:02:24  lr: 0.000026  loss: 1.3526 (1.5364)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [360/781]  eta: 0:02:21  lr: 0.000026  loss: 1.3771 (1.5355)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [370/781]  eta: 0:02:17  lr: 0.000026  loss: 1.3792 (1.5374)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [380/781]  eta: 0:02:14  lr: 0.000026  loss: 1.3358 (1.5369)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [390/781]  eta: 0:02:10  lr: 0.000026  loss: 1.2975 (1.5367)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [400/781]  eta: 0:02:07  lr: 0.000026  loss: 1.4398 (1.5394)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [410/781]  eta: 0:02:04  lr: 0.000026  loss: 1.3501 (1.5335)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [420/781]  eta: 0:02:00  lr: 0.000026  loss: 1.2945 (1.5395)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [430/781]  eta: 0:01:57  lr: 0.000026  loss: 1.3586 (1.5382)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [440/781]  eta: 0:01:54  lr: 0.000026  loss: 1.3626 (1.5401)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [450/781]  eta: 0:01:50  lr: 0.000026  loss: 1.3626 (1.5375)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [460/781]  eta: 0:01:47  lr: 0.000026  loss: 1.3708 (1.5441)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [470/781]  eta: 0:01:44  lr: 0.000026  loss: 1.4397 (1.5469)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [480/781]  eta: 0:01:40  lr: 0.000026  loss: 1.3960 (1.5459)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [490/781]  eta: 0:01:37  lr: 0.000026  loss: 1.4228 (1.5461)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [500/781]  eta: 0:01:33  lr: 0.000026  loss: 1.4549 (1.5524)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [510/781]  eta: 0:01:30  lr: 0.000026  loss: 1.4224 (1.5536)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [520/781]  eta: 0:01:27  lr: 0.000026  loss: 1.4197 (1.5546)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [530/781]  eta: 0:01:23  lr: 0.000026  loss: 1.3587 (1.5526)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [540/781]  eta: 0:01:20  lr: 0.000026  loss: 1.3352 (1.5504)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [550/781]  eta: 0:01:17  lr: 0.000026  loss: 1.3224 (1.5499)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [560/781]  eta: 0:01:13  lr: 0.000026  loss: 1.3382 (1.5532)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [570/781]  eta: 0:01:10  lr: 0.000026  loss: 1.3287 (1.5520)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [580/781]  eta: 0:01:07  lr: 0.000026  loss: 1.3323 (1.5503)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [590/781]  eta: 0:01:03  lr: 0.000026  loss: 1.3515 (1.5499)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [600/781]  eta: 0:01:00  lr: 0.000026  loss: 1.3273 (1.5472)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [610/781]  eta: 0:00:57  lr: 0.000026  loss: 1.3678 (1.5469)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [620/781]  eta: 0:00:53  lr: 0.000026  loss: 1.4158 (1.5510)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [630/781]  eta: 0:00:50  lr: 0.000026  loss: 1.3799 (1.5512)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [640/781]  eta: 0:00:47  lr: 0.000026  loss: 1.3783 (1.5502)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [650/781]  eta: 0:00:43  lr: 0.000026  loss: 1.3599 (1.5500)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [660/781]  eta: 0:00:40  lr: 0.000026  loss: 1.3575 (1.5481)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [670/781]  eta: 0:00:37  lr: 0.000026  loss: 1.3206 (1.5505)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [680/781]  eta: 0:00:33  lr: 0.000026  loss: 1.4337 (1.5518)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [690/781]  eta: 0:00:30  lr: 0.000026  loss: 1.3971 (1.5525)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [700/781]  eta: 0:00:27  lr: 0.000026  loss: 1.3439 (1.5523)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [710/781]  eta: 0:00:23  lr: 0.000026  loss: 1.3835 (1.5569)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [720/781]  eta: 0:00:20  lr: 0.000026  loss: 1.3835 (1.5571)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [730/781]  eta: 0:00:17  lr: 0.000026  loss: 1.3211 (1.5555)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [740/781]  eta: 0:00:13  lr: 0.000026  loss: 1.3211 (1.5536)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [750/781]  eta: 0:00:10  lr: 0.000026  loss: 1.3201 (1.5535)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [760/781]  eta: 0:00:07  lr: 0.000026  loss: 1.3310 (1.5547)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [770/781]  eta: 0:00:03  lr: 0.000026  loss: 1.3059 (1.5525)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [780/781]  eta: 0:00:00  lr: 0.000026  loss: 1.3095 (1.5510)  time: 0.3329  data: 0.0005  max mem: 6459\n",
            "Epoch: [76] Total time: 0:04:20 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000026  loss: 1.3095 (1.5510)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3243286609649658, 'lambda_convnext_base': 0.25553593039512634, 'lambda_tf_efficientnetv2_l': 0.42013514041900635}\n",
            "Test:  [ 0/53]  eta: 0:00:41  loss: 0.7774 (0.7774)  acc1: 85.9375 (85.9375)  acc5: 96.3542 (96.3542)  time: 0.7902  data: 0.7593  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9693 (1.0186)  acc1: 82.8125 (80.9186)  acc5: 94.2708 (93.3712)  time: 0.1727  data: 0.1420  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0437 (1.0748)  acc1: 78.6458 (79.8859)  acc5: 92.1875 (92.4355)  time: 0.1363  data: 0.1056  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2260 (1.1300)  acc1: 75.5208 (78.6962)  acc5: 91.6667 (91.8347)  time: 0.1393  data: 0.1086  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2356 (1.1673)  acc1: 74.4792 (78.0361)  acc5: 89.5833 (91.4634)  time: 0.1339  data: 0.1032  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1543 (1.1643)  acc1: 75.0000 (77.7165)  acc5: 91.6667 (91.6462)  time: 0.1355  data: 0.1049  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1843 (1.1756)  acc1: 73.4375 (77.5700)  acc5: 91.6667 (91.6800)  time: 0.1160  data: 0.0864  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1414 s / it)\n",
            "* Acc@1 77.570 Acc@5 91.680 loss 1.176\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=77 distillation_alpha=0.5337\n",
            "Epoch: [77]  [  0/781]  eta: 0:14:38  lr: 0.000026  loss: 2.2551 (2.2551)  time: 1.1247  data: 0.7752  max mem: 6459\n",
            "Epoch: [77]  [ 10/781]  eta: 0:05:12  lr: 0.000026  loss: 1.3230 (1.4701)  time: 0.4049  data: 0.0707  max mem: 6459\n",
            "Epoch: [77]  [ 20/781]  eta: 0:04:41  lr: 0.000026  loss: 1.3127 (1.4636)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 30/781]  eta: 0:04:29  lr: 0.000026  loss: 1.3625 (1.5101)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 40/781]  eta: 0:04:20  lr: 0.000026  loss: 1.3085 (1.4643)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 50/781]  eta: 0:04:14  lr: 0.000026  loss: 1.2846 (1.4559)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 60/781]  eta: 0:04:09  lr: 0.000026  loss: 1.3082 (1.4488)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 70/781]  eta: 0:04:04  lr: 0.000026  loss: 1.2830 (1.4420)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 80/781]  eta: 0:04:00  lr: 0.000026  loss: 1.2998 (1.4407)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 90/781]  eta: 0:03:55  lr: 0.000026  loss: 1.3219 (1.4574)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [100/781]  eta: 0:03:51  lr: 0.000026  loss: 1.3221 (1.4664)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [110/781]  eta: 0:03:48  lr: 0.000026  loss: 1.3038 (1.4522)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [120/781]  eta: 0:03:44  lr: 0.000026  loss: 1.2999 (1.4558)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [130/781]  eta: 0:03:40  lr: 0.000026  loss: 1.3114 (1.4558)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [140/781]  eta: 0:03:36  lr: 0.000026  loss: 1.3292 (1.4650)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [150/781]  eta: 0:03:33  lr: 0.000026  loss: 1.3292 (1.4773)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [160/781]  eta: 0:03:29  lr: 0.000026  loss: 1.3447 (1.4851)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [170/781]  eta: 0:03:26  lr: 0.000026  loss: 1.3030 (1.4924)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [180/781]  eta: 0:03:22  lr: 0.000026  loss: 1.3241 (1.4880)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [190/781]  eta: 0:03:19  lr: 0.000026  loss: 1.3254 (1.4828)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [200/781]  eta: 0:03:15  lr: 0.000026  loss: 1.3254 (1.4970)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [210/781]  eta: 0:03:12  lr: 0.000026  loss: 1.3236 (1.4921)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [220/781]  eta: 0:03:08  lr: 0.000026  loss: 1.3178 (1.4872)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [230/781]  eta: 0:03:05  lr: 0.000026  loss: 1.3178 (1.4915)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [240/781]  eta: 0:03:01  lr: 0.000026  loss: 1.3210 (1.5016)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [250/781]  eta: 0:02:58  lr: 0.000026  loss: 1.3602 (1.5017)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [260/781]  eta: 0:02:54  lr: 0.000026  loss: 1.3342 (1.4996)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [270/781]  eta: 0:02:51  lr: 0.000026  loss: 1.3291 (1.4986)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [280/781]  eta: 0:02:48  lr: 0.000026  loss: 1.3651 (1.5036)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [290/781]  eta: 0:02:44  lr: 0.000026  loss: 1.3651 (1.5079)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [300/781]  eta: 0:02:41  lr: 0.000026  loss: 1.5404 (1.5168)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [310/781]  eta: 0:02:37  lr: 0.000026  loss: 1.3736 (1.5122)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [320/781]  eta: 0:02:34  lr: 0.000026  loss: 1.3458 (1.5111)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [330/781]  eta: 0:02:31  lr: 0.000026  loss: 1.3652 (1.5169)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [340/781]  eta: 0:02:27  lr: 0.000026  loss: 1.2954 (1.5126)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [350/781]  eta: 0:02:24  lr: 0.000026  loss: 1.3000 (1.5099)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [360/781]  eta: 0:02:21  lr: 0.000026  loss: 1.3658 (1.5150)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [370/781]  eta: 0:02:17  lr: 0.000026  loss: 1.2879 (1.5121)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [380/781]  eta: 0:02:14  lr: 0.000026  loss: 1.3301 (1.5105)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [390/781]  eta: 0:02:10  lr: 0.000026  loss: 1.3557 (1.5114)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [400/781]  eta: 0:02:07  lr: 0.000026  loss: 1.3315 (1.5149)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [410/781]  eta: 0:02:04  lr: 0.000026  loss: 1.3180 (1.5134)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [420/781]  eta: 0:02:00  lr: 0.000026  loss: 1.3575 (1.5149)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [430/781]  eta: 0:01:57  lr: 0.000026  loss: 1.3894 (1.5169)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [440/781]  eta: 0:01:54  lr: 0.000026  loss: 1.3894 (1.5179)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [450/781]  eta: 0:01:50  lr: 0.000026  loss: 1.3115 (1.5178)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [460/781]  eta: 0:01:47  lr: 0.000026  loss: 1.3600 (1.5215)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [470/781]  eta: 0:01:44  lr: 0.000026  loss: 1.3372 (1.5213)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [480/781]  eta: 0:01:40  lr: 0.000026  loss: 1.3062 (1.5187)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [490/781]  eta: 0:01:37  lr: 0.000026  loss: 1.3091 (1.5171)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [500/781]  eta: 0:01:33  lr: 0.000026  loss: 1.3448 (1.5166)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [510/781]  eta: 0:01:30  lr: 0.000026  loss: 1.3808 (1.5185)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [520/781]  eta: 0:01:27  lr: 0.000026  loss: 1.3308 (1.5180)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [530/781]  eta: 0:01:23  lr: 0.000026  loss: 1.3253 (1.5166)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [540/781]  eta: 0:01:20  lr: 0.000026  loss: 1.3443 (1.5179)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [550/781]  eta: 0:01:17  lr: 0.000026  loss: 1.3493 (1.5141)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [560/781]  eta: 0:01:13  lr: 0.000026  loss: 1.3493 (1.5132)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [570/781]  eta: 0:01:10  lr: 0.000026  loss: 1.3708 (1.5132)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [580/781]  eta: 0:01:07  lr: 0.000026  loss: 1.3660 (1.5172)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [590/781]  eta: 0:01:03  lr: 0.000026  loss: 1.3633 (1.5178)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [600/781]  eta: 0:01:00  lr: 0.000026  loss: 1.3633 (1.5193)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [610/781]  eta: 0:00:57  lr: 0.000026  loss: 1.3359 (1.5193)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [620/781]  eta: 0:00:53  lr: 0.000026  loss: 1.3359 (1.5211)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [630/781]  eta: 0:00:50  lr: 0.000026  loss: 1.3699 (1.5210)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [640/781]  eta: 0:00:47  lr: 0.000026  loss: 1.3492 (1.5202)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [650/781]  eta: 0:00:43  lr: 0.000026  loss: 1.3355 (1.5215)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [660/781]  eta: 0:00:40  lr: 0.000026  loss: 1.3585 (1.5218)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [670/781]  eta: 0:00:37  lr: 0.000026  loss: 1.3463 (1.5199)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [680/781]  eta: 0:00:33  lr: 0.000026  loss: 1.3392 (1.5198)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [690/781]  eta: 0:00:30  lr: 0.000026  loss: 1.3402 (1.5181)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [700/781]  eta: 0:00:27  lr: 0.000026  loss: 1.3381 (1.5167)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [710/781]  eta: 0:00:23  lr: 0.000026  loss: 1.3067 (1.5159)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [720/781]  eta: 0:00:20  lr: 0.000026  loss: 1.3067 (1.5157)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [730/781]  eta: 0:00:17  lr: 0.000026  loss: 1.3403 (1.5157)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [740/781]  eta: 0:00:13  lr: 0.000026  loss: 1.3167 (1.5148)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [750/781]  eta: 0:00:10  lr: 0.000026  loss: 1.3670 (1.5161)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [760/781]  eta: 0:00:07  lr: 0.000026  loss: 1.3228 (1.5146)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [770/781]  eta: 0:00:03  lr: 0.000026  loss: 1.3361 (1.5172)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [780/781]  eta: 0:00:00  lr: 0.000026  loss: 1.3567 (1.5183)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [77] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000026  loss: 1.3567 (1.5183)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32551419734954834, 'lambda_convnext_base': 0.2555869221687317, 'lambda_tf_efficientnetv2_l': 0.4188987612724304}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8518 (0.8518)  acc1: 82.2917 (82.2917)  acc5: 94.7917 (94.7917)  time: 0.8420  data: 0.8112  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9676 (1.0218)  acc1: 82.2917 (81.2027)  acc5: 94.7917 (93.3239)  time: 0.1700  data: 0.1394  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0329 (1.0816)  acc1: 76.5625 (79.8859)  acc5: 92.7083 (92.3115)  time: 0.1212  data: 0.0905  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1974 (1.1356)  acc1: 76.0417 (78.9315)  acc5: 90.6250 (91.8011)  time: 0.1242  data: 0.0936  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2536 (1.1845)  acc1: 76.0417 (77.9472)  acc5: 90.6250 (91.2856)  time: 0.1273  data: 0.0966  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1612 (1.1740)  acc1: 75.5208 (77.9003)  acc5: 91.6667 (91.6871)  time: 0.1298  data: 0.0991  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1759 (1.1838)  acc1: 75.5208 (77.7400)  acc5: 92.7083 (91.7000)  time: 0.1116  data: 0.0819  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1334 s / it)\n",
            "* Acc@1 77.740 Acc@5 91.700 loss 1.184\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=78 distillation_alpha=0.5408\n",
            "Epoch: [78]  [  0/781]  eta: 0:14:54  lr: 0.000025  loss: 2.1553 (2.1553)  time: 1.1454  data: 0.7999  max mem: 6459\n",
            "Epoch: [78]  [ 10/781]  eta: 0:05:13  lr: 0.000025  loss: 1.3229 (1.4991)  time: 0.4065  data: 0.0730  max mem: 6459\n",
            "Epoch: [78]  [ 20/781]  eta: 0:04:42  lr: 0.000025  loss: 1.3468 (1.5436)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 30/781]  eta: 0:04:29  lr: 0.000025  loss: 1.4438 (1.6102)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 40/781]  eta: 0:04:21  lr: 0.000025  loss: 1.3605 (1.5561)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 50/781]  eta: 0:04:14  lr: 0.000025  loss: 1.3695 (1.5690)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 60/781]  eta: 0:04:09  lr: 0.000025  loss: 1.3980 (1.6018)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 70/781]  eta: 0:04:04  lr: 0.000025  loss: 1.5051 (1.6169)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 80/781]  eta: 0:04:00  lr: 0.000025  loss: 1.3780 (1.6103)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 90/781]  eta: 0:03:56  lr: 0.000025  loss: 1.3780 (1.6131)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [100/781]  eta: 0:03:52  lr: 0.000025  loss: 1.4030 (1.6204)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [110/781]  eta: 0:03:48  lr: 0.000025  loss: 1.3618 (1.6090)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [120/781]  eta: 0:03:44  lr: 0.000025  loss: 1.3378 (1.6001)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [130/781]  eta: 0:03:40  lr: 0.000025  loss: 1.2972 (1.5883)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [140/781]  eta: 0:03:36  lr: 0.000025  loss: 1.3159 (1.5884)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [150/781]  eta: 0:03:33  lr: 0.000025  loss: 1.3250 (1.5719)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [160/781]  eta: 0:03:29  lr: 0.000025  loss: 1.3007 (1.5598)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [170/781]  eta: 0:03:26  lr: 0.000025  loss: 1.3007 (1.5526)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [180/781]  eta: 0:03:22  lr: 0.000025  loss: 1.3840 (1.5563)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [190/781]  eta: 0:03:19  lr: 0.000025  loss: 1.3203 (1.5508)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [200/781]  eta: 0:03:15  lr: 0.000025  loss: 1.3098 (1.5506)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [210/781]  eta: 0:03:12  lr: 0.000025  loss: 1.3840 (1.5540)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [220/781]  eta: 0:03:08  lr: 0.000025  loss: 1.3868 (1.5512)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [230/781]  eta: 0:03:05  lr: 0.000025  loss: 1.3939 (1.5552)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [240/781]  eta: 0:03:01  lr: 0.000025  loss: 1.4487 (1.5585)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [250/781]  eta: 0:02:58  lr: 0.000025  loss: 1.4240 (1.5642)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [260/781]  eta: 0:02:54  lr: 0.000025  loss: 1.3596 (1.5619)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [270/781]  eta: 0:02:51  lr: 0.000025  loss: 1.2809 (1.5579)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [280/781]  eta: 0:02:48  lr: 0.000025  loss: 1.2669 (1.5474)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [290/781]  eta: 0:02:44  lr: 0.000025  loss: 1.2764 (1.5419)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [300/781]  eta: 0:02:41  lr: 0.000025  loss: 1.3013 (1.5444)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [310/781]  eta: 0:02:37  lr: 0.000025  loss: 1.3409 (1.5419)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [320/781]  eta: 0:02:34  lr: 0.000025  loss: 1.3036 (1.5384)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [330/781]  eta: 0:02:31  lr: 0.000025  loss: 1.3223 (1.5316)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [340/781]  eta: 0:02:27  lr: 0.000025  loss: 1.3096 (1.5313)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [350/781]  eta: 0:02:24  lr: 0.000025  loss: 1.3073 (1.5287)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [360/781]  eta: 0:02:21  lr: 0.000025  loss: 1.3299 (1.5239)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [370/781]  eta: 0:02:17  lr: 0.000025  loss: 1.3791 (1.5275)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [380/781]  eta: 0:02:14  lr: 0.000025  loss: 1.3831 (1.5290)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [390/781]  eta: 0:02:10  lr: 0.000025  loss: 1.3002 (1.5252)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [400/781]  eta: 0:02:07  lr: 0.000025  loss: 1.3654 (1.5290)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [410/781]  eta: 0:02:04  lr: 0.000025  loss: 1.3648 (1.5254)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [420/781]  eta: 0:02:00  lr: 0.000025  loss: 1.3169 (1.5255)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [430/781]  eta: 0:01:57  lr: 0.000025  loss: 1.3217 (1.5276)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [440/781]  eta: 0:01:54  lr: 0.000025  loss: 1.3217 (1.5264)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [450/781]  eta: 0:01:50  lr: 0.000025  loss: 1.3119 (1.5227)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [460/781]  eta: 0:01:47  lr: 0.000025  loss: 1.3244 (1.5218)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [470/781]  eta: 0:01:44  lr: 0.000025  loss: 1.3795 (1.5221)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [480/781]  eta: 0:01:40  lr: 0.000025  loss: 1.3968 (1.5212)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [490/781]  eta: 0:01:37  lr: 0.000025  loss: 1.3975 (1.5226)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [500/781]  eta: 0:01:34  lr: 0.000025  loss: 1.3769 (1.5204)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [510/781]  eta: 0:01:30  lr: 0.000025  loss: 1.3086 (1.5198)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [520/781]  eta: 0:01:27  lr: 0.000025  loss: 1.3186 (1.5233)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [530/781]  eta: 0:01:23  lr: 0.000025  loss: 1.3724 (1.5249)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [540/781]  eta: 0:01:20  lr: 0.000025  loss: 1.3091 (1.5202)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [550/781]  eta: 0:01:17  lr: 0.000025  loss: 1.3093 (1.5220)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [560/781]  eta: 0:01:13  lr: 0.000025  loss: 1.3425 (1.5214)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [570/781]  eta: 0:01:10  lr: 0.000025  loss: 1.3297 (1.5202)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [580/781]  eta: 0:01:07  lr: 0.000025  loss: 1.3276 (1.5187)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [590/781]  eta: 0:01:03  lr: 0.000025  loss: 1.3196 (1.5168)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [600/781]  eta: 0:01:00  lr: 0.000025  loss: 1.3147 (1.5166)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [610/781]  eta: 0:00:57  lr: 0.000025  loss: 1.3100 (1.5155)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [620/781]  eta: 0:00:53  lr: 0.000025  loss: 1.3631 (1.5166)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [630/781]  eta: 0:00:50  lr: 0.000025  loss: 1.3670 (1.5181)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [640/781]  eta: 0:00:47  lr: 0.000025  loss: 1.3459 (1.5193)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [650/781]  eta: 0:00:43  lr: 0.000025  loss: 1.3242 (1.5170)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [660/781]  eta: 0:00:40  lr: 0.000025  loss: 1.2938 (1.5155)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [670/781]  eta: 0:00:37  lr: 0.000025  loss: 1.4004 (1.5163)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [680/781]  eta: 0:00:33  lr: 0.000025  loss: 1.3231 (1.5155)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [690/781]  eta: 0:00:30  lr: 0.000025  loss: 1.3125 (1.5164)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [700/781]  eta: 0:00:27  lr: 0.000025  loss: 1.3653 (1.5158)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [710/781]  eta: 0:00:23  lr: 0.000025  loss: 1.3462 (1.5154)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [720/781]  eta: 0:00:20  lr: 0.000025  loss: 1.3460 (1.5163)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [730/781]  eta: 0:00:17  lr: 0.000025  loss: 1.3548 (1.5152)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [740/781]  eta: 0:00:13  lr: 0.000025  loss: 1.3202 (1.5144)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [750/781]  eta: 0:00:10  lr: 0.000025  loss: 1.3817 (1.5180)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [760/781]  eta: 0:00:07  lr: 0.000025  loss: 1.4077 (1.5167)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [770/781]  eta: 0:00:03  lr: 0.000025  loss: 1.3439 (1.5163)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [780/781]  eta: 0:00:00  lr: 0.000025  loss: 1.3048 (1.5144)  time: 0.3329  data: 0.0006  max mem: 6459\n",
            "Epoch: [78] Total time: 0:04:20 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000025  loss: 1.3048 (1.5144)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3253879249095917, 'lambda_convnext_base': 0.25505557656288147, 'lambda_tf_efficientnetv2_l': 0.41955652832984924}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8330 (0.8330)  acc1: 82.8125 (82.8125)  acc5: 94.7917 (94.7917)  time: 0.8454  data: 0.8145  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9490 (1.0169)  acc1: 82.8125 (80.8712)  acc5: 93.7500 (93.0398)  time: 0.1746  data: 0.1439  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1435 (1.0880)  acc1: 77.0833 (79.3899)  acc5: 92.1875 (92.2619)  time: 0.1257  data: 0.0951  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2006 (1.1335)  acc1: 75.5208 (78.3938)  acc5: 91.6667 (91.8011)  time: 0.1237  data: 0.0930  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2209 (1.1726)  acc1: 76.0417 (77.9218)  acc5: 89.5833 (91.3491)  time: 0.1233  data: 0.0926  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1643 (1.1699)  acc1: 77.0833 (77.6246)  acc5: 91.6667 (91.5748)  time: 0.1275  data: 0.0968  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2192 (1.1875)  acc1: 76.5625 (77.5000)  acc5: 91.6667 (91.6000)  time: 0.1101  data: 0.0803  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1329 s / it)\n",
            "* Acc@1 77.500 Acc@5 91.600 loss 1.187\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=79 distillation_alpha=0.5477\n",
            "Epoch: [79]  [  0/781]  eta: 0:14:43  lr: 0.000024  loss: 1.2893 (1.2893)  time: 1.1306  data: 0.7864  max mem: 6459\n",
            "Epoch: [79]  [ 10/781]  eta: 0:05:12  lr: 0.000024  loss: 1.3540 (1.4620)  time: 0.4057  data: 0.0718  max mem: 6459\n",
            "Epoch: [79]  [ 20/781]  eta: 0:04:42  lr: 0.000024  loss: 1.3492 (1.4770)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 30/781]  eta: 0:04:29  lr: 0.000024  loss: 1.4015 (1.5706)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 40/781]  eta: 0:04:21  lr: 0.000024  loss: 1.3700 (1.5303)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 50/781]  eta: 0:04:14  lr: 0.000024  loss: 1.3561 (1.5725)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 60/781]  eta: 0:04:09  lr: 0.000024  loss: 1.7449 (1.5847)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 70/781]  eta: 0:04:04  lr: 0.000024  loss: 1.3351 (1.5674)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 80/781]  eta: 0:04:00  lr: 0.000024  loss: 1.2945 (1.5581)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 90/781]  eta: 0:03:56  lr: 0.000024  loss: 1.2926 (1.5535)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [100/781]  eta: 0:03:52  lr: 0.000024  loss: 1.3592 (1.5630)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [110/781]  eta: 0:03:48  lr: 0.000024  loss: 1.3754 (1.5684)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [120/781]  eta: 0:03:44  lr: 0.000024  loss: 1.3636 (1.5659)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [130/781]  eta: 0:03:40  lr: 0.000024  loss: 1.3237 (1.5501)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [140/781]  eta: 0:03:37  lr: 0.000024  loss: 1.3176 (1.5582)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [150/781]  eta: 0:03:33  lr: 0.000024  loss: 1.3519 (1.5655)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [160/781]  eta: 0:03:29  lr: 0.000024  loss: 1.3051 (1.5606)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [170/781]  eta: 0:03:26  lr: 0.000024  loss: 1.3069 (1.5455)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [180/781]  eta: 0:03:22  lr: 0.000024  loss: 1.3069 (1.5407)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [190/781]  eta: 0:03:19  lr: 0.000024  loss: 1.3101 (1.5399)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [200/781]  eta: 0:03:15  lr: 0.000024  loss: 1.3315 (1.5345)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [210/781]  eta: 0:03:12  lr: 0.000024  loss: 1.3456 (1.5446)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [220/781]  eta: 0:03:08  lr: 0.000024  loss: 1.3193 (1.5379)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [230/781]  eta: 0:03:05  lr: 0.000024  loss: 1.3452 (1.5476)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [240/781]  eta: 0:03:01  lr: 0.000024  loss: 1.3793 (1.5505)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [250/781]  eta: 0:02:58  lr: 0.000024  loss: 1.4239 (1.5538)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [260/781]  eta: 0:02:55  lr: 0.000024  loss: 1.4239 (1.5501)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [270/781]  eta: 0:02:51  lr: 0.000024  loss: 1.3340 (1.5471)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [280/781]  eta: 0:02:48  lr: 0.000024  loss: 1.3219 (1.5452)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [290/781]  eta: 0:02:44  lr: 0.000024  loss: 1.3260 (1.5439)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [300/781]  eta: 0:02:41  lr: 0.000024  loss: 1.3362 (1.5379)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [310/781]  eta: 0:02:38  lr: 0.000024  loss: 1.3358 (1.5363)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [320/781]  eta: 0:02:34  lr: 0.000024  loss: 1.2952 (1.5335)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [330/781]  eta: 0:02:31  lr: 0.000024  loss: 1.3288 (1.5383)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [340/781]  eta: 0:02:27  lr: 0.000024  loss: 1.3979 (1.5393)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [350/781]  eta: 0:02:24  lr: 0.000024  loss: 1.3057 (1.5350)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [360/781]  eta: 0:02:21  lr: 0.000024  loss: 1.3205 (1.5298)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [370/781]  eta: 0:02:17  lr: 0.000024  loss: 1.3596 (1.5334)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [380/781]  eta: 0:02:14  lr: 0.000024  loss: 1.3637 (1.5320)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [390/781]  eta: 0:02:10  lr: 0.000024  loss: 1.3581 (1.5297)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [400/781]  eta: 0:02:07  lr: 0.000024  loss: 1.3769 (1.5321)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [410/781]  eta: 0:02:04  lr: 0.000024  loss: 1.3395 (1.5315)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [420/781]  eta: 0:02:00  lr: 0.000024  loss: 1.3182 (1.5296)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [430/781]  eta: 0:01:57  lr: 0.000024  loss: 1.3736 (1.5284)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [440/781]  eta: 0:01:54  lr: 0.000024  loss: 1.3736 (1.5289)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [450/781]  eta: 0:01:50  lr: 0.000024  loss: 1.3758 (1.5300)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [460/781]  eta: 0:01:47  lr: 0.000024  loss: 1.3607 (1.5295)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [470/781]  eta: 0:01:44  lr: 0.000024  loss: 1.3466 (1.5308)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [480/781]  eta: 0:01:40  lr: 0.000024  loss: 1.2986 (1.5298)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [490/781]  eta: 0:01:37  lr: 0.000024  loss: 1.3018 (1.5323)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [500/781]  eta: 0:01:33  lr: 0.000024  loss: 1.4051 (1.5373)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [510/781]  eta: 0:01:30  lr: 0.000024  loss: 1.3437 (1.5360)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [520/781]  eta: 0:01:27  lr: 0.000024  loss: 1.3108 (1.5369)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [530/781]  eta: 0:01:23  lr: 0.000024  loss: 1.3368 (1.5350)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [540/781]  eta: 0:01:20  lr: 0.000024  loss: 1.3268 (1.5331)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [550/781]  eta: 0:01:17  lr: 0.000024  loss: 1.3088 (1.5295)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [560/781]  eta: 0:01:13  lr: 0.000024  loss: 1.3088 (1.5312)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [570/781]  eta: 0:01:10  lr: 0.000024  loss: 1.3023 (1.5308)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [580/781]  eta: 0:01:07  lr: 0.000024  loss: 1.3239 (1.5331)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [590/781]  eta: 0:01:03  lr: 0.000024  loss: 1.3318 (1.5332)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [600/781]  eta: 0:01:00  lr: 0.000024  loss: 1.3313 (1.5324)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [610/781]  eta: 0:00:57  lr: 0.000024  loss: 1.3916 (1.5327)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [620/781]  eta: 0:00:53  lr: 0.000024  loss: 1.4182 (1.5343)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [630/781]  eta: 0:00:50  lr: 0.000024  loss: 1.3433 (1.5341)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [640/781]  eta: 0:00:47  lr: 0.000024  loss: 1.3433 (1.5342)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [650/781]  eta: 0:00:43  lr: 0.000024  loss: 1.3119 (1.5329)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [660/781]  eta: 0:00:40  lr: 0.000024  loss: 1.2618 (1.5304)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [670/781]  eta: 0:00:37  lr: 0.000024  loss: 1.3099 (1.5294)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [680/781]  eta: 0:00:33  lr: 0.000024  loss: 1.3293 (1.5298)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [690/781]  eta: 0:00:30  lr: 0.000024  loss: 1.3229 (1.5310)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [700/781]  eta: 0:00:27  lr: 0.000024  loss: 1.3490 (1.5319)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [710/781]  eta: 0:00:23  lr: 0.000024  loss: 1.4011 (1.5356)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [720/781]  eta: 0:00:20  lr: 0.000024  loss: 1.4912 (1.5385)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [730/781]  eta: 0:00:17  lr: 0.000024  loss: 1.3475 (1.5382)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [740/781]  eta: 0:00:13  lr: 0.000024  loss: 1.3475 (1.5396)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [750/781]  eta: 0:00:10  lr: 0.000024  loss: 1.3507 (1.5387)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [760/781]  eta: 0:00:07  lr: 0.000024  loss: 1.3548 (1.5374)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [770/781]  eta: 0:00:03  lr: 0.000024  loss: 1.3676 (1.5379)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [780/781]  eta: 0:00:00  lr: 0.000024  loss: 1.3533 (1.5368)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [79] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000024  loss: 1.3533 (1.5368)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32476943731307983, 'lambda_convnext_base': 0.2554762363433838, 'lambda_tf_efficientnetv2_l': 0.41975459456443787}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8732 (0.8732)  acc1: 83.3333 (83.3333)  acc5: 94.2708 (94.2708)  time: 0.8524  data: 0.8215  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0415 (1.0043)  acc1: 82.2917 (81.0606)  acc5: 93.7500 (93.0398)  time: 0.1746  data: 0.1439  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0906 (1.0764)  acc1: 77.0833 (79.6627)  acc5: 91.6667 (92.3115)  time: 0.1265  data: 0.0958  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2018 (1.1306)  acc1: 75.0000 (78.7130)  acc5: 91.1458 (91.6499)  time: 0.1282  data: 0.0976  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3112 (1.1717)  acc1: 75.0000 (77.9980)  acc5: 89.5833 (91.1585)  time: 0.1322  data: 0.1016  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1407 (1.1655)  acc1: 76.0417 (77.7063)  acc5: 91.6667 (91.4726)  time: 0.1307  data: 0.1000  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1505 (1.1779)  acc1: 75.0000 (77.5800)  acc5: 91.6667 (91.4800)  time: 0.1086  data: 0.0790  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1357 s / it)\n",
            "* Acc@1 77.580 Acc@5 91.480 loss 1.178\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=80 distillation_alpha=0.5545\n",
            "Epoch: [80]  [  0/781]  eta: 0:12:54  lr: 0.000024  loss: 1.2688 (1.2688)  time: 0.9912  data: 0.6530  max mem: 6459\n",
            "Epoch: [80]  [ 10/781]  eta: 0:05:03  lr: 0.000024  loss: 1.2964 (1.3826)  time: 0.3932  data: 0.0596  max mem: 6459\n",
            "Epoch: [80]  [ 20/781]  eta: 0:04:37  lr: 0.000024  loss: 1.3132 (1.3470)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 30/781]  eta: 0:04:26  lr: 0.000024  loss: 1.3250 (1.3849)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 40/781]  eta: 0:04:18  lr: 0.000024  loss: 1.3346 (1.4166)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 50/781]  eta: 0:04:12  lr: 0.000024  loss: 1.3346 (1.4480)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 60/781]  eta: 0:04:07  lr: 0.000024  loss: 1.3251 (1.4527)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 70/781]  eta: 0:04:03  lr: 0.000024  loss: 1.3385 (1.4685)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 80/781]  eta: 0:03:58  lr: 0.000024  loss: 1.3445 (1.4610)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 90/781]  eta: 0:03:54  lr: 0.000024  loss: 1.3445 (1.4764)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [100/781]  eta: 0:03:51  lr: 0.000024  loss: 1.3452 (1.4777)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [110/781]  eta: 0:03:47  lr: 0.000024  loss: 1.3360 (1.4787)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [120/781]  eta: 0:03:43  lr: 0.000024  loss: 1.2769 (1.4702)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [130/781]  eta: 0:03:39  lr: 0.000024  loss: 1.2765 (1.4945)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [140/781]  eta: 0:03:36  lr: 0.000024  loss: 1.3544 (1.4855)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [150/781]  eta: 0:03:32  lr: 0.000024  loss: 1.3598 (1.4859)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [160/781]  eta: 0:03:29  lr: 0.000024  loss: 1.3856 (1.4890)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [170/781]  eta: 0:03:25  lr: 0.000024  loss: 1.3488 (1.4943)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [180/781]  eta: 0:03:22  lr: 0.000024  loss: 1.2947 (1.4997)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [190/781]  eta: 0:03:18  lr: 0.000024  loss: 1.3098 (1.5032)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [200/781]  eta: 0:03:15  lr: 0.000024  loss: 1.3383 (1.5034)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [210/781]  eta: 0:03:11  lr: 0.000024  loss: 1.3477 (1.5009)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [220/781]  eta: 0:03:08  lr: 0.000024  loss: 1.3483 (1.5066)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [230/781]  eta: 0:03:04  lr: 0.000024  loss: 1.3374 (1.5034)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [240/781]  eta: 0:03:01  lr: 0.000024  loss: 1.2914 (1.4965)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [250/781]  eta: 0:02:58  lr: 0.000024  loss: 1.2914 (1.4937)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [260/781]  eta: 0:02:54  lr: 0.000024  loss: 1.3258 (1.4989)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [270/781]  eta: 0:02:51  lr: 0.000024  loss: 1.3448 (1.4960)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [280/781]  eta: 0:02:47  lr: 0.000024  loss: 1.3394 (1.4992)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [290/781]  eta: 0:02:44  lr: 0.000024  loss: 1.3592 (1.5057)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [300/781]  eta: 0:02:41  lr: 0.000024  loss: 1.3818 (1.5088)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [310/781]  eta: 0:02:37  lr: 0.000024  loss: 1.3818 (1.5135)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [320/781]  eta: 0:02:34  lr: 0.000024  loss: 1.4050 (1.5155)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [330/781]  eta: 0:02:31  lr: 0.000024  loss: 1.3296 (1.5129)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [340/781]  eta: 0:02:27  lr: 0.000024  loss: 1.3098 (1.5150)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [350/781]  eta: 0:02:24  lr: 0.000024  loss: 1.3886 (1.5225)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [360/781]  eta: 0:02:20  lr: 0.000024  loss: 1.3560 (1.5205)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [370/781]  eta: 0:02:17  lr: 0.000024  loss: 1.4013 (1.5255)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [380/781]  eta: 0:02:14  lr: 0.000024  loss: 1.3714 (1.5240)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [390/781]  eta: 0:02:10  lr: 0.000024  loss: 1.3303 (1.5256)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [400/781]  eta: 0:02:07  lr: 0.000024  loss: 1.3658 (1.5263)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [410/781]  eta: 0:02:04  lr: 0.000024  loss: 1.3658 (1.5299)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [420/781]  eta: 0:02:00  lr: 0.000024  loss: 1.3580 (1.5290)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [430/781]  eta: 0:01:57  lr: 0.000024  loss: 1.3392 (1.5287)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [440/781]  eta: 0:01:54  lr: 0.000024  loss: 1.2820 (1.5242)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [450/781]  eta: 0:01:50  lr: 0.000024  loss: 1.3423 (1.5318)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [460/781]  eta: 0:01:47  lr: 0.000024  loss: 1.4027 (1.5297)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [470/781]  eta: 0:01:43  lr: 0.000024  loss: 1.3144 (1.5245)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [480/781]  eta: 0:01:40  lr: 0.000024  loss: 1.3251 (1.5244)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [490/781]  eta: 0:01:37  lr: 0.000024  loss: 1.4224 (1.5313)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [500/781]  eta: 0:01:33  lr: 0.000024  loss: 1.3846 (1.5298)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [510/781]  eta: 0:01:30  lr: 0.000024  loss: 1.3285 (1.5319)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [520/781]  eta: 0:01:27  lr: 0.000024  loss: 1.3289 (1.5322)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [530/781]  eta: 0:01:23  lr: 0.000024  loss: 1.3289 (1.5303)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [540/781]  eta: 0:01:20  lr: 0.000024  loss: 1.3234 (1.5297)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [550/781]  eta: 0:01:17  lr: 0.000024  loss: 1.3190 (1.5277)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [560/781]  eta: 0:01:13  lr: 0.000024  loss: 1.3141 (1.5249)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [570/781]  eta: 0:01:10  lr: 0.000024  loss: 1.3336 (1.5288)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [580/781]  eta: 0:01:07  lr: 0.000024  loss: 1.3036 (1.5256)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [590/781]  eta: 0:01:03  lr: 0.000024  loss: 1.3036 (1.5278)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [600/781]  eta: 0:01:00  lr: 0.000024  loss: 1.3424 (1.5263)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [610/781]  eta: 0:00:57  lr: 0.000024  loss: 1.3690 (1.5268)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [620/781]  eta: 0:00:53  lr: 0.000024  loss: 1.3654 (1.5242)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [630/781]  eta: 0:00:50  lr: 0.000024  loss: 1.2854 (1.5227)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [640/781]  eta: 0:00:47  lr: 0.000024  loss: 1.3248 (1.5213)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [650/781]  eta: 0:00:43  lr: 0.000024  loss: 1.3463 (1.5216)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [660/781]  eta: 0:00:40  lr: 0.000024  loss: 1.3321 (1.5185)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [670/781]  eta: 0:00:37  lr: 0.000024  loss: 1.3199 (1.5205)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [680/781]  eta: 0:00:33  lr: 0.000024  loss: 1.2947 (1.5206)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [690/781]  eta: 0:00:30  lr: 0.000024  loss: 1.2613 (1.5171)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [700/781]  eta: 0:00:27  lr: 0.000024  loss: 1.2909 (1.5172)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [710/781]  eta: 0:00:23  lr: 0.000024  loss: 1.3473 (1.5184)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [720/781]  eta: 0:00:20  lr: 0.000024  loss: 1.3926 (1.5197)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [730/781]  eta: 0:00:17  lr: 0.000024  loss: 1.4083 (1.5207)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [740/781]  eta: 0:00:13  lr: 0.000024  loss: 1.3570 (1.5205)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [750/781]  eta: 0:00:10  lr: 0.000024  loss: 1.3692 (1.5209)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [760/781]  eta: 0:00:07  lr: 0.000024  loss: 1.3679 (1.5210)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [770/781]  eta: 0:00:03  lr: 0.000024  loss: 1.3525 (1.5205)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [780/781]  eta: 0:00:00  lr: 0.000024  loss: 1.3525 (1.5214)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [80] Total time: 0:04:20 (0.3338 s / it)\n",
            "Averaged stats: lr: 0.000024  loss: 1.3525 (1.5214)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32371804118156433, 'lambda_convnext_base': 0.2548198401927948, 'lambda_tf_efficientnetv2_l': 0.42146170139312744}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8410 (0.8410)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8211  data: 0.7902  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8912 (1.0050)  acc1: 83.3333 (81.0606)  acc5: 93.7500 (93.2292)  time: 0.1697  data: 0.1391  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0395 (1.0636)  acc1: 80.2083 (80.0099)  acc5: 93.2292 (92.5099)  time: 0.1245  data: 0.0939  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1650 (1.1154)  acc1: 76.5625 (78.9987)  acc5: 92.7083 (92.0363)  time: 0.1278  data: 0.0971  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1934 (1.1626)  acc1: 76.0417 (78.1758)  acc5: 89.5833 (91.5523)  time: 0.1279  data: 0.0972  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1735 (1.1621)  acc1: 75.0000 (77.8901)  acc5: 91.6667 (91.7279)  time: 0.1280  data: 0.0974  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2130 (1.1739)  acc1: 75.0000 (77.7700)  acc5: 91.6667 (91.7500)  time: 0.1112  data: 0.0815  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1334 s / it)\n",
            "* Acc@1 77.770 Acc@5 91.750 loss 1.174\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=81 distillation_alpha=0.5613\n",
            "Epoch: [81]  [  0/781]  eta: 0:14:30  lr: 0.000023  loss: 1.2369 (1.2369)  time: 1.1144  data: 0.7699  max mem: 6459\n",
            "Epoch: [81]  [ 10/781]  eta: 0:05:11  lr: 0.000023  loss: 1.3217 (1.4588)  time: 0.4040  data: 0.0703  max mem: 6459\n",
            "Epoch: [81]  [ 20/781]  eta: 0:04:41  lr: 0.000023  loss: 1.3232 (1.4542)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 30/781]  eta: 0:04:29  lr: 0.000023  loss: 1.3315 (1.4588)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 40/781]  eta: 0:04:20  lr: 0.000023  loss: 1.3504 (1.4829)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 50/781]  eta: 0:04:14  lr: 0.000023  loss: 1.2621 (1.4509)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 60/781]  eta: 0:04:09  lr: 0.000023  loss: 1.2804 (1.4879)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 70/781]  eta: 0:04:04  lr: 0.000023  loss: 1.3186 (1.4747)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 80/781]  eta: 0:04:00  lr: 0.000023  loss: 1.3306 (1.4966)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 90/781]  eta: 0:03:55  lr: 0.000023  loss: 1.3576 (1.4956)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [100/781]  eta: 0:03:51  lr: 0.000023  loss: 1.3076 (1.4975)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [110/781]  eta: 0:03:48  lr: 0.000023  loss: 1.2798 (1.4900)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [120/781]  eta: 0:03:44  lr: 0.000023  loss: 1.3022 (1.4951)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [130/781]  eta: 0:03:40  lr: 0.000023  loss: 1.3150 (1.4867)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [140/781]  eta: 0:03:36  lr: 0.000023  loss: 1.3194 (1.4911)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [150/781]  eta: 0:03:33  lr: 0.000023  loss: 1.3194 (1.4839)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [160/781]  eta: 0:03:29  lr: 0.000023  loss: 1.3134 (1.4799)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [170/781]  eta: 0:03:26  lr: 0.000023  loss: 1.3257 (1.4856)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [180/781]  eta: 0:03:22  lr: 0.000023  loss: 1.3246 (1.4810)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [190/781]  eta: 0:03:19  lr: 0.000023  loss: 1.3156 (1.4824)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [200/781]  eta: 0:03:15  lr: 0.000023  loss: 1.3362 (1.4863)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [210/781]  eta: 0:03:12  lr: 0.000023  loss: 1.3362 (1.4903)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [220/781]  eta: 0:03:08  lr: 0.000023  loss: 1.3278 (1.4911)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [230/781]  eta: 0:03:05  lr: 0.000023  loss: 1.3546 (1.5026)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [240/781]  eta: 0:03:01  lr: 0.000023  loss: 1.4342 (1.5077)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [250/781]  eta: 0:02:58  lr: 0.000023  loss: 1.3139 (1.5082)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [260/781]  eta: 0:02:55  lr: 0.000023  loss: 1.2993 (1.5092)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [270/781]  eta: 0:02:51  lr: 0.000023  loss: 1.3199 (1.5026)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [280/781]  eta: 0:02:48  lr: 0.000023  loss: 1.3280 (1.5038)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [290/781]  eta: 0:02:45  lr: 0.000023  loss: 1.3267 (1.5091)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [300/781]  eta: 0:02:41  lr: 0.000023  loss: 1.3539 (1.5083)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [310/781]  eta: 0:02:38  lr: 0.000023  loss: 1.3431 (1.5093)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [320/781]  eta: 0:02:34  lr: 0.000023  loss: 1.3430 (1.5070)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [330/781]  eta: 0:02:31  lr: 0.000023  loss: 1.3335 (1.5059)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [340/781]  eta: 0:02:28  lr: 0.000023  loss: 1.3335 (1.5085)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [350/781]  eta: 0:02:24  lr: 0.000023  loss: 1.4068 (1.5112)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [360/781]  eta: 0:02:21  lr: 0.000023  loss: 1.3904 (1.5120)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [370/781]  eta: 0:02:17  lr: 0.000023  loss: 1.3117 (1.5090)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [380/781]  eta: 0:02:14  lr: 0.000023  loss: 1.2657 (1.5052)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [390/781]  eta: 0:02:11  lr: 0.000023  loss: 1.2811 (1.5063)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [400/781]  eta: 0:02:07  lr: 0.000023  loss: 1.3798 (1.5093)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [410/781]  eta: 0:02:04  lr: 0.000023  loss: 1.4255 (1.5146)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [420/781]  eta: 0:02:00  lr: 0.000023  loss: 1.4145 (1.5140)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [430/781]  eta: 0:01:57  lr: 0.000023  loss: 1.3000 (1.5098)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [440/781]  eta: 0:01:54  lr: 0.000023  loss: 1.2889 (1.5066)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [450/781]  eta: 0:01:50  lr: 0.000023  loss: 1.3002 (1.5048)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [460/781]  eta: 0:01:47  lr: 0.000023  loss: 1.2928 (1.5000)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [470/781]  eta: 0:01:44  lr: 0.000023  loss: 1.2849 (1.4998)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [480/781]  eta: 0:01:40  lr: 0.000023  loss: 1.3389 (1.5029)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [490/781]  eta: 0:01:37  lr: 0.000023  loss: 1.3275 (1.5009)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [500/781]  eta: 0:01:34  lr: 0.000023  loss: 1.2856 (1.4995)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [510/781]  eta: 0:01:30  lr: 0.000023  loss: 1.3087 (1.5027)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [520/781]  eta: 0:01:27  lr: 0.000023  loss: 1.2961 (1.4988)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [530/781]  eta: 0:01:23  lr: 0.000023  loss: 1.2717 (1.4982)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [540/781]  eta: 0:01:20  lr: 0.000023  loss: 1.2901 (1.4955)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [550/781]  eta: 0:01:17  lr: 0.000023  loss: 1.3316 (1.4965)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [560/781]  eta: 0:01:13  lr: 0.000023  loss: 1.3838 (1.4982)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [570/781]  eta: 0:01:10  lr: 0.000023  loss: 1.3662 (1.4969)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [580/781]  eta: 0:01:07  lr: 0.000023  loss: 1.3397 (1.4969)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [590/781]  eta: 0:01:03  lr: 0.000023  loss: 1.2970 (1.4956)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [600/781]  eta: 0:01:00  lr: 0.000023  loss: 1.2941 (1.4939)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [610/781]  eta: 0:00:57  lr: 0.000023  loss: 1.3002 (1.4977)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [620/781]  eta: 0:00:53  lr: 0.000023  loss: 1.2849 (1.4967)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [630/781]  eta: 0:00:50  lr: 0.000023  loss: 1.2979 (1.4976)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [640/781]  eta: 0:00:47  lr: 0.000023  loss: 1.3408 (1.4986)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [650/781]  eta: 0:00:43  lr: 0.000023  loss: 1.3046 (1.4985)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [660/781]  eta: 0:00:40  lr: 0.000023  loss: 1.3826 (1.4997)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [670/781]  eta: 0:00:37  lr: 0.000023  loss: 1.3365 (1.4980)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [680/781]  eta: 0:00:33  lr: 0.000023  loss: 1.3049 (1.4973)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [690/781]  eta: 0:00:30  lr: 0.000023  loss: 1.3541 (1.4990)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [700/781]  eta: 0:00:27  lr: 0.000023  loss: 1.3037 (1.4968)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [710/781]  eta: 0:00:23  lr: 0.000023  loss: 1.3037 (1.4976)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [720/781]  eta: 0:00:20  lr: 0.000023  loss: 1.4466 (1.4997)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [730/781]  eta: 0:00:17  lr: 0.000023  loss: 1.4613 (1.5028)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [740/781]  eta: 0:00:13  lr: 0.000023  loss: 1.4180 (1.5049)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [750/781]  eta: 0:00:10  lr: 0.000023  loss: 1.3449 (1.5046)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [760/781]  eta: 0:00:07  lr: 0.000023  loss: 1.3322 (1.5048)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [770/781]  eta: 0:00:03  lr: 0.000023  loss: 1.3404 (1.5041)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [780/781]  eta: 0:00:00  lr: 0.000023  loss: 1.3511 (1.5042)  time: 0.3327  data: 0.0005  max mem: 6459\n",
            "Epoch: [81] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000023  loss: 1.3511 (1.5042)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32573553919792175, 'lambda_convnext_base': 0.2555809020996094, 'lambda_tf_efficientnetv2_l': 0.41868337988853455}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.9137 (0.9137)  acc1: 82.2917 (82.2917)  acc5: 94.7917 (94.7917)  time: 0.8314  data: 0.8006  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9780 (1.0155)  acc1: 82.2917 (80.8712)  acc5: 94.2708 (93.0871)  time: 0.1762  data: 0.1455  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1242 (1.0722)  acc1: 77.6042 (79.7371)  acc5: 92.7083 (92.5099)  time: 0.1286  data: 0.0979  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2056 (1.1272)  acc1: 76.0417 (78.5786)  acc5: 91.6667 (91.9523)  time: 0.1268  data: 0.0962  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2785 (1.1692)  acc1: 74.4792 (77.9472)  acc5: 90.6250 (91.5015)  time: 0.1232  data: 0.0926  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1348 (1.1646)  acc1: 78.1250 (77.7574)  acc5: 91.6667 (91.7484)  time: 0.1213  data: 0.0906  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1439 (1.1801)  acc1: 74.4792 (77.5900)  acc5: 92.1875 (91.7600)  time: 0.1035  data: 0.0737  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1324 s / it)\n",
            "* Acc@1 77.590 Acc@5 91.760 loss 1.180\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=82 distillation_alpha=0.5679\n",
            "Epoch: [82]  [  0/781]  eta: 0:14:52  lr: 0.000023  loss: 1.2225 (1.2225)  time: 1.1428  data: 0.7946  max mem: 6459\n",
            "Epoch: [82]  [ 10/781]  eta: 0:05:13  lr: 0.000023  loss: 1.3297 (1.5031)  time: 0.4067  data: 0.0725  max mem: 6459\n",
            "Epoch: [82]  [ 20/781]  eta: 0:04:42  lr: 0.000023  loss: 1.3297 (1.4563)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 30/781]  eta: 0:04:29  lr: 0.000023  loss: 1.2819 (1.4273)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 40/781]  eta: 0:04:21  lr: 0.000023  loss: 1.2755 (1.4121)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 50/781]  eta: 0:04:14  lr: 0.000023  loss: 1.3252 (1.4198)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 60/781]  eta: 0:04:09  lr: 0.000023  loss: 1.2900 (1.4235)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 70/781]  eta: 0:04:04  lr: 0.000023  loss: 1.3251 (1.4577)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 80/781]  eta: 0:04:00  lr: 0.000023  loss: 1.3503 (1.4574)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 90/781]  eta: 0:03:56  lr: 0.000023  loss: 1.3218 (1.4862)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [100/781]  eta: 0:03:52  lr: 0.000023  loss: 1.3546 (1.4900)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [110/781]  eta: 0:03:48  lr: 0.000023  loss: 1.6284 (1.5264)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [120/781]  eta: 0:03:44  lr: 0.000023  loss: 1.3304 (1.5183)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [130/781]  eta: 0:03:40  lr: 0.000023  loss: 1.2947 (1.5258)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [140/781]  eta: 0:03:37  lr: 0.000023  loss: 1.2947 (1.5099)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [150/781]  eta: 0:03:33  lr: 0.000023  loss: 1.2887 (1.5136)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [160/781]  eta: 0:03:29  lr: 0.000023  loss: 1.3070 (1.5084)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [170/781]  eta: 0:03:26  lr: 0.000023  loss: 1.3560 (1.5224)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [180/781]  eta: 0:03:22  lr: 0.000023  loss: 1.3901 (1.5287)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [190/781]  eta: 0:03:19  lr: 0.000023  loss: 1.3597 (1.5360)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [200/781]  eta: 0:03:15  lr: 0.000023  loss: 1.4026 (1.5437)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [210/781]  eta: 0:03:12  lr: 0.000023  loss: 1.3248 (1.5464)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [220/781]  eta: 0:03:08  lr: 0.000023  loss: 1.3061 (1.5356)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [230/781]  eta: 0:03:05  lr: 0.000023  loss: 1.3106 (1.5296)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [240/781]  eta: 0:03:01  lr: 0.000023  loss: 1.3747 (1.5270)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [250/781]  eta: 0:02:58  lr: 0.000023  loss: 1.4044 (1.5270)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [260/781]  eta: 0:02:55  lr: 0.000023  loss: 1.3262 (1.5273)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [270/781]  eta: 0:02:51  lr: 0.000023  loss: 1.3211 (1.5268)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [280/781]  eta: 0:02:48  lr: 0.000023  loss: 1.3408 (1.5297)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [290/781]  eta: 0:02:44  lr: 0.000023  loss: 1.3467 (1.5316)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [300/781]  eta: 0:02:41  lr: 0.000023  loss: 1.3136 (1.5281)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [310/781]  eta: 0:02:37  lr: 0.000023  loss: 1.2875 (1.5231)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [320/781]  eta: 0:02:34  lr: 0.000023  loss: 1.2875 (1.5209)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [330/781]  eta: 0:02:31  lr: 0.000023  loss: 1.2833 (1.5197)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [340/781]  eta: 0:02:27  lr: 0.000023  loss: 1.3345 (1.5183)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [350/781]  eta: 0:02:24  lr: 0.000023  loss: 1.3215 (1.5150)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [360/781]  eta: 0:02:21  lr: 0.000023  loss: 1.2870 (1.5162)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [370/781]  eta: 0:02:17  lr: 0.000023  loss: 1.3099 (1.5164)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [380/781]  eta: 0:02:14  lr: 0.000023  loss: 1.3233 (1.5146)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [390/781]  eta: 0:02:10  lr: 0.000023  loss: 1.3555 (1.5167)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [400/781]  eta: 0:02:07  lr: 0.000023  loss: 1.3555 (1.5130)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [410/781]  eta: 0:02:04  lr: 0.000023  loss: 1.3168 (1.5141)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [420/781]  eta: 0:02:00  lr: 0.000023  loss: 1.3168 (1.5132)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [430/781]  eta: 0:01:57  lr: 0.000023  loss: 1.3168 (1.5138)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [440/781]  eta: 0:01:54  lr: 0.000023  loss: 1.3704 (1.5145)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [450/781]  eta: 0:01:50  lr: 0.000023  loss: 1.3606 (1.5143)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [460/781]  eta: 0:01:47  lr: 0.000023  loss: 1.3371 (1.5131)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [470/781]  eta: 0:01:44  lr: 0.000023  loss: 1.3159 (1.5139)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [480/781]  eta: 0:01:40  lr: 0.000023  loss: 1.3229 (1.5180)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [490/781]  eta: 0:01:37  lr: 0.000023  loss: 1.3618 (1.5197)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [500/781]  eta: 0:01:33  lr: 0.000023  loss: 1.3178 (1.5160)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [510/781]  eta: 0:01:30  lr: 0.000023  loss: 1.3223 (1.5156)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [520/781]  eta: 0:01:27  lr: 0.000023  loss: 1.3451 (1.5134)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [530/781]  eta: 0:01:23  lr: 0.000023  loss: 1.3239 (1.5166)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [540/781]  eta: 0:01:20  lr: 0.000023  loss: 1.3239 (1.5155)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [550/781]  eta: 0:01:17  lr: 0.000023  loss: 1.2852 (1.5144)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [560/781]  eta: 0:01:13  lr: 0.000023  loss: 1.3223 (1.5158)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [570/781]  eta: 0:01:10  lr: 0.000023  loss: 1.3223 (1.5161)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [580/781]  eta: 0:01:07  lr: 0.000023  loss: 1.3230 (1.5141)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [590/781]  eta: 0:01:03  lr: 0.000023  loss: 1.3380 (1.5175)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [600/781]  eta: 0:01:00  lr: 0.000023  loss: 1.4337 (1.5218)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [610/781]  eta: 0:00:57  lr: 0.000023  loss: 1.3538 (1.5200)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [620/781]  eta: 0:00:53  lr: 0.000023  loss: 1.3129 (1.5198)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [630/781]  eta: 0:00:50  lr: 0.000023  loss: 1.3062 (1.5211)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [640/781]  eta: 0:00:47  lr: 0.000023  loss: 1.3442 (1.5219)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [650/781]  eta: 0:00:43  lr: 0.000023  loss: 1.3190 (1.5205)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [660/781]  eta: 0:00:40  lr: 0.000023  loss: 1.2931 (1.5215)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [670/781]  eta: 0:00:37  lr: 0.000023  loss: 1.3514 (1.5207)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [680/781]  eta: 0:00:33  lr: 0.000023  loss: 1.3450 (1.5183)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [690/781]  eta: 0:00:30  lr: 0.000023  loss: 1.2852 (1.5166)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [700/781]  eta: 0:00:27  lr: 0.000023  loss: 1.2910 (1.5150)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [710/781]  eta: 0:00:23  lr: 0.000023  loss: 1.3209 (1.5158)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [720/781]  eta: 0:00:20  lr: 0.000023  loss: 1.3683 (1.5174)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [730/781]  eta: 0:00:17  lr: 0.000023  loss: 1.3687 (1.5176)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [740/781]  eta: 0:00:13  lr: 0.000023  loss: 1.3298 (1.5171)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [750/781]  eta: 0:00:10  lr: 0.000023  loss: 1.3058 (1.5153)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [760/781]  eta: 0:00:07  lr: 0.000023  loss: 1.3058 (1.5157)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [770/781]  eta: 0:00:03  lr: 0.000023  loss: 1.3054 (1.5139)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [780/781]  eta: 0:00:00  lr: 0.000023  loss: 1.3007 (1.5113)  time: 0.3333  data: 0.0006  max mem: 6459\n",
            "Epoch: [82] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000023  loss: 1.3007 (1.5113)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3246121108531952, 'lambda_convnext_base': 0.25610318779945374, 'lambda_tf_efficientnetv2_l': 0.41928479075431824}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8246 (0.8246)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8490  data: 0.8181  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9964 (0.9989)  acc1: 81.7708 (81.1080)  acc5: 94.2708 (93.1818)  time: 0.1704  data: 0.1397  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0298 (1.0736)  acc1: 80.7292 (80.0843)  acc5: 93.2292 (92.3363)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2478 (1.1359)  acc1: 75.0000 (78.8306)  acc5: 90.6250 (91.6667)  time: 0.1280  data: 0.0973  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2636 (1.1776)  acc1: 74.4792 (78.1250)  acc5: 89.5833 (91.3110)  time: 0.1279  data: 0.0972  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1591 (1.1716)  acc1: 75.5208 (77.7880)  acc5: 92.1875 (91.6769)  time: 0.1293  data: 0.0986  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1822 (1.1867)  acc1: 75.0000 (77.6300)  acc5: 92.1875 (91.7000)  time: 0.1091  data: 0.0793  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1342 s / it)\n",
            "* Acc@1 77.630 Acc@5 91.700 loss 1.187\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=83 distillation_alpha=0.5744\n",
            "Epoch: [83]  [  0/781]  eta: 0:14:09  lr: 0.000022  loss: 1.4484 (1.4484)  time: 1.0877  data: 0.7331  max mem: 6459\n",
            "Epoch: [83]  [ 10/781]  eta: 0:05:09  lr: 0.000022  loss: 1.3292 (1.5061)  time: 0.4016  data: 0.0669  max mem: 6459\n",
            "Epoch: [83]  [ 20/781]  eta: 0:04:40  lr: 0.000022  loss: 1.2718 (1.4276)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 30/781]  eta: 0:04:28  lr: 0.000022  loss: 1.3179 (1.4960)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 40/781]  eta: 0:04:20  lr: 0.000022  loss: 1.3335 (1.5378)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 50/781]  eta: 0:04:14  lr: 0.000022  loss: 1.3565 (1.5449)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 60/781]  eta: 0:04:08  lr: 0.000022  loss: 1.3532 (1.5277)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 70/781]  eta: 0:04:04  lr: 0.000022  loss: 1.3062 (1.5359)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 80/781]  eta: 0:03:59  lr: 0.000022  loss: 1.2761 (1.5152)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 90/781]  eta: 0:03:55  lr: 0.000022  loss: 1.2918 (1.5227)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [100/781]  eta: 0:03:51  lr: 0.000022  loss: 1.3087 (1.5293)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [110/781]  eta: 0:03:47  lr: 0.000022  loss: 1.3623 (1.5544)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [120/781]  eta: 0:03:44  lr: 0.000022  loss: 1.4509 (1.5607)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [130/781]  eta: 0:03:40  lr: 0.000022  loss: 1.3876 (1.5546)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [140/781]  eta: 0:03:36  lr: 0.000022  loss: 1.3192 (1.5464)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [150/781]  eta: 0:03:33  lr: 0.000022  loss: 1.3150 (1.5383)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [160/781]  eta: 0:03:29  lr: 0.000022  loss: 1.3408 (1.5485)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [170/781]  eta: 0:03:26  lr: 0.000022  loss: 1.3374 (1.5430)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [180/781]  eta: 0:03:22  lr: 0.000022  loss: 1.2779 (1.5423)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [190/781]  eta: 0:03:19  lr: 0.000022  loss: 1.4517 (1.5505)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [200/781]  eta: 0:03:15  lr: 0.000022  loss: 1.4517 (1.5506)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [210/781]  eta: 0:03:12  lr: 0.000022  loss: 1.3546 (1.5613)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [220/781]  eta: 0:03:08  lr: 0.000022  loss: 1.3282 (1.5598)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [230/781]  eta: 0:03:05  lr: 0.000022  loss: 1.3013 (1.5517)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [240/781]  eta: 0:03:01  lr: 0.000022  loss: 1.2436 (1.5463)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [250/781]  eta: 0:02:58  lr: 0.000022  loss: 1.3092 (1.5536)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [260/781]  eta: 0:02:54  lr: 0.000022  loss: 1.2996 (1.5457)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [270/781]  eta: 0:02:51  lr: 0.000022  loss: 1.2719 (1.5412)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [280/781]  eta: 0:02:48  lr: 0.000022  loss: 1.3472 (1.5362)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [290/781]  eta: 0:02:44  lr: 0.000022  loss: 1.3293 (1.5338)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [300/781]  eta: 0:02:41  lr: 0.000022  loss: 1.3386 (1.5375)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [310/781]  eta: 0:02:37  lr: 0.000022  loss: 1.3867 (1.5435)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [320/781]  eta: 0:02:34  lr: 0.000022  loss: 1.3909 (1.5484)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [330/781]  eta: 0:02:31  lr: 0.000022  loss: 1.3618 (1.5469)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [340/781]  eta: 0:02:27  lr: 0.000022  loss: 1.3270 (1.5490)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [350/781]  eta: 0:02:24  lr: 0.000022  loss: 1.3571 (1.5496)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [360/781]  eta: 0:02:21  lr: 0.000022  loss: 1.3713 (1.5501)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [370/781]  eta: 0:02:17  lr: 0.000022  loss: 1.4202 (1.5513)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [380/781]  eta: 0:02:14  lr: 0.000022  loss: 1.3527 (1.5493)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [390/781]  eta: 0:02:10  lr: 0.000022  loss: 1.3102 (1.5521)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [400/781]  eta: 0:02:07  lr: 0.000022  loss: 1.3610 (1.5518)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [410/781]  eta: 0:02:04  lr: 0.000022  loss: 1.3482 (1.5541)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [420/781]  eta: 0:02:00  lr: 0.000022  loss: 1.3158 (1.5504)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [430/781]  eta: 0:01:57  lr: 0.000022  loss: 1.3456 (1.5497)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [440/781]  eta: 0:01:54  lr: 0.000022  loss: 1.3506 (1.5468)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [450/781]  eta: 0:01:50  lr: 0.000022  loss: 1.3051 (1.5466)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [460/781]  eta: 0:01:47  lr: 0.000022  loss: 1.2705 (1.5421)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [470/781]  eta: 0:01:44  lr: 0.000022  loss: 1.2977 (1.5457)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [480/781]  eta: 0:01:40  lr: 0.000022  loss: 1.3024 (1.5425)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [490/781]  eta: 0:01:37  lr: 0.000022  loss: 1.3071 (1.5424)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [500/781]  eta: 0:01:33  lr: 0.000022  loss: 1.3479 (1.5425)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [510/781]  eta: 0:01:30  lr: 0.000022  loss: 1.3483 (1.5436)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [520/781]  eta: 0:01:27  lr: 0.000022  loss: 1.3483 (1.5444)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [530/781]  eta: 0:01:23  lr: 0.000022  loss: 1.3067 (1.5448)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [540/781]  eta: 0:01:20  lr: 0.000022  loss: 1.2780 (1.5431)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [550/781]  eta: 0:01:17  lr: 0.000022  loss: 1.2993 (1.5453)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [560/781]  eta: 0:01:13  lr: 0.000022  loss: 1.2972 (1.5421)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [570/781]  eta: 0:01:10  lr: 0.000022  loss: 1.2924 (1.5409)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [580/781]  eta: 0:01:07  lr: 0.000022  loss: 1.2924 (1.5374)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [590/781]  eta: 0:01:03  lr: 0.000022  loss: 1.2841 (1.5387)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [600/781]  eta: 0:01:00  lr: 0.000022  loss: 1.5096 (1.5422)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [610/781]  eta: 0:00:57  lr: 0.000022  loss: 1.5303 (1.5461)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [620/781]  eta: 0:00:53  lr: 0.000022  loss: 1.4162 (1.5481)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [630/781]  eta: 0:00:50  lr: 0.000022  loss: 1.3870 (1.5466)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [640/781]  eta: 0:00:47  lr: 0.000022  loss: 1.2891 (1.5450)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [650/781]  eta: 0:00:43  lr: 0.000022  loss: 1.2950 (1.5469)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [660/781]  eta: 0:00:40  lr: 0.000022  loss: 1.3483 (1.5458)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [670/781]  eta: 0:00:37  lr: 0.000022  loss: 1.3313 (1.5424)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [680/781]  eta: 0:00:33  lr: 0.000022  loss: 1.2776 (1.5393)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [690/781]  eta: 0:00:30  lr: 0.000022  loss: 1.3203 (1.5417)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [700/781]  eta: 0:00:27  lr: 0.000022  loss: 1.3635 (1.5416)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [710/781]  eta: 0:00:23  lr: 0.000022  loss: 1.3332 (1.5424)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [720/781]  eta: 0:00:20  lr: 0.000022  loss: 1.2616 (1.5407)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [730/781]  eta: 0:00:17  lr: 0.000022  loss: 1.2764 (1.5400)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [740/781]  eta: 0:00:13  lr: 0.000022  loss: 1.2922 (1.5387)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [750/781]  eta: 0:00:10  lr: 0.000022  loss: 1.2997 (1.5381)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [760/781]  eta: 0:00:07  lr: 0.000022  loss: 1.3289 (1.5383)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [770/781]  eta: 0:00:03  lr: 0.000022  loss: 1.3289 (1.5384)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [780/781]  eta: 0:00:00  lr: 0.000022  loss: 1.3258 (1.5391)  time: 0.3328  data: 0.0005  max mem: 6459\n",
            "Epoch: [83] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000022  loss: 1.3258 (1.5391)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32396644353866577, 'lambda_convnext_base': 0.25540298223495483, 'lambda_tf_efficientnetv2_l': 0.4206308126449585}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7730 (0.7730)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8186  data: 0.7876  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9472 (0.9864)  acc1: 83.8542 (81.4867)  acc5: 94.7917 (93.8447)  time: 0.1708  data: 0.1401  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0124 (1.0573)  acc1: 79.6875 (80.2331)  acc5: 93.2292 (92.6339)  time: 0.1280  data: 0.0973  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2269 (1.1238)  acc1: 75.5208 (78.7802)  acc5: 91.1458 (92.0195)  time: 0.1324  data: 0.1017  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2516 (1.1725)  acc1: 75.0000 (77.8963)  acc5: 90.1042 (91.3872)  time: 0.1312  data: 0.1005  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.2162 (1.1698)  acc1: 75.5208 (77.7063)  acc5: 91.1458 (91.6565)  time: 0.1349  data: 0.1043  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2293 (1.1832)  acc1: 74.4792 (77.5700)  acc5: 91.6667 (91.6800)  time: 0.1153  data: 0.0856  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1381 s / it)\n",
            "* Acc@1 77.570 Acc@5 91.680 loss 1.183\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=84 distillation_alpha=0.5808\n",
            "Epoch: [84]  [  0/781]  eta: 0:14:17  lr: 0.000021  loss: 1.2667 (1.2667)  time: 1.0974  data: 0.7580  max mem: 6459\n",
            "Epoch: [84]  [ 10/781]  eta: 0:05:25  lr: 0.000021  loss: 1.3406 (1.5442)  time: 0.4220  data: 0.0692  max mem: 6459\n",
            "Epoch: [84]  [ 20/781]  eta: 0:04:48  lr: 0.000021  loss: 1.3112 (1.4734)  time: 0.3437  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 30/781]  eta: 0:04:33  lr: 0.000021  loss: 1.2940 (1.5099)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 40/781]  eta: 0:04:24  lr: 0.000021  loss: 1.2752 (1.4485)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 50/781]  eta: 0:04:17  lr: 0.000021  loss: 1.2705 (1.4773)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 60/781]  eta: 0:04:11  lr: 0.000021  loss: 1.6725 (1.5522)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 70/781]  eta: 0:04:06  lr: 0.000021  loss: 1.3895 (1.5369)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 80/781]  eta: 0:04:01  lr: 0.000021  loss: 1.2708 (1.5299)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 90/781]  eta: 0:03:57  lr: 0.000021  loss: 1.2895 (1.5302)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [100/781]  eta: 0:03:53  lr: 0.000021  loss: 1.3102 (1.5122)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [110/781]  eta: 0:03:49  lr: 0.000021  loss: 1.3440 (1.5213)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [120/781]  eta: 0:03:45  lr: 0.000021  loss: 1.3791 (1.5318)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [130/781]  eta: 0:03:41  lr: 0.000021  loss: 1.3708 (1.5430)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [140/781]  eta: 0:03:37  lr: 0.000021  loss: 1.3299 (1.5383)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [150/781]  eta: 0:03:34  lr: 0.000021  loss: 1.3026 (1.5305)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [160/781]  eta: 0:03:30  lr: 0.000021  loss: 1.3026 (1.5296)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [170/781]  eta: 0:03:26  lr: 0.000021  loss: 1.3024 (1.5179)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [180/781]  eta: 0:03:23  lr: 0.000021  loss: 1.2697 (1.5121)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [190/781]  eta: 0:03:19  lr: 0.000021  loss: 1.3216 (1.5144)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [200/781]  eta: 0:03:16  lr: 0.000021  loss: 1.3083 (1.5180)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [210/781]  eta: 0:03:12  lr: 0.000021  loss: 1.3064 (1.5152)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [220/781]  eta: 0:03:09  lr: 0.000021  loss: 1.2806 (1.5106)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [230/781]  eta: 0:03:05  lr: 0.000021  loss: 1.2679 (1.5179)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [240/781]  eta: 0:03:02  lr: 0.000021  loss: 1.3792 (1.5196)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [250/781]  eta: 0:02:58  lr: 0.000021  loss: 1.4119 (1.5304)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [260/781]  eta: 0:02:55  lr: 0.000021  loss: 1.4973 (1.5358)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [270/781]  eta: 0:02:52  lr: 0.000021  loss: 1.3446 (1.5269)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [280/781]  eta: 0:02:48  lr: 0.000021  loss: 1.3254 (1.5273)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [290/781]  eta: 0:02:45  lr: 0.000021  loss: 1.3423 (1.5225)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [300/781]  eta: 0:02:41  lr: 0.000021  loss: 1.3423 (1.5272)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [310/781]  eta: 0:02:38  lr: 0.000021  loss: 1.4765 (1.5307)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [320/781]  eta: 0:02:34  lr: 0.000021  loss: 1.3179 (1.5303)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [330/781]  eta: 0:02:31  lr: 0.000021  loss: 1.3221 (1.5318)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [340/781]  eta: 0:02:28  lr: 0.000021  loss: 1.3221 (1.5270)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [350/781]  eta: 0:02:24  lr: 0.000021  loss: 1.2935 (1.5229)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [360/781]  eta: 0:02:21  lr: 0.000021  loss: 1.2863 (1.5234)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [370/781]  eta: 0:02:17  lr: 0.000021  loss: 1.2997 (1.5243)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [380/781]  eta: 0:02:14  lr: 0.000021  loss: 1.3705 (1.5264)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [390/781]  eta: 0:02:11  lr: 0.000021  loss: 1.3514 (1.5269)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [400/781]  eta: 0:02:07  lr: 0.000021  loss: 1.3444 (1.5259)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [410/781]  eta: 0:02:04  lr: 0.000021  loss: 1.3515 (1.5278)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [420/781]  eta: 0:02:01  lr: 0.000021  loss: 1.3620 (1.5284)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [430/781]  eta: 0:01:57  lr: 0.000021  loss: 1.3411 (1.5251)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [440/781]  eta: 0:01:54  lr: 0.000021  loss: 1.3669 (1.5260)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [450/781]  eta: 0:01:50  lr: 0.000021  loss: 1.2960 (1.5203)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [460/781]  eta: 0:01:47  lr: 0.000021  loss: 1.2881 (1.5201)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [470/781]  eta: 0:01:44  lr: 0.000021  loss: 1.2990 (1.5182)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [480/781]  eta: 0:01:40  lr: 0.000021  loss: 1.3101 (1.5171)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [490/781]  eta: 0:01:37  lr: 0.000021  loss: 1.3498 (1.5181)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [500/781]  eta: 0:01:34  lr: 0.000021  loss: 1.3618 (1.5200)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [510/781]  eta: 0:01:30  lr: 0.000021  loss: 1.3415 (1.5203)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [520/781]  eta: 0:01:27  lr: 0.000021  loss: 1.4620 (1.5285)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [530/781]  eta: 0:01:24  lr: 0.000021  loss: 1.5370 (1.5289)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [540/781]  eta: 0:01:20  lr: 0.000021  loss: 1.4575 (1.5323)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [550/781]  eta: 0:01:17  lr: 0.000021  loss: 1.4521 (1.5352)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [560/781]  eta: 0:01:13  lr: 0.000021  loss: 1.2864 (1.5335)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [570/781]  eta: 0:01:10  lr: 0.000021  loss: 1.3769 (1.5406)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [580/781]  eta: 0:01:07  lr: 0.000021  loss: 1.4404 (1.5399)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [590/781]  eta: 0:01:03  lr: 0.000021  loss: 1.3681 (1.5429)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [600/781]  eta: 0:01:00  lr: 0.000021  loss: 1.3681 (1.5417)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [610/781]  eta: 0:00:57  lr: 0.000021  loss: 1.3543 (1.5418)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [620/781]  eta: 0:00:53  lr: 0.000021  loss: 1.2844 (1.5413)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [630/781]  eta: 0:00:50  lr: 0.000021  loss: 1.2923 (1.5381)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [640/781]  eta: 0:00:47  lr: 0.000021  loss: 1.2876 (1.5365)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [650/781]  eta: 0:00:43  lr: 0.000021  loss: 1.3022 (1.5358)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [660/781]  eta: 0:00:40  lr: 0.000021  loss: 1.3181 (1.5330)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [670/781]  eta: 0:00:37  lr: 0.000021  loss: 1.3273 (1.5328)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [680/781]  eta: 0:00:33  lr: 0.000021  loss: 1.3302 (1.5331)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [690/781]  eta: 0:00:30  lr: 0.000021  loss: 1.3312 (1.5340)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [700/781]  eta: 0:00:27  lr: 0.000021  loss: 1.4573 (1.5355)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [710/781]  eta: 0:00:23  lr: 0.000021  loss: 1.3583 (1.5361)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [720/781]  eta: 0:00:20  lr: 0.000021  loss: 1.3583 (1.5393)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [730/781]  eta: 0:00:17  lr: 0.000021  loss: 1.5966 (1.5414)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [740/781]  eta: 0:00:13  lr: 0.000021  loss: 1.3597 (1.5392)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [750/781]  eta: 0:00:10  lr: 0.000021  loss: 1.3309 (1.5382)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [760/781]  eta: 0:00:07  lr: 0.000021  loss: 1.2942 (1.5368)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [770/781]  eta: 0:00:03  lr: 0.000021  loss: 1.2989 (1.5396)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [780/781]  eta: 0:00:00  lr: 0.000021  loss: 1.3698 (1.5393)  time: 0.3327  data: 0.0005  max mem: 6459\n",
            "Epoch: [84] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000021  loss: 1.3698 (1.5393)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32378172874450684, 'lambda_convnext_base': 0.25563958287239075, 'lambda_tf_efficientnetv2_l': 0.4205789566040039}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8289 (0.8289)  acc1: 82.2917 (82.2917)  acc5: 94.7917 (94.7917)  time: 0.8191  data: 0.7883  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9081 (0.9870)  acc1: 82.8125 (81.4867)  acc5: 94.2708 (93.3239)  time: 0.1679  data: 0.1373  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0833 (1.0680)  acc1: 79.6875 (79.9851)  acc5: 93.2292 (92.2619)  time: 0.1125  data: 0.0818  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1858 (1.1198)  acc1: 75.5208 (78.9651)  acc5: 90.6250 (91.7339)  time: 0.1371  data: 0.1064  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2311 (1.1610)  acc1: 76.5625 (78.1758)  acc5: 89.5833 (91.3491)  time: 0.1323  data: 0.1016  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1589 (1.1573)  acc1: 77.0833 (78.0127)  acc5: 91.6667 (91.5952)  time: 0.1323  data: 0.1017  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1908 (1.1818)  acc1: 76.5625 (77.8300)  acc5: 91.6667 (91.6100)  time: 0.1313  data: 0.1016  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1382 s / it)\n",
            "* Acc@1 77.830 Acc@5 91.610 loss 1.182\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=85 distillation_alpha=0.5870\n",
            "Epoch: [85]  [  0/781]  eta: 0:14:31  lr: 0.000021  loss: 1.3713 (1.3713)  time: 1.1161  data: 0.7769  max mem: 6459\n",
            "Epoch: [85]  [ 10/781]  eta: 0:05:11  lr: 0.000021  loss: 1.3451 (1.3664)  time: 0.4041  data: 0.0709  max mem: 6459\n",
            "Epoch: [85]  [ 20/781]  eta: 0:04:41  lr: 0.000021  loss: 1.3451 (1.4923)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 30/781]  eta: 0:04:29  lr: 0.000021  loss: 1.3030 (1.4721)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 40/781]  eta: 0:04:20  lr: 0.000021  loss: 1.3024 (1.5527)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 50/781]  eta: 0:04:14  lr: 0.000021  loss: 1.3079 (1.5074)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 60/781]  eta: 0:04:09  lr: 0.000021  loss: 1.2908 (1.5075)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 70/781]  eta: 0:04:04  lr: 0.000021  loss: 1.3200 (1.4870)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 80/781]  eta: 0:04:00  lr: 0.000021  loss: 1.3403 (1.5115)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 90/781]  eta: 0:03:55  lr: 0.000021  loss: 1.4436 (1.5281)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [100/781]  eta: 0:03:51  lr: 0.000021  loss: 1.4142 (1.5234)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [110/781]  eta: 0:03:48  lr: 0.000021  loss: 1.3444 (1.5115)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [120/781]  eta: 0:03:44  lr: 0.000021  loss: 1.3643 (1.5251)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [130/781]  eta: 0:03:40  lr: 0.000021  loss: 1.3100 (1.5166)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [140/781]  eta: 0:03:36  lr: 0.000021  loss: 1.2996 (1.5142)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [150/781]  eta: 0:03:33  lr: 0.000021  loss: 1.2817 (1.5121)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [160/781]  eta: 0:03:29  lr: 0.000021  loss: 1.3323 (1.5159)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [170/781]  eta: 0:03:26  lr: 0.000021  loss: 1.3441 (1.5300)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [180/781]  eta: 0:03:22  lr: 0.000021  loss: 1.3263 (1.5259)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [190/781]  eta: 0:03:19  lr: 0.000021  loss: 1.2890 (1.5271)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [200/781]  eta: 0:03:15  lr: 0.000021  loss: 1.3930 (1.5326)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [210/781]  eta: 0:03:12  lr: 0.000021  loss: 1.3040 (1.5255)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [220/781]  eta: 0:03:08  lr: 0.000021  loss: 1.3040 (1.5227)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [230/781]  eta: 0:03:05  lr: 0.000021  loss: 1.3318 (1.5196)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [240/781]  eta: 0:03:01  lr: 0.000021  loss: 1.3552 (1.5256)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [250/781]  eta: 0:02:58  lr: 0.000021  loss: 1.3417 (1.5230)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [260/781]  eta: 0:02:54  lr: 0.000021  loss: 1.3417 (1.5264)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [270/781]  eta: 0:02:51  lr: 0.000021  loss: 1.3446 (1.5268)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [280/781]  eta: 0:02:48  lr: 0.000021  loss: 1.3554 (1.5263)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [290/781]  eta: 0:02:44  lr: 0.000021  loss: 1.3554 (1.5306)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [300/781]  eta: 0:02:41  lr: 0.000021  loss: 1.3545 (1.5348)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [310/781]  eta: 0:02:37  lr: 0.000021  loss: 1.3610 (1.5396)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [320/781]  eta: 0:02:34  lr: 0.000021  loss: 1.3706 (1.5428)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [330/781]  eta: 0:02:31  lr: 0.000021  loss: 1.3804 (1.5478)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [340/781]  eta: 0:02:27  lr: 0.000021  loss: 1.3622 (1.5471)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [350/781]  eta: 0:02:24  lr: 0.000021  loss: 1.2814 (1.5455)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [360/781]  eta: 0:02:21  lr: 0.000021  loss: 1.2950 (1.5406)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [370/781]  eta: 0:02:17  lr: 0.000021  loss: 1.2969 (1.5370)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [380/781]  eta: 0:02:14  lr: 0.000021  loss: 1.2850 (1.5345)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [390/781]  eta: 0:02:10  lr: 0.000021  loss: 1.2687 (1.5300)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [400/781]  eta: 0:02:07  lr: 0.000021  loss: 1.2929 (1.5302)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [410/781]  eta: 0:02:04  lr: 0.000021  loss: 1.3423 (1.5291)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [420/781]  eta: 0:02:00  lr: 0.000021  loss: 1.3423 (1.5287)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [430/781]  eta: 0:01:57  lr: 0.000021  loss: 1.3105 (1.5297)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [440/781]  eta: 0:01:54  lr: 0.000021  loss: 1.4706 (1.5335)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [450/781]  eta: 0:01:50  lr: 0.000021  loss: 1.3779 (1.5311)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [460/781]  eta: 0:01:47  lr: 0.000021  loss: 1.3779 (1.5353)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [470/781]  eta: 0:01:44  lr: 0.000021  loss: 1.3481 (1.5321)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [480/781]  eta: 0:01:40  lr: 0.000021  loss: 1.3476 (1.5337)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [490/781]  eta: 0:01:37  lr: 0.000021  loss: 1.3836 (1.5327)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [500/781]  eta: 0:01:33  lr: 0.000021  loss: 1.3943 (1.5361)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [510/781]  eta: 0:01:30  lr: 0.000021  loss: 1.3477 (1.5332)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [520/781]  eta: 0:01:27  lr: 0.000021  loss: 1.2952 (1.5321)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [530/781]  eta: 0:01:23  lr: 0.000021  loss: 1.2926 (1.5308)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [540/781]  eta: 0:01:20  lr: 0.000021  loss: 1.2926 (1.5312)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [550/781]  eta: 0:01:17  lr: 0.000021  loss: 1.2880 (1.5269)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [560/781]  eta: 0:01:13  lr: 0.000021  loss: 1.2880 (1.5244)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [570/781]  eta: 0:01:10  lr: 0.000021  loss: 1.2930 (1.5230)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [580/781]  eta: 0:01:07  lr: 0.000021  loss: 1.2869 (1.5215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [590/781]  eta: 0:01:03  lr: 0.000021  loss: 1.2902 (1.5218)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [600/781]  eta: 0:01:00  lr: 0.000021  loss: 1.3389 (1.5209)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [610/781]  eta: 0:00:57  lr: 0.000021  loss: 1.3895 (1.5242)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [620/781]  eta: 0:00:53  lr: 0.000021  loss: 1.3489 (1.5231)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [630/781]  eta: 0:00:50  lr: 0.000021  loss: 1.3168 (1.5212)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [640/781]  eta: 0:00:47  lr: 0.000021  loss: 1.2649 (1.5194)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [650/781]  eta: 0:00:43  lr: 0.000021  loss: 1.2719 (1.5169)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [660/781]  eta: 0:00:40  lr: 0.000021  loss: 1.2875 (1.5179)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [670/781]  eta: 0:00:37  lr: 0.000021  loss: 1.3270 (1.5176)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [680/781]  eta: 0:00:33  lr: 0.000021  loss: 1.2446 (1.5167)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [690/781]  eta: 0:00:30  lr: 0.000021  loss: 1.2583 (1.5162)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [700/781]  eta: 0:00:27  lr: 0.000021  loss: 1.2932 (1.5155)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [710/781]  eta: 0:00:23  lr: 0.000021  loss: 1.2979 (1.5160)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [720/781]  eta: 0:00:20  lr: 0.000021  loss: 1.3426 (1.5166)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [730/781]  eta: 0:00:17  lr: 0.000021  loss: 1.2858 (1.5162)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [740/781]  eta: 0:00:13  lr: 0.000021  loss: 1.2965 (1.5137)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [750/781]  eta: 0:00:10  lr: 0.000021  loss: 1.3253 (1.5156)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [760/781]  eta: 0:00:07  lr: 0.000021  loss: 1.4259 (1.5158)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [770/781]  eta: 0:00:03  lr: 0.000021  loss: 1.3287 (1.5156)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [780/781]  eta: 0:00:00  lr: 0.000021  loss: 1.3437 (1.5174)  time: 0.3329  data: 0.0005  max mem: 6459\n",
            "Epoch: [85] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000021  loss: 1.3437 (1.5174)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32499659061431885, 'lambda_convnext_base': 0.25562235713005066, 'lambda_tf_efficientnetv2_l': 0.41938120126724243}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8815 (0.8815)  acc1: 81.7708 (81.7708)  acc5: 94.2708 (94.2708)  time: 0.8446  data: 0.8137  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9369 (1.0046)  acc1: 81.7708 (81.7235)  acc5: 93.2292 (92.7083)  time: 0.1744  data: 0.1437  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1191 (1.0702)  acc1: 78.6458 (80.2083)  acc5: 92.7083 (91.9891)  time: 0.1269  data: 0.0962  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1709 (1.1162)  acc1: 76.5625 (79.1835)  acc5: 91.1458 (91.7171)  time: 0.1275  data: 0.0968  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1775 (1.1602)  acc1: 75.5208 (78.3791)  acc5: 90.6250 (91.3999)  time: 0.1279  data: 0.0973  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1447 (1.1624)  acc1: 76.0417 (77.9514)  acc5: 91.6667 (91.5952)  time: 0.1275  data: 0.0969  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2132 (1.1766)  acc1: 75.0000 (77.8300)  acc5: 91.6667 (91.6200)  time: 0.1072  data: 0.0776  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1340 s / it)\n",
            "* Acc@1 77.830 Acc@5 91.620 loss 1.177\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=86 distillation_alpha=0.5932\n",
            "Epoch: [86]  [  0/781]  eta: 0:14:25  lr: 0.000020  loss: 1.2647 (1.2647)  time: 1.1086  data: 0.7679  max mem: 6459\n",
            "Epoch: [86]  [ 10/781]  eta: 0:05:11  lr: 0.000020  loss: 1.3638 (1.4595)  time: 0.4041  data: 0.0701  max mem: 6459\n",
            "Epoch: [86]  [ 20/781]  eta: 0:04:41  lr: 0.000020  loss: 1.3263 (1.4304)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 30/781]  eta: 0:04:28  lr: 0.000020  loss: 1.3400 (1.4695)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 40/781]  eta: 0:04:20  lr: 0.000020  loss: 1.3503 (1.5109)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 50/781]  eta: 0:04:14  lr: 0.000020  loss: 1.2772 (1.4960)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 60/781]  eta: 0:04:09  lr: 0.000020  loss: 1.2710 (1.4760)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 70/781]  eta: 0:04:04  lr: 0.000020  loss: 1.2815 (1.4992)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 80/781]  eta: 0:04:00  lr: 0.000020  loss: 1.3090 (1.4942)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 90/781]  eta: 0:03:55  lr: 0.000020  loss: 1.2587 (1.4972)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [100/781]  eta: 0:03:51  lr: 0.000020  loss: 1.2838 (1.4783)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [110/781]  eta: 0:03:47  lr: 0.000020  loss: 1.2667 (1.4595)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [120/781]  eta: 0:03:44  lr: 0.000020  loss: 1.2578 (1.4608)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [130/781]  eta: 0:03:40  lr: 0.000020  loss: 1.3289 (1.4548)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [140/781]  eta: 0:03:36  lr: 0.000020  loss: 1.3557 (1.4569)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [150/781]  eta: 0:03:33  lr: 0.000020  loss: 1.3971 (1.4710)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [160/781]  eta: 0:03:29  lr: 0.000020  loss: 1.3971 (1.4755)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [170/781]  eta: 0:03:26  lr: 0.000020  loss: 1.3312 (1.4779)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [180/781]  eta: 0:03:22  lr: 0.000020  loss: 1.3196 (1.4779)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [190/781]  eta: 0:03:19  lr: 0.000020  loss: 1.2926 (1.4719)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [200/781]  eta: 0:03:15  lr: 0.000020  loss: 1.2667 (1.4616)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [210/781]  eta: 0:03:12  lr: 0.000020  loss: 1.2828 (1.4638)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [220/781]  eta: 0:03:08  lr: 0.000020  loss: 1.3212 (1.4718)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [230/781]  eta: 0:03:05  lr: 0.000020  loss: 1.3212 (1.4739)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [240/781]  eta: 0:03:01  lr: 0.000020  loss: 1.3315 (1.4784)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [250/781]  eta: 0:02:58  lr: 0.000020  loss: 1.3073 (1.4753)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [260/781]  eta: 0:02:54  lr: 0.000020  loss: 1.3011 (1.4752)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [270/781]  eta: 0:02:51  lr: 0.000020  loss: 1.2955 (1.4720)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [280/781]  eta: 0:02:48  lr: 0.000020  loss: 1.2839 (1.4653)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [290/781]  eta: 0:02:44  lr: 0.000020  loss: 1.3213 (1.4656)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [300/781]  eta: 0:02:41  lr: 0.000020  loss: 1.3499 (1.4673)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [310/781]  eta: 0:02:37  lr: 0.000020  loss: 1.3164 (1.4678)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [320/781]  eta: 0:02:34  lr: 0.000020  loss: 1.3000 (1.4634)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [330/781]  eta: 0:02:31  lr: 0.000020  loss: 1.3000 (1.4635)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [340/781]  eta: 0:02:27  lr: 0.000020  loss: 1.3257 (1.4634)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [350/781]  eta: 0:02:24  lr: 0.000020  loss: 1.3257 (1.4662)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [360/781]  eta: 0:02:21  lr: 0.000020  loss: 1.3087 (1.4636)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [370/781]  eta: 0:02:17  lr: 0.000020  loss: 1.3236 (1.4639)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [380/781]  eta: 0:02:14  lr: 0.000020  loss: 1.3148 (1.4621)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [390/781]  eta: 0:02:10  lr: 0.000020  loss: 1.3136 (1.4646)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.3432 (1.4650)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [410/781]  eta: 0:02:04  lr: 0.000020  loss: 1.3432 (1.4682)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [420/781]  eta: 0:02:00  lr: 0.000020  loss: 1.3181 (1.4670)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.2966 (1.4648)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [440/781]  eta: 0:01:54  lr: 0.000020  loss: 1.3410 (1.4673)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [450/781]  eta: 0:01:50  lr: 0.000020  loss: 1.3410 (1.4660)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.3160 (1.4675)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [470/781]  eta: 0:01:44  lr: 0.000020  loss: 1.2933 (1.4675)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.2836 (1.4670)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.3302 (1.4694)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [500/781]  eta: 0:01:33  lr: 0.000020  loss: 1.3714 (1.4725)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.3533 (1.4743)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [520/781]  eta: 0:01:27  lr: 0.000020  loss: 1.3233 (1.4768)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [530/781]  eta: 0:01:23  lr: 0.000020  loss: 1.3574 (1.4787)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.4092 (1.4812)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [550/781]  eta: 0:01:17  lr: 0.000020  loss: 1.3467 (1.4806)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [560/781]  eta: 0:01:13  lr: 0.000020  loss: 1.2913 (1.4782)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.2898 (1.4789)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [580/781]  eta: 0:01:07  lr: 0.000020  loss: 1.3317 (1.4812)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.3099 (1.4799)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.3166 (1.4820)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [610/781]  eta: 0:00:57  lr: 0.000020  loss: 1.3592 (1.4830)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.4010 (1.4887)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.4145 (1.4915)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [640/781]  eta: 0:00:47  lr: 0.000020  loss: 1.2827 (1.4912)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.3438 (1.4925)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.3624 (1.4960)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [670/781]  eta: 0:00:37  lr: 0.000020  loss: 1.3220 (1.4951)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.3117 (1.4945)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3545 (1.4965)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [700/781]  eta: 0:00:27  lr: 0.000020  loss: 1.3793 (1.4984)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.3304 (1.4979)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.4286 (1.5018)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [730/781]  eta: 0:00:17  lr: 0.000020  loss: 1.3944 (1.5008)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.3100 (1.4999)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.2752 (1.4985)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [760/781]  eta: 0:00:07  lr: 0.000020  loss: 1.3170 (1.4981)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.3220 (1.4964)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.3305 (1.4970)  time: 0.3328  data: 0.0005  max mem: 6459\n",
            "Epoch: [86] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.3305 (1.4970)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32511505484580994, 'lambda_convnext_base': 0.2559131681919098, 'lambda_tf_efficientnetv2_l': 0.41897153854370117}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8475 (0.8475)  acc1: 81.7708 (81.7708)  acc5: 94.7917 (94.7917)  time: 0.8198  data: 0.7890  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9661 (1.0250)  acc1: 81.7708 (80.4924)  acc5: 94.2708 (92.8030)  time: 0.1645  data: 0.1338  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.1459 (1.0904)  acc1: 76.5625 (79.1419)  acc5: 93.2292 (91.9147)  time: 0.1150  data: 0.0843  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2077 (1.1358)  acc1: 75.5208 (78.3602)  acc5: 91.1458 (91.4987)  time: 0.1279  data: 0.0972  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2283 (1.1748)  acc1: 75.0000 (77.7820)  acc5: 89.5833 (91.0950)  time: 0.1231  data: 0.0925  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1664 (1.1703)  acc1: 75.5208 (77.5940)  acc5: 91.6667 (91.4216)  time: 0.1287  data: 0.0980  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1953 (1.1828)  acc1: 75.0000 (77.4600)  acc5: 91.6667 (91.4400)  time: 0.1303  data: 0.1006  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1356 s / it)\n",
            "* Acc@1 77.460 Acc@5 91.440 loss 1.183\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=87 distillation_alpha=0.5992\n",
            "Epoch: [87]  [  0/781]  eta: 0:14:53  lr: 0.000020  loss: 1.3072 (1.3072)  time: 1.1440  data: 0.7617  max mem: 6459\n",
            "Epoch: [87]  [ 10/781]  eta: 0:05:13  lr: 0.000020  loss: 1.3149 (1.3807)  time: 0.4072  data: 0.0695  max mem: 6459\n",
            "Epoch: [87]  [ 20/781]  eta: 0:04:43  lr: 0.000020  loss: 1.3498 (1.4513)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 30/781]  eta: 0:04:29  lr: 0.000020  loss: 1.4236 (1.5060)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 40/781]  eta: 0:04:21  lr: 0.000020  loss: 1.3554 (1.4949)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 50/781]  eta: 0:04:15  lr: 0.000020  loss: 1.3163 (1.4969)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 60/781]  eta: 0:04:09  lr: 0.000020  loss: 1.3394 (1.5327)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 70/781]  eta: 0:04:05  lr: 0.000020  loss: 1.3886 (1.5370)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 80/781]  eta: 0:04:00  lr: 0.000020  loss: 1.3045 (1.5402)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 90/781]  eta: 0:03:56  lr: 0.000020  loss: 1.2952 (1.5348)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [100/781]  eta: 0:03:52  lr: 0.000020  loss: 1.2844 (1.5156)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [110/781]  eta: 0:03:48  lr: 0.000020  loss: 1.2908 (1.5007)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [120/781]  eta: 0:03:44  lr: 0.000020  loss: 1.2964 (1.4970)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [130/781]  eta: 0:03:40  lr: 0.000020  loss: 1.3420 (1.4963)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [140/781]  eta: 0:03:37  lr: 0.000020  loss: 1.3327 (1.4802)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [150/781]  eta: 0:03:33  lr: 0.000020  loss: 1.2754 (1.4720)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [160/781]  eta: 0:03:30  lr: 0.000020  loss: 1.2822 (1.4723)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [170/781]  eta: 0:03:26  lr: 0.000020  loss: 1.2756 (1.4717)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [180/781]  eta: 0:03:22  lr: 0.000020  loss: 1.3763 (1.4863)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [190/781]  eta: 0:03:19  lr: 0.000020  loss: 1.3726 (1.4868)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [200/781]  eta: 0:03:15  lr: 0.000020  loss: 1.3119 (1.4922)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [210/781]  eta: 0:03:12  lr: 0.000020  loss: 1.3536 (1.4977)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [220/781]  eta: 0:03:08  lr: 0.000020  loss: 1.3307 (1.5051)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [230/781]  eta: 0:03:05  lr: 0.000020  loss: 1.3052 (1.5054)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [240/781]  eta: 0:03:02  lr: 0.000020  loss: 1.3059 (1.5123)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [250/781]  eta: 0:02:58  lr: 0.000020  loss: 1.3213 (1.5104)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [260/781]  eta: 0:02:55  lr: 0.000020  loss: 1.3143 (1.5105)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [270/781]  eta: 0:02:51  lr: 0.000020  loss: 1.3207 (1.5086)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [280/781]  eta: 0:02:48  lr: 0.000020  loss: 1.3215 (1.5076)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [290/781]  eta: 0:02:44  lr: 0.000020  loss: 1.2939 (1.5067)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [300/781]  eta: 0:02:41  lr: 0.000020  loss: 1.2836 (1.5001)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [310/781]  eta: 0:02:38  lr: 0.000020  loss: 1.2977 (1.4981)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [320/781]  eta: 0:02:34  lr: 0.000020  loss: 1.3204 (1.5036)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [330/781]  eta: 0:02:31  lr: 0.000020  loss: 1.3199 (1.5001)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [340/781]  eta: 0:02:27  lr: 0.000020  loss: 1.2775 (1.5068)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [350/781]  eta: 0:02:24  lr: 0.000020  loss: 1.2883 (1.5033)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [360/781]  eta: 0:02:21  lr: 0.000020  loss: 1.3082 (1.5027)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [370/781]  eta: 0:02:17  lr: 0.000020  loss: 1.3377 (1.5066)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [380/781]  eta: 0:02:14  lr: 0.000020  loss: 1.3150 (1.5080)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [390/781]  eta: 0:02:11  lr: 0.000020  loss: 1.2654 (1.5046)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.2856 (1.5022)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [410/781]  eta: 0:02:04  lr: 0.000020  loss: 1.3407 (1.5068)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [420/781]  eta: 0:02:00  lr: 0.000020  loss: 1.2755 (1.5048)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.2899 (1.5044)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [440/781]  eta: 0:01:54  lr: 0.000020  loss: 1.3207 (1.5104)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [450/781]  eta: 0:01:50  lr: 0.000020  loss: 1.3518 (1.5127)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.2980 (1.5128)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [470/781]  eta: 0:01:44  lr: 0.000020  loss: 1.3581 (1.5146)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.3581 (1.5147)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.3061 (1.5140)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [500/781]  eta: 0:01:34  lr: 0.000020  loss: 1.3059 (1.5138)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.3415 (1.5125)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [520/781]  eta: 0:01:27  lr: 0.000020  loss: 1.3415 (1.5103)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [530/781]  eta: 0:01:23  lr: 0.000020  loss: 1.2916 (1.5099)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.2865 (1.5104)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [550/781]  eta: 0:01:17  lr: 0.000020  loss: 1.2843 (1.5134)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [560/781]  eta: 0:01:13  lr: 0.000020  loss: 1.2843 (1.5097)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.3274 (1.5113)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [580/781]  eta: 0:01:07  lr: 0.000020  loss: 1.3674 (1.5131)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.4001 (1.5143)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.3843 (1.5154)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [610/781]  eta: 0:00:57  lr: 0.000020  loss: 1.3304 (1.5164)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.2829 (1.5176)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.3216 (1.5187)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [640/781]  eta: 0:00:47  lr: 0.000020  loss: 1.3188 (1.5163)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.3315 (1.5164)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.5968 (1.5229)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [670/781]  eta: 0:00:37  lr: 0.000020  loss: 1.5968 (1.5226)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.3780 (1.5243)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3780 (1.5257)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [700/781]  eta: 0:00:27  lr: 0.000020  loss: 1.3457 (1.5266)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.3457 (1.5303)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.3771 (1.5302)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [730/781]  eta: 0:00:17  lr: 0.000020  loss: 1.3788 (1.5323)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.3288 (1.5302)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.3996 (1.5319)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [760/781]  eta: 0:00:07  lr: 0.000020  loss: 1.3996 (1.5333)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.3394 (1.5352)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.3654 (1.5351)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [87] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.3654 (1.5351)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.324261337518692, 'lambda_convnext_base': 0.25559455156326294, 'lambda_tf_efficientnetv2_l': 0.42014428973197937}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.9040 (0.9040)  acc1: 82.8125 (82.8125)  acc5: 94.2708 (94.2708)  time: 0.8306  data: 0.7997  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9469 (0.9974)  acc1: 82.8125 (81.1553)  acc5: 93.2292 (93.1345)  time: 0.1743  data: 0.1436  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0798 (1.0795)  acc1: 77.6042 (79.9851)  acc5: 92.7083 (92.3115)  time: 0.1218  data: 0.0912  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2310 (1.1418)  acc1: 76.0417 (78.7130)  acc5: 91.6667 (91.6331)  time: 0.1158  data: 0.0851  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2856 (1.1825)  acc1: 74.4792 (78.0234)  acc5: 90.1042 (91.2602)  time: 0.1140  data: 0.0833  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1591 (1.1751)  acc1: 76.0417 (77.9412)  acc5: 91.6667 (91.5237)  time: 0.1148  data: 0.0842  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1791 (1.1894)  acc1: 74.4792 (77.7700)  acc5: 91.6667 (91.5500)  time: 0.0974  data: 0.0676  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1249 s / it)\n",
            "* Acc@1 77.770 Acc@5 91.550 loss 1.189\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=88 distillation_alpha=0.6050\n",
            "Epoch: [88]  [  0/781]  eta: 0:14:30  lr: 0.000019  loss: 1.1807 (1.1807)  time: 1.1146  data: 0.7750  max mem: 6459\n",
            "Epoch: [88]  [ 10/781]  eta: 0:05:11  lr: 0.000019  loss: 1.3580 (1.5332)  time: 0.4041  data: 0.0707  max mem: 6459\n",
            "Epoch: [88]  [ 20/781]  eta: 0:04:41  lr: 0.000019  loss: 1.3367 (1.4689)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 30/781]  eta: 0:04:28  lr: 0.000019  loss: 1.3067 (1.4741)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 40/781]  eta: 0:04:20  lr: 0.000019  loss: 1.3476 (1.4891)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 50/781]  eta: 0:04:14  lr: 0.000019  loss: 1.3435 (1.4700)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 60/781]  eta: 0:04:09  lr: 0.000019  loss: 1.2995 (1.5159)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 70/781]  eta: 0:04:04  lr: 0.000019  loss: 1.4367 (1.5191)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 80/781]  eta: 0:04:00  lr: 0.000019  loss: 1.2902 (1.5120)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 90/781]  eta: 0:03:55  lr: 0.000019  loss: 1.2787 (1.4977)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [100/781]  eta: 0:03:51  lr: 0.000019  loss: 1.3187 (1.4877)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [110/781]  eta: 0:03:48  lr: 0.000019  loss: 1.3173 (1.4821)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [120/781]  eta: 0:03:44  lr: 0.000019  loss: 1.3175 (1.4876)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [130/781]  eta: 0:03:40  lr: 0.000019  loss: 1.3507 (1.4931)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [140/781]  eta: 0:03:36  lr: 0.000019  loss: 1.3507 (1.5123)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [150/781]  eta: 0:03:33  lr: 0.000019  loss: 1.3113 (1.5006)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [160/781]  eta: 0:03:29  lr: 0.000019  loss: 1.3113 (1.5024)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [170/781]  eta: 0:03:26  lr: 0.000019  loss: 1.3632 (1.5095)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [180/781]  eta: 0:03:22  lr: 0.000019  loss: 1.3562 (1.5046)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [190/781]  eta: 0:03:19  lr: 0.000019  loss: 1.3165 (1.5071)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [200/781]  eta: 0:03:15  lr: 0.000019  loss: 1.3378 (1.5042)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [210/781]  eta: 0:03:12  lr: 0.000019  loss: 1.3147 (1.4996)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [220/781]  eta: 0:03:08  lr: 0.000019  loss: 1.3147 (1.4913)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [230/781]  eta: 0:03:05  lr: 0.000019  loss: 1.2958 (1.4851)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [240/781]  eta: 0:03:01  lr: 0.000019  loss: 1.2964 (1.4821)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [250/781]  eta: 0:02:58  lr: 0.000019  loss: 1.3380 (1.4817)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [260/781]  eta: 0:02:54  lr: 0.000019  loss: 1.3065 (1.4815)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [270/781]  eta: 0:02:51  lr: 0.000019  loss: 1.2997 (1.4845)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [280/781]  eta: 0:02:48  lr: 0.000019  loss: 1.2893 (1.4819)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [290/781]  eta: 0:02:44  lr: 0.000019  loss: 1.2675 (1.4780)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [300/781]  eta: 0:02:41  lr: 0.000019  loss: 1.2841 (1.4807)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [310/781]  eta: 0:02:37  lr: 0.000019  loss: 1.3320 (1.4779)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [320/781]  eta: 0:02:34  lr: 0.000019  loss: 1.2983 (1.4785)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [330/781]  eta: 0:02:31  lr: 0.000019  loss: 1.3160 (1.4850)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [340/781]  eta: 0:02:27  lr: 0.000019  loss: 1.3894 (1.4844)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [350/781]  eta: 0:02:24  lr: 0.000019  loss: 1.3245 (1.4883)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [360/781]  eta: 0:02:21  lr: 0.000019  loss: 1.3160 (1.4854)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [370/781]  eta: 0:02:17  lr: 0.000019  loss: 1.3375 (1.4873)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [380/781]  eta: 0:02:14  lr: 0.000019  loss: 1.3337 (1.4853)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [390/781]  eta: 0:02:10  lr: 0.000019  loss: 1.3026 (1.4864)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [400/781]  eta: 0:02:07  lr: 0.000019  loss: 1.3419 (1.4871)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [410/781]  eta: 0:02:04  lr: 0.000019  loss: 1.3093 (1.4869)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [420/781]  eta: 0:02:00  lr: 0.000019  loss: 1.2963 (1.4930)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [430/781]  eta: 0:01:57  lr: 0.000019  loss: 1.3007 (1.4923)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [440/781]  eta: 0:01:54  lr: 0.000019  loss: 1.3045 (1.4943)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [450/781]  eta: 0:01:50  lr: 0.000019  loss: 1.3414 (1.4970)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [460/781]  eta: 0:01:47  lr: 0.000019  loss: 1.3169 (1.4983)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [470/781]  eta: 0:01:44  lr: 0.000019  loss: 1.2842 (1.4968)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [480/781]  eta: 0:01:40  lr: 0.000019  loss: 1.2646 (1.4948)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [490/781]  eta: 0:01:37  lr: 0.000019  loss: 1.2646 (1.4925)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [500/781]  eta: 0:01:33  lr: 0.000019  loss: 1.3037 (1.4951)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [510/781]  eta: 0:01:30  lr: 0.000019  loss: 1.5483 (1.5006)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [520/781]  eta: 0:01:27  lr: 0.000019  loss: 1.3427 (1.4997)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [530/781]  eta: 0:01:23  lr: 0.000019  loss: 1.2778 (1.4968)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [540/781]  eta: 0:01:20  lr: 0.000019  loss: 1.3505 (1.4993)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [550/781]  eta: 0:01:17  lr: 0.000019  loss: 1.3593 (1.5016)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [560/781]  eta: 0:01:13  lr: 0.000019  loss: 1.3264 (1.5035)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [570/781]  eta: 0:01:10  lr: 0.000019  loss: 1.3434 (1.5048)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [580/781]  eta: 0:01:07  lr: 0.000019  loss: 1.2736 (1.5023)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [590/781]  eta: 0:01:03  lr: 0.000019  loss: 1.2736 (1.5028)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [600/781]  eta: 0:01:00  lr: 0.000019  loss: 1.3202 (1.5020)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [610/781]  eta: 0:00:57  lr: 0.000019  loss: 1.3237 (1.5034)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [620/781]  eta: 0:00:53  lr: 0.000019  loss: 1.3257 (1.5078)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [630/781]  eta: 0:00:50  lr: 0.000019  loss: 1.3181 (1.5088)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [640/781]  eta: 0:00:47  lr: 0.000019  loss: 1.3414 (1.5080)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [650/781]  eta: 0:00:43  lr: 0.000019  loss: 1.3414 (1.5088)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [660/781]  eta: 0:00:40  lr: 0.000019  loss: 1.3435 (1.5090)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [670/781]  eta: 0:00:37  lr: 0.000019  loss: 1.3024 (1.5072)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [680/781]  eta: 0:00:33  lr: 0.000019  loss: 1.2615 (1.5040)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [690/781]  eta: 0:00:30  lr: 0.000019  loss: 1.2871 (1.5063)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [700/781]  eta: 0:00:27  lr: 0.000019  loss: 1.4143 (1.5086)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [710/781]  eta: 0:00:23  lr: 0.000019  loss: 1.4143 (1.5080)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [720/781]  eta: 0:00:20  lr: 0.000019  loss: 1.3207 (1.5109)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [730/781]  eta: 0:00:17  lr: 0.000019  loss: 1.3497 (1.5134)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [740/781]  eta: 0:00:13  lr: 0.000019  loss: 1.3363 (1.5138)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [750/781]  eta: 0:00:10  lr: 0.000019  loss: 1.3242 (1.5140)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [760/781]  eta: 0:00:07  lr: 0.000019  loss: 1.3023 (1.5148)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [770/781]  eta: 0:00:03  lr: 0.000019  loss: 1.2773 (1.5127)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [780/781]  eta: 0:00:00  lr: 0.000019  loss: 1.2765 (1.5111)  time: 0.3328  data: 0.0005  max mem: 6459\n",
            "Epoch: [88] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000019  loss: 1.2765 (1.5111)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3255544602870941, 'lambda_convnext_base': 0.2557471692562103, 'lambda_tf_efficientnetv2_l': 0.41869792342185974}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8664 (0.8664)  acc1: 81.2500 (81.2500)  acc5: 95.8333 (95.8333)  time: 0.8489  data: 0.8180  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9303 (0.9944)  acc1: 81.7708 (81.2974)  acc5: 93.7500 (93.1818)  time: 0.1679  data: 0.1373  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1004 (1.0657)  acc1: 77.0833 (80.1339)  acc5: 93.2292 (92.4355)  time: 0.1179  data: 0.0872  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1999 (1.1175)  acc1: 76.5625 (78.9987)  acc5: 91.6667 (91.9187)  time: 0.1190  data: 0.0883  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2649 (1.1686)  acc1: 76.0417 (78.0996)  acc5: 90.1042 (91.3745)  time: 0.1102  data: 0.0796  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1789 (1.1651)  acc1: 76.5625 (77.8901)  acc5: 92.1875 (91.6462)  time: 0.1133  data: 0.0826  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2009 (1.1787)  acc1: 74.4792 (77.7400)  acc5: 92.7083 (91.6800)  time: 0.1006  data: 0.0709  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1244 s / it)\n",
            "* Acc@1 77.740 Acc@5 91.680 loss 1.179\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=89 distillation_alpha=0.6107\n",
            "Epoch: [89]  [  0/781]  eta: 0:14:46  lr: 0.000019  loss: 1.2979 (1.2979)  time: 1.1355  data: 0.7903  max mem: 6459\n",
            "Epoch: [89]  [ 10/781]  eta: 0:05:13  lr: 0.000019  loss: 1.3097 (1.5754)  time: 0.4062  data: 0.0721  max mem: 6459\n",
            "Epoch: [89]  [ 20/781]  eta: 0:04:42  lr: 0.000019  loss: 1.3276 (1.5178)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 30/781]  eta: 0:04:29  lr: 0.000019  loss: 1.3572 (1.5681)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 40/781]  eta: 0:04:21  lr: 0.000019  loss: 1.3053 (1.4938)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 50/781]  eta: 0:04:14  lr: 0.000019  loss: 1.2842 (1.4950)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 60/781]  eta: 0:04:09  lr: 0.000019  loss: 1.3062 (1.4895)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 70/781]  eta: 0:04:04  lr: 0.000019  loss: 1.2796 (1.4698)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 80/781]  eta: 0:04:00  lr: 0.000019  loss: 1.2568 (1.4619)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 90/781]  eta: 0:03:56  lr: 0.000019  loss: 1.3196 (1.4682)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [100/781]  eta: 0:03:51  lr: 0.000019  loss: 1.3196 (1.4569)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [110/781]  eta: 0:03:48  lr: 0.000019  loss: 1.3056 (1.4826)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [120/781]  eta: 0:03:44  lr: 0.000019  loss: 1.3844 (1.4970)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [130/781]  eta: 0:03:40  lr: 0.000019  loss: 1.3191 (1.4929)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [140/781]  eta: 0:03:36  lr: 0.000019  loss: 1.2806 (1.4981)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [150/781]  eta: 0:03:33  lr: 0.000019  loss: 1.3375 (1.5057)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [160/781]  eta: 0:03:29  lr: 0.000019  loss: 1.3185 (1.5021)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [170/781]  eta: 0:03:26  lr: 0.000019  loss: 1.2808 (1.5032)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [180/781]  eta: 0:03:22  lr: 0.000019  loss: 1.3162 (1.4969)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [190/781]  eta: 0:03:19  lr: 0.000019  loss: 1.3162 (1.5019)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [200/781]  eta: 0:03:15  lr: 0.000019  loss: 1.3449 (1.5122)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [210/781]  eta: 0:03:12  lr: 0.000019  loss: 1.3263 (1.5097)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [220/781]  eta: 0:03:08  lr: 0.000019  loss: 1.3263 (1.5071)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [230/781]  eta: 0:03:05  lr: 0.000019  loss: 1.3065 (1.5113)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [240/781]  eta: 0:03:01  lr: 0.000019  loss: 1.3065 (1.5235)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [250/781]  eta: 0:02:58  lr: 0.000019  loss: 1.3041 (1.5224)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [260/781]  eta: 0:02:55  lr: 0.000019  loss: 1.3041 (1.5216)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [270/781]  eta: 0:02:51  lr: 0.000019  loss: 1.3776 (1.5268)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [280/781]  eta: 0:02:48  lr: 0.000019  loss: 1.3776 (1.5304)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [290/781]  eta: 0:02:44  lr: 0.000019  loss: 1.3477 (1.5318)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [300/781]  eta: 0:02:41  lr: 0.000019  loss: 1.3383 (1.5295)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [310/781]  eta: 0:02:37  lr: 0.000019  loss: 1.3702 (1.5333)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [320/781]  eta: 0:02:34  lr: 0.000019  loss: 1.3568 (1.5343)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [330/781]  eta: 0:02:31  lr: 0.000019  loss: 1.3001 (1.5331)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [340/781]  eta: 0:02:27  lr: 0.000019  loss: 1.2995 (1.5284)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [350/781]  eta: 0:02:24  lr: 0.000019  loss: 1.3228 (1.5297)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [360/781]  eta: 0:02:21  lr: 0.000019  loss: 1.3413 (1.5328)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [370/781]  eta: 0:02:17  lr: 0.000019  loss: 1.2842 (1.5282)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [380/781]  eta: 0:02:14  lr: 0.000019  loss: 1.3025 (1.5352)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [390/781]  eta: 0:02:10  lr: 0.000019  loss: 1.3492 (1.5313)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [400/781]  eta: 0:02:07  lr: 0.000019  loss: 1.3492 (1.5324)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [410/781]  eta: 0:02:04  lr: 0.000019  loss: 1.3569 (1.5316)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [420/781]  eta: 0:02:01  lr: 0.000019  loss: 1.2971 (1.5305)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [430/781]  eta: 0:01:57  lr: 0.000019  loss: 1.2874 (1.5313)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [440/781]  eta: 0:01:54  lr: 0.000019  loss: 1.3141 (1.5312)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [450/781]  eta: 0:01:50  lr: 0.000019  loss: 1.3151 (1.5333)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [460/781]  eta: 0:01:47  lr: 0.000019  loss: 1.3264 (1.5323)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [470/781]  eta: 0:01:44  lr: 0.000019  loss: 1.2794 (1.5293)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [480/781]  eta: 0:01:40  lr: 0.000019  loss: 1.2857 (1.5281)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [490/781]  eta: 0:01:37  lr: 0.000019  loss: 1.3398 (1.5294)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [500/781]  eta: 0:01:34  lr: 0.000019  loss: 1.3255 (1.5264)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [510/781]  eta: 0:01:30  lr: 0.000019  loss: 1.2878 (1.5259)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [520/781]  eta: 0:01:27  lr: 0.000019  loss: 1.3008 (1.5238)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [530/781]  eta: 0:01:24  lr: 0.000019  loss: 1.3198 (1.5244)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [540/781]  eta: 0:01:20  lr: 0.000019  loss: 1.2537 (1.5193)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [550/781]  eta: 0:01:17  lr: 0.000019  loss: 1.2814 (1.5241)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [560/781]  eta: 0:01:13  lr: 0.000019  loss: 1.2763 (1.5221)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [570/781]  eta: 0:01:10  lr: 0.000019  loss: 1.2763 (1.5204)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [580/781]  eta: 0:01:07  lr: 0.000019  loss: 1.3107 (1.5206)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [590/781]  eta: 0:01:03  lr: 0.000019  loss: 1.3059 (1.5196)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [600/781]  eta: 0:01:00  lr: 0.000019  loss: 1.2894 (1.5186)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [610/781]  eta: 0:00:57  lr: 0.000019  loss: 1.3046 (1.5207)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [620/781]  eta: 0:00:53  lr: 0.000019  loss: 1.3780 (1.5230)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [630/781]  eta: 0:00:50  lr: 0.000019  loss: 1.3454 (1.5198)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [640/781]  eta: 0:00:47  lr: 0.000019  loss: 1.3454 (1.5230)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [650/781]  eta: 0:00:43  lr: 0.000019  loss: 1.3986 (1.5252)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [660/781]  eta: 0:00:40  lr: 0.000019  loss: 1.3204 (1.5243)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [670/781]  eta: 0:00:37  lr: 0.000019  loss: 1.2875 (1.5227)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [680/781]  eta: 0:00:33  lr: 0.000019  loss: 1.3081 (1.5227)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [690/781]  eta: 0:00:30  lr: 0.000019  loss: 1.3279 (1.5237)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [700/781]  eta: 0:00:27  lr: 0.000019  loss: 1.3435 (1.5226)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [710/781]  eta: 0:00:23  lr: 0.000019  loss: 1.3138 (1.5224)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [720/781]  eta: 0:00:20  lr: 0.000019  loss: 1.3351 (1.5240)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [730/781]  eta: 0:00:17  lr: 0.000019  loss: 1.3945 (1.5244)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [740/781]  eta: 0:00:13  lr: 0.000019  loss: 1.3156 (1.5226)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [750/781]  eta: 0:00:10  lr: 0.000019  loss: 1.3100 (1.5225)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [760/781]  eta: 0:00:07  lr: 0.000019  loss: 1.3116 (1.5214)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [770/781]  eta: 0:00:03  lr: 0.000019  loss: 1.2999 (1.5215)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [780/781]  eta: 0:00:00  lr: 0.000019  loss: 1.2897 (1.5216)  time: 0.3328  data: 0.0005  max mem: 6459\n",
            "Epoch: [89] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000019  loss: 1.2897 (1.5216)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3248494267463684, 'lambda_convnext_base': 0.25636017322540283, 'lambda_tf_efficientnetv2_l': 0.4187907576560974}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.8364 (0.8364)  acc1: 81.7708 (81.7708)  acc5: 94.2708 (94.2708)  time: 0.8099  data: 0.7790  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9630 (1.0065)  acc1: 83.3333 (80.8712)  acc5: 93.7500 (93.2765)  time: 0.1680  data: 0.1373  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0870 (1.0699)  acc1: 78.6458 (79.9355)  acc5: 92.1875 (92.3859)  time: 0.1208  data: 0.0901  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2482 (1.1232)  acc1: 76.5625 (78.8642)  acc5: 90.6250 (91.7843)  time: 0.1249  data: 0.0942  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2482 (1.1718)  acc1: 76.5625 (78.1885)  acc5: 90.1042 (91.2983)  time: 0.1250  data: 0.0943  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1717 (1.1672)  acc1: 75.5208 (78.0535)  acc5: 91.6667 (91.5850)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1729 (1.1794)  acc1: 75.0000 (77.9200)  acc5: 91.6667 (91.6000)  time: 0.1067  data: 0.0770  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1300 s / it)\n",
            "* Acc@1 77.920 Acc@5 91.600 loss 1.179\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.96%\n",
            "[alpha-schedule=cosine] epoch=90 distillation_alpha=0.6163\n",
            "Epoch: [90]  [  0/781]  eta: 0:14:01  lr: 0.000018  loss: 1.1997 (1.1997)  time: 1.0768  data: 0.7256  max mem: 6459\n",
            "Epoch: [90]  [ 10/781]  eta: 0:05:08  lr: 0.000018  loss: 1.3521 (1.6289)  time: 0.4005  data: 0.0662  max mem: 6459\n",
            "Epoch: [90]  [ 20/781]  eta: 0:04:40  lr: 0.000018  loss: 1.2877 (1.4711)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 30/781]  eta: 0:04:28  lr: 0.000018  loss: 1.2965 (1.5125)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 40/781]  eta: 0:04:20  lr: 0.000018  loss: 1.4073 (1.5855)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 50/781]  eta: 0:04:14  lr: 0.000018  loss: 1.3668 (1.5902)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 60/781]  eta: 0:04:08  lr: 0.000018  loss: 1.2863 (1.5767)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 70/781]  eta: 0:04:04  lr: 0.000018  loss: 1.2751 (1.5467)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 80/781]  eta: 0:03:59  lr: 0.000018  loss: 1.3115 (1.5630)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 90/781]  eta: 0:03:55  lr: 0.000018  loss: 1.3756 (1.5749)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [100/781]  eta: 0:03:51  lr: 0.000018  loss: 1.3324 (1.5717)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [110/781]  eta: 0:03:47  lr: 0.000018  loss: 1.2912 (1.5614)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [120/781]  eta: 0:03:44  lr: 0.000018  loss: 1.2752 (1.5548)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [130/781]  eta: 0:03:40  lr: 0.000018  loss: 1.3110 (1.5627)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [140/781]  eta: 0:03:36  lr: 0.000018  loss: 1.3327 (1.5606)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [150/781]  eta: 0:03:33  lr: 0.000018  loss: 1.3201 (1.5470)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [160/781]  eta: 0:03:29  lr: 0.000018  loss: 1.3463 (1.5606)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [170/781]  eta: 0:03:26  lr: 0.000018  loss: 1.3667 (1.5546)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [180/781]  eta: 0:03:22  lr: 0.000018  loss: 1.2579 (1.5500)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [190/781]  eta: 0:03:19  lr: 0.000018  loss: 1.2558 (1.5430)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [200/781]  eta: 0:03:15  lr: 0.000018  loss: 1.2765 (1.5379)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [210/781]  eta: 0:03:12  lr: 0.000018  loss: 1.3082 (1.5385)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [220/781]  eta: 0:03:08  lr: 0.000018  loss: 1.3082 (1.5363)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [230/781]  eta: 0:03:05  lr: 0.000018  loss: 1.2944 (1.5398)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [240/781]  eta: 0:03:01  lr: 0.000018  loss: 1.3259 (1.5369)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [250/781]  eta: 0:02:58  lr: 0.000018  loss: 1.3203 (1.5338)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [260/781]  eta: 0:02:54  lr: 0.000018  loss: 1.3249 (1.5316)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.3249 (1.5276)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [280/781]  eta: 0:02:48  lr: 0.000018  loss: 1.3367 (1.5243)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [290/781]  eta: 0:02:44  lr: 0.000018  loss: 1.3367 (1.5291)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [300/781]  eta: 0:02:41  lr: 0.000018  loss: 1.3817 (1.5318)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [310/781]  eta: 0:02:37  lr: 0.000018  loss: 1.2951 (1.5295)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.2642 (1.5214)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [330/781]  eta: 0:02:31  lr: 0.000018  loss: 1.2942 (1.5197)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [340/781]  eta: 0:02:27  lr: 0.000018  loss: 1.3078 (1.5163)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [350/781]  eta: 0:02:24  lr: 0.000018  loss: 1.3275 (1.5195)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [360/781]  eta: 0:02:21  lr: 0.000018  loss: 1.3115 (1.5168)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [370/781]  eta: 0:02:17  lr: 0.000018  loss: 1.2860 (1.5128)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [380/781]  eta: 0:02:14  lr: 0.000018  loss: 1.3042 (1.5132)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [390/781]  eta: 0:02:10  lr: 0.000018  loss: 1.2971 (1.5156)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [400/781]  eta: 0:02:07  lr: 0.000018  loss: 1.2625 (1.5093)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [410/781]  eta: 0:02:04  lr: 0.000018  loss: 1.2761 (1.5117)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [420/781]  eta: 0:02:00  lr: 0.000018  loss: 1.3273 (1.5130)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.3556 (1.5135)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [440/781]  eta: 0:01:54  lr: 0.000018  loss: 1.3556 (1.5143)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [450/781]  eta: 0:01:50  lr: 0.000018  loss: 1.3285 (1.5130)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.3234 (1.5127)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [470/781]  eta: 0:01:44  lr: 0.000018  loss: 1.3146 (1.5123)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [480/781]  eta: 0:01:40  lr: 0.000018  loss: 1.2923 (1.5094)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.3034 (1.5075)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [500/781]  eta: 0:01:33  lr: 0.000018  loss: 1.3259 (1.5094)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.3119 (1.5123)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [520/781]  eta: 0:01:27  lr: 0.000018  loss: 1.2939 (1.5100)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [530/781]  eta: 0:01:23  lr: 0.000018  loss: 1.3330 (1.5143)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.3428 (1.5143)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [550/781]  eta: 0:01:17  lr: 0.000018  loss: 1.3173 (1.5156)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [560/781]  eta: 0:01:13  lr: 0.000018  loss: 1.3051 (1.5154)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.2837 (1.5144)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [580/781]  eta: 0:01:07  lr: 0.000018  loss: 1.3002 (1.5168)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [590/781]  eta: 0:01:03  lr: 0.000018  loss: 1.2861 (1.5163)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.2906 (1.5156)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [610/781]  eta: 0:00:57  lr: 0.000018  loss: 1.3168 (1.5171)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.3246 (1.5160)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3039 (1.5164)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [640/781]  eta: 0:00:47  lr: 0.000018  loss: 1.3014 (1.5140)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.2888 (1.5125)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.2888 (1.5105)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [670/781]  eta: 0:00:37  lr: 0.000018  loss: 1.2862 (1.5101)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.2884 (1.5089)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.3201 (1.5086)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [700/781]  eta: 0:00:27  lr: 0.000018  loss: 1.3255 (1.5073)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.2957 (1.5061)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.2791 (1.5070)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [730/781]  eta: 0:00:17  lr: 0.000018  loss: 1.3229 (1.5086)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.3060 (1.5065)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.2773 (1.5036)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [760/781]  eta: 0:00:07  lr: 0.000018  loss: 1.2968 (1.5028)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.3102 (1.5011)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.2960 (1.5012)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [90] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.2960 (1.5012)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3251059055328369, 'lambda_convnext_base': 0.2559303939342499, 'lambda_tf_efficientnetv2_l': 0.418963760137558}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8259 (0.8259)  acc1: 82.8125 (82.8125)  acc5: 94.7917 (94.7917)  time: 0.8477  data: 0.8168  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0183 (0.9829)  acc1: 82.2917 (81.3920)  acc5: 94.7917 (93.7974)  time: 0.1673  data: 0.1358  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0451 (1.0497)  acc1: 76.5625 (80.1587)  acc5: 93.2292 (92.7579)  time: 0.1209  data: 0.0897  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1784 (1.1090)  acc1: 76.0417 (79.1499)  acc5: 91.1458 (92.0531)  time: 0.1243  data: 0.0935  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2460 (1.1607)  acc1: 76.0417 (78.3791)  acc5: 89.5833 (91.5142)  time: 0.1241  data: 0.0935  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1180 (1.1585)  acc1: 76.0417 (78.1965)  acc5: 91.1458 (91.7892)  time: 0.1237  data: 0.0931  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1856 (1.1664)  acc1: 76.0417 (78.1000)  acc5: 92.7083 (91.8100)  time: 0.1062  data: 0.0765  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1299 s / it)\n",
            "* Acc@1 78.100 Acc@5 91.810 loss 1.166\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=91 distillation_alpha=0.6217\n",
            "Epoch: [91]  [  0/781]  eta: 0:14:52  lr: 0.000018  loss: 1.9423 (1.9423)  time: 1.1422  data: 0.7985  max mem: 6459\n",
            "Epoch: [91]  [ 10/781]  eta: 0:05:13  lr: 0.000018  loss: 1.3728 (1.6680)  time: 0.4065  data: 0.0729  max mem: 6459\n",
            "Epoch: [91]  [ 20/781]  eta: 0:04:42  lr: 0.000018  loss: 1.3060 (1.5512)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 30/781]  eta: 0:04:29  lr: 0.000018  loss: 1.2769 (1.4919)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 40/781]  eta: 0:04:21  lr: 0.000018  loss: 1.2769 (1.5086)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 50/781]  eta: 0:04:15  lr: 0.000018  loss: 1.3137 (1.4795)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 60/781]  eta: 0:04:09  lr: 0.000018  loss: 1.3137 (1.4680)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 70/781]  eta: 0:04:04  lr: 0.000018  loss: 1.2969 (1.4698)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 80/781]  eta: 0:04:00  lr: 0.000018  loss: 1.2969 (1.4685)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 90/781]  eta: 0:03:56  lr: 0.000018  loss: 1.2860 (1.4567)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [100/781]  eta: 0:03:52  lr: 0.000018  loss: 1.2860 (1.4588)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [110/781]  eta: 0:03:48  lr: 0.000018  loss: 1.2442 (1.4523)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [120/781]  eta: 0:03:44  lr: 0.000018  loss: 1.2777 (1.4689)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [130/781]  eta: 0:03:40  lr: 0.000018  loss: 1.3760 (1.4697)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [140/781]  eta: 0:03:37  lr: 0.000018  loss: 1.3297 (1.4774)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [150/781]  eta: 0:03:33  lr: 0.000018  loss: 1.3297 (1.4734)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [160/781]  eta: 0:03:29  lr: 0.000018  loss: 1.2519 (1.4617)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [170/781]  eta: 0:03:26  lr: 0.000018  loss: 1.2811 (1.4659)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [180/781]  eta: 0:03:22  lr: 0.000018  loss: 1.3603 (1.4741)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [190/781]  eta: 0:03:19  lr: 0.000018  loss: 1.3433 (1.4759)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [200/781]  eta: 0:03:15  lr: 0.000018  loss: 1.2761 (1.4676)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [210/781]  eta: 0:03:12  lr: 0.000018  loss: 1.2761 (1.4676)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [220/781]  eta: 0:03:08  lr: 0.000018  loss: 1.3410 (1.4757)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [230/781]  eta: 0:03:05  lr: 0.000018  loss: 1.2790 (1.4678)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [240/781]  eta: 0:03:01  lr: 0.000018  loss: 1.2675 (1.4669)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [250/781]  eta: 0:02:58  lr: 0.000018  loss: 1.2835 (1.4626)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [260/781]  eta: 0:02:55  lr: 0.000018  loss: 1.2890 (1.4731)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.2692 (1.4718)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [280/781]  eta: 0:02:48  lr: 0.000018  loss: 1.2856 (1.4766)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [290/781]  eta: 0:02:44  lr: 0.000018  loss: 1.3036 (1.4734)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [300/781]  eta: 0:02:41  lr: 0.000018  loss: 1.3068 (1.4793)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [310/781]  eta: 0:02:37  lr: 0.000018  loss: 1.3843 (1.4823)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.3484 (1.4820)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [330/781]  eta: 0:02:31  lr: 0.000018  loss: 1.3140 (1.4847)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [340/781]  eta: 0:02:27  lr: 0.000018  loss: 1.3661 (1.4876)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [350/781]  eta: 0:02:24  lr: 0.000018  loss: 1.2835 (1.4847)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [360/781]  eta: 0:02:21  lr: 0.000018  loss: 1.2792 (1.4855)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [370/781]  eta: 0:02:17  lr: 0.000018  loss: 1.2686 (1.4823)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [380/781]  eta: 0:02:14  lr: 0.000018  loss: 1.2855 (1.4851)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [390/781]  eta: 0:02:10  lr: 0.000018  loss: 1.3291 (1.4840)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [400/781]  eta: 0:02:07  lr: 0.000018  loss: 1.3291 (1.4879)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [410/781]  eta: 0:02:04  lr: 0.000018  loss: 1.2502 (1.4828)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [420/781]  eta: 0:02:00  lr: 0.000018  loss: 1.2502 (1.4832)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.2993 (1.4832)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [440/781]  eta: 0:01:54  lr: 0.000018  loss: 1.3225 (1.4836)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [450/781]  eta: 0:01:50  lr: 0.000018  loss: 1.2947 (1.4838)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.2814 (1.4831)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [470/781]  eta: 0:01:44  lr: 0.000018  loss: 1.2906 (1.4822)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [480/781]  eta: 0:01:40  lr: 0.000018  loss: 1.2733 (1.4775)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.2945 (1.4785)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [500/781]  eta: 0:01:33  lr: 0.000018  loss: 1.3096 (1.4769)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.2662 (1.4787)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [520/781]  eta: 0:01:27  lr: 0.000018  loss: 1.2537 (1.4768)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [530/781]  eta: 0:01:23  lr: 0.000018  loss: 1.2728 (1.4738)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.3422 (1.4767)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [550/781]  eta: 0:01:17  lr: 0.000018  loss: 1.3120 (1.4762)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [560/781]  eta: 0:01:13  lr: 0.000018  loss: 1.3120 (1.4766)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.3650 (1.4804)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [580/781]  eta: 0:01:07  lr: 0.000018  loss: 1.3087 (1.4783)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [590/781]  eta: 0:01:03  lr: 0.000018  loss: 1.3087 (1.4766)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.2828 (1.4756)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [610/781]  eta: 0:00:57  lr: 0.000018  loss: 1.2613 (1.4742)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.2875 (1.4758)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3237 (1.4795)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [640/781]  eta: 0:00:47  lr: 0.000018  loss: 1.2808 (1.4774)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.2647 (1.4761)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.2710 (1.4754)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [670/781]  eta: 0:00:37  lr: 0.000018  loss: 1.2944 (1.4790)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.3208 (1.4788)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.3212 (1.4782)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [700/781]  eta: 0:00:27  lr: 0.000018  loss: 1.3297 (1.4789)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.3085 (1.4796)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.3085 (1.4798)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [730/781]  eta: 0:00:17  lr: 0.000018  loss: 1.2900 (1.4797)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.2597 (1.4809)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.3326 (1.4811)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [760/781]  eta: 0:00:07  lr: 0.000018  loss: 1.3287 (1.4839)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.3722 (1.4853)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.3905 (1.4877)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [91] Total time: 0:04:20 (0.3340 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.3905 (1.4877)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3248770833015442, 'lambda_convnext_base': 0.25581520795822144, 'lambda_tf_efficientnetv2_l': 0.41930776834487915}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.8768 (0.8768)  acc1: 82.8125 (82.8125)  acc5: 94.7917 (94.7917)  time: 0.7984  data: 0.7676  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9146 (0.9911)  acc1: 83.3333 (81.2974)  acc5: 94.7917 (93.8447)  time: 0.1734  data: 0.1427  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0566 (1.0605)  acc1: 78.1250 (80.1091)  acc5: 92.7083 (92.7331)  time: 0.1336  data: 0.1029  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2020 (1.1106)  acc1: 77.0833 (79.3011)  acc5: 92.1875 (92.1539)  time: 0.1360  data: 0.1053  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2253 (1.1657)  acc1: 77.0833 (78.3028)  acc5: 90.6250 (91.6032)  time: 0.1347  data: 0.1041  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1205 (1.1593)  acc1: 78.1250 (78.1556)  acc5: 92.7083 (91.8403)  time: 0.1309  data: 0.1002  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1549 (1.1746)  acc1: 77.6042 (78.0300)  acc5: 92.7083 (91.8600)  time: 0.1099  data: 0.0802  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1382 s / it)\n",
            "* Acc@1 78.030 Acc@5 91.860 loss 1.175\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=92 distillation_alpha=0.6270\n",
            "Epoch: [92]  [  0/781]  eta: 0:14:16  lr: 0.000017  loss: 1.2603 (1.2603)  time: 1.0961  data: 0.7444  max mem: 6459\n",
            "Epoch: [92]  [ 10/781]  eta: 0:05:10  lr: 0.000017  loss: 1.2882 (1.4273)  time: 0.4023  data: 0.0680  max mem: 6459\n",
            "Epoch: [92]  [ 20/781]  eta: 0:04:41  lr: 0.000017  loss: 1.2852 (1.3873)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 30/781]  eta: 0:04:28  lr: 0.000017  loss: 1.2700 (1.4119)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 40/781]  eta: 0:04:20  lr: 0.000017  loss: 1.2832 (1.4427)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 50/781]  eta: 0:04:14  lr: 0.000017  loss: 1.2922 (1.4492)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 60/781]  eta: 0:04:09  lr: 0.000017  loss: 1.2917 (1.4542)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 70/781]  eta: 0:04:04  lr: 0.000017  loss: 1.2746 (1.4647)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 80/781]  eta: 0:04:00  lr: 0.000017  loss: 1.3063 (1.4592)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 90/781]  eta: 0:03:56  lr: 0.000017  loss: 1.3194 (1.4525)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [100/781]  eta: 0:03:52  lr: 0.000017  loss: 1.3131 (1.4637)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [110/781]  eta: 0:03:48  lr: 0.000017  loss: 1.2766 (1.4735)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [120/781]  eta: 0:03:44  lr: 0.000017  loss: 1.3117 (1.4891)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [130/781]  eta: 0:03:40  lr: 0.000017  loss: 1.4297 (1.5054)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [140/781]  eta: 0:03:37  lr: 0.000017  loss: 1.3126 (1.5010)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [150/781]  eta: 0:03:33  lr: 0.000017  loss: 1.2796 (1.4945)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [160/781]  eta: 0:03:29  lr: 0.000017  loss: 1.2932 (1.4875)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [170/781]  eta: 0:03:26  lr: 0.000017  loss: 1.2679 (1.4735)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [180/781]  eta: 0:03:23  lr: 0.000017  loss: 1.2679 (1.4705)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [190/781]  eta: 0:03:19  lr: 0.000017  loss: 1.2693 (1.4594)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [200/781]  eta: 0:03:16  lr: 0.000017  loss: 1.3294 (1.4711)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [210/781]  eta: 0:03:12  lr: 0.000017  loss: 1.3193 (1.4624)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [220/781]  eta: 0:03:09  lr: 0.000017  loss: 1.2737 (1.4636)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [230/781]  eta: 0:03:05  lr: 0.000017  loss: 1.3072 (1.4605)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [240/781]  eta: 0:03:02  lr: 0.000017  loss: 1.3226 (1.4692)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [250/781]  eta: 0:02:58  lr: 0.000017  loss: 1.2956 (1.4672)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [260/781]  eta: 0:02:55  lr: 0.000017  loss: 1.2822 (1.4620)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [270/781]  eta: 0:02:51  lr: 0.000017  loss: 1.3074 (1.4653)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [280/781]  eta: 0:02:48  lr: 0.000017  loss: 1.3246 (1.4704)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [290/781]  eta: 0:02:45  lr: 0.000017  loss: 1.3014 (1.4683)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [300/781]  eta: 0:02:41  lr: 0.000017  loss: 1.3243 (1.4744)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [310/781]  eta: 0:02:38  lr: 0.000017  loss: 1.3274 (1.4755)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [320/781]  eta: 0:02:34  lr: 0.000017  loss: 1.2993 (1.4760)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [330/781]  eta: 0:02:31  lr: 0.000017  loss: 1.3468 (1.4792)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [340/781]  eta: 0:02:28  lr: 0.000017  loss: 1.3413 (1.4791)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [350/781]  eta: 0:02:24  lr: 0.000017  loss: 1.3296 (1.4815)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [360/781]  eta: 0:02:21  lr: 0.000017  loss: 1.3021 (1.4798)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [370/781]  eta: 0:02:17  lr: 0.000017  loss: 1.3654 (1.4878)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [380/781]  eta: 0:02:14  lr: 0.000017  loss: 1.3295 (1.4853)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [390/781]  eta: 0:02:11  lr: 0.000017  loss: 1.2655 (1.4822)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [400/781]  eta: 0:02:07  lr: 0.000017  loss: 1.2912 (1.4839)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [410/781]  eta: 0:02:04  lr: 0.000017  loss: 1.2508 (1.4803)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [420/781]  eta: 0:02:01  lr: 0.000017  loss: 1.2591 (1.4783)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [430/781]  eta: 0:01:57  lr: 0.000017  loss: 1.3801 (1.4821)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [440/781]  eta: 0:01:54  lr: 0.000017  loss: 1.3395 (1.4798)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [450/781]  eta: 0:01:50  lr: 0.000017  loss: 1.2491 (1.4761)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [460/781]  eta: 0:01:47  lr: 0.000017  loss: 1.2491 (1.4757)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [470/781]  eta: 0:01:44  lr: 0.000017  loss: 1.2802 (1.4735)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [480/781]  eta: 0:01:40  lr: 0.000017  loss: 1.3307 (1.4736)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [490/781]  eta: 0:01:37  lr: 0.000017  loss: 1.3307 (1.4709)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [500/781]  eta: 0:01:34  lr: 0.000017  loss: 1.2831 (1.4723)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [510/781]  eta: 0:01:30  lr: 0.000017  loss: 1.3221 (1.4729)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [520/781]  eta: 0:01:27  lr: 0.000017  loss: 1.3297 (1.4763)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [530/781]  eta: 0:01:24  lr: 0.000017  loss: 1.7130 (1.4826)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [540/781]  eta: 0:01:20  lr: 0.000017  loss: 1.7293 (1.4860)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [550/781]  eta: 0:01:17  lr: 0.000017  loss: 1.3295 (1.4845)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [560/781]  eta: 0:01:13  lr: 0.000017  loss: 1.2944 (1.4856)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [570/781]  eta: 0:01:10  lr: 0.000017  loss: 1.3250 (1.4857)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [580/781]  eta: 0:01:07  lr: 0.000017  loss: 1.3516 (1.4869)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [590/781]  eta: 0:01:03  lr: 0.000017  loss: 1.4470 (1.4932)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [600/781]  eta: 0:01:00  lr: 0.000017  loss: 1.3589 (1.4909)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [610/781]  eta: 0:00:57  lr: 0.000017  loss: 1.3183 (1.4924)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [620/781]  eta: 0:00:53  lr: 0.000017  loss: 1.4099 (1.4957)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [630/781]  eta: 0:00:50  lr: 0.000017  loss: 1.3927 (1.4966)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [640/781]  eta: 0:00:47  lr: 0.000017  loss: 1.3086 (1.4962)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [650/781]  eta: 0:00:43  lr: 0.000017  loss: 1.2855 (1.4958)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [660/781]  eta: 0:00:40  lr: 0.000017  loss: 1.2795 (1.4965)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [670/781]  eta: 0:00:37  lr: 0.000017  loss: 1.3226 (1.4980)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [680/781]  eta: 0:00:33  lr: 0.000017  loss: 1.3069 (1.4973)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [690/781]  eta: 0:00:30  lr: 0.000017  loss: 1.2821 (1.4981)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [700/781]  eta: 0:00:27  lr: 0.000017  loss: 1.2821 (1.4984)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [710/781]  eta: 0:00:23  lr: 0.000017  loss: 1.3210 (1.4987)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [720/781]  eta: 0:00:20  lr: 0.000017  loss: 1.3554 (1.4989)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [730/781]  eta: 0:00:17  lr: 0.000017  loss: 1.3832 (1.5011)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [740/781]  eta: 0:00:13  lr: 0.000017  loss: 1.3906 (1.5028)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [750/781]  eta: 0:00:10  lr: 0.000017  loss: 1.2854 (1.5011)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [760/781]  eta: 0:00:07  lr: 0.000017  loss: 1.2716 (1.4997)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [770/781]  eta: 0:00:03  lr: 0.000017  loss: 1.2590 (1.5002)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [780/781]  eta: 0:00:00  lr: 0.000017  loss: 1.3294 (1.5017)  time: 0.3332  data: 0.0006  max mem: 6459\n",
            "Epoch: [92] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000017  loss: 1.3294 (1.5017)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32452037930488586, 'lambda_convnext_base': 0.2556980550289154, 'lambda_tf_efficientnetv2_l': 0.4197818636894226}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8436 (0.8436)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8125  data: 0.7815  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9483 (1.0073)  acc1: 83.3333 (81.4867)  acc5: 94.2708 (92.9924)  time: 0.1699  data: 0.1392  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0659 (1.0860)  acc1: 80.7292 (80.0347)  acc5: 92.1875 (92.2123)  time: 0.1212  data: 0.0905  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2282 (1.1445)  acc1: 76.0417 (78.7970)  acc5: 91.6667 (91.6499)  time: 0.1209  data: 0.0902  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2436 (1.1849)  acc1: 74.4792 (78.0742)  acc5: 90.1042 (91.2348)  time: 0.1146  data: 0.0839  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1290 (1.1793)  acc1: 78.1250 (77.9718)  acc5: 92.1875 (91.4216)  time: 0.1245  data: 0.0938  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2056 (1.1921)  acc1: 75.0000 (77.8300)  acc5: 92.1875 (91.4200)  time: 0.1087  data: 0.0790  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1297 s / it)\n",
            "* Acc@1 77.830 Acc@5 91.420 loss 1.192\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=93 distillation_alpha=0.6321\n",
            "Epoch: [93]  [  0/781]  eta: 0:15:08  lr: 0.000017  loss: 1.3236 (1.3236)  time: 1.1638  data: 0.8070  max mem: 6459\n",
            "Epoch: [93]  [ 10/781]  eta: 0:05:14  lr: 0.000017  loss: 1.2959 (1.3924)  time: 0.4083  data: 0.0736  max mem: 6459\n",
            "Epoch: [93]  [ 20/781]  eta: 0:04:43  lr: 0.000017  loss: 1.2758 (1.4570)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 30/781]  eta: 0:04:30  lr: 0.000017  loss: 1.4570 (1.5134)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 40/781]  eta: 0:04:21  lr: 0.000017  loss: 1.3251 (1.5058)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 50/781]  eta: 0:04:15  lr: 0.000017  loss: 1.3211 (1.5250)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 60/781]  eta: 0:04:09  lr: 0.000017  loss: 1.2927 (1.4981)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 70/781]  eta: 0:04:05  lr: 0.000017  loss: 1.2669 (1.4823)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 80/781]  eta: 0:04:00  lr: 0.000017  loss: 1.2696 (1.4596)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 90/781]  eta: 0:03:56  lr: 0.000017  loss: 1.2811 (1.4709)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [100/781]  eta: 0:03:52  lr: 0.000017  loss: 1.3095 (1.4705)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [110/781]  eta: 0:03:48  lr: 0.000017  loss: 1.2569 (1.4707)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [120/781]  eta: 0:03:44  lr: 0.000017  loss: 1.2680 (1.4722)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [130/781]  eta: 0:03:40  lr: 0.000017  loss: 1.2628 (1.4777)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [140/781]  eta: 0:03:37  lr: 0.000017  loss: 1.2875 (1.4835)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [150/781]  eta: 0:03:33  lr: 0.000017  loss: 1.3269 (1.4835)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [160/781]  eta: 0:03:30  lr: 0.000017  loss: 1.2872 (1.4865)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [170/781]  eta: 0:03:26  lr: 0.000017  loss: 1.2927 (1.4951)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [180/781]  eta: 0:03:22  lr: 0.000017  loss: 1.3722 (1.5011)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [190/781]  eta: 0:03:19  lr: 0.000017  loss: 1.3138 (1.4986)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [200/781]  eta: 0:03:15  lr: 0.000017  loss: 1.3088 (1.4955)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [210/781]  eta: 0:03:12  lr: 0.000017  loss: 1.2818 (1.4944)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [220/781]  eta: 0:03:08  lr: 0.000017  loss: 1.3053 (1.4899)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [230/781]  eta: 0:03:05  lr: 0.000017  loss: 1.3171 (1.4935)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [240/781]  eta: 0:03:01  lr: 0.000017  loss: 1.3259 (1.4905)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [250/781]  eta: 0:02:58  lr: 0.000017  loss: 1.2817 (1.4859)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [260/781]  eta: 0:02:55  lr: 0.000017  loss: 1.3283 (1.4920)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [270/781]  eta: 0:02:51  lr: 0.000017  loss: 1.4918 (1.4981)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [280/781]  eta: 0:02:48  lr: 0.000017  loss: 1.4083 (1.5064)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [290/781]  eta: 0:02:44  lr: 0.000017  loss: 1.4083 (1.5099)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [300/781]  eta: 0:02:41  lr: 0.000017  loss: 1.3835 (1.5143)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [310/781]  eta: 0:02:38  lr: 0.000017  loss: 1.3523 (1.5144)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [320/781]  eta: 0:02:34  lr: 0.000017  loss: 1.2662 (1.5107)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [330/781]  eta: 0:02:31  lr: 0.000017  loss: 1.2773 (1.5115)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [340/781]  eta: 0:02:27  lr: 0.000017  loss: 1.2712 (1.5071)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [350/781]  eta: 0:02:24  lr: 0.000017  loss: 1.2873 (1.5039)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [360/781]  eta: 0:02:21  lr: 0.000017  loss: 1.2873 (1.4996)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [370/781]  eta: 0:02:17  lr: 0.000017  loss: 1.2832 (1.4994)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [380/781]  eta: 0:02:14  lr: 0.000017  loss: 1.3232 (1.5010)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [390/781]  eta: 0:02:10  lr: 0.000017  loss: 1.3404 (1.5044)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [400/781]  eta: 0:02:07  lr: 0.000017  loss: 1.3556 (1.5063)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [410/781]  eta: 0:02:04  lr: 0.000017  loss: 1.2648 (1.5030)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [420/781]  eta: 0:02:00  lr: 0.000017  loss: 1.2564 (1.5012)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [430/781]  eta: 0:01:57  lr: 0.000017  loss: 1.3098 (1.5035)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [440/781]  eta: 0:01:54  lr: 0.000017  loss: 1.2817 (1.4985)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [450/781]  eta: 0:01:50  lr: 0.000017  loss: 1.2573 (1.4935)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [460/781]  eta: 0:01:47  lr: 0.000017  loss: 1.2592 (1.4946)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [470/781]  eta: 0:01:44  lr: 0.000017  loss: 1.3168 (1.4978)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [480/781]  eta: 0:01:40  lr: 0.000017  loss: 1.3238 (1.4989)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [490/781]  eta: 0:01:37  lr: 0.000017  loss: 1.3116 (1.5001)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [500/781]  eta: 0:01:33  lr: 0.000017  loss: 1.3171 (1.5017)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [510/781]  eta: 0:01:30  lr: 0.000017  loss: 1.4304 (1.5062)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [520/781]  eta: 0:01:27  lr: 0.000017  loss: 1.4064 (1.5054)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [530/781]  eta: 0:01:23  lr: 0.000017  loss: 1.3366 (1.5052)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [540/781]  eta: 0:01:20  lr: 0.000017  loss: 1.3626 (1.5077)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [550/781]  eta: 0:01:17  lr: 0.000017  loss: 1.3347 (1.5083)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [560/781]  eta: 0:01:13  lr: 0.000017  loss: 1.3128 (1.5082)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [570/781]  eta: 0:01:10  lr: 0.000017  loss: 1.2993 (1.5074)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [580/781]  eta: 0:01:07  lr: 0.000017  loss: 1.3011 (1.5067)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [590/781]  eta: 0:01:03  lr: 0.000017  loss: 1.3217 (1.5095)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [600/781]  eta: 0:01:00  lr: 0.000017  loss: 1.5996 (1.5147)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [610/781]  eta: 0:00:57  lr: 0.000017  loss: 1.3219 (1.5119)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [620/781]  eta: 0:00:53  lr: 0.000017  loss: 1.2889 (1.5114)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [630/781]  eta: 0:00:50  lr: 0.000017  loss: 1.3068 (1.5118)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [640/781]  eta: 0:00:47  lr: 0.000017  loss: 1.3083 (1.5121)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [650/781]  eta: 0:00:43  lr: 0.000017  loss: 1.2703 (1.5122)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [660/781]  eta: 0:00:40  lr: 0.000017  loss: 1.2703 (1.5108)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [670/781]  eta: 0:00:37  lr: 0.000017  loss: 1.2739 (1.5069)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [680/781]  eta: 0:00:33  lr: 0.000017  loss: 1.2913 (1.5057)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [690/781]  eta: 0:00:30  lr: 0.000017  loss: 1.3321 (1.5061)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [700/781]  eta: 0:00:27  lr: 0.000017  loss: 1.2720 (1.5029)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [710/781]  eta: 0:00:23  lr: 0.000017  loss: 1.2719 (1.5019)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [720/781]  eta: 0:00:20  lr: 0.000017  loss: 1.2674 (1.4990)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [730/781]  eta: 0:00:17  lr: 0.000017  loss: 1.2799 (1.5007)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [740/781]  eta: 0:00:13  lr: 0.000017  loss: 1.4312 (1.5037)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [750/781]  eta: 0:00:10  lr: 0.000017  loss: 1.2833 (1.5016)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [760/781]  eta: 0:00:07  lr: 0.000017  loss: 1.2833 (1.5024)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [770/781]  eta: 0:00:03  lr: 0.000017  loss: 1.2954 (1.5012)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [780/781]  eta: 0:00:00  lr: 0.000017  loss: 1.2995 (1.5026)  time: 0.3329  data: 0.0006  max mem: 6459\n",
            "Epoch: [93] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000017  loss: 1.2995 (1.5026)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3238615393638611, 'lambda_convnext_base': 0.2555025517940521, 'lambda_tf_efficientnetv2_l': 0.42063599824905396}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7923 (0.7923)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8342  data: 0.8033  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9113 (0.9974)  acc1: 83.3333 (81.1080)  acc5: 95.3125 (93.7027)  time: 0.1774  data: 0.1468  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1531 (1.0949)  acc1: 77.0833 (79.4891)  acc5: 92.7083 (92.2867)  time: 0.1268  data: 0.0961  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2404 (1.1347)  acc1: 75.5208 (78.8474)  acc5: 91.1458 (91.8683)  time: 0.1272  data: 0.0965  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2789 (1.1807)  acc1: 76.0417 (78.0107)  acc5: 90.6250 (91.3745)  time: 0.1315  data: 0.1008  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1819 (1.1783)  acc1: 76.5625 (77.8493)  acc5: 91.6667 (91.5339)  time: 0.1316  data: 0.1009  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1973 (1.1905)  acc1: 76.0417 (77.7300)  acc5: 92.1875 (91.5600)  time: 0.1121  data: 0.0824  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1364 s / it)\n",
            "* Acc@1 77.730 Acc@5 91.560 loss 1.191\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=94 distillation_alpha=0.6370\n",
            "Epoch: [94]  [  0/781]  eta: 0:14:18  lr: 0.000016  loss: 1.2696 (1.2696)  time: 1.0997  data: 0.7435  max mem: 6459\n",
            "Epoch: [94]  [ 10/781]  eta: 0:05:10  lr: 0.000016  loss: 1.2696 (1.4297)  time: 0.4029  data: 0.0679  max mem: 6459\n",
            "Epoch: [94]  [ 20/781]  eta: 0:04:41  lr: 0.000016  loss: 1.2636 (1.4283)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 30/781]  eta: 0:04:28  lr: 0.000016  loss: 1.3333 (1.4774)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 40/781]  eta: 0:04:20  lr: 0.000016  loss: 1.3773 (1.4989)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 50/781]  eta: 0:04:14  lr: 0.000016  loss: 1.3341 (1.4972)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 60/781]  eta: 0:04:09  lr: 0.000016  loss: 1.2951 (1.4941)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 70/781]  eta: 0:04:04  lr: 0.000016  loss: 1.3123 (1.5045)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 80/781]  eta: 0:04:00  lr: 0.000016  loss: 1.3019 (1.5073)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 90/781]  eta: 0:03:55  lr: 0.000016  loss: 1.3004 (1.5019)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [100/781]  eta: 0:03:51  lr: 0.000016  loss: 1.2786 (1.4796)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [110/781]  eta: 0:03:48  lr: 0.000016  loss: 1.2829 (1.4732)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [120/781]  eta: 0:03:44  lr: 0.000016  loss: 1.2829 (1.4733)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.2727 (1.4839)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [140/781]  eta: 0:03:36  lr: 0.000016  loss: 1.5943 (1.5047)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [150/781]  eta: 0:03:33  lr: 0.000016  loss: 1.3203 (1.4962)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [160/781]  eta: 0:03:29  lr: 0.000016  loss: 1.2636 (1.4910)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [170/781]  eta: 0:03:26  lr: 0.000016  loss: 1.2836 (1.4899)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [180/781]  eta: 0:03:22  lr: 0.000016  loss: 1.3649 (1.4970)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [190/781]  eta: 0:03:19  lr: 0.000016  loss: 1.2786 (1.4969)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [200/781]  eta: 0:03:15  lr: 0.000016  loss: 1.3105 (1.4999)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [210/781]  eta: 0:03:12  lr: 0.000016  loss: 1.2894 (1.4931)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [220/781]  eta: 0:03:08  lr: 0.000016  loss: 1.2694 (1.4897)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [230/781]  eta: 0:03:05  lr: 0.000016  loss: 1.2669 (1.4872)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [240/781]  eta: 0:03:01  lr: 0.000016  loss: 1.2606 (1.4796)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [250/781]  eta: 0:02:58  lr: 0.000016  loss: 1.2454 (1.4824)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [260/781]  eta: 0:02:54  lr: 0.000016  loss: 1.2794 (1.4820)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.3068 (1.4806)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [280/781]  eta: 0:02:48  lr: 0.000016  loss: 1.3419 (1.4814)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [290/781]  eta: 0:02:44  lr: 0.000016  loss: 1.3395 (1.4777)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [300/781]  eta: 0:02:41  lr: 0.000016  loss: 1.2942 (1.4706)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [310/781]  eta: 0:02:37  lr: 0.000016  loss: 1.2941 (1.4761)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.3603 (1.4752)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [330/781]  eta: 0:02:31  lr: 0.000016  loss: 1.3270 (1.4757)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [340/781]  eta: 0:02:27  lr: 0.000016  loss: 1.2977 (1.4728)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.2875 (1.4713)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [360/781]  eta: 0:02:21  lr: 0.000016  loss: 1.3073 (1.4713)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.2786 (1.4681)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [380/781]  eta: 0:02:14  lr: 0.000016  loss: 1.2715 (1.4682)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [390/781]  eta: 0:02:10  lr: 0.000016  loss: 1.3424 (1.4729)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.3645 (1.4716)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [410/781]  eta: 0:02:04  lr: 0.000016  loss: 1.2832 (1.4690)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [420/781]  eta: 0:02:00  lr: 0.000016  loss: 1.2640 (1.4700)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.3127 (1.4742)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [440/781]  eta: 0:01:54  lr: 0.000016  loss: 1.3283 (1.4732)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.2874 (1.4723)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.2874 (1.4741)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [470/781]  eta: 0:01:44  lr: 0.000016  loss: 1.2872 (1.4752)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.2747 (1.4753)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.2919 (1.4785)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [500/781]  eta: 0:01:33  lr: 0.000016  loss: 1.2756 (1.4770)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.2756 (1.4762)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.2602 (1.4719)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [530/781]  eta: 0:01:23  lr: 0.000016  loss: 1.2492 (1.4702)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.2855 (1.4675)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [550/781]  eta: 0:01:17  lr: 0.000016  loss: 1.3131 (1.4711)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [560/781]  eta: 0:01:13  lr: 0.000016  loss: 1.3550 (1.4710)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.2835 (1.4716)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [580/781]  eta: 0:01:07  lr: 0.000016  loss: 1.2835 (1.4724)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.3279 (1.4738)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.3393 (1.4735)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [610/781]  eta: 0:00:57  lr: 0.000016  loss: 1.3044 (1.4715)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.2995 (1.4699)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.2990 (1.4735)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [640/781]  eta: 0:00:47  lr: 0.000016  loss: 1.2990 (1.4719)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.3004 (1.4732)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.3708 (1.4782)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [670/781]  eta: 0:00:37  lr: 0.000016  loss: 1.4018 (1.4806)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.3074 (1.4782)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.2902 (1.4790)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [700/781]  eta: 0:00:27  lr: 0.000016  loss: 1.3238 (1.4787)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.2746 (1.4779)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.2686 (1.4780)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [730/781]  eta: 0:00:17  lr: 0.000016  loss: 1.2994 (1.4763)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.2480 (1.4745)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.2625 (1.4749)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [760/781]  eta: 0:00:07  lr: 0.000016  loss: 1.2927 (1.4750)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.2927 (1.4762)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.2755 (1.4738)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [94] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.2755 (1.4738)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32516977190971375, 'lambda_convnext_base': 0.2558813691139221, 'lambda_tf_efficientnetv2_l': 0.41894903779029846}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8168 (0.8168)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8263  data: 0.7954  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9728 (0.9916)  acc1: 81.7708 (81.2027)  acc5: 94.7917 (93.6080)  time: 0.1762  data: 0.1456  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1079 (1.0731)  acc1: 80.7292 (80.1835)  acc5: 93.2292 (92.5347)  time: 0.1310  data: 0.1004  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2075 (1.1284)  acc1: 76.0417 (79.0323)  acc5: 90.6250 (91.8683)  time: 0.1314  data: 0.1007  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2150 (1.1752)  acc1: 76.0417 (78.3156)  acc5: 89.5833 (91.3872)  time: 0.1325  data: 0.1019  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1689 (1.1719)  acc1: 77.0833 (78.1148)  acc5: 90.6250 (91.6156)  time: 0.1323  data: 0.1016  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1843 (1.1866)  acc1: 75.5208 (77.9700)  acc5: 91.1458 (91.6100)  time: 0.1107  data: 0.0810  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1377 s / it)\n",
            "* Acc@1 77.970 Acc@5 91.610 loss 1.187\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=95 distillation_alpha=0.6418\n",
            "Epoch: [95]  [  0/781]  eta: 0:14:13  lr: 0.000016  loss: 2.0124 (2.0124)  time: 1.0933  data: 0.7491  max mem: 6459\n",
            "Epoch: [95]  [ 10/781]  eta: 0:05:09  lr: 0.000016  loss: 1.2887 (1.4779)  time: 0.4020  data: 0.0684  max mem: 6459\n",
            "Epoch: [95]  [ 20/781]  eta: 0:04:40  lr: 0.000016  loss: 1.2887 (1.5009)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 30/781]  eta: 0:04:28  lr: 0.000016  loss: 1.3153 (1.5443)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 40/781]  eta: 0:04:20  lr: 0.000016  loss: 1.3153 (1.5300)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 50/781]  eta: 0:04:14  lr: 0.000016  loss: 1.2881 (1.5341)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 60/781]  eta: 0:04:08  lr: 0.000016  loss: 1.3144 (1.5194)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 70/781]  eta: 0:04:04  lr: 0.000016  loss: 1.3144 (1.5306)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 80/781]  eta: 0:03:59  lr: 0.000016  loss: 1.2905 (1.4998)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 90/781]  eta: 0:03:55  lr: 0.000016  loss: 1.2686 (1.4824)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [100/781]  eta: 0:03:51  lr: 0.000016  loss: 1.2578 (1.4902)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [110/781]  eta: 0:03:47  lr: 0.000016  loss: 1.6056 (1.5204)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [120/781]  eta: 0:03:44  lr: 0.000016  loss: 1.2846 (1.5132)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.2844 (1.5090)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [140/781]  eta: 0:03:36  lr: 0.000016  loss: 1.3152 (1.5064)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [150/781]  eta: 0:03:33  lr: 0.000016  loss: 1.3152 (1.5126)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [160/781]  eta: 0:03:29  lr: 0.000016  loss: 1.2937 (1.5091)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [170/781]  eta: 0:03:25  lr: 0.000016  loss: 1.2949 (1.5236)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [180/781]  eta: 0:03:22  lr: 0.000016  loss: 1.3343 (1.5253)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [190/781]  eta: 0:03:18  lr: 0.000016  loss: 1.3419 (1.5312)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [200/781]  eta: 0:03:15  lr: 0.000016  loss: 1.3579 (1.5270)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [210/781]  eta: 0:03:12  lr: 0.000016  loss: 1.3791 (1.5351)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [220/781]  eta: 0:03:08  lr: 0.000016  loss: 1.4068 (1.5374)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [230/781]  eta: 0:03:05  lr: 0.000016  loss: 1.3213 (1.5318)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [240/781]  eta: 0:03:01  lr: 0.000016  loss: 1.3413 (1.5321)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [250/781]  eta: 0:02:58  lr: 0.000016  loss: 1.3780 (1.5328)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [260/781]  eta: 0:02:54  lr: 0.000016  loss: 1.3022 (1.5280)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.2717 (1.5283)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [280/781]  eta: 0:02:48  lr: 0.000016  loss: 1.3273 (1.5305)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [290/781]  eta: 0:02:44  lr: 0.000016  loss: 1.3220 (1.5254)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [300/781]  eta: 0:02:41  lr: 0.000016  loss: 1.3027 (1.5308)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [310/781]  eta: 0:02:37  lr: 0.000016  loss: 1.3498 (1.5308)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.2739 (1.5266)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [330/781]  eta: 0:02:31  lr: 0.000016  loss: 1.2707 (1.5244)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [340/781]  eta: 0:02:27  lr: 0.000016  loss: 1.2711 (1.5198)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.3350 (1.5231)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [360/781]  eta: 0:02:20  lr: 0.000016  loss: 1.3859 (1.5227)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.2581 (1.5180)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [380/781]  eta: 0:02:14  lr: 0.000016  loss: 1.2473 (1.5108)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [390/781]  eta: 0:02:10  lr: 0.000016  loss: 1.2640 (1.5134)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.4027 (1.5146)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [410/781]  eta: 0:02:04  lr: 0.000016  loss: 1.3027 (1.5113)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [420/781]  eta: 0:02:00  lr: 0.000016  loss: 1.2722 (1.5070)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.3158 (1.5065)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [440/781]  eta: 0:01:54  lr: 0.000016  loss: 1.3424 (1.5055)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.2983 (1.5068)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.2983 (1.5036)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [470/781]  eta: 0:01:43  lr: 0.000016  loss: 1.2941 (1.5046)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.2865 (1.5052)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.3181 (1.5062)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [500/781]  eta: 0:01:33  lr: 0.000016  loss: 1.2952 (1.5058)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.2877 (1.5043)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.3086 (1.5043)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [530/781]  eta: 0:01:23  lr: 0.000016  loss: 1.2642 (1.5051)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.3191 (1.5039)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [550/781]  eta: 0:01:17  lr: 0.000016  loss: 1.2874 (1.5013)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [560/781]  eta: 0:01:13  lr: 0.000016  loss: 1.2676 (1.5008)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.2782 (1.5005)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [580/781]  eta: 0:01:07  lr: 0.000016  loss: 1.2705 (1.4998)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.3497 (1.5035)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.3497 (1.5019)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [610/781]  eta: 0:00:57  lr: 0.000016  loss: 1.2776 (1.5032)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.2849 (1.5024)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.2849 (1.4997)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [640/781]  eta: 0:00:47  lr: 0.000016  loss: 1.2868 (1.4979)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.3020 (1.4956)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.3372 (1.4964)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [670/781]  eta: 0:00:37  lr: 0.000016  loss: 1.3021 (1.4945)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.2908 (1.4954)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.4332 (1.4957)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [700/781]  eta: 0:00:27  lr: 0.000016  loss: 1.3632 (1.4970)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.2914 (1.4963)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.2721 (1.4930)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [730/781]  eta: 0:00:17  lr: 0.000016  loss: 1.2669 (1.4935)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.2738 (1.4906)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.2633 (1.4873)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [760/781]  eta: 0:00:07  lr: 0.000016  loss: 1.2652 (1.4859)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.3023 (1.4862)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.2884 (1.4859)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [95] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.2884 (1.4859)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3248562216758728, 'lambda_convnext_base': 0.25502127408981323, 'lambda_tf_efficientnetv2_l': 0.42012208700180054}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8209 (0.8209)  acc1: 82.8125 (82.8125)  acc5: 94.2708 (94.2708)  time: 0.8284  data: 0.7976  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9692 (0.9960)  acc1: 82.8125 (81.2027)  acc5: 94.2708 (93.8920)  time: 0.1667  data: 0.1361  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0442 (1.0563)  acc1: 78.1250 (80.1339)  acc5: 93.2292 (92.7331)  time: 0.1068  data: 0.0761  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1948 (1.1036)  acc1: 76.5625 (79.2003)  acc5: 92.7083 (92.2043)  time: 0.1275  data: 0.0969  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2060 (1.1546)  acc1: 75.0000 (78.1377)  acc5: 90.6250 (91.6667)  time: 0.1245  data: 0.0939  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1383 (1.1522)  acc1: 76.5625 (77.9105)  acc5: 91.6667 (91.8505)  time: 0.1265  data: 0.0958  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1610 (1.1653)  acc1: 73.4375 (77.7700)  acc5: 92.1875 (91.8700)  time: 0.1255  data: 0.0958  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1324 s / it)\n",
            "* Acc@1 77.770 Acc@5 91.870 loss 1.165\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=96 distillation_alpha=0.6464\n",
            "Epoch: [96]  [  0/781]  eta: 0:14:06  lr: 0.000015  loss: 1.3065 (1.3065)  time: 1.0841  data: 0.7401  max mem: 6459\n",
            "Epoch: [96]  [ 10/781]  eta: 0:05:09  lr: 0.000015  loss: 1.3065 (1.4571)  time: 0.4015  data: 0.0675  max mem: 6459\n",
            "Epoch: [96]  [ 20/781]  eta: 0:04:40  lr: 0.000015  loss: 1.2194 (1.4298)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 30/781]  eta: 0:04:28  lr: 0.000015  loss: 1.2248 (1.4027)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 40/781]  eta: 0:04:20  lr: 0.000015  loss: 1.2929 (1.3980)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 50/781]  eta: 0:04:14  lr: 0.000015  loss: 1.2988 (1.3954)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 60/781]  eta: 0:04:08  lr: 0.000015  loss: 1.3089 (1.4080)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 70/781]  eta: 0:04:04  lr: 0.000015  loss: 1.3089 (1.4205)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 80/781]  eta: 0:03:59  lr: 0.000015  loss: 1.3083 (1.4270)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 90/781]  eta: 0:03:55  lr: 0.000015  loss: 1.2777 (1.4211)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [100/781]  eta: 0:03:51  lr: 0.000015  loss: 1.2715 (1.4153)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [110/781]  eta: 0:03:48  lr: 0.000015  loss: 1.2830 (1.4226)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [120/781]  eta: 0:03:44  lr: 0.000015  loss: 1.3028 (1.4221)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [130/781]  eta: 0:03:40  lr: 0.000015  loss: 1.3028 (1.4260)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [140/781]  eta: 0:03:36  lr: 0.000015  loss: 1.2931 (1.4258)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [150/781]  eta: 0:03:33  lr: 0.000015  loss: 1.2940 (1.4259)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [160/781]  eta: 0:03:29  lr: 0.000015  loss: 1.3091 (1.4247)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [170/781]  eta: 0:03:26  lr: 0.000015  loss: 1.3104 (1.4214)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [180/781]  eta: 0:03:22  lr: 0.000015  loss: 1.2700 (1.4299)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [190/781]  eta: 0:03:19  lr: 0.000015  loss: 1.2700 (1.4243)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [200/781]  eta: 0:03:15  lr: 0.000015  loss: 1.2570 (1.4273)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [210/781]  eta: 0:03:12  lr: 0.000015  loss: 1.3027 (1.4368)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [220/781]  eta: 0:03:08  lr: 0.000015  loss: 1.2947 (1.4297)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [230/781]  eta: 0:03:05  lr: 0.000015  loss: 1.3145 (1.4366)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [240/781]  eta: 0:03:01  lr: 0.000015  loss: 1.3145 (1.4358)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [250/781]  eta: 0:02:58  lr: 0.000015  loss: 1.2707 (1.4378)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [260/781]  eta: 0:02:54  lr: 0.000015  loss: 1.2783 (1.4406)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [270/781]  eta: 0:02:51  lr: 0.000015  loss: 1.2820 (1.4342)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [280/781]  eta: 0:02:48  lr: 0.000015  loss: 1.2846 (1.4352)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [290/781]  eta: 0:02:44  lr: 0.000015  loss: 1.3122 (1.4371)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [300/781]  eta: 0:02:41  lr: 0.000015  loss: 1.2826 (1.4366)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [310/781]  eta: 0:02:37  lr: 0.000015  loss: 1.2644 (1.4330)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.2644 (1.4354)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [330/781]  eta: 0:02:31  lr: 0.000015  loss: 1.2671 (1.4323)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [340/781]  eta: 0:02:27  lr: 0.000015  loss: 1.2501 (1.4340)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [350/781]  eta: 0:02:24  lr: 0.000015  loss: 1.2624 (1.4372)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [360/781]  eta: 0:02:21  lr: 0.000015  loss: 1.3590 (1.4401)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [370/781]  eta: 0:02:17  lr: 0.000015  loss: 1.3102 (1.4377)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [380/781]  eta: 0:02:14  lr: 0.000015  loss: 1.3124 (1.4444)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [390/781]  eta: 0:02:10  lr: 0.000015  loss: 1.3123 (1.4409)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.3003 (1.4408)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [410/781]  eta: 0:02:04  lr: 0.000015  loss: 1.3567 (1.4480)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [420/781]  eta: 0:02:00  lr: 0.000015  loss: 1.2804 (1.4450)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.2885 (1.4458)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [440/781]  eta: 0:01:54  lr: 0.000015  loss: 1.3325 (1.4463)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [450/781]  eta: 0:01:50  lr: 0.000015  loss: 1.2579 (1.4475)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.2918 (1.4482)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [470/781]  eta: 0:01:44  lr: 0.000015  loss: 1.3241 (1.4478)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.2606 (1.4454)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.2317 (1.4489)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [500/781]  eta: 0:01:33  lr: 0.000015  loss: 1.3103 (1.4515)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.3420 (1.4547)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.3420 (1.4569)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [530/781]  eta: 0:01:23  lr: 0.000015  loss: 1.2823 (1.4566)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.2758 (1.4594)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [550/781]  eta: 0:01:17  lr: 0.000015  loss: 1.3206 (1.4604)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [560/781]  eta: 0:01:13  lr: 0.000015  loss: 1.2876 (1.4584)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.2876 (1.4590)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [580/781]  eta: 0:01:07  lr: 0.000015  loss: 1.3840 (1.4589)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.3358 (1.4600)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.3100 (1.4599)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [610/781]  eta: 0:00:57  lr: 0.000015  loss: 1.3068 (1.4608)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.2621 (1.4582)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.2450 (1.4570)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [640/781]  eta: 0:00:47  lr: 0.000015  loss: 1.2477 (1.4560)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.2870 (1.4539)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.3311 (1.4561)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [670/781]  eta: 0:00:37  lr: 0.000015  loss: 1.3252 (1.4551)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.3252 (1.4559)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.3380 (1.4585)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [700/781]  eta: 0:00:27  lr: 0.000015  loss: 1.3302 (1.4584)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.2877 (1.4595)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.3181 (1.4585)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [730/781]  eta: 0:00:17  lr: 0.000015  loss: 1.3128 (1.4575)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.3180 (1.4595)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.8839 (1.4661)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [760/781]  eta: 0:00:07  lr: 0.000015  loss: 1.3156 (1.4649)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.2486 (1.4627)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.2696 (1.4626)  time: 0.3327  data: 0.0005  max mem: 6459\n",
            "Epoch: [96] Total time: 0:04:20 (0.3339 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.2696 (1.4626)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32477349042892456, 'lambda_convnext_base': 0.25497910380363464, 'lambda_tf_efficientnetv2_l': 0.4202471673488617}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7986 (0.7986)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8267  data: 0.7958  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9570 (0.9771)  acc1: 82.8125 (81.5341)  acc5: 94.2708 (93.7974)  time: 0.1713  data: 0.1406  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0870 (1.0673)  acc1: 79.1667 (80.1091)  acc5: 92.1875 (92.4107)  time: 0.1231  data: 0.0924  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2057 (1.1221)  acc1: 76.0417 (79.0995)  acc5: 91.1458 (91.7003)  time: 0.1259  data: 0.0953  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2193 (1.1692)  acc1: 76.0417 (78.1758)  acc5: 89.5833 (91.3237)  time: 0.1287  data: 0.0980  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.2094 (1.1668)  acc1: 76.0417 (77.9208)  acc5: 92.1875 (91.6156)  time: 0.1301  data: 0.0995  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2174 (1.1788)  acc1: 75.5208 (77.8000)  acc5: 92.7083 (91.6500)  time: 0.1111  data: 0.0814  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1337 s / it)\n",
            "* Acc@1 77.800 Acc@5 91.650 loss 1.179\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=97 distillation_alpha=0.6508\n",
            "Epoch: [97]  [  0/781]  eta: 0:14:31  lr: 0.000015  loss: 2.2714 (2.2714)  time: 1.1157  data: 0.7756  max mem: 6459\n",
            "Epoch: [97]  [ 10/781]  eta: 0:05:11  lr: 0.000015  loss: 1.3437 (1.5486)  time: 0.4039  data: 0.0708  max mem: 6459\n",
            "Epoch: [97]  [ 20/781]  eta: 0:04:41  lr: 0.000015  loss: 1.2950 (1.4795)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 30/781]  eta: 0:04:28  lr: 0.000015  loss: 1.2950 (1.5148)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 40/781]  eta: 0:04:20  lr: 0.000015  loss: 1.3291 (1.5323)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 50/781]  eta: 0:04:14  lr: 0.000015  loss: 1.2999 (1.5061)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 60/781]  eta: 0:04:09  lr: 0.000015  loss: 1.2641 (1.5105)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 70/781]  eta: 0:04:04  lr: 0.000015  loss: 1.2834 (1.5276)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 80/781]  eta: 0:04:00  lr: 0.000015  loss: 1.3545 (1.5251)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 90/781]  eta: 0:03:55  lr: 0.000015  loss: 1.3375 (1.5156)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [100/781]  eta: 0:03:51  lr: 0.000015  loss: 1.3601 (1.5269)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [110/781]  eta: 0:03:47  lr: 0.000015  loss: 1.3601 (1.5331)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [120/781]  eta: 0:03:44  lr: 0.000015  loss: 1.3268 (1.5256)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [130/781]  eta: 0:03:40  lr: 0.000015  loss: 1.2990 (1.5313)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [140/781]  eta: 0:03:36  lr: 0.000015  loss: 1.3007 (1.5335)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [150/781]  eta: 0:03:33  lr: 0.000015  loss: 1.2714 (1.5254)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [160/781]  eta: 0:03:29  lr: 0.000015  loss: 1.2708 (1.5183)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [170/781]  eta: 0:03:26  lr: 0.000015  loss: 1.3058 (1.5167)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [180/781]  eta: 0:03:22  lr: 0.000015  loss: 1.3128 (1.5111)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [190/781]  eta: 0:03:19  lr: 0.000015  loss: 1.2953 (1.5028)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [200/781]  eta: 0:03:15  lr: 0.000015  loss: 1.2971 (1.5054)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [210/781]  eta: 0:03:12  lr: 0.000015  loss: 1.3259 (1.5024)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [220/781]  eta: 0:03:08  lr: 0.000015  loss: 1.2814 (1.4911)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [230/781]  eta: 0:03:05  lr: 0.000015  loss: 1.2720 (1.4856)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [240/781]  eta: 0:03:01  lr: 0.000015  loss: 1.2973 (1.4891)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [250/781]  eta: 0:02:58  lr: 0.000015  loss: 1.3131 (1.4917)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [260/781]  eta: 0:02:54  lr: 0.000015  loss: 1.3356 (1.4898)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [270/781]  eta: 0:02:51  lr: 0.000015  loss: 1.3227 (1.4914)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [280/781]  eta: 0:02:48  lr: 0.000015  loss: 1.2683 (1.4950)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [290/781]  eta: 0:02:44  lr: 0.000015  loss: 1.2879 (1.4963)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [300/781]  eta: 0:02:41  lr: 0.000015  loss: 1.3211 (1.4994)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [310/781]  eta: 0:02:37  lr: 0.000015  loss: 1.2771 (1.4998)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.2771 (1.4961)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [330/781]  eta: 0:02:31  lr: 0.000015  loss: 1.3554 (1.5061)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [340/781]  eta: 0:02:27  lr: 0.000015  loss: 1.3602 (1.5020)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [350/781]  eta: 0:02:24  lr: 0.000015  loss: 1.2987 (1.5021)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [360/781]  eta: 0:02:20  lr: 0.000015  loss: 1.2734 (1.5064)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [370/781]  eta: 0:02:17  lr: 0.000015  loss: 1.3212 (1.5111)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [380/781]  eta: 0:02:14  lr: 0.000015  loss: 1.3210 (1.5080)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [390/781]  eta: 0:02:10  lr: 0.000015  loss: 1.3096 (1.5050)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.3119 (1.5106)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [410/781]  eta: 0:02:04  lr: 0.000015  loss: 1.4261 (1.5142)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [420/781]  eta: 0:02:00  lr: 0.000015  loss: 1.3291 (1.5144)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.2747 (1.5088)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [440/781]  eta: 0:01:54  lr: 0.000015  loss: 1.2785 (1.5076)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [450/781]  eta: 0:01:50  lr: 0.000015  loss: 1.3459 (1.5077)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.2984 (1.5060)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [470/781]  eta: 0:01:43  lr: 0.000015  loss: 1.2308 (1.5057)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.3025 (1.5062)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.3375 (1.5071)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [500/781]  eta: 0:01:33  lr: 0.000015  loss: 1.3375 (1.5106)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.3613 (1.5126)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.3460 (1.5116)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [530/781]  eta: 0:01:23  lr: 0.000015  loss: 1.3460 (1.5122)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.3280 (1.5136)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [550/781]  eta: 0:01:17  lr: 0.000015  loss: 1.2417 (1.5094)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [560/781]  eta: 0:01:13  lr: 0.000015  loss: 1.2538 (1.5070)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.2762 (1.5036)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [580/781]  eta: 0:01:07  lr: 0.000015  loss: 1.2707 (1.5043)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.2759 (1.5029)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.3015 (1.5041)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [610/781]  eta: 0:00:57  lr: 0.000015  loss: 1.3063 (1.5031)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.3063 (1.5044)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.3213 (1.5039)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [640/781]  eta: 0:00:47  lr: 0.000015  loss: 1.3016 (1.5047)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.2640 (1.5023)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.2684 (1.5027)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [670/781]  eta: 0:00:37  lr: 0.000015  loss: 1.3155 (1.5027)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.3510 (1.5037)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.3215 (1.5024)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [700/781]  eta: 0:00:27  lr: 0.000015  loss: 1.2740 (1.5002)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.3327 (1.5019)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.3336 (1.5011)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [730/781]  eta: 0:00:17  lr: 0.000015  loss: 1.3135 (1.5019)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.2935 (1.5008)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.2918 (1.4998)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [760/781]  eta: 0:00:07  lr: 0.000015  loss: 1.2939 (1.5000)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.2839 (1.4977)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.2733 (1.5002)  time: 0.3326  data: 0.0005  max mem: 6459\n",
            "Epoch: [97] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.2733 (1.5002)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32454368472099304, 'lambda_convnext_base': 0.25503936409950256, 'lambda_tf_efficientnetv2_l': 0.4204168915748596}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8285 (0.8285)  acc1: 85.4167 (85.4167)  acc5: 94.2708 (94.2708)  time: 0.8424  data: 0.8116  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9328 (1.0006)  acc1: 83.8542 (81.6288)  acc5: 93.7500 (93.1818)  time: 0.1736  data: 0.1429  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1140 (1.0730)  acc1: 76.5625 (80.0843)  acc5: 92.7083 (92.2123)  time: 0.1293  data: 0.0987  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1729 (1.1228)  acc1: 76.0417 (79.0827)  acc5: 92.1875 (91.7843)  time: 0.1295  data: 0.0988  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2385 (1.1724)  acc1: 74.4792 (78.0996)  acc5: 90.1042 (91.4253)  time: 0.1324  data: 0.1018  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1327 (1.1640)  acc1: 76.5625 (78.0944)  acc5: 91.1458 (91.6667)  time: 0.1373  data: 0.1067  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1923 (1.1759)  acc1: 75.5208 (77.9800)  acc5: 91.6667 (91.6800)  time: 0.1163  data: 0.0866  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1383 s / it)\n",
            "* Acc@1 77.980 Acc@5 91.680 loss 1.176\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=98 distillation_alpha=0.6551\n",
            "Epoch: [98]  [  0/781]  eta: 0:14:21  lr: 0.000015  loss: 1.2810 (1.2810)  time: 1.1036  data: 0.7576  max mem: 6459\n",
            "Epoch: [98]  [ 10/781]  eta: 0:05:10  lr: 0.000015  loss: 1.3004 (1.4776)  time: 0.4032  data: 0.0691  max mem: 6459\n",
            "Epoch: [98]  [ 20/781]  eta: 0:04:41  lr: 0.000015  loss: 1.3004 (1.5142)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 30/781]  eta: 0:04:28  lr: 0.000015  loss: 1.2636 (1.5489)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 40/781]  eta: 0:04:20  lr: 0.000015  loss: 1.3050 (1.5603)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 50/781]  eta: 0:04:14  lr: 0.000015  loss: 1.2999 (1.5248)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 60/781]  eta: 0:04:08  lr: 0.000015  loss: 1.2999 (1.5182)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 70/781]  eta: 0:04:04  lr: 0.000015  loss: 1.3030 (1.4975)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 80/781]  eta: 0:03:59  lr: 0.000015  loss: 1.2745 (1.4876)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 90/781]  eta: 0:03:55  lr: 0.000015  loss: 1.2664 (1.4863)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [100/781]  eta: 0:03:51  lr: 0.000015  loss: 1.3331 (1.5029)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [110/781]  eta: 0:03:47  lr: 0.000015  loss: 1.3435 (1.5086)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [120/781]  eta: 0:03:44  lr: 0.000015  loss: 1.3040 (1.4987)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [130/781]  eta: 0:03:40  lr: 0.000015  loss: 1.3026 (1.4909)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [140/781]  eta: 0:03:36  lr: 0.000015  loss: 1.3075 (1.4939)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [150/781]  eta: 0:03:33  lr: 0.000015  loss: 1.3240 (1.4982)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [160/781]  eta: 0:03:29  lr: 0.000015  loss: 1.3240 (1.5095)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [170/781]  eta: 0:03:26  lr: 0.000015  loss: 1.2880 (1.5097)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [180/781]  eta: 0:03:22  lr: 0.000015  loss: 1.2880 (1.5186)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [190/781]  eta: 0:03:19  lr: 0.000015  loss: 1.3230 (1.5173)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [200/781]  eta: 0:03:15  lr: 0.000015  loss: 1.3008 (1.5140)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [210/781]  eta: 0:03:12  lr: 0.000015  loss: 1.2788 (1.5106)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [220/781]  eta: 0:03:08  lr: 0.000015  loss: 1.2712 (1.5039)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [230/781]  eta: 0:03:05  lr: 0.000015  loss: 1.2712 (1.4990)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [240/781]  eta: 0:03:01  lr: 0.000015  loss: 1.2867 (1.4953)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [250/781]  eta: 0:02:58  lr: 0.000015  loss: 1.3336 (1.5056)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [260/781]  eta: 0:02:55  lr: 0.000015  loss: 1.4708 (1.5093)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [270/781]  eta: 0:02:51  lr: 0.000015  loss: 1.3625 (1.5096)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [280/781]  eta: 0:02:48  lr: 0.000015  loss: 1.2996 (1.5058)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [290/781]  eta: 0:02:44  lr: 0.000015  loss: 1.2852 (1.5017)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [300/781]  eta: 0:02:41  lr: 0.000015  loss: 1.2831 (1.5003)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [310/781]  eta: 0:02:38  lr: 0.000015  loss: 1.2944 (1.5026)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.3143 (1.5037)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [330/781]  eta: 0:02:31  lr: 0.000015  loss: 1.3104 (1.4989)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [340/781]  eta: 0:02:27  lr: 0.000015  loss: 1.3178 (1.4982)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [350/781]  eta: 0:02:24  lr: 0.000015  loss: 1.3288 (1.4952)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [360/781]  eta: 0:02:21  lr: 0.000015  loss: 1.2854 (1.4932)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [370/781]  eta: 0:02:17  lr: 0.000015  loss: 1.2675 (1.4920)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [380/781]  eta: 0:02:14  lr: 0.000015  loss: 1.2931 (1.4926)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [390/781]  eta: 0:02:11  lr: 0.000015  loss: 1.2818 (1.4935)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.2588 (1.4933)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [410/781]  eta: 0:02:04  lr: 0.000015  loss: 1.2711 (1.4946)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [420/781]  eta: 0:02:00  lr: 0.000015  loss: 1.2711 (1.4963)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.2668 (1.5003)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [440/781]  eta: 0:01:54  lr: 0.000015  loss: 1.2790 (1.5015)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [450/781]  eta: 0:01:50  lr: 0.000015  loss: 1.2790 (1.4991)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.3158 (1.5000)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [470/781]  eta: 0:01:44  lr: 0.000015  loss: 1.3158 (1.4986)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.2833 (1.4960)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.2850 (1.4947)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [500/781]  eta: 0:01:34  lr: 0.000015  loss: 1.2953 (1.4970)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.2733 (1.4958)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.2854 (1.4969)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [530/781]  eta: 0:01:23  lr: 0.000015  loss: 1.3011 (1.4997)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.3032 (1.4988)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [550/781]  eta: 0:01:17  lr: 0.000015  loss: 1.2878 (1.4979)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [560/781]  eta: 0:01:13  lr: 0.000015  loss: 1.3210 (1.4989)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.2823 (1.4990)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [580/781]  eta: 0:01:07  lr: 0.000015  loss: 1.2674 (1.5000)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.3336 (1.5025)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.3155 (1.5030)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [610/781]  eta: 0:00:57  lr: 0.000015  loss: 1.2961 (1.5049)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.2477 (1.5012)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.2728 (1.5049)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [640/781]  eta: 0:00:47  lr: 0.000015  loss: 1.3714 (1.5086)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.3278 (1.5088)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.2976 (1.5087)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [670/781]  eta: 0:00:37  lr: 0.000015  loss: 1.3672 (1.5112)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.3672 (1.5117)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.2753 (1.5081)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [700/781]  eta: 0:00:27  lr: 0.000015  loss: 1.2462 (1.5079)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.2804 (1.5069)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.3123 (1.5095)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [730/781]  eta: 0:00:17  lr: 0.000015  loss: 1.4233 (1.5129)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.3133 (1.5129)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.3098 (1.5146)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [760/781]  eta: 0:00:07  lr: 0.000015  loss: 1.3206 (1.5136)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.2955 (1.5107)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.2852 (1.5106)  time: 0.3330  data: 0.0005  max mem: 6459\n",
            "Epoch: [98] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.2852 (1.5106)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3244627118110657, 'lambda_convnext_base': 0.2556796967983246, 'lambda_tf_efficientnetv2_l': 0.41985756158828735}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7934 (0.7934)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8456  data: 0.8148  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9106 (0.9817)  acc1: 83.8542 (81.4867)  acc5: 94.2708 (93.6553)  time: 0.1705  data: 0.1399  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0081 (1.0623)  acc1: 80.7292 (80.2579)  acc5: 93.2292 (92.5843)  time: 0.1163  data: 0.0856  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2159 (1.1197)  acc1: 76.5625 (79.2171)  acc5: 91.1458 (91.9019)  time: 0.1319  data: 0.1012  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2442 (1.1683)  acc1: 75.5208 (78.3664)  acc5: 90.1042 (91.4126)  time: 0.1239  data: 0.0932  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1675 (1.1669)  acc1: 76.0417 (78.0535)  acc5: 91.1458 (91.6258)  time: 0.1331  data: 0.1024  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2132 (1.1795)  acc1: 75.5208 (77.9200)  acc5: 91.6667 (91.6300)  time: 0.1321  data: 0.1024  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1374 s / it)\n",
            "* Acc@1 77.920 Acc@5 91.630 loss 1.179\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=99 distillation_alpha=0.6591\n",
            "Epoch: [99]  [  0/781]  eta: 0:14:20  lr: 0.000014  loss: 1.3311 (1.3311)  time: 1.1022  data: 0.7511  max mem: 6459\n",
            "Epoch: [99]  [ 10/781]  eta: 0:05:10  lr: 0.000014  loss: 1.2825 (1.4106)  time: 0.4032  data: 0.0686  max mem: 6459\n",
            "Epoch: [99]  [ 20/781]  eta: 0:04:41  lr: 0.000014  loss: 1.2825 (1.4032)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 30/781]  eta: 0:04:28  lr: 0.000014  loss: 1.2415 (1.3459)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 40/781]  eta: 0:04:20  lr: 0.000014  loss: 1.2555 (1.3812)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.3259 (1.3862)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 60/781]  eta: 0:04:09  lr: 0.000014  loss: 1.3259 (1.4192)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.3235 (1.4539)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 80/781]  eta: 0:04:00  lr: 0.000014  loss: 1.4009 (1.4814)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 90/781]  eta: 0:03:56  lr: 0.000014  loss: 1.3084 (1.4921)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [100/781]  eta: 0:03:52  lr: 0.000014  loss: 1.3084 (1.5029)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [110/781]  eta: 0:03:48  lr: 0.000014  loss: 1.2921 (1.4978)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [120/781]  eta: 0:03:44  lr: 0.000014  loss: 1.2380 (1.5051)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.3205 (1.5109)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [140/781]  eta: 0:03:36  lr: 0.000014  loss: 1.3243 (1.5057)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [150/781]  eta: 0:03:33  lr: 0.000014  loss: 1.3152 (1.5051)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [160/781]  eta: 0:03:29  lr: 0.000014  loss: 1.2830 (1.4988)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [170/781]  eta: 0:03:26  lr: 0.000014  loss: 1.2886 (1.4935)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2918 (1.4960)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [190/781]  eta: 0:03:19  lr: 0.000014  loss: 1.2781 (1.4854)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.3143 (1.4907)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [210/781]  eta: 0:03:12  lr: 0.000014  loss: 1.2775 (1.4845)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.2775 (1.4837)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [230/781]  eta: 0:03:05  lr: 0.000014  loss: 1.2956 (1.4765)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [240/781]  eta: 0:03:01  lr: 0.000014  loss: 1.2758 (1.4702)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.2295 (1.4649)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [260/781]  eta: 0:02:55  lr: 0.000014  loss: 1.2785 (1.4741)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.3418 (1.4712)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [280/781]  eta: 0:02:48  lr: 0.000014  loss: 1.2976 (1.4738)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.3424 (1.4783)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.3689 (1.4895)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [310/781]  eta: 0:02:38  lr: 0.000014  loss: 1.3200 (1.4836)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.2277 (1.4792)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [330/781]  eta: 0:02:31  lr: 0.000014  loss: 1.2445 (1.4783)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.2578 (1.4771)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.2937 (1.4840)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [360/781]  eta: 0:02:21  lr: 0.000014  loss: 1.3588 (1.4871)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.3129 (1.4889)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.3129 (1.4874)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [390/781]  eta: 0:02:11  lr: 0.000014  loss: 1.3109 (1.4891)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.3179 (1.4890)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [410/781]  eta: 0:02:04  lr: 0.000014  loss: 1.3263 (1.4868)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.3263 (1.4916)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.3609 (1.4959)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [440/781]  eta: 0:01:54  lr: 0.000014  loss: 1.3267 (1.4952)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.2943 (1.4927)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2697 (1.4903)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [470/781]  eta: 0:01:44  lr: 0.000014  loss: 1.2623 (1.4887)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.3117 (1.4905)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.3027 (1.4897)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [500/781]  eta: 0:01:34  lr: 0.000014  loss: 1.2972 (1.4890)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.3278 (1.4955)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.2977 (1.4939)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [530/781]  eta: 0:01:23  lr: 0.000014  loss: 1.2749 (1.4928)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.2552 (1.4900)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.2980 (1.4902)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [560/781]  eta: 0:01:13  lr: 0.000014  loss: 1.3434 (1.4911)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.3238 (1.4921)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2737 (1.4896)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2651 (1.4928)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.3104 (1.4915)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2920 (1.4908)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.2920 (1.4903)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.3315 (1.4919)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.2946 (1.4931)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.2876 (1.4941)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.3214 (1.4975)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.3214 (1.4949)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2818 (1.4977)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.3938 (1.4998)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.3265 (1.5008)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.3808 (1.5031)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.3167 (1.5011)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.2842 (1.4998)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.2737 (1.4982)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.3339 (1.4998)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [760/781]  eta: 0:00:07  lr: 0.000014  loss: 1.3458 (1.5005)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.4459 (1.5035)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.6611 (1.5064)  time: 0.3332  data: 0.0006  max mem: 6459\n",
            "Epoch: [99] Total time: 0:04:20 (0.3341 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.6611 (1.5064)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3245506286621094, 'lambda_convnext_base': 0.25622332096099854, 'lambda_tf_efficientnetv2_l': 0.41922610998153687}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8164 (0.8164)  acc1: 83.3333 (83.3333)  acc5: 94.2708 (94.2708)  time: 0.8329  data: 0.8020  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8738 (0.9722)  acc1: 83.3333 (81.7235)  acc5: 94.2708 (93.7027)  time: 0.1738  data: 0.1432  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0285 (1.0523)  acc1: 79.6875 (80.2827)  acc5: 92.7083 (92.8075)  time: 0.1262  data: 0.0956  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2403 (1.1163)  acc1: 76.0417 (79.0659)  acc5: 91.1458 (92.1035)  time: 0.1267  data: 0.0960  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2590 (1.1596)  acc1: 75.0000 (78.3537)  acc5: 90.1042 (91.7175)  time: 0.1279  data: 0.0972  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1482 (1.1589)  acc1: 77.0833 (78.1556)  acc5: 91.1458 (91.8301)  time: 0.1269  data: 0.0963  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1530 (1.1723)  acc1: 75.0000 (77.9800)  acc5: 91.6667 (91.8600)  time: 0.1067  data: 0.0771  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1335 s / it)\n",
            "* Acc@1 77.980 Acc@5 91.860 loss 1.172\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=100 distillation_alpha=0.6630\n",
            "Epoch: [100]  [  0/781]  eta: 0:14:42  lr: 0.000014  loss: 1.2749 (1.2749)  time: 1.1305  data: 0.7916  max mem: 6459\n",
            "Epoch: [100]  [ 10/781]  eta: 0:05:12  lr: 0.000014  loss: 1.3216 (1.6226)  time: 0.4053  data: 0.0722  max mem: 6459\n",
            "Epoch: [100]  [ 20/781]  eta: 0:04:42  lr: 0.000014  loss: 1.3068 (1.5423)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 30/781]  eta: 0:04:29  lr: 0.000014  loss: 1.3479 (1.5614)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 40/781]  eta: 0:04:21  lr: 0.000014  loss: 1.4057 (1.5747)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.3101 (1.5336)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 60/781]  eta: 0:04:09  lr: 0.000014  loss: 1.2787 (1.5329)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.3756 (1.5407)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 80/781]  eta: 0:04:00  lr: 0.000014  loss: 1.3756 (1.5438)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [ 90/781]  eta: 0:03:56  lr: 0.000014  loss: 1.3322 (1.5584)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [100/781]  eta: 0:03:52  lr: 0.000014  loss: 1.2983 (1.5357)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [110/781]  eta: 0:03:48  lr: 0.000014  loss: 1.2976 (1.5400)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [120/781]  eta: 0:03:44  lr: 0.000014  loss: 1.2901 (1.5310)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.3670 (1.5548)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [140/781]  eta: 0:03:37  lr: 0.000014  loss: 1.3670 (1.5511)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [150/781]  eta: 0:03:33  lr: 0.000014  loss: 1.2812 (1.5315)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [160/781]  eta: 0:03:30  lr: 0.000014  loss: 1.2553 (1.5298)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [170/781]  eta: 0:03:26  lr: 0.000014  loss: 1.2678 (1.5224)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2609 (1.5174)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [190/781]  eta: 0:03:19  lr: 0.000014  loss: 1.2769 (1.5232)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.3486 (1.5275)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [210/781]  eta: 0:03:12  lr: 0.000014  loss: 1.3247 (1.5239)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.2839 (1.5195)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [230/781]  eta: 0:03:05  lr: 0.000014  loss: 1.2994 (1.5224)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [240/781]  eta: 0:03:02  lr: 0.000014  loss: 1.2962 (1.5217)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.2715 (1.5196)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [260/781]  eta: 0:02:55  lr: 0.000014  loss: 1.2789 (1.5164)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.2633 (1.5080)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [280/781]  eta: 0:02:48  lr: 0.000014  loss: 1.2531 (1.5048)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.2516 (1.5012)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.2516 (1.4956)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [310/781]  eta: 0:02:38  lr: 0.000014  loss: 1.3007 (1.4954)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.3243 (1.4930)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [330/781]  eta: 0:02:31  lr: 0.000014  loss: 1.3181 (1.4919)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.3075 (1.4915)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.2760 (1.4899)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [360/781]  eta: 0:02:21  lr: 0.000014  loss: 1.2457 (1.4878)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.2696 (1.4897)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.3061 (1.4890)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [390/781]  eta: 0:02:11  lr: 0.000014  loss: 1.2927 (1.4885)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.3030 (1.4916)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [410/781]  eta: 0:02:04  lr: 0.000014  loss: 1.3353 (1.4931)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [420/781]  eta: 0:02:01  lr: 0.000014  loss: 1.3468 (1.4929)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.3468 (1.4910)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [440/781]  eta: 0:01:54  lr: 0.000014  loss: 1.3314 (1.4920)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [450/781]  eta: 0:01:51  lr: 0.000014  loss: 1.3158 (1.4909)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2547 (1.4878)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [470/781]  eta: 0:01:44  lr: 0.000014  loss: 1.2547 (1.4864)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2795 (1.4867)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.2963 (1.4857)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [500/781]  eta: 0:01:34  lr: 0.000014  loss: 1.2739 (1.4825)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.2625 (1.4812)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.2916 (1.4816)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [530/781]  eta: 0:01:24  lr: 0.000014  loss: 1.3122 (1.4832)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.3252 (1.4871)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.3403 (1.4853)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [560/781]  eta: 0:01:14  lr: 0.000014  loss: 1.3167 (1.4860)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.2811 (1.4846)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2863 (1.4872)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.3047 (1.4869)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.3225 (1.4902)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2668 (1.4885)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.2559 (1.4865)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.2800 (1.4865)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.3241 (1.4872)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.3241 (1.4863)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.3139 (1.4857)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.2485 (1.4856)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2558 (1.4865)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.2822 (1.4840)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.3198 (1.4866)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.3380 (1.4863)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.3095 (1.4851)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.3320 (1.4866)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.3132 (1.4869)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.2349 (1.4857)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [760/781]  eta: 0:00:07  lr: 0.000014  loss: 1.2862 (1.4863)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.5048 (1.4908)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [100]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.2970 (1.4896)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [100] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.2970 (1.4896)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3244496285915375, 'lambda_convnext_base': 0.25504595041275024, 'lambda_tf_efficientnetv2_l': 0.42050406336784363}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.9047 (0.9047)  acc1: 82.2917 (82.2917)  acc5: 94.2708 (94.2708)  time: 0.8480  data: 0.8172  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9621 (1.0216)  acc1: 82.2917 (80.6818)  acc5: 93.2292 (92.9924)  time: 0.1692  data: 0.1385  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0333 (1.0767)  acc1: 80.2083 (79.8363)  acc5: 92.7083 (92.4355)  time: 0.1203  data: 0.0896  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2167 (1.1329)  acc1: 75.0000 (78.8138)  acc5: 91.6667 (91.7843)  time: 0.1222  data: 0.0915  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2694 (1.1800)  acc1: 75.0000 (77.9853)  acc5: 90.1042 (91.3110)  time: 0.1224  data: 0.0917  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1539 (1.1763)  acc1: 77.0833 (77.8697)  acc5: 90.1042 (91.4011)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1882 (1.1850)  acc1: 74.4792 (77.7300)  acc5: 92.1875 (91.4200)  time: 0.1041  data: 0.0744  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1293 s / it)\n",
            "* Acc@1 77.730 Acc@5 91.420 loss 1.185\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 78.10%\n",
            "[alpha-schedule=cosine] epoch=101 distillation_alpha=0.6668\n",
            "Epoch: [101]  [  0/781]  eta: 0:14:39  lr: 0.000014  loss: 1.1837 (1.1837)  time: 1.1265  data: 0.7723  max mem: 6459\n",
            "Epoch: [101]  [ 10/781]  eta: 0:05:12  lr: 0.000014  loss: 1.2466 (1.5668)  time: 0.4054  data: 0.0705  max mem: 6459\n",
            "Epoch: [101]  [ 20/781]  eta: 0:04:42  lr: 0.000014  loss: 1.2625 (1.5142)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 30/781]  eta: 0:04:29  lr: 0.000014  loss: 1.2496 (1.4675)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 40/781]  eta: 0:04:21  lr: 0.000014  loss: 1.2734 (1.4770)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.3367 (1.5076)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 60/781]  eta: 0:04:09  lr: 0.000014  loss: 1.3108 (1.4850)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.3035 (1.4877)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 80/781]  eta: 0:04:00  lr: 0.000014  loss: 1.3034 (1.4982)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [ 90/781]  eta: 0:03:56  lr: 0.000014  loss: 1.2886 (1.4919)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [100/781]  eta: 0:03:52  lr: 0.000014  loss: 1.2886 (1.4917)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [110/781]  eta: 0:03:48  lr: 0.000014  loss: 1.2886 (1.4899)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [120/781]  eta: 0:03:44  lr: 0.000014  loss: 1.2699 (1.4988)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.2799 (1.4884)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [140/781]  eta: 0:03:37  lr: 0.000014  loss: 1.2799 (1.4814)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [150/781]  eta: 0:03:33  lr: 0.000014  loss: 1.3069 (1.4968)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [160/781]  eta: 0:03:29  lr: 0.000014  loss: 1.2947 (1.4910)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [170/781]  eta: 0:03:26  lr: 0.000014  loss: 1.3067 (1.4963)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2671 (1.4865)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [190/781]  eta: 0:03:19  lr: 0.000014  loss: 1.2686 (1.4902)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.2870 (1.4848)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [210/781]  eta: 0:03:12  lr: 0.000014  loss: 1.2566 (1.4862)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.2987 (1.4877)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [230/781]  eta: 0:03:05  lr: 0.000014  loss: 1.3660 (1.4926)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [240/781]  eta: 0:03:01  lr: 0.000014  loss: 1.2746 (1.4908)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.2959 (1.4898)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [260/781]  eta: 0:02:55  lr: 0.000014  loss: 1.3002 (1.4909)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.3002 (1.4944)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [280/781]  eta: 0:02:48  lr: 0.000014  loss: 1.3231 (1.4927)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.3231 (1.4962)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.3169 (1.5024)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [310/781]  eta: 0:02:38  lr: 0.000014  loss: 1.6407 (1.5074)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.2779 (1.5085)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [330/781]  eta: 0:02:31  lr: 0.000014  loss: 1.2779 (1.5071)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.2853 (1.5059)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.2819 (1.5071)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [360/781]  eta: 0:02:21  lr: 0.000014  loss: 1.2743 (1.5051)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.2588 (1.5052)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.2765 (1.5011)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [390/781]  eta: 0:02:10  lr: 0.000014  loss: 1.3060 (1.4978)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.3338 (1.5054)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [410/781]  eta: 0:02:04  lr: 0.000014  loss: 1.7289 (1.5100)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.2736 (1.5077)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.2508 (1.5058)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [440/781]  eta: 0:01:54  lr: 0.000014  loss: 1.3347 (1.5111)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.2776 (1.5062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2746 (1.5065)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [470/781]  eta: 0:01:44  lr: 0.000014  loss: 1.2537 (1.5029)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2537 (1.5038)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.2810 (1.5022)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [500/781]  eta: 0:01:34  lr: 0.000014  loss: 1.2810 (1.5015)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.2636 (1.4992)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.2581 (1.4967)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [530/781]  eta: 0:01:23  lr: 0.000014  loss: 1.2581 (1.4975)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.2883 (1.4963)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.3153 (1.4967)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [560/781]  eta: 0:01:13  lr: 0.000014  loss: 1.3153 (1.4986)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.3046 (1.5006)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2683 (1.4985)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2478 (1.4955)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.2810 (1.4935)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2924 (1.4940)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.2959 (1.4921)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.2864 (1.4903)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.3098 (1.4950)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.3138 (1.4920)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.2477 (1.4905)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.2739 (1.4913)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2908 (1.4887)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.3020 (1.4895)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.3417 (1.4890)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.3304 (1.4876)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.3304 (1.4895)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.6170 (1.4912)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.3461 (1.4907)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.2303 (1.4897)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [760/781]  eta: 0:00:07  lr: 0.000014  loss: 1.2362 (1.4904)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.2527 (1.4870)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [101]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.2692 (1.4875)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [101] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.2692 (1.4875)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32424038648605347, 'lambda_convnext_base': 0.2554173171520233, 'lambda_tf_efficientnetv2_l': 0.42034199833869934}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8131 (0.8131)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8481  data: 0.8173  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8551 (0.9932)  acc1: 83.3333 (81.7708)  acc5: 94.7917 (93.1345)  time: 0.1750  data: 0.1443  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.1307 (1.0657)  acc1: 78.1250 (80.7044)  acc5: 92.7083 (92.2867)  time: 0.1259  data: 0.0952  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2030 (1.1276)  acc1: 76.0417 (79.3011)  acc5: 90.6250 (91.7507)  time: 0.1283  data: 0.0976  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3162 (1.1737)  acc1: 74.4792 (78.3664)  acc5: 89.5833 (91.2856)  time: 0.1276  data: 0.0969  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1669 (1.1700)  acc1: 76.0417 (78.2373)  acc5: 91.6667 (91.5441)  time: 0.1286  data: 0.0979  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1838 (1.1855)  acc1: 75.0000 (78.1200)  acc5: 91.1458 (91.5200)  time: 0.1101  data: 0.0804  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1350 s / it)\n",
            "* Acc@1 78.120 Acc@5 91.520 loss 1.186\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.12%\n",
            "[alpha-schedule=cosine] epoch=102 distillation_alpha=0.6703\n",
            "Epoch: [102]  [  0/781]  eta: 0:14:44  lr: 0.000013  loss: 1.3155 (1.3155)  time: 1.1325  data: 0.7853  max mem: 6459\n",
            "Epoch: [102]  [ 10/781]  eta: 0:05:12  lr: 0.000013  loss: 1.4876 (1.7541)  time: 0.4059  data: 0.0717  max mem: 6459\n",
            "Epoch: [102]  [ 20/781]  eta: 0:04:42  lr: 0.000013  loss: 1.3098 (1.6254)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 30/781]  eta: 0:04:29  lr: 0.000013  loss: 1.3076 (1.5980)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 40/781]  eta: 0:04:21  lr: 0.000013  loss: 1.3254 (1.5817)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 50/781]  eta: 0:04:15  lr: 0.000013  loss: 1.3528 (1.6039)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 60/781]  eta: 0:04:09  lr: 0.000013  loss: 1.3120 (1.5781)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 70/781]  eta: 0:04:05  lr: 0.000013  loss: 1.3120 (1.5734)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 80/781]  eta: 0:04:00  lr: 0.000013  loss: 1.3598 (1.5857)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [ 90/781]  eta: 0:03:56  lr: 0.000013  loss: 1.3190 (1.5637)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [100/781]  eta: 0:03:52  lr: 0.000013  loss: 1.3190 (1.5630)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [110/781]  eta: 0:03:48  lr: 0.000013  loss: 1.3062 (1.5430)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [120/781]  eta: 0:03:44  lr: 0.000013  loss: 1.3057 (1.5441)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.3882 (1.5472)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [140/781]  eta: 0:03:37  lr: 0.000013  loss: 1.3741 (1.5504)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [150/781]  eta: 0:03:33  lr: 0.000013  loss: 1.2636 (1.5433)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [160/781]  eta: 0:03:30  lr: 0.000013  loss: 1.3057 (1.5479)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [170/781]  eta: 0:03:26  lr: 0.000013  loss: 1.3273 (1.5396)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [180/781]  eta: 0:03:23  lr: 0.000013  loss: 1.2547 (1.5380)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [190/781]  eta: 0:03:19  lr: 0.000013  loss: 1.2489 (1.5306)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [200/781]  eta: 0:03:16  lr: 0.000013  loss: 1.2678 (1.5244)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [210/781]  eta: 0:03:12  lr: 0.000013  loss: 1.2919 (1.5193)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [220/781]  eta: 0:03:09  lr: 0.000013  loss: 1.2928 (1.5168)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [230/781]  eta: 0:03:05  lr: 0.000013  loss: 1.2600 (1.5092)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [240/781]  eta: 0:03:02  lr: 0.000013  loss: 1.2743 (1.5118)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [250/781]  eta: 0:02:58  lr: 0.000013  loss: 1.2715 (1.5080)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [260/781]  eta: 0:02:55  lr: 0.000013  loss: 1.2833 (1.5020)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.2833 (1.5042)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [280/781]  eta: 0:02:48  lr: 0.000013  loss: 1.2547 (1.4989)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.2663 (1.5026)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [300/781]  eta: 0:02:41  lr: 0.000013  loss: 1.2751 (1.4978)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [310/781]  eta: 0:02:38  lr: 0.000013  loss: 1.2644 (1.4944)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.2460 (1.4925)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [330/781]  eta: 0:02:31  lr: 0.000013  loss: 1.2518 (1.4916)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [340/781]  eta: 0:02:27  lr: 0.000013  loss: 1.2588 (1.4870)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [350/781]  eta: 0:02:24  lr: 0.000013  loss: 1.2653 (1.4872)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [360/781]  eta: 0:02:21  lr: 0.000013  loss: 1.2732 (1.4893)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.2732 (1.4896)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [380/781]  eta: 0:02:14  lr: 0.000013  loss: 1.2636 (1.4889)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [390/781]  eta: 0:02:11  lr: 0.000013  loss: 1.3522 (1.4933)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.3145 (1.4914)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [410/781]  eta: 0:02:04  lr: 0.000013  loss: 1.2461 (1.4890)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [420/781]  eta: 0:02:00  lr: 0.000013  loss: 1.2793 (1.4902)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.3084 (1.4881)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [440/781]  eta: 0:01:54  lr: 0.000013  loss: 1.2819 (1.4863)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.2683 (1.4871)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.2651 (1.4860)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [470/781]  eta: 0:01:44  lr: 0.000013  loss: 1.2517 (1.4834)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2449 (1.4807)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.2497 (1.4801)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [500/781]  eta: 0:01:34  lr: 0.000013  loss: 1.2716 (1.4770)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2726 (1.4765)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.3047 (1.4792)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [530/781]  eta: 0:01:23  lr: 0.000013  loss: 1.3040 (1.4780)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.3261 (1.4840)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.3372 (1.4841)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.2653 (1.4841)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.2805 (1.4877)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2673 (1.4886)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.4116 (1.4942)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.4082 (1.4963)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.3644 (1.4967)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.2670 (1.4963)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2670 (1.4956)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.2684 (1.4930)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2568 (1.4898)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2233 (1.4883)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [670/781]  eta: 0:00:37  lr: 0.000013  loss: 1.2988 (1.4933)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.3266 (1.4911)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.2684 (1.4920)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [700/781]  eta: 0:00:27  lr: 0.000013  loss: 1.4154 (1.4943)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.3064 (1.4940)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.3002 (1.4935)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [730/781]  eta: 0:00:17  lr: 0.000013  loss: 1.3100 (1.4942)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.2923 (1.4963)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.3057 (1.4948)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [760/781]  eta: 0:00:07  lr: 0.000013  loss: 1.3057 (1.4953)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.3080 (1.4956)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [102]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2994 (1.4944)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [102] Total time: 0:04:21 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2994 (1.4944)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32399648427963257, 'lambda_convnext_base': 0.2558141350746155, 'lambda_tf_efficientnetv2_l': 0.4201897382736206}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8046 (0.8046)  acc1: 82.2917 (82.2917)  acc5: 95.8333 (95.8333)  time: 0.8295  data: 0.7986  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8791 (0.9823)  acc1: 82.2917 (82.0076)  acc5: 94.7917 (93.2765)  time: 0.1687  data: 0.1381  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0786 (1.0597)  acc1: 78.1250 (80.4315)  acc5: 93.2292 (92.5595)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1913 (1.1173)  acc1: 75.5208 (79.2843)  acc5: 91.1458 (91.8515)  time: 0.1291  data: 0.0984  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2437 (1.1687)  acc1: 75.5208 (78.4807)  acc5: 89.5833 (91.3872)  time: 0.1322  data: 0.1015  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1664 (1.1686)  acc1: 76.0417 (78.2271)  acc5: 90.6250 (91.5033)  time: 0.1324  data: 0.1017  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1949 (1.1767)  acc1: 76.0417 (78.1000)  acc5: 90.6250 (91.5200)  time: 0.1115  data: 0.0818  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1354 s / it)\n",
            "* Acc@1 78.100 Acc@5 91.520 loss 1.177\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.12%\n",
            "[alpha-schedule=cosine] epoch=103 distillation_alpha=0.6736\n",
            "Epoch: [103]  [  0/781]  eta: 0:14:20  lr: 0.000013  loss: 1.2508 (1.2508)  time: 1.1018  data: 0.7531  max mem: 6459\n",
            "Epoch: [103]  [ 10/781]  eta: 0:05:10  lr: 0.000013  loss: 1.2658 (1.3848)  time: 0.4029  data: 0.0687  max mem: 6459\n",
            "Epoch: [103]  [ 20/781]  eta: 0:04:41  lr: 0.000013  loss: 1.3059 (1.4834)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 30/781]  eta: 0:04:28  lr: 0.000013  loss: 1.3460 (1.5325)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 40/781]  eta: 0:04:20  lr: 0.000013  loss: 1.2610 (1.4775)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 50/781]  eta: 0:04:14  lr: 0.000013  loss: 1.2521 (1.4700)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 60/781]  eta: 0:04:09  lr: 0.000013  loss: 1.2904 (1.4860)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 70/781]  eta: 0:04:04  lr: 0.000013  loss: 1.3096 (1.4806)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 80/781]  eta: 0:04:00  lr: 0.000013  loss: 1.2948 (1.4777)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [ 90/781]  eta: 0:03:55  lr: 0.000013  loss: 1.2948 (1.4686)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [100/781]  eta: 0:03:52  lr: 0.000013  loss: 1.2905 (1.4735)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [110/781]  eta: 0:03:48  lr: 0.000013  loss: 1.2905 (1.4813)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [120/781]  eta: 0:03:44  lr: 0.000013  loss: 1.3160 (1.4876)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.3227 (1.4910)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [140/781]  eta: 0:03:36  lr: 0.000013  loss: 1.3243 (1.4912)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [150/781]  eta: 0:03:34  lr: 0.000013  loss: 1.2868 (1.4893)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [160/781]  eta: 0:03:30  lr: 0.000013  loss: 1.2793 (1.4859)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [170/781]  eta: 0:03:26  lr: 0.000013  loss: 1.2797 (1.4920)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [180/781]  eta: 0:03:23  lr: 0.000013  loss: 1.2797 (1.4798)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [190/781]  eta: 0:03:19  lr: 0.000013  loss: 1.2670 (1.4761)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [200/781]  eta: 0:03:16  lr: 0.000013  loss: 1.2914 (1.4845)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [210/781]  eta: 0:03:12  lr: 0.000013  loss: 1.3207 (1.4851)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [220/781]  eta: 0:03:09  lr: 0.000013  loss: 1.3353 (1.4841)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [230/781]  eta: 0:03:05  lr: 0.000013  loss: 1.2978 (1.4814)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [240/781]  eta: 0:03:02  lr: 0.000013  loss: 1.2956 (1.4933)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [250/781]  eta: 0:02:58  lr: 0.000013  loss: 1.2623 (1.4864)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [260/781]  eta: 0:02:55  lr: 0.000013  loss: 1.2449 (1.4864)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.2772 (1.4832)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [280/781]  eta: 0:02:48  lr: 0.000013  loss: 1.2817 (1.4808)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [290/781]  eta: 0:02:45  lr: 0.000013  loss: 1.2461 (1.4742)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [300/781]  eta: 0:02:41  lr: 0.000013  loss: 1.2483 (1.4691)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [310/781]  eta: 0:02:38  lr: 0.000013  loss: 1.2977 (1.4721)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.2548 (1.4690)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [330/781]  eta: 0:02:31  lr: 0.000013  loss: 1.2389 (1.4700)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [340/781]  eta: 0:02:28  lr: 0.000013  loss: 1.2785 (1.4693)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [350/781]  eta: 0:02:24  lr: 0.000013  loss: 1.2825 (1.4667)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [360/781]  eta: 0:02:21  lr: 0.000013  loss: 1.2383 (1.4648)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.2658 (1.4655)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [380/781]  eta: 0:02:14  lr: 0.000013  loss: 1.3008 (1.4664)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [390/781]  eta: 0:02:11  lr: 0.000013  loss: 1.3376 (1.4704)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2678 (1.4729)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [410/781]  eta: 0:02:04  lr: 0.000013  loss: 1.2678 (1.4700)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [420/781]  eta: 0:02:01  lr: 0.000013  loss: 1.2728 (1.4700)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2753 (1.4689)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [440/781]  eta: 0:01:54  lr: 0.000013  loss: 1.2686 (1.4664)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.2673 (1.4660)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.3460 (1.4673)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [470/781]  eta: 0:01:44  lr: 0.000013  loss: 1.3098 (1.4684)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2893 (1.4672)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.2942 (1.4688)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [500/781]  eta: 0:01:34  lr: 0.000013  loss: 1.2962 (1.4707)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.3254 (1.4734)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.2693 (1.4716)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [530/781]  eta: 0:01:24  lr: 0.000013  loss: 1.2481 (1.4685)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.2535 (1.4670)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.2953 (1.4678)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.4689 (1.4741)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.4005 (1.4756)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2585 (1.4769)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.2659 (1.4775)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.3548 (1.4774)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.3520 (1.4765)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.2794 (1.4768)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2888 (1.4780)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.2992 (1.4760)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2992 (1.4777)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.3008 (1.4786)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [670/781]  eta: 0:00:37  lr: 0.000013  loss: 1.2721 (1.4794)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.2904 (1.4790)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.2904 (1.4781)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [700/781]  eta: 0:00:27  lr: 0.000013  loss: 1.2981 (1.4783)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.3334 (1.4786)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.3730 (1.4817)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [730/781]  eta: 0:00:17  lr: 0.000013  loss: 1.4655 (1.4827)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.3349 (1.4833)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.3146 (1.4826)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [760/781]  eta: 0:00:07  lr: 0.000013  loss: 1.2987 (1.4808)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.2795 (1.4783)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [103]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2795 (1.4778)  time: 0.3329  data: 0.0006  max mem: 6459\n",
            "Epoch: [103] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2795 (1.4778)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3238864243030548, 'lambda_convnext_base': 0.25570765137672424, 'lambda_tf_efficientnetv2_l': 0.42040616273880005}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8048 (0.8048)  acc1: 82.2917 (82.2917)  acc5: 95.3125 (95.3125)  time: 0.8451  data: 0.8141  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8762 (0.9782)  acc1: 82.8125 (82.0549)  acc5: 95.3125 (93.7974)  time: 0.1651  data: 0.1344  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0664 (1.0614)  acc1: 79.1667 (80.5060)  acc5: 92.7083 (92.5595)  time: 0.1237  data: 0.0930  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2238 (1.1239)  acc1: 76.0417 (79.0323)  acc5: 91.6667 (91.9355)  time: 0.1292  data: 0.0985  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3033 (1.1695)  acc1: 72.9167 (78.3537)  acc5: 89.0625 (91.4380)  time: 0.1288  data: 0.0981  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1989 (1.1703)  acc1: 76.0417 (78.1863)  acc5: 91.1458 (91.5543)  time: 0.1285  data: 0.0978  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2123 (1.1783)  acc1: 75.0000 (78.0800)  acc5: 91.6667 (91.5700)  time: 0.1071  data: 0.0774  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1331 s / it)\n",
            "* Acc@1 78.080 Acc@5 91.570 loss 1.178\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.12%\n",
            "[alpha-schedule=cosine] epoch=104 distillation_alpha=0.6768\n",
            "Epoch: [104]  [  0/781]  eta: 0:14:53  lr: 0.000013  loss: 1.2072 (1.2072)  time: 1.1446  data: 0.8060  max mem: 6459\n",
            "Epoch: [104]  [ 10/781]  eta: 0:05:13  lr: 0.000013  loss: 1.2335 (1.4479)  time: 0.4068  data: 0.0735  max mem: 6459\n",
            "Epoch: [104]  [ 20/781]  eta: 0:04:42  lr: 0.000013  loss: 1.2453 (1.4534)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 30/781]  eta: 0:04:29  lr: 0.000013  loss: 1.2768 (1.5191)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 40/781]  eta: 0:04:21  lr: 0.000013  loss: 1.3400 (1.5313)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 50/781]  eta: 0:04:14  lr: 0.000013  loss: 1.2567 (1.5043)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 60/781]  eta: 0:04:09  lr: 0.000013  loss: 1.2445 (1.4861)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 70/781]  eta: 0:04:04  lr: 0.000013  loss: 1.2818 (1.4632)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 80/781]  eta: 0:04:00  lr: 0.000013  loss: 1.2983 (1.4718)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [ 90/781]  eta: 0:03:56  lr: 0.000013  loss: 1.3428 (1.4927)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [100/781]  eta: 0:03:52  lr: 0.000013  loss: 1.5536 (1.5082)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [110/781]  eta: 0:03:48  lr: 0.000013  loss: 1.2962 (1.4925)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [120/781]  eta: 0:03:44  lr: 0.000013  loss: 1.2936 (1.4939)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.3373 (1.4879)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [140/781]  eta: 0:03:37  lr: 0.000013  loss: 1.3373 (1.4954)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [150/781]  eta: 0:03:33  lr: 0.000013  loss: 1.3129 (1.4988)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [160/781]  eta: 0:03:29  lr: 0.000013  loss: 1.2876 (1.4927)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [170/781]  eta: 0:03:26  lr: 0.000013  loss: 1.2597 (1.4796)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [180/781]  eta: 0:03:22  lr: 0.000013  loss: 1.2382 (1.4726)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [190/781]  eta: 0:03:19  lr: 0.000013  loss: 1.2848 (1.4854)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [200/781]  eta: 0:03:15  lr: 0.000013  loss: 1.4892 (1.4915)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [210/781]  eta: 0:03:12  lr: 0.000013  loss: 1.3156 (1.4933)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [220/781]  eta: 0:03:08  lr: 0.000013  loss: 1.2760 (1.4924)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [230/781]  eta: 0:03:05  lr: 0.000013  loss: 1.3164 (1.4954)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [240/781]  eta: 0:03:01  lr: 0.000013  loss: 1.3237 (1.4920)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [250/781]  eta: 0:02:58  lr: 0.000013  loss: 1.2887 (1.4887)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [260/781]  eta: 0:02:55  lr: 0.000013  loss: 1.2887 (1.4924)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.2671 (1.4858)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [280/781]  eta: 0:02:48  lr: 0.000013  loss: 1.2916 (1.4979)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.3722 (1.4967)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [300/781]  eta: 0:02:41  lr: 0.000013  loss: 1.3013 (1.4978)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [310/781]  eta: 0:02:38  lr: 0.000013  loss: 1.2806 (1.4981)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.2708 (1.4941)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [330/781]  eta: 0:02:31  lr: 0.000013  loss: 1.2370 (1.4922)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [340/781]  eta: 0:02:27  lr: 0.000013  loss: 1.2475 (1.4862)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [350/781]  eta: 0:02:24  lr: 0.000013  loss: 1.2937 (1.4917)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [360/781]  eta: 0:02:21  lr: 0.000013  loss: 1.4586 (1.4971)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.3256 (1.4971)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [380/781]  eta: 0:02:14  lr: 0.000013  loss: 1.2582 (1.4964)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [390/781]  eta: 0:02:11  lr: 0.000013  loss: 1.2430 (1.4944)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2430 (1.4907)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [410/781]  eta: 0:02:04  lr: 0.000013  loss: 1.2952 (1.4979)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [420/781]  eta: 0:02:00  lr: 0.000013  loss: 1.3704 (1.4944)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2697 (1.4945)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [440/781]  eta: 0:01:54  lr: 0.000013  loss: 1.2819 (1.4932)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.2605 (1.4899)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.2996 (1.4880)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [470/781]  eta: 0:01:44  lr: 0.000013  loss: 1.3104 (1.4865)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.3127 (1.4858)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.2698 (1.4832)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [500/781]  eta: 0:01:34  lr: 0.000013  loss: 1.2605 (1.4821)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2810 (1.4837)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.2772 (1.4818)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [530/781]  eta: 0:01:24  lr: 0.000013  loss: 1.2600 (1.4816)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.2896 (1.4831)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.2665 (1.4830)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.2883 (1.4859)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.2854 (1.4838)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2358 (1.4839)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.2688 (1.4861)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.2785 (1.4851)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.3198 (1.4843)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.2638 (1.4817)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2659 (1.4827)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.3143 (1.4855)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.3067 (1.4860)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.3067 (1.4864)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [670/781]  eta: 0:00:37  lr: 0.000013  loss: 1.3131 (1.4866)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.3345 (1.4889)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.3241 (1.4890)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [700/781]  eta: 0:00:27  lr: 0.000013  loss: 1.2703 (1.4878)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.2723 (1.4891)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.2723 (1.4896)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [730/781]  eta: 0:00:17  lr: 0.000013  loss: 1.2727 (1.4920)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.3017 (1.4929)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.3313 (1.4919)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [760/781]  eta: 0:00:07  lr: 0.000013  loss: 1.3006 (1.4934)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.2989 (1.4926)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [104]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2774 (1.4915)  time: 0.3333  data: 0.0006  max mem: 6459\n",
            "Epoch: [104] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2774 (1.4915)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32465261220932007, 'lambda_convnext_base': 0.2551058232784271, 'lambda_tf_efficientnetv2_l': 0.4202418327331543}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8119 (0.8119)  acc1: 82.2917 (82.2917)  acc5: 95.3125 (95.3125)  time: 0.8570  data: 0.8260  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9018 (0.9875)  acc1: 83.3333 (81.8182)  acc5: 94.2708 (93.2765)  time: 0.1722  data: 0.1415  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0987 (1.0600)  acc1: 78.6458 (80.6548)  acc5: 91.6667 (92.2867)  time: 0.1217  data: 0.0910  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2277 (1.1292)  acc1: 76.0417 (79.1667)  acc5: 90.6250 (91.6667)  time: 0.1221  data: 0.0914  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2951 (1.1793)  acc1: 74.4792 (78.3410)  acc5: 89.5833 (91.2475)  time: 0.1208  data: 0.0901  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1413 (1.1699)  acc1: 77.6042 (78.2271)  acc5: 92.1875 (91.4828)  time: 0.1219  data: 0.0912  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1571 (1.1858)  acc1: 76.5625 (78.0200)  acc5: 92.1875 (91.4900)  time: 0.1027  data: 0.0730  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1295 s / it)\n",
            "* Acc@1 78.020 Acc@5 91.490 loss 1.186\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.12%\n",
            "[alpha-schedule=cosine] epoch=105 distillation_alpha=0.6797\n",
            "Epoch: [105]  [  0/781]  eta: 0:14:41  lr: 0.000012  loss: 1.8940 (1.8940)  time: 1.1282  data: 0.7879  max mem: 6459\n",
            "Epoch: [105]  [ 10/781]  eta: 0:05:12  lr: 0.000012  loss: 1.2610 (1.4139)  time: 0.4053  data: 0.0719  max mem: 6459\n",
            "Epoch: [105]  [ 20/781]  eta: 0:04:42  lr: 0.000012  loss: 1.2892 (1.4502)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 30/781]  eta: 0:04:29  lr: 0.000012  loss: 1.3126 (1.4233)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 40/781]  eta: 0:04:21  lr: 0.000012  loss: 1.2668 (1.4243)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2561 (1.4005)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2617 (1.3945)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.2771 (1.4071)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 80/781]  eta: 0:04:00  lr: 0.000012  loss: 1.2775 (1.4133)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [ 90/781]  eta: 0:03:56  lr: 0.000012  loss: 1.2775 (1.4139)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [100/781]  eta: 0:03:52  lr: 0.000012  loss: 1.2736 (1.4202)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [110/781]  eta: 0:03:48  lr: 0.000012  loss: 1.2735 (1.4330)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [120/781]  eta: 0:03:44  lr: 0.000012  loss: 1.2833 (1.4391)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.3489 (1.4582)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [140/781]  eta: 0:03:36  lr: 0.000012  loss: 1.8235 (1.4811)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [150/781]  eta: 0:03:33  lr: 0.000012  loss: 1.3393 (1.4765)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [160/781]  eta: 0:03:29  lr: 0.000012  loss: 1.2566 (1.4663)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [170/781]  eta: 0:03:26  lr: 0.000012  loss: 1.2669 (1.4640)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2577 (1.4522)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.2526 (1.4499)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.2659 (1.4438)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.2763 (1.4530)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.2763 (1.4472)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.2718 (1.4556)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [240/781]  eta: 0:03:01  lr: 0.000012  loss: 1.2718 (1.4505)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.3073 (1.4496)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [260/781]  eta: 0:02:54  lr: 0.000012  loss: 1.2782 (1.4448)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2402 (1.4456)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2169 (1.4382)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2169 (1.4465)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2494 (1.4454)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [310/781]  eta: 0:02:37  lr: 0.000012  loss: 1.2494 (1.4482)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.2589 (1.4468)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.2632 (1.4463)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.2612 (1.4417)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2418 (1.4508)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.7808 (1.4581)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.3578 (1.4543)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.3025 (1.4521)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [390/781]  eta: 0:02:10  lr: 0.000012  loss: 1.3020 (1.4525)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2814 (1.4522)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.2814 (1.4544)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2917 (1.4574)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2840 (1.4583)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.3422 (1.4577)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.3629 (1.4638)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.2719 (1.4593)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.2752 (1.4566)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.3165 (1.4616)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.3387 (1.4601)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [500/781]  eta: 0:01:33  lr: 0.000012  loss: 1.2647 (1.4601)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2559 (1.4597)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.2487 (1.4615)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [530/781]  eta: 0:01:23  lr: 0.000012  loss: 1.2968 (1.4647)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.3456 (1.4663)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.3456 (1.4673)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.3183 (1.4683)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2994 (1.4672)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2576 (1.4684)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2480 (1.4660)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2375 (1.4652)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.3451 (1.4686)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.3582 (1.4679)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2558 (1.4658)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.2580 (1.4626)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2703 (1.4638)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2995 (1.4669)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.2708 (1.4675)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2251 (1.4673)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.3962 (1.4709)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.3656 (1.4710)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2717 (1.4702)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2578 (1.4692)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.3132 (1.4700)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.3208 (1.4698)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.2760 (1.4695)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [760/781]  eta: 0:00:07  lr: 0.000012  loss: 1.2987 (1.4699)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2987 (1.4690)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [105]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.2959 (1.4713)  time: 0.3329  data: 0.0006  max mem: 6459\n",
            "Epoch: [105] Total time: 0:04:20 (0.3342 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.2959 (1.4713)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32449468970298767, 'lambda_convnext_base': 0.2553117275238037, 'lambda_tf_efficientnetv2_l': 0.42019379138946533}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8593 (0.8593)  acc1: 84.3750 (84.3750)  acc5: 94.7917 (94.7917)  time: 0.8467  data: 0.8158  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9161 (0.9897)  acc1: 84.3750 (81.7235)  acc5: 94.7917 (93.3239)  time: 0.1722  data: 0.1415  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0820 (1.0705)  acc1: 80.7292 (80.3571)  acc5: 92.1875 (92.3611)  time: 0.1233  data: 0.0926  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2355 (1.1318)  acc1: 76.5625 (79.0995)  acc5: 90.6250 (91.7171)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2446 (1.1770)  acc1: 75.0000 (78.3028)  acc5: 89.5833 (91.2729)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1914 (1.1672)  acc1: 76.5625 (78.2884)  acc5: 91.1458 (91.5033)  time: 0.1243  data: 0.0936  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1965 (1.1813)  acc1: 75.5208 (78.1400)  acc5: 91.1458 (91.5100)  time: 0.1053  data: 0.0756  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1308 s / it)\n",
            "* Acc@1 78.140 Acc@5 91.510 loss 1.181\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.14%\n",
            "[alpha-schedule=cosine] epoch=106 distillation_alpha=0.6825\n",
            "Epoch: [106]  [  0/781]  eta: 0:14:59  lr: 0.000012  loss: 1.2543 (1.2543)  time: 1.1513  data: 0.8046  max mem: 6459\n",
            "Epoch: [106]  [ 10/781]  eta: 0:05:13  lr: 0.000012  loss: 1.2610 (1.4962)  time: 0.4072  data: 0.0734  max mem: 6459\n",
            "Epoch: [106]  [ 20/781]  eta: 0:04:42  lr: 0.000012  loss: 1.2537 (1.4803)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 30/781]  eta: 0:04:29  lr: 0.000012  loss: 1.2537 (1.4566)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 40/781]  eta: 0:04:21  lr: 0.000012  loss: 1.2468 (1.4559)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 50/781]  eta: 0:04:15  lr: 0.000012  loss: 1.2345 (1.4602)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2643 (1.4754)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.3074 (1.4892)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 80/781]  eta: 0:04:00  lr: 0.000012  loss: 1.3076 (1.4770)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [ 90/781]  eta: 0:03:56  lr: 0.000012  loss: 1.3076 (1.4771)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [100/781]  eta: 0:03:52  lr: 0.000012  loss: 1.2804 (1.4723)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [110/781]  eta: 0:03:48  lr: 0.000012  loss: 1.2761 (1.4604)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [120/781]  eta: 0:03:44  lr: 0.000012  loss: 1.2683 (1.4807)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.2774 (1.4789)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [140/781]  eta: 0:03:37  lr: 0.000012  loss: 1.2774 (1.4808)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [150/781]  eta: 0:03:33  lr: 0.000012  loss: 1.2789 (1.4852)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [160/781]  eta: 0:03:29  lr: 0.000012  loss: 1.2869 (1.4813)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [170/781]  eta: 0:03:26  lr: 0.000012  loss: 1.2725 (1.4732)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2870 (1.4823)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.4987 (1.4922)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.2711 (1.4921)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.2711 (1.4912)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.3085 (1.4922)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.3313 (1.5053)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [240/781]  eta: 0:03:01  lr: 0.000012  loss: 1.3079 (1.5048)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.2868 (1.5090)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [260/781]  eta: 0:02:55  lr: 0.000012  loss: 1.2889 (1.5158)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2609 (1.5129)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2565 (1.5128)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2622 (1.5166)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2954 (1.5170)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [310/781]  eta: 0:02:38  lr: 0.000012  loss: 1.3013 (1.5191)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.3568 (1.5239)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.3342 (1.5256)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.3322 (1.5239)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2713 (1.5167)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.2744 (1.5175)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.3083 (1.5161)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.3405 (1.5203)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [390/781]  eta: 0:02:11  lr: 0.000012  loss: 1.3942 (1.5198)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2727 (1.5160)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.2521 (1.5137)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2787 (1.5126)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.3121 (1.5105)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.3669 (1.5166)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.3788 (1.5185)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.3618 (1.5201)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.2976 (1.5201)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.2493 (1.5166)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.3285 (1.5179)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [500/781]  eta: 0:01:34  lr: 0.000012  loss: 1.3252 (1.5173)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2743 (1.5144)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.2847 (1.5143)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [530/781]  eta: 0:01:23  lr: 0.000012  loss: 1.3073 (1.5120)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.2873 (1.5132)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.2215 (1.5093)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2121 (1.5056)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2375 (1.5048)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.3440 (1.5045)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.3102 (1.5059)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2757 (1.5030)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2874 (1.5037)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.2874 (1.5027)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2758 (1.5033)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.2676 (1.4991)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2458 (1.4970)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2600 (1.4962)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.2967 (1.4954)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2967 (1.4946)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.2589 (1.4921)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.2286 (1.4898)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2439 (1.4875)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2662 (1.4851)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.2649 (1.4859)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [106]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.2511 (1.4836)  time: 0.3331  data: 0.0003  max mem: 6459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 2: Base Environment — Teacher Models & Multi-Teacher Adaptations**"
      ],
      "metadata": {
        "id": "ck_VO0908kCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer 2 extends the baseline DeiT environment to support knowledge distillation from one or more teacher models. This layer is additive: it does not modify the baseline DeiT training loop unless explicitly stated.\n",
        "It includes\n",
        "1. Teacher Model Support (Single & Multiple)\n",
        "2. Teacher Registry / Configuration\n",
        "3. Multi-Teacher Fusion Mechanism (Adaptation Layer)\n",
        "4. Distillation Loss Integration"
      ],
      "metadata": {
        "id": "0ZO3MUL88nog"
      }
    }
  ]
}