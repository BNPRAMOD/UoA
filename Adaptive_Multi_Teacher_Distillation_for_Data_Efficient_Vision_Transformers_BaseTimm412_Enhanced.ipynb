{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 1: Baseline DeiT environment**"
      ],
      "metadata": {
        "id": "A814LG7i7w0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeiT’s baseline training script expects a teacher model name and distillation settings via CLI flags in main.py (e.g., --teacher-model, --teacher-path, --distillation-type).\n",
        "GitHub\n",
        "+1\n",
        "\n",
        "So the “base environment” Layer 1 must include:\n",
        "\n",
        "DeiT repo (cloned)\n",
        "\n",
        "PyTorch (Colab default) + GPU\n",
        "\n",
        "timm installed (for both student and teacher models)\n",
        "\n",
        "compatibility patches if any (because Colab uses new torch/timm)"
      ],
      "metadata": {
        "id": "yZ7gvhPl8OL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install PyTorch without pinning"
      ],
      "metadata": {
        "id": "25JXNJNx7v2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "OZgeujT4qBSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb20b048-adc7-45f9-e07f-05410cf5eeae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "WWb1brNPqbEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uvYnPeqaBB",
        "outputId": "7cd9c36a-5a43-4059-9ad7-46463be6ddc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu128\n",
            "CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the baseline repo (official DeiT)"
      ],
      "metadata": {
        "id": "3awWPnZtp7E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aYSAUqVmQid",
        "outputId": "7e5d8b6e-24a1-4991-cd6f-91a7e7bb7940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'deit'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Total 456 (delta 0), reused 0 (delta 0), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 5.73 MiB | 6.39 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n",
            "/content/deit\n",
            "1:torch==1.13.1\n",
            "2:torchvision==0.8.1\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "# Check if 'deit' folder exists → delete it\n",
        "!if [ -d \"deit\" ]; then rm -rf deit; fi\n",
        "\n",
        "!git clone https://github.com/facebookresearch/deit.git\n",
        "%cd /content/deit\n",
        "!grep -n \"torch\" -n requirements.txt || true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab Compatibility Fixes\n",
        "\n",
        "1. torch pin removal\n",
        "\n",
        "2. timm API changes\n",
        "\n",
        "3. kwargs popping (pretrained_cfg, cache_dir, etc.)\n",
        "\n"
      ],
      "metadata": {
        "id": "fVJsxhJv4Dwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch requirements.txt to remove torch pins"
      ],
      "metadata": {
        "id": "kHpCHaaDr1u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"requirements.txt\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "filtered = []\n",
        "removed = []\n",
        "for line in lines:\n",
        "    s = line.strip()\n",
        "    if s.startswith(\"torch==\") or s.startswith(\"torchvision==\") or s.startswith(\"torchaudio==\"):\n",
        "        removed.append(line)\n",
        "        continue\n",
        "    filtered.append(line)\n",
        "\n",
        "p.write_text(\"\\n\".join(filtered) + \"\\n\")\n",
        "print(\"✅ Removed these pinned lines:\")\n",
        "for r in removed:\n",
        "    print(\"  -\", r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3mRQRCcrLmU",
        "outputId": "63730035-6573-44e5-c6de-613d91d14d86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Removed these pinned lines:\n",
            "  - torch==1.13.1\n",
            "  - torchvision==0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Pins are gone!i.e torch==1.13.1 pin was removed"
      ],
      "metadata": {
        "id": "lyODjd5lsAqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -nE \"torch|torchvision|torchaudio\" requirements.txt || echo \"✅ No torch pins remain\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7QRJmf7rg6a",
        "outputId": "6baf024f-7d6b-4d21-c6aa-8059a2c8d430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No torch pins remain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the baseline dependencies"
      ],
      "metadata": {
        "id": "csYbu0BampB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"jedi>=0.16,<0.19\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNoLOzs5xUxa",
        "outputId": "937357dc-2ee0-4e82-9e65-78c8b3c4c950"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi<0.19,>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from jedi<0.19,>=0.16) (0.8.5)\n",
            "Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y timm\n",
        "!pip -q install \"jedi>=0.16,<0.19\"\n",
        "!pip -q install timm==0.6.13 submitit\n",
        "#!pip -q install timm==0.4.12 submitit\n"
      ],
      "metadata": {
        "id": "Xsc3-5Ab2Azw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "llX7-GOnsQQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import timm; print('timm:', timm.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG39iey7tfMQ",
        "outputId": "9d9bcbdd-5da9-4d30-8362-82c7d3a8e964"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timm: 0.6.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart the Session**"
      ],
      "metadata": {
        "id": "r3tle6N46b7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "needle = \"OPENAI_CLIP_MEAN\"\n",
        "if needle in txt:\n",
        "    print(\"✅ timm.data already mentions OPENAI_CLIP_MEAN; no patch needed.\")\n",
        "else:\n",
        "    patch = \"\"\"\n",
        "\n",
        "# --- Colab patch: expose CLIP normalization constants for older exports ---\n",
        "try:\n",
        "    from .constants import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD  # timm versions where defined in constants\n",
        "except Exception:\n",
        "    # Standard OpenAI CLIP normalization\n",
        "    OPENAI_CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
        "    OPENAI_CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n",
        "# --- end patch ---\n",
        "\"\"\"\n",
        "    p.write_text(txt + patch)\n",
        "    print(\"✅ Patched:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEsR06SsuQa1",
        "outputId": "ce8f328f-c4b2-4988-eb18-f6a70fc94ac9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched: /usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "from models import deit_tiny_patch16_224\n",
        "m = deit_tiny_patch16_224()\n",
        "print(\"✅ DeiT model instantiated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h97jFzzrupzp",
        "outputId": "455bf9c1-0135-4ead-8590-3c382f5ca9d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "✅ DeiT model instantiated successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, timm\n",
        "print(torch.__version__)\n",
        "print(timm.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37b1qcS72uJs",
        "outputId": "cad57029-0f68-4375-e10a-c1ec6889ca83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu128\n",
            "0.6.13\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Tiny-ImageNet"
      ],
      "metadata": {
        "id": "uu-A5-G7vzTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IraDkD4vavm",
        "outputId": "fae9933e-228f-4273-ddde-49c275675de0",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix Tiny-ImageNet validation folder"
      ],
      "metadata": {
        "id": "qlrZWkYCvyN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'EOF'\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"/content/tiny-imagenet-200\")\n",
        "val_dir = root/\"val\"\n",
        "img_dir = val_dir/\"images\"\n",
        "ann = val_dir/\"val_annotations.txt\"\n",
        "\n",
        "with ann.open(\"r\") as f:\n",
        "    for line in f:\n",
        "        img, cls = line.strip().split(\"\\t\")[:2]\n",
        "        (val_dir/cls).mkdir(parents=True, exist_ok=True)\n",
        "        src = img_dir/img\n",
        "        dst = val_dir/cls/img\n",
        "        if src.exists():\n",
        "            shutil.move(str(src), str(dst))\n",
        "\n",
        "if img_dir.exists():\n",
        "    shutil.rmtree(img_dir)\n",
        "\n",
        "print(\"✅ Tiny-ImageNet val reorganized into class subfolders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYzGeXJwSsy",
        "outputId": "ecbde77e-4ff5-48f3-8419-fb136f5dbe89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n",
            "✅ Tiny-ImageNet val reorganized into class subfolders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/tiny-imagenet-200/val -maxdepth 1 -type d | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bwwo30Qwi0V",
        "outputId": "a09ee5b3-49c1-47ca-e45e-cf8966581d8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tiny-imagenet-200/val\n",
            "/content/tiny-imagenet-200/val/n02002724\n",
            "/content/tiny-imagenet-200/val/n03447447\n",
            "/content/tiny-imagenet-200/val/n07715103\n",
            "/content/tiny-imagenet-200/val/n02486410\n",
            "/content/tiny-imagenet-200/val/n01770393\n",
            "/content/tiny-imagenet-200/val/n02666196\n",
            "/content/tiny-imagenet-200/val/n02892201\n",
            "/content/tiny-imagenet-200/val/n04356056\n",
            "/content/tiny-imagenet-200/val/n02364673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/tiny-imagenet-200 | head"
      ],
      "metadata": {
        "id": "0e-EkPZf6GgG",
        "outputId": "de291579-d924-4d94-989d-bd49160f2ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.6M\n",
            "drwxrwxr-x   5 root root 4.0K Feb  9  2015 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x   1 root root 4.0K Feb 13 07:46 \u001b[01;34m..\u001b[0m/\n",
            "drwxrwxr-x   3 root root 4.0K Dec 12  2014 \u001b[01;34mtest\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Dec 12  2014 \u001b[01;34mtrain\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Feb 13 07:47 \u001b[01;34mval\u001b[0m/\n",
            "-rw-rw-r--   1 root root 2.0K Feb  9  2015 wnids.txt\n",
            "-rw-------   1 root root 2.6M Feb  9  2015 words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle timm incompatibilities. Although we can instantiate the model directly, the training script uses timm.create_model(), which injects metadata arguments such as pretrained_cfg and cache_dir.\n",
        "The original DeiT constructors do not support these arguments, so we remove them\n",
        "YOUR NOTEBOOK CALL\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224()          ✅ works (no kwargs)\n",
        "\n",
        "TRAINING PIPELINE\n",
        "    |\n",
        "    v\n",
        "timm.create_model()\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224(**kwargs)  ❌ injects extra keys\n"
      ],
      "metadata": {
        "id": "Rtyo7rkj3vLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch /content/deit/augment.py (safe compatibility fix)"
      ],
      "metadata": {
        "id": "mWebMtbWxHi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"augment.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "old = \"from timm.data.transforms import _pil_interp, RandomResizedCropAndInterpolation, ToNumpy, ToTensor\"\n",
        "if old in txt:\n",
        "    txt = txt.replace(\n",
        "        old,\n",
        "        \"from timm.data.transforms import RandomResizedCropAndInterpolation, ToNumpy, ToTensor\\n\"\n",
        "        \"try:\\n\"\n",
        "        \"    from timm.data.transforms import _pil_interp  # older timm\\n\"\n",
        "        \"except Exception:\\n\"\n",
        "        \"    _pil_interp = None  # newer timm doesn't expose this\\n\"\n",
        "    )\n",
        "    p.write_text(txt)\n",
        "    print(\"✅ Patched augment.py for timm compatibility.\")\n",
        "else:\n",
        "    print(\"ℹ️ Expected import line not found; augment.py may already be patched or different.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZwKyJqIxG2d",
        "outputId": "0e4ce65c-b50b-4346-fdf4-3e0e91559281"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched augment.py for timm compatibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!rm -f multiteacher_loss.py\n",
        "!ls -l multiteacher_loss.py || echo \"✅ old file removed\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RizknqA6MBXb",
        "outputId": "f59c1e85-5f05-45e5-e573-9614d10e7876"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "ls: cannot access 'multiteacher_loss.py': No such file or directory\n",
            "✅ old file removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "code = r'''\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Dict, List, Optional\n",
        "import json\n",
        "from pathlib import Path as _Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def normalize_lambdas(lmb: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Normalize teacher weights so they sum to 1 (supports shape (T,) or (B,T)).\n",
        "    \"\"\"\n",
        "    if lmb.dim() == 1:\n",
        "        return lmb / lmb.sum().clamp_min(eps)\n",
        "    return lmb / lmb.sum(dim=-1, keepdim=True).clamp_min(eps)\n",
        "\n",
        "\n",
        "def fuse_logits(\n",
        "    teacher_logits: Dict[str, torch.Tensor],\n",
        "    teacher_order: List[str],\n",
        "    lambdas: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Weighted sum of teacher logits.\n",
        "    teacher_logits[k]: (B,C)\n",
        "    lambdas: (B,T) or (T,)\n",
        "    returns: (B,C)\n",
        "    \"\"\"\n",
        "    logits_list = [teacher_logits[k] for k in teacher_order]\n",
        "    stacked = torch.stack(logits_list, dim=1)  # (B,T,C)\n",
        "\n",
        "    lmb = normalize_lambdas(lambdas).to(stacked.device)\n",
        "    if lmb.dim() == 1:\n",
        "        lmb = lmb.unsqueeze(0).expand(stacked.size(0), -1)  # (B,T)\n",
        "\n",
        "    return (stacked * lmb.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "def kd_soft(student_logits: torch.Tensor, teacher_logits: torch.Tensor, T: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Standard KL-based soft distillation loss with temperature scaling.\n",
        "    \"\"\"\n",
        "    p_t = F.softmax(teacher_logits / T, dim=-1)\n",
        "    log_p_s = F.log_softmax(student_logits / T, dim=-1)\n",
        "    return F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T * T)\n",
        "\n",
        "\n",
        "def kd_hard(student_logits: torch.Tensor, teacher_logits: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Hard distillation: cross-entropy against teacher argmax.\n",
        "    \"\"\"\n",
        "    return F.cross_entropy(student_logits, teacher_logits.argmax(dim=-1))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teachers\n",
        "# -----------------------------\n",
        "class FrozenTeacherEnsemble(nn.Module):\n",
        "    \"\"\"\n",
        "    Loads a list of timm pretrained teachers and freezes them.\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_names: List[str], device: torch.device):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleDict(\n",
        "            {\n",
        "                name: timm.create_model(name, pretrained=True, num_classes=1000).eval().to(device)\n",
        "                for name in teacher_names\n",
        "            }\n",
        "        )\n",
        "        for m in self.models.values():\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad_(False)\n",
        "        self.teacher_order = list(self.models.keys())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        return {k: m(x) for k, m in self.models.items()}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teacher logits mapping: ImageNet-1k -> Tiny-ImageNet (wnid-aligned gather)\n",
        "# -----------------------------\n",
        "def build_tiny_imagenet_im1k_indices(\n",
        "    tiny_root: str,\n",
        "    class_index_json: str = \"/content/imagenet_class_index.json\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns a LongTensor of shape (200,) containing the ImageNet-1k class indices\n",
        "    corresponding to Tiny-ImageNet wnids.txt ordering.\n",
        "\n",
        "    Requires torchvision's imagenet_class_index.json (wnid->index via JSON).\n",
        "    \"\"\"\n",
        "    tiny_root_p = _Path(tiny_root)\n",
        "    wnids_path = tiny_root_p / \"wnids.txt\"\n",
        "    if not wnids_path.exists():\n",
        "        raise FileNotFoundError(f\"Could not find Tiny-ImageNet wnids.txt at: {wnids_path}\")\n",
        "\n",
        "    wnids = wnids_path.read_text().strip().splitlines()\n",
        "\n",
        "    class_index_path = _Path(class_index_json)\n",
        "    if not class_index_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing {class_index_json}. Download it before training.\\n\"\n",
        "            \"Example:\\n\"\n",
        "            \"  !wget -q https://raw.githubusercontent.com/pytorch/vision/main/torchvision/models/imagenet_class_index.json \"\n",
        "            f\"-O {class_index_json}\"\n",
        "        )\n",
        "\n",
        "    class_index = json.loads(class_index_path.read_text())\n",
        "    # class_index: {\"0\": [\"n01440764\", \"tench\"], ...}\n",
        "    wnid_to_idx = {v[0]: int(k) for k, v in class_index.items()}\n",
        "\n",
        "    indices: List[int] = []\n",
        "    missing: List[str] = []\n",
        "    for w in wnids:\n",
        "        if w in wnid_to_idx:\n",
        "            indices.append(wnid_to_idx[w])\n",
        "        else:\n",
        "            missing.append(w)\n",
        "\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            f\"{len(missing)} Tiny-ImageNet wnids were not found in ImageNet-1k mapping. \"\n",
        "            f\"First few missing: {missing[:10]}\"\n",
        "        )\n",
        "\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "\n",
        "class TeacherLogitMapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Maps ImageNet-1k teacher logits (B,1000) -> Tiny-ImageNet logits (B,200)\n",
        "    by selecting the 200 corresponding ImageNet indices (gather/index_select).\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_keys: List[str], im1k_indices: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.teacher_keys = list(teacher_keys)\n",
        "        self.register_buffer(\"im1k_indices\", im1k_indices)  # (200,)\n",
        "\n",
        "    def forward(self, teacher_logits: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        out: Dict[str, torch.Tensor] = {}\n",
        "        idx = self.im1k_indices\n",
        "        for k, v in teacher_logits.items():\n",
        "            # v: (B,1000) -> (B,200)\n",
        "            out[k] = v.index_select(dim=-1, index=idx)\n",
        "        return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# HDTSE confidence weighting\n",
        "# -----------------------------\n",
        "class HDTSEConfidence(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes per-sample teacher weights based on each teacher's confidence\n",
        "    on the (possibly soft) targets.\n",
        "    \"\"\"\n",
        "    def __init__(self, temp: float = 1.0):\n",
        "        super().__init__()\n",
        "        self.temp = float(temp)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(\n",
        "        self,\n",
        "        teacher_logits: Dict[str, torch.Tensor],\n",
        "        teacher_order: List[str],\n",
        "        targets: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        stacked = torch.stack([teacher_logits[k] for k in teacher_order], dim=1)  # (B,T,C)\n",
        "        probs = F.softmax(stacked / self.temp, dim=-1)  # (B,T,C)\n",
        "\n",
        "        # Hard labels: (B,)\n",
        "        if targets.dim() == 1:\n",
        "            idx = targets.to(dtype=torch.long, device=probs.device)\n",
        "            conf = probs.gather(-1, idx[:, None, None]).squeeze(-1)  # (B,T)\n",
        "            return normalize_lambdas(conf)\n",
        "\n",
        "        # Soft labels (mixup/cutmix): (B,C)\n",
        "        tgt = targets.to(dtype=probs.dtype, device=probs.device)\n",
        "        conf = (probs * tgt[:, None, :]).sum(dim=-1)  # (B,T)\n",
        "        return normalize_lambdas(conf)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Multi-teacher distillation loss\n",
        "# -----------------------------\n",
        "class MultiTeacherDistillationLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_criterion,\n",
        "        student_num_classes: int,\n",
        "        teacher_names: List[str],\n",
        "        distillation_type: str = \"soft\",\n",
        "        alpha: float = 0.5,\n",
        "        tau: float = 2.0,\n",
        "        device=None,\n",
        "        use_adapter: bool = True,\n",
        "        hdtse_warmup_epochs: int = 0,\n",
        "        lambda_log: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        base_criterion: supervised loss (CE or soft-target CE when mixup is enabled)\n",
        "        distillation_type: \"soft\" or \"hard\"\n",
        "        alpha: final KD weight\n",
        "        tau: KD temperature\n",
        "        use_adapter: if True, expects Tiny-ImageNet mapping via set_tiny_root() before training\n",
        "        hdtse_warmup_epochs: use uniform lambdas until this epoch (exclusive)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.base_criterion = base_criterion\n",
        "        self.distillation_type = str(distillation_type)\n",
        "        self.tau = float(tau)\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # teachers (frozen)\n",
        "        self.teachers = FrozenTeacherEnsemble(teacher_names, self.device)\n",
        "        self.teacher_order = list(self.teachers.teacher_order)\n",
        "\n",
        "        # teacher->student class mapping (ImageNet-1k -> dataset classes)\n",
        "        self.use_adapter = bool(use_adapter)\n",
        "        self.adapter: Optional[nn.Module] = None  # created by set_tiny_root()\n",
        "\n",
        "        # HDTSE teacher weighting\n",
        "        self.hdtse = HDTSEConfidence()\n",
        "\n",
        "        # epoch state\n",
        "        self.epoch: int = 0\n",
        "        self.hdtse_warmup_epochs = int(hdtse_warmup_epochs)\n",
        "\n",
        "        # alpha schedule (KD weight ramp)\n",
        "        self.alpha_final = float(alpha)\n",
        "        self.alpha_start = 0.0\n",
        "        self.alpha_ramp_epochs = 20  # default ramp duration\n",
        "\n",
        "        # lambda logging (epoch-level)\n",
        "        self.lambda_log = bool(lambda_log)\n",
        "        self._lambda_sum = torch.zeros(len(self.teacher_order), dtype=torch.float32)\n",
        "        self._lambda_count = 0\n",
        "\n",
        "    # ---- Public setters ----\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self.epoch = int(epoch)\n",
        "\n",
        "    def set_alpha_schedule(self, alpha_start: float = 0.0, alpha_ramp_epochs: int = 20):\n",
        "        self.alpha_start = float(alpha_start)\n",
        "        self.alpha_ramp_epochs = int(alpha_ramp_epochs)\n",
        "\n",
        "    def set_tiny_root(self, tiny_root: str, class_index_json: str = \"/content/imagenet_class_index.json\"):\n",
        "        \"\"\"\n",
        "        Call once (from main.py) after constructing this loss, before training starts.\n",
        "        Creates the gather-based teacher logits mapper: (B,1000)->(B,C).\n",
        "        \"\"\"\n",
        "        im1k_indices = build_tiny_imagenet_im1k_indices(tiny_root, class_index_json=class_index_json).to(self.device)\n",
        "        self.adapter = TeacherLogitMapper(self.teacher_order, im1k_indices).to(self.device)\n",
        "\n",
        "    # ---- Logging ----\n",
        "    def pop_lambda_stats(self) -> Optional[Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Returns mean λ per teacher over the epoch, then resets accumulators.\n",
        "        Call once per epoch from main.py.\n",
        "        \"\"\"\n",
        "        if self._lambda_count <= 0:\n",
        "            return None\n",
        "\n",
        "        mean_lmb = (self._lambda_sum / float(self._lambda_count)).tolist()\n",
        "        out = {f\"lambda_{name}\": float(v) for name, v in zip(self.teacher_order, mean_lmb)}\n",
        "\n",
        "        self._lambda_sum.zero_()\n",
        "        self._lambda_count = 0\n",
        "        return out\n",
        "\n",
        "    # ---- Internals ----\n",
        "    def _uniform_lambdas(self, batch_size: int, device: torch.device) -> torch.Tensor:\n",
        "        t = len(self.teacher_order)\n",
        "        return torch.full((batch_size, t), 1.0 / t, device=device, dtype=torch.float32)\n",
        "\n",
        "    def _alpha_effective(self) -> float:\n",
        "        if self.alpha_ramp_epochs <= 0:\n",
        "            return self.alpha_final\n",
        "        t = min(1.0, float(self.epoch) / float(self.alpha_ramp_epochs))\n",
        "        return self.alpha_start + t * (self.alpha_final - self.alpha_start)\n",
        "\n",
        "    # ---- Forward ----\n",
        "    def forward(self, inputs: torch.Tensor, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        inputs: images (B,3,H,W)\n",
        "        outputs: student logits (B,C)\n",
        "        targets: hard labels (B,) or soft labels (B,C) when mixup/cutmix is enabled\n",
        "        \"\"\"\n",
        "        base_loss = self.base_criterion(outputs, targets)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_logits = self.teachers(inputs)  # dict: teacher -> (B,1000)\n",
        "\n",
        "        student_C = outputs.shape[-1]\n",
        "        any_teacher = next(iter(t_logits.values()))\n",
        "        teacher_C = any_teacher.shape[-1]\n",
        "\n",
        "        if teacher_C != student_C:\n",
        "            if self.adapter is None:\n",
        "                raise RuntimeError(\n",
        "                f\"Teacher logits have {teacher_C} classes but student has {student_C}. \"\n",
        "                \"Adapter not initialized. Call criterion.set_tiny_root(args.data_path).\"\n",
        "            )\n",
        "            t_logits = self.adapter(t_logits)  # dict: teacher -> (B,student_C)\n",
        "\n",
        "        # ---- Teacher weights (λ) ----\n",
        "        if self.epoch < self.hdtse_warmup_epochs:\n",
        "            lambdas = self._uniform_lambdas(outputs.size(0), outputs.device)  # (B,T)\n",
        "        else:\n",
        "            lambdas = self.hdtse(t_logits, self.teacher_order, targets)  # (B,T)\n",
        "\n",
        "        # ---- λ logging ----\n",
        "        if self.lambda_log:\n",
        "            batch_mean = lambdas.detach().mean(dim=0).cpu()  # (T,)\n",
        "            self._lambda_sum += batch_mean * outputs.size(0)\n",
        "            self._lambda_count += outputs.size(0)\n",
        "\n",
        "        fused = fuse_logits(t_logits, self.teacher_order, lambdas)  # (B,C)\n",
        "\n",
        "        kd = kd_soft(outputs, fused, self.tau) if self.distillation_type == \"soft\" else kd_hard(outputs, fused)\n",
        "\n",
        "        alpha_eff = self._alpha_effective()\n",
        "        return (1.0 - alpha_eff) * base_loss + alpha_eff * kd\n",
        "'''\n",
        "\n",
        "path = Path(\"multiteacher_loss.py\")\n",
        "path.write_text(code)\n",
        "\n",
        "print(\"File written:\", path)\n",
        "print(\"File size (bytes):\", path.stat().st_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k4jzkzbMHD-",
        "outputId": "9bd16401-e17f-4ad7-99e4-8a9c510d6f23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "File written: multiteacher_loss.py\n",
            "File size (bytes): 11996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re, py_compile\n",
        "\n",
        "MAIN = Path(\"/content/deit/main.py\")\n",
        "txt = MAIN.read_text()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helpers (line-safe insertions to avoid indentation/newline bugs)\n",
        "# ------------------------------------------------------------\n",
        "def fix_broken_import_concatenation():\n",
        "    global txt\n",
        "    # Fix exact failure mode:\n",
        "    txt = txt.replace(\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLossfrom samplers import RASampler\",\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLoss\\nfrom samplers import RASampler\"\n",
        "    )\n",
        "\n",
        "def ensure_line_after(match_line_regex: str, new_line: str):\n",
        "    \"\"\"Insert `new_line` as a full line right AFTER the first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if new_line.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)  # keep line endings\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            # insert after this line\n",
        "            if not new_line.endswith(\"\\n\"):\n",
        "                new_line2 = new_line + \"\\n\"\n",
        "            else:\n",
        "                new_line2 = new_line\n",
        "            lines.insert(i + 1, new_line2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert after: {match_line_regex}\")\n",
        "\n",
        "def ensure_block_after_line(match_line_regex: str, block: str):\n",
        "    \"\"\"Insert a multi-line block after first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    # Heuristic: if first unique token already exists, don't re-add\n",
        "    if \"--teacher-models\" in block and \"--teacher-models\" in txt and \"--hdtse-warmup-epochs\" in txt and \"--lambda-log\" in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            if not block.endswith(\"\\n\"):\n",
        "                block2 = block + \"\\n\"\n",
        "            else:\n",
        "                block2 = block\n",
        "            lines.insert(i + 1, block2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert block after: {match_line_regex}\")\n",
        "\n",
        "def replace_first(pattern: str, repl: str, flags=re.DOTALL):\n",
        "    global txt\n",
        "    m = re.search(pattern, txt, flags)\n",
        "    if not m:\n",
        "        return False\n",
        "    txt = txt[:m.start()] + repl + txt[m.end():]\n",
        "    return True\n",
        "\n",
        "def remove_first_line_matching(line_regex: str):\n",
        "    global txt\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(line_regex, line):\n",
        "            del lines[i]\n",
        "            txt = \"\".join(lines)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Repair if prior patch created the exact SyntaxError\n",
        "# ------------------------------------------------------------\n",
        "fix_broken_import_concatenation()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Ensure MultiTeacherDistillationLoss import (safe line insertion)\n",
        "# Insert after: from losses import DistillationLoss\n",
        "# ------------------------------------------------------------\n",
        "ensure_line_after(\n",
        "    r\"^\\s*from\\s+losses\\s+import\\s+DistillationLoss\\s*$\",\n",
        "    \"from multiteacher_loss import MultiTeacherDistillationLoss\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Ensure CLI args after --teacher-path\n",
        "# ------------------------------------------------------------\n",
        "cli_block = \"\"\"\\\n",
        "    parser.add_argument('--teacher-models', type=str, default='',\n",
        "                        help='Comma-separated timm model names for multi-teacher distillation')\n",
        "    parser.add_argument('--hdtse-warmup-epochs', type=int, default=0,\n",
        "                        help='Use uniform teacher weights for first N epochs, then enable HDTSE weighting')\n",
        "    parser.add_argument('--lambda-log', action='store_true', default=False,\n",
        "                        help='Log mean λ (teacher weights) each epoch for multi-teacher distillation')\n",
        "\"\"\"\n",
        "ensure_block_after_line(r\"^\\s*parser\\.add_argument\\('--teacher-path'\", cli_block)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Allow finetune + distillation ONLY when multi-teacher is used\n",
        "# Base guard is:\n",
        "# if args.distillation_type != 'none' and args.finetune and not args.eval:\n",
        "#     raise NotImplementedError(...)\n",
        "# ------------------------------------------------------------\n",
        "replace_first(\n",
        "    r\"^\\s*if\\s+args\\.distillation_type\\s*!=\\s*'none'\\s+and\\s+args\\.finetune\\s+and\\s+not\\s+args\\.eval\\s*:\\s*\\n\\s*raise\\s+NotImplementedError\\([^\\n]*\\)\\s*$\",\n",
        "    \"    if args.distillation_type != 'none' and args.finetune and not args.eval and not getattr(args, 'teacher_models', ''):\\n\"\n",
        "    \"        raise NotImplementedError(\\\"Finetuning with distillation not yet supported (single-teacher path)\\\")\\n\",\n",
        "    flags=re.MULTILINE\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Move scheduler creation to AFTER adapter param-group add:\n",
        "# Remove early: lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "# ------------------------------------------------------------\n",
        "remove_first_line_matching(r\"^\\s*lr_scheduler,\\s*_\\s*=\\s*create_scheduler\\(\\s*args\\s*,\\s*optimizer\\s*\\)\\s*$\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Unify distillation region (multi-teacher vs single-teacher)\n",
        "# We'll replace from \"teacher_model = None\" up to \"output_dir = Path(args.output_dir)\"\n",
        "# This avoids indentation mistakes and prevents teacher_path='' crash.\n",
        "# ------------------------------------------------------------\n",
        "m_start = re.search(r\"^\\s*teacher_model\\s*=\\s*None\\s*$\", txt, flags=re.MULTILINE)\n",
        "m_end   = re.search(r\"^\\s*output_dir\\s*=\\s*Path\\(args\\.output_dir\\)\\s*$\", txt, flags=re.MULTILINE)\n",
        "if not (m_start and m_end and m_start.start() < m_end.start()):\n",
        "    raise RuntimeError(\"Could not locate distillation region anchors (teacher_model=None ... output_dir=Path(...))\")\n",
        "\n",
        "unified = \"\"\"\\\n",
        "    teacher_model = None\n",
        "\n",
        "    # -------------------------------\n",
        "    # Unified single + multi-teacher distillation\n",
        "    # -------------------------------\n",
        "    teacher_models_str = getattr(args, 'teacher_models', '').strip()\n",
        "\n",
        "    if args.distillation_type != 'none' and teacher_models_str:\n",
        "        teacher_names = [t.strip() for t in teacher_models_str.split(',') if t.strip()]\n",
        "        print(f\"✅ Multi-teacher distillation enabled. Teachers: {teacher_names}\")\n",
        "\n",
        "        criterion = MultiTeacherDistillationLoss(\n",
        "            base_criterion=criterion,\n",
        "            student_num_classes=args.nb_classes,\n",
        "            teacher_names=teacher_names,\n",
        "            distillation_type=args.distillation_type,\n",
        "            alpha=args.distillation_alpha,\n",
        "            tau=args.distillation_tau,\n",
        "            device=device,\n",
        "            use_adapter=True,\n",
        "            hdtse_warmup_epochs=getattr(args, 'hdtse_warmup_epochs', 0),\n",
        "            lambda_log=getattr(args, 'lambda_log', False),\n",
        "        )\n",
        "\n",
        "        # Initialize Tiny-ImageNet wnid -> ImageNet-1k index mapping for teacher logits\n",
        "        if hasattr(criterion, \"set_tiny_root\"):\n",
        "            criterion.set_tiny_root(args.data_path)\n",
        "\n",
        "        # Optional: alpha ramp if you add args later\n",
        "        if hasattr(criterion, \"set_alpha_schedule\") and hasattr(args, \"alpha_ramp_epochs\"):\n",
        "            criterion.set_alpha_schedule(\n",
        "                alpha_start=getattr(args, \"alpha_start\", 0.0),\n",
        "                alpha_ramp_epochs=getattr(args, \"alpha_ramp_epochs\", 20),\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        if args.distillation_type != 'none':\n",
        "            assert args.teacher_path, 'need to specify teacher-path when using single-teacher distillation'\n",
        "            print(f\"Creating teacher model: {args.teacher_model}\")\n",
        "            teacher_model = create_model(\n",
        "                args.teacher_model,\n",
        "                pretrained=False,\n",
        "                num_classes=args.nb_classes,\n",
        "                global_pool='avg',\n",
        "            )\n",
        "            if args.teacher_path.startswith('https'):\n",
        "                checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                    args.teacher_path, map_location='cpu', check_hash=True)\n",
        "            else:\n",
        "                checkpoint = torch.load(args.teacher_path, map_location='cpu')\n",
        "            teacher_model.load_state_dict(checkpoint['model'])\n",
        "            teacher_model.to(device)\n",
        "            teacher_model.eval()\n",
        "\n",
        "        criterion = DistillationLoss(\n",
        "            criterion, teacher_model, args.distillation_type, args.distillation_alpha, args.distillation_tau\n",
        "        )\n",
        "\n",
        "    # Scheduler must be created AFTER all optimizer param groups are finalized\n",
        "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "\"\"\"\n",
        "\n",
        "txt = txt[:m_start.start()] + unified + \"\\n    output_dir = Path(args.output_dir)\\n\" + txt[m_end.end():]\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Ensure loss call uses (samples, outputs, targets)\n",
        "# ----------------------------\n",
        "# Patch ONLY the simple 2-arg form if present.\n",
        "if \"criterion(samples, outputs, targets)\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"loss\\s*=\\s*criterion\\(\\s*outputs\\s*,\\s*targets\\s*\\)\",\n",
        "        r\"loss = criterion(samples, outputs, targets)\",\n",
        "        txt\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Insert criterion.set_epoch(epoch) before train_one_epoch\n",
        "# We add it inside the epoch loop, after sampler.set_epoch if present.\n",
        "# ------------------------------------------------------------\n",
        "if \"criterion.set_epoch(epoch)\" not in txt:\n",
        "    # If distributed block exists, insert after it\n",
        "    if re.search(r\"^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$\", txt, flags=re.MULTILINE):\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "    else:\n",
        "        # Otherwise put at top of loop\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*for\\s+epoch\\s+in\\s+range\\(args\\.start_epoch,\\s*args\\.epochs\\)\\s*:\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Per-epoch λ logging after train_one_epoch call\n",
        "# ------------------------------------------------------------\n",
        "if \"print('λ means:'\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"(train_stats\\s*=\\s*train_one_epoch\\([\\s\\S]*?\\)\\s*)\\n\",\n",
        "        r\"\\1\\n\\n\"\n",
        "        r\"        # Optional: log mean λ per teacher (multi-teacher only)\\n\"\n",
        "        r\"        if getattr(args, 'lambda_log', False) and hasattr(criterion, 'pop_lambda_stats'):\\n\"\n",
        "        r\"            lambda_means = criterion.pop_lambda_stats()\\n\"\n",
        "        r\"            if lambda_means:\\n\"\n",
        "        r\"                print('λ means:', lambda_means)\\n\",\n",
        "        txt,\n",
        "        count=1\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Write + compile check\n",
        "# ------------------------------------------------------------\n",
        "MAIN.write_text(txt)\n",
        "py_compile.compile(str(MAIN), doraise=True)\n",
        "print(\"✅ Patched main.py written and compiles:\", MAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUdJZ4F-NoE-",
        "outputId": "0e0aab37-c2e0-46ef-8654-a63144b9599a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched main.py written and compiles: /content/deit/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidated patcher for /content/deit/main.py\n",
        "# Adds: Cosine α schedule CLI args + per-epoch α update (works for DistillationLoss + MultiTeacherDistillationLoss)\n",
        "#\n",
        "# Base file reference (as you shared): :contentReference[oaicite:0]{index=0}\n",
        "\n",
        "from pathlib import Path\n",
        "import re, py_compile\n",
        "\n",
        "MAIN = Path(\"/content/deit/main.py\")\n",
        "txt = MAIN.read_text()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helpers (line-safe insertions to avoid indentation/newline bugs)\n",
        "# ------------------------------------------------------------\n",
        "def ensure_import(module_name: str):\n",
        "    \"\"\"Ensure `import <module_name>` exists near the top-level imports.\"\"\"\n",
        "    global txt\n",
        "    pat = rf\"^\\s*import\\s+{re.escape(module_name)}\\s*$\"\n",
        "    if re.search(pat, txt, flags=re.MULTILINE):\n",
        "        return\n",
        "    # Insert after \"import time\" if present, else after argparse\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r\"^\\s*import\\s+time\\s*$\", line):\n",
        "            lines.insert(i + 1, f\"import {module_name}\\n\")\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r\"^\\s*import\\s+argparse\\s*$\", line):\n",
        "            lines.insert(i + 1, f\"import {module_name}\\n\")\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    # fallback: very top\n",
        "    txt = f\"import {module_name}\\n\" + txt\n",
        "\n",
        "def ensure_line_after(match_line_regex: str, new_line: str):\n",
        "    \"\"\"Insert `new_line` as a full line RIGHT AFTER the first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if new_line.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            lines.insert(i + 1, (new_line if new_line.endswith(\"\\n\") else new_line + \"\\n\"))\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert after: {match_line_regex}\")\n",
        "\n",
        "def ensure_block_after_line(match_line_regex: str, block: str, unique_guard: str = None):\n",
        "    \"\"\"Insert a multi-line block after first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if unique_guard and unique_guard in txt:\n",
        "        return\n",
        "    if (not unique_guard) and block.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            lines.insert(i + 1, (block if block.endswith(\"\\n\") else block + \"\\n\"))\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert block after: {match_line_regex}\")\n",
        "\n",
        "def replace_first(pattern: str, repl: str, flags=re.DOTALL):\n",
        "    global txt\n",
        "    m = re.search(pattern, txt, flags)\n",
        "    if not m:\n",
        "        return False\n",
        "    txt = txt[:m.start()] + repl + txt[m.end():]\n",
        "    return True\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Ensure `import math` (needed for cosine schedule)\n",
        "# ------------------------------------------------------------\n",
        "ensure_import(\"math\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Add CLI args for alpha scheduling (after distillation params)\n",
        "#    Insert right after: parser.add_argument('--distillation-tau' ...)\n",
        "# ------------------------------------------------------------\n",
        "alpha_cli_block = \"\"\"\\\n",
        "    # ---- Distillation alpha scheduling (epoch-level) ----\n",
        "    parser.add_argument('--alpha-schedule', default='none',\n",
        "                        choices=['none', 'cosine'],\n",
        "                        type=str, help=\"Schedule distillation alpha across epochs.\")\n",
        "    parser.add_argument('--alpha-start', default=0.05, type=float,\n",
        "                        help=\"Starting alpha for alpha schedule (ignored if alpha-schedule=none).\")\n",
        "    parser.add_argument('--alpha-end', default=0.7, type=float,\n",
        "                        help=\"Final alpha for alpha schedule (ignored if alpha-schedule=none).\")\n",
        "\"\"\"\n",
        "ensure_block_after_line(\n",
        "    r\"^\\s*parser\\.add_argument\\('--distillation-tau'.*\\)\\s*$\",\n",
        "    alpha_cli_block,\n",
        "    unique_guard=\"--alpha-schedule\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Add helper function for cosine schedule (module-level, before main())\n",
        "#    Insert right after get_args_parser() returns `parser`\n",
        "# ------------------------------------------------------------\n",
        "alpha_fn_block = \"\"\"\\\n",
        "\n",
        "def _cosine_alpha(epoch: int, total_epochs: int, alpha_start: float, alpha_end: float) -> float:\n",
        "    # Smoothly increases alpha from alpha_start to alpha_end over training.\n",
        "    total_epochs = int(total_epochs)\n",
        "    if total_epochs <= 1:\n",
        "        return alpha_end\n",
        "\n",
        "    progress = float(epoch) / float(total_epochs-1)\n",
        "    progress = min(max(progress, 0.0), 1.0)\n",
        "    cosine = 0.5 * (1.0 - math.cos(math.pi * progress))\n",
        "    return alpha_start + cosine * (alpha_end - alpha_start)\n",
        "\"\"\"\n",
        "# Insert after the \"return parser\" line inside get_args_parser()\n",
        "ensure_block_after_line(\n",
        "    r\"^\\s*return\\s+parser\\s*$\",\n",
        "    alpha_fn_block,\n",
        "    unique_guard=\"def _cosine_alpha\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Update α each epoch BEFORE train_one_epoch call, and push into criterion\n",
        "#    Key detail: DistillationLoss() captures alpha at init in this base main.py,\n",
        "#    so we must update criterion.alpha (or criterion.set_alpha) per epoch.\n",
        "# ------------------------------------------------------------\n",
        "epoch_hook_block = \"\"\"\\\n",
        "        # ---- Cosine α schedule (distillation weight) ----\n",
        "        if args.distillation_type != 'none' and getattr(args, 'alpha_schedule', 'none') == 'cosine':\n",
        "            args.distillation_alpha = _cosine_alpha(\n",
        "                epoch=epoch,\n",
        "                total_epochs=args.epochs,\n",
        "                alpha_start=getattr(args, 'alpha_start', 0.05),\n",
        "                alpha_end=getattr(args, 'alpha_end', 0.7),\n",
        "            )\n",
        "            # Propagate into the actual loss wrapper (DistillationLoss / MultiTeacherDistillationLoss)\n",
        "            if hasattr(criterion, \"alpha\"):\n",
        "                criterion.alpha = args.distillation_alpha\n",
        "            elif hasattr(criterion, \"set_alpha\"):\n",
        "                criterion.set_alpha(args.distillation_alpha)\n",
        "\n",
        "            if (not getattr(args, \"distributed\", False)) or getattr(args, \"rank\", 0) == 0:\n",
        "                print(f\"[alpha-schedule=cosine] epoch={epoch} distillation_alpha={args.distillation_alpha:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "# Insert this block after the distributed sampler epoch set (if present),\n",
        "# otherwise right after the for-loop line.\n",
        "if \"alpha-schedule=cosine\" not in txt:\n",
        "    # Case A: distributed sampler.set_epoch exists\n",
        "    if re.search(\n",
        "        r\"^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$\",\n",
        "        txt,\n",
        "        flags=re.MULTILINE\n",
        "    ):\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$)\",\n",
        "            r\"\\1\\n\\n\" + epoch_hook_block.rstrip(\"\\n\"),\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "    else:\n",
        "        # Case B: no distributed stanza → insert at top of loop\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*for\\s+epoch\\s+in\\s+range\\(args\\.start_epoch,\\s*args\\.epochs\\)\\s*:\\s*$)\",\n",
        "            r\"\\1\\n\" + epoch_hook_block.rstrip(\"\\n\"),\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Write + compile check\n",
        "# ------------------------------------------------------------\n",
        "MAIN.write_text(txt)\n",
        "py_compile.compile(str(MAIN), doraise=True)\n",
        "print(\"✅ Patched main.py written and compiles:\", MAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcHzSlpfe-Ap",
        "outputId": "5eaa7737-5d49-461c-9ee6-9adeb71fb9e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched main.py written and compiles: /content/deit/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before constructing the model, remove those keys from kwargs"
      ],
      "metadata": {
        "id": "4sFpztpw00XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    if line.strip().startswith(\"def deit_\") and \"**kwargs\" in line:\n",
        "        out.append(\"    # Drop timm-injected kwargs not supported by DeiT\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_overlay', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_priority', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ models.py patched to drop pretrained_cfg kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1qywwxV0RS-",
        "outputId": "6e0a1243-9005-4466-a9f2-0a92f25c71a8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ models.py patched to drop pretrained_cfg kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "Yh47-0Pv0-R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix: Patch /content/deit/models.py to drop pretrained_cfg=..."
      ],
      "metadata": {
        "id": "hfueTM11xy00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch models.py to also drop cache_dir (and friends)"
      ],
      "metadata": {
        "id": "OK2GsetX1ZkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "# Keys that timm may inject but DeiT constructors don't accept\n",
        "DROP_KEYS = [\n",
        "    \"cache_dir\",\n",
        "    \"hf_hub_id\",\n",
        "    \"hf_hub_filename\",\n",
        "    \"hf_hub_revision\",\n",
        "]\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    # Right after the comment line we previously inserted, add more pops once per function\n",
        "    if line.strip() == \"# Drop timm-injected kwargs not supported by DeiT\":\n",
        "        for k in DROP_KEYS:\n",
        "            out.append(f\"    kwargs.pop('{k}', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ Patched models.py to drop cache_dir/hf_hub* kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0-XJmyw1aed",
        "outputId": "7ba81312-660a-45ef-f194-d1515442318f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched models.py to drop cache_dir/hf_hub* kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/imagenet_class_index.json\n",
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json \\\n",
        "  -O /content/imagenet_class_index.json\n",
        "\n",
        "!python - <<'PY'\n",
        "import json\n",
        "p=\"/content/imagenet_class_index.json\"\n",
        "with open(p,\"r\",encoding=\"utf-8\") as f:\n",
        "    obj=json.load(f)\n",
        "print(\"Loaded OK. Entries:\", len(obj))\n",
        "print(\"Example 0:\", obj[\"0\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAeUxFOQMFrE",
        "outputId": "109aa934-e902-4c2f-afcb-41f327f709a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-13 07:47:02--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 3.5.0.81, 52.217.235.72, 52.216.40.224, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|3.5.0.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/octet-stream]\n",
            "Saving to: ‘/content/imagenet_class_index.json’\n",
            "\n",
            "/content/imagenet_c 100%[===================>]  34.53K   158KB/s    in 0.2s    \n",
            "\n",
            "2026-02-13 07:47:03 (158 KB/s) - ‘/content/imagenet_class_index.json’ saved [35363/35363]\n",
            "\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "Loaded OK. Entries: 1000\n",
            "Example 0: ['n01440764', 'tench']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --pretrained \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 64 \\\n",
        "#   --num_workers 2 \\\n",
        "#   --output_dir /content/deit_runs/smoke_test\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 128 \\\n",
        "#   --num_workers 4 \\\n",
        "#   --input-size 224 \\\n",
        "#   --opt adamw \\\n",
        "#   --lr 5e-4 \\\n",
        "#   --weight-decay 0.05 \\\n",
        "#   --sched cosine \\\n",
        "#   --aa rand-m9-mstd0.5 \\\n",
        "#   --reprob 0.25 \\\n",
        "#   --remode pixel \\\n",
        "#   --recount 1 \\\n",
        "#   --output_dir /content/deit_runs/tiny_imagenet\n",
        "### correct one\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 3e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_5ep\n",
        "%cd /content/deit\n",
        "!python main.py \\\n",
        " --model deit_tiny_patch16_224 \\\n",
        " --data-path /content/tiny-imagenet-200 \\\n",
        " --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        " --epochs 90 \\\n",
        " --batch-size 128 \\\n",
        " --num_workers 4 \\\n",
        " --input-size 224 \\\n",
        " --opt adamw \\\n",
        " --lr 2.5e-4 \\\n",
        " --weight-decay 0.05 \\\n",
        " --sched cosine \\\n",
        " --warmup-epochs 4 \\\n",
        " --smoothing 0.1 \\\n",
        " --aa rand-m6-mstd0.5 \\\n",
        " --reprob 0.2 \\\n",
        " --model-ema \\\n",
        " --model-ema-decay 0.9999 \\\n",
        " --drop-path 0.05 \\\n",
        " --mixup 0.2 \\\n",
        " --cutmix 0.0 \\\n",
        " --mixup-prob 0.5 \\\n",
        " --distillation-type soft \\\n",
        " --alpha-schedule cosine --alpha-start 0.1 --alpha-end 0.6 \\\n",
        " --distillation-alpha 0.5 \\\n",
        " --distillation-tau 3.5 \\\n",
        " --hdtse-warmup-epochs 8 \\\n",
        " --lambda-log \\\n",
        " --output_dir /content/deit_runs/tiny_imagenet \\\n",
        " --teacher-models \"swin_base_patch4_window7_224,convnext_base,tf_efficientnetv2_l\"\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 2.5e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --distillation-type hard \\\n",
        "# --teacher-model regnety_160 \\\n",
        "# --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_10ep\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_distilled_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 7e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.0 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.0 \\\n",
        "#  --distillation-type hard \\\n",
        "#  --distillation-alpha 0.7 \\\n",
        "#  --teacher-model regnety_160 \\\n",
        "#  --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/deit_tiny_distilled_10ep\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TYvrcwJwlde",
        "outputId": "85551174-704f-4c4f-bbfb-cdcf2341d92f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [31]  [760/781]  eta: 0:00:06  lr: 0.000048  loss: 1.4568 (1.5607)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [31]  [770/781]  eta: 0:00:03  lr: 0.000048  loss: 1.5040 (1.5617)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [31]  [780/781]  eta: 0:00:00  lr: 0.000048  loss: 1.5088 (1.5629)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [31] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000048  loss: 1.5088 (1.5629)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32951927185058594, 'lambda_convnext_base': 0.2587185204029083, 'lambda_tf_efficientnetv2_l': 0.41176265478134155}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8254 (0.8254)  acc1: 81.7708 (81.7708)  acc5: 95.3125 (95.3125)  time: 0.8467  data: 0.8161  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0174 (1.0066)  acc1: 80.2083 (79.6875)  acc5: 94.2708 (92.8504)  time: 0.1783  data: 0.1479  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0737 (1.0678)  acc1: 77.0833 (78.4970)  acc5: 92.7083 (92.2619)  time: 0.1320  data: 0.1016  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1732 (1.1184)  acc1: 73.9583 (77.6882)  acc5: 90.6250 (91.8515)  time: 0.1338  data: 0.1033  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2499 (1.1545)  acc1: 73.9583 (76.8801)  acc5: 90.6250 (91.6794)  time: 0.1341  data: 0.1036  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1555 (1.1577)  acc1: 75.5208 (76.5012)  acc5: 92.1875 (91.8505)  time: 0.1427  data: 0.1122  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1555 (1.1601)  acc1: 75.0000 (76.3200)  acc5: 92.7083 (91.8900)  time: 0.1224  data: 0.0927  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1430 s / it)\n",
            "* Acc@1 76.320 Acc@5 91.890 loss 1.160\n",
            "Accuracy of the network on the 10000 test images: 76.3%\n",
            "Max accuracy: 76.81%\n",
            "[alpha-schedule=cosine] epoch=32 distillation_alpha=0.2587\n",
            "Epoch: [32]  [  0/781]  eta: 0:15:30  lr: 0.000047  loss: 1.4877 (1.4877)  time: 1.1916  data: 0.8092  max mem: 6459\n",
            "Epoch: [32]  [ 10/781]  eta: 0:05:16  lr: 0.000047  loss: 1.4904 (1.6042)  time: 0.4105  data: 0.0739  max mem: 6459\n",
            "Epoch: [32]  [ 20/781]  eta: 0:04:43  lr: 0.000047  loss: 1.4282 (1.5240)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [32]  [ 30/781]  eta: 0:04:30  lr: 0.000047  loss: 1.4071 (1.5920)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 40/781]  eta: 0:04:21  lr: 0.000047  loss: 1.5075 (1.5922)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 50/781]  eta: 0:04:14  lr: 0.000047  loss: 1.4586 (1.5540)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 60/781]  eta: 0:04:09  lr: 0.000047  loss: 1.4393 (1.5795)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 70/781]  eta: 0:04:04  lr: 0.000047  loss: 1.4601 (1.5736)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 80/781]  eta: 0:04:01  lr: 0.000047  loss: 1.4407 (1.5708)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [ 90/781]  eta: 0:03:57  lr: 0.000047  loss: 1.4407 (1.5638)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [100/781]  eta: 0:03:53  lr: 0.000047  loss: 1.4330 (1.5635)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [110/781]  eta: 0:03:49  lr: 0.000047  loss: 1.3955 (1.5504)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [120/781]  eta: 0:03:45  lr: 0.000047  loss: 1.3871 (1.5593)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [130/781]  eta: 0:03:41  lr: 0.000047  loss: 1.4318 (1.5497)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [140/781]  eta: 0:03:37  lr: 0.000047  loss: 1.4126 (1.5449)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [150/781]  eta: 0:03:33  lr: 0.000047  loss: 1.4049 (1.5393)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [160/781]  eta: 0:03:30  lr: 0.000047  loss: 1.3793 (1.5339)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [170/781]  eta: 0:03:26  lr: 0.000047  loss: 1.4495 (1.5495)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [180/781]  eta: 0:03:23  lr: 0.000047  loss: 1.4402 (1.5569)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [190/781]  eta: 0:03:19  lr: 0.000047  loss: 1.4170 (1.5515)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [200/781]  eta: 0:03:15  lr: 0.000047  loss: 1.3775 (1.5463)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [210/781]  eta: 0:03:12  lr: 0.000047  loss: 1.4112 (1.5433)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [220/781]  eta: 0:03:08  lr: 0.000047  loss: 1.4464 (1.5462)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [230/781]  eta: 0:03:05  lr: 0.000047  loss: 1.4406 (1.5418)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [240/781]  eta: 0:03:01  lr: 0.000047  loss: 1.4055 (1.5436)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [250/781]  eta: 0:02:58  lr: 0.000047  loss: 1.4467 (1.5415)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [260/781]  eta: 0:02:55  lr: 0.000047  loss: 1.4460 (1.5424)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [270/781]  eta: 0:02:51  lr: 0.000047  loss: 1.4393 (1.5416)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [280/781]  eta: 0:02:48  lr: 0.000047  loss: 1.4381 (1.5451)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [290/781]  eta: 0:02:44  lr: 0.000047  loss: 1.4520 (1.5473)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [300/781]  eta: 0:02:41  lr: 0.000047  loss: 1.4364 (1.5457)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [310/781]  eta: 0:02:37  lr: 0.000047  loss: 1.4268 (1.5413)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [320/781]  eta: 0:02:34  lr: 0.000047  loss: 1.4412 (1.5405)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [330/781]  eta: 0:02:31  lr: 0.000047  loss: 1.4778 (1.5413)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [340/781]  eta: 0:02:27  lr: 0.000047  loss: 1.4959 (1.5424)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [350/781]  eta: 0:02:24  lr: 0.000047  loss: 1.5165 (1.5505)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [360/781]  eta: 0:02:20  lr: 0.000047  loss: 1.4551 (1.5486)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [370/781]  eta: 0:02:17  lr: 0.000047  loss: 1.3961 (1.5487)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [380/781]  eta: 0:02:14  lr: 0.000047  loss: 1.4282 (1.5540)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [390/781]  eta: 0:02:10  lr: 0.000047  loss: 1.5123 (1.5575)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [400/781]  eta: 0:02:07  lr: 0.000047  loss: 1.4919 (1.5579)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [410/781]  eta: 0:02:04  lr: 0.000047  loss: 1.4094 (1.5549)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [420/781]  eta: 0:02:00  lr: 0.000047  loss: 1.4493 (1.5594)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [430/781]  eta: 0:01:57  lr: 0.000047  loss: 1.5126 (1.5570)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [440/781]  eta: 0:01:54  lr: 0.000047  loss: 1.4165 (1.5589)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [450/781]  eta: 0:01:50  lr: 0.000047  loss: 1.4183 (1.5563)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [460/781]  eta: 0:01:47  lr: 0.000047  loss: 1.4475 (1.5559)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [470/781]  eta: 0:01:43  lr: 0.000047  loss: 1.4773 (1.5568)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [32]  [480/781]  eta: 0:01:40  lr: 0.000047  loss: 1.4944 (1.5591)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [490/781]  eta: 0:01:37  lr: 0.000047  loss: 1.4671 (1.5596)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [500/781]  eta: 0:01:33  lr: 0.000047  loss: 1.4586 (1.5571)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [510/781]  eta: 0:01:30  lr: 0.000047  loss: 1.4586 (1.5562)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [520/781]  eta: 0:01:27  lr: 0.000047  loss: 1.4606 (1.5573)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [530/781]  eta: 0:01:23  lr: 0.000047  loss: 1.4584 (1.5555)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [540/781]  eta: 0:01:20  lr: 0.000047  loss: 1.4353 (1.5536)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [550/781]  eta: 0:01:17  lr: 0.000047  loss: 1.4226 (1.5555)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [560/781]  eta: 0:01:13  lr: 0.000047  loss: 1.4899 (1.5558)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [570/781]  eta: 0:01:10  lr: 0.000047  loss: 1.4529 (1.5551)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [580/781]  eta: 0:01:07  lr: 0.000047  loss: 1.4427 (1.5554)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [590/781]  eta: 0:01:03  lr: 0.000047  loss: 1.4787 (1.5549)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [600/781]  eta: 0:01:00  lr: 0.000047  loss: 1.4605 (1.5551)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [610/781]  eta: 0:00:57  lr: 0.000047  loss: 1.4605 (1.5557)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [620/781]  eta: 0:00:53  lr: 0.000047  loss: 1.4548 (1.5561)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [630/781]  eta: 0:00:50  lr: 0.000047  loss: 1.4524 (1.5586)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [640/781]  eta: 0:00:47  lr: 0.000047  loss: 1.4316 (1.5588)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [650/781]  eta: 0:00:43  lr: 0.000047  loss: 1.4702 (1.5610)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [660/781]  eta: 0:00:40  lr: 0.000047  loss: 1.4654 (1.5591)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [670/781]  eta: 0:00:37  lr: 0.000047  loss: 1.4599 (1.5597)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [680/781]  eta: 0:00:33  lr: 0.000047  loss: 1.4885 (1.5600)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [690/781]  eta: 0:00:30  lr: 0.000047  loss: 1.4272 (1.5604)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [700/781]  eta: 0:00:27  lr: 0.000047  loss: 1.4277 (1.5602)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [710/781]  eta: 0:00:23  lr: 0.000047  loss: 1.4586 (1.5599)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [720/781]  eta: 0:00:20  lr: 0.000047  loss: 1.4666 (1.5614)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [730/781]  eta: 0:00:16  lr: 0.000047  loss: 1.4454 (1.5613)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [740/781]  eta: 0:00:13  lr: 0.000047  loss: 1.4362 (1.5640)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [750/781]  eta: 0:00:10  lr: 0.000047  loss: 1.4414 (1.5641)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [760/781]  eta: 0:00:06  lr: 0.000047  loss: 1.4435 (1.5646)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [770/781]  eta: 0:00:03  lr: 0.000047  loss: 1.4586 (1.5672)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [32]  [780/781]  eta: 0:00:00  lr: 0.000047  loss: 1.4237 (1.5649)  time: 0.3319  data: 0.0006  max mem: 6459\n",
            "Epoch: [32] Total time: 0:04:20 (0.3333 s / it)\n",
            "Averaged stats: lr: 0.000047  loss: 1.4237 (1.5649)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32909461855888367, 'lambda_convnext_base': 0.25917956233024597, 'lambda_tf_efficientnetv2_l': 0.4117256700992584}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7334 (0.7334)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8790  data: 0.8483  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9965 (0.9659)  acc1: 78.6458 (79.6402)  acc5: 93.7500 (93.6080)  time: 0.1786  data: 0.1480  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0854 (1.0484)  acc1: 77.6042 (78.2242)  acc5: 92.7083 (92.8323)  time: 0.1309  data: 0.1003  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1507 (1.0856)  acc1: 76.0417 (77.9906)  acc5: 91.6667 (92.5739)  time: 0.1358  data: 0.1053  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:02  loss: 1.1858 (1.1324)  acc1: 76.0417 (77.2485)  acc5: 91.1458 (92.0478)  time: 0.1408  data: 0.1103  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1687 (1.1313)  acc1: 75.0000 (76.9608)  acc5: 91.6667 (92.1773)  time: 0.1385  data: 0.1081  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1958 (1.1390)  acc1: 72.3958 (76.8200)  acc5: 91.6667 (92.2100)  time: 0.1185  data: 0.0889  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1422 s / it)\n",
            "* Acc@1 76.820 Acc@5 92.210 loss 1.139\n",
            "Accuracy of the network on the 10000 test images: 76.8%\n",
            "Max accuracy: 76.82%\n",
            "[alpha-schedule=cosine] epoch=33 distillation_alpha=0.2674\n",
            "Epoch: [33]  [  0/781]  eta: 0:14:34  lr: 0.000046  loss: 1.3138 (1.3138)  time: 1.1200  data: 0.7684  max mem: 6459\n",
            "Epoch: [33]  [ 10/781]  eta: 0:05:11  lr: 0.000046  loss: 1.3914 (1.6056)  time: 0.4036  data: 0.0702  max mem: 6459\n",
            "Epoch: [33]  [ 20/781]  eta: 0:04:40  lr: 0.000046  loss: 1.4089 (1.5482)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 30/781]  eta: 0:04:28  lr: 0.000046  loss: 1.3889 (1.4981)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 40/781]  eta: 0:04:19  lr: 0.000046  loss: 1.4010 (1.4869)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 50/781]  eta: 0:04:13  lr: 0.000046  loss: 1.4732 (1.5294)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 60/781]  eta: 0:04:08  lr: 0.000046  loss: 1.4732 (1.5212)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 70/781]  eta: 0:04:03  lr: 0.000046  loss: 1.4277 (1.5260)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 80/781]  eta: 0:03:59  lr: 0.000046  loss: 1.4762 (1.5611)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [ 90/781]  eta: 0:03:55  lr: 0.000046  loss: 1.4507 (1.5498)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [100/781]  eta: 0:03:51  lr: 0.000046  loss: 1.4017 (1.5388)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [110/781]  eta: 0:03:47  lr: 0.000046  loss: 1.4281 (1.5501)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [120/781]  eta: 0:03:43  lr: 0.000046  loss: 1.4219 (1.5478)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [33]  [130/781]  eta: 0:03:39  lr: 0.000046  loss: 1.4211 (1.5492)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [140/781]  eta: 0:03:36  lr: 0.000046  loss: 1.4336 (1.5538)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [150/781]  eta: 0:03:32  lr: 0.000046  loss: 1.4584 (1.5495)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [160/781]  eta: 0:03:29  lr: 0.000046  loss: 1.4003 (1.5475)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [33]  [170/781]  eta: 0:03:25  lr: 0.000046  loss: 1.4892 (1.5561)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [33]  [180/781]  eta: 0:03:22  lr: 0.000046  loss: 1.5157 (1.5518)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [190/781]  eta: 0:03:18  lr: 0.000046  loss: 1.4291 (1.5519)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [200/781]  eta: 0:03:15  lr: 0.000046  loss: 1.4155 (1.5488)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [210/781]  eta: 0:03:11  lr: 0.000046  loss: 1.3870 (1.5454)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [220/781]  eta: 0:03:08  lr: 0.000046  loss: 1.3982 (1.5439)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [230/781]  eta: 0:03:04  lr: 0.000046  loss: 1.4221 (1.5480)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [240/781]  eta: 0:03:01  lr: 0.000046  loss: 1.4322 (1.5543)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [250/781]  eta: 0:02:57  lr: 0.000046  loss: 1.4322 (1.5557)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [260/781]  eta: 0:02:54  lr: 0.000046  loss: 1.4719 (1.5573)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [270/781]  eta: 0:02:51  lr: 0.000046  loss: 1.4335 (1.5542)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [280/781]  eta: 0:02:47  lr: 0.000046  loss: 1.4086 (1.5543)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [290/781]  eta: 0:02:44  lr: 0.000046  loss: 1.4413 (1.5600)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [300/781]  eta: 0:02:40  lr: 0.000046  loss: 1.5030 (1.5667)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [310/781]  eta: 0:02:37  lr: 0.000046  loss: 1.4441 (1.5678)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [320/781]  eta: 0:02:34  lr: 0.000046  loss: 1.4270 (1.5636)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [330/781]  eta: 0:02:30  lr: 0.000046  loss: 1.4468 (1.5658)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [33]  [340/781]  eta: 0:02:27  lr: 0.000046  loss: 1.3770 (1.5641)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [33]  [350/781]  eta: 0:02:24  lr: 0.000046  loss: 1.3953 (1.5663)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [360/781]  eta: 0:02:20  lr: 0.000046  loss: 1.4553 (1.5628)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [370/781]  eta: 0:02:17  lr: 0.000046  loss: 1.4373 (1.5613)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [380/781]  eta: 0:02:13  lr: 0.000046  loss: 1.4641 (1.5618)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [390/781]  eta: 0:02:10  lr: 0.000046  loss: 1.4986 (1.5660)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [400/781]  eta: 0:02:07  lr: 0.000046  loss: 1.4609 (1.5642)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [410/781]  eta: 0:02:03  lr: 0.000046  loss: 1.4221 (1.5619)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [420/781]  eta: 0:02:00  lr: 0.000046  loss: 1.4305 (1.5608)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [430/781]  eta: 0:01:57  lr: 0.000046  loss: 1.4610 (1.5592)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [440/781]  eta: 0:01:53  lr: 0.000046  loss: 1.4253 (1.5616)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [450/781]  eta: 0:01:50  lr: 0.000046  loss: 1.4445 (1.5595)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [460/781]  eta: 0:01:47  lr: 0.000046  loss: 1.5168 (1.5660)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [470/781]  eta: 0:01:43  lr: 0.000046  loss: 1.5592 (1.5662)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [480/781]  eta: 0:01:40  lr: 0.000046  loss: 1.4307 (1.5669)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [490/781]  eta: 0:01:37  lr: 0.000046  loss: 1.4329 (1.5667)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [500/781]  eta: 0:01:33  lr: 0.000046  loss: 1.4758 (1.5669)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [510/781]  eta: 0:01:30  lr: 0.000046  loss: 1.4758 (1.5687)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [520/781]  eta: 0:01:27  lr: 0.000046  loss: 1.4609 (1.5697)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [530/781]  eta: 0:01:23  lr: 0.000046  loss: 1.4528 (1.5683)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [540/781]  eta: 0:01:20  lr: 0.000046  loss: 1.4305 (1.5686)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [550/781]  eta: 0:01:17  lr: 0.000046  loss: 1.4305 (1.5680)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [560/781]  eta: 0:01:13  lr: 0.000046  loss: 1.4362 (1.5689)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [570/781]  eta: 0:01:10  lr: 0.000046  loss: 1.4447 (1.5685)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [580/781]  eta: 0:01:06  lr: 0.000046  loss: 1.4447 (1.5691)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [590/781]  eta: 0:01:03  lr: 0.000046  loss: 1.4516 (1.5698)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [600/781]  eta: 0:01:00  lr: 0.000046  loss: 1.4422 (1.5676)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [610/781]  eta: 0:00:56  lr: 0.000046  loss: 1.4374 (1.5658)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [620/781]  eta: 0:00:53  lr: 0.000046  loss: 1.3841 (1.5644)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [630/781]  eta: 0:00:50  lr: 0.000046  loss: 1.3841 (1.5642)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [640/781]  eta: 0:00:46  lr: 0.000046  loss: 1.4175 (1.5623)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [650/781]  eta: 0:00:43  lr: 0.000046  loss: 1.4024 (1.5611)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [660/781]  eta: 0:00:40  lr: 0.000046  loss: 1.4024 (1.5645)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [670/781]  eta: 0:00:36  lr: 0.000046  loss: 1.4315 (1.5627)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [680/781]  eta: 0:00:33  lr: 0.000046  loss: 1.4214 (1.5620)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [690/781]  eta: 0:00:30  lr: 0.000046  loss: 1.4275 (1.5623)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [700/781]  eta: 0:00:26  lr: 0.000046  loss: 1.4331 (1.5623)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [710/781]  eta: 0:00:23  lr: 0.000046  loss: 1.4330 (1.5646)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [720/781]  eta: 0:00:20  lr: 0.000046  loss: 1.4330 (1.5658)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [730/781]  eta: 0:00:16  lr: 0.000046  loss: 1.4153 (1.5641)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [740/781]  eta: 0:00:13  lr: 0.000046  loss: 1.4153 (1.5639)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [750/781]  eta: 0:00:10  lr: 0.000046  loss: 1.4291 (1.5638)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [760/781]  eta: 0:00:06  lr: 0.000046  loss: 1.4389 (1.5646)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [770/781]  eta: 0:00:03  lr: 0.000046  loss: 1.5219 (1.5675)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [33]  [780/781]  eta: 0:00:00  lr: 0.000046  loss: 1.5083 (1.5668)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [33] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000046  loss: 1.5083 (1.5668)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32807889580726624, 'lambda_convnext_base': 0.259855180978775, 'lambda_tf_efficientnetv2_l': 0.41206568479537964}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8224 (0.8224)  acc1: 80.7292 (80.7292)  acc5: 94.7917 (94.7917)  time: 0.8458  data: 0.8152  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0140 (0.9826)  acc1: 80.7292 (79.5455)  acc5: 94.2708 (93.3239)  time: 0.1753  data: 0.1449  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0561 (1.0283)  acc1: 79.1667 (79.0179)  acc5: 93.2292 (92.6835)  time: 0.1256  data: 0.0951  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1158 (1.0807)  acc1: 75.5208 (77.9738)  acc5: 90.6250 (91.9859)  time: 0.1350  data: 0.1045  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2007 (1.1187)  acc1: 75.0000 (77.1596)  acc5: 90.1042 (91.5650)  time: 0.1306  data: 0.1001  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0955 (1.1153)  acc1: 75.5208 (77.0221)  acc5: 92.1875 (91.8096)  time: 0.1381  data: 0.1076  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1287 (1.1228)  acc1: 74.4792 (76.8500)  acc5: 92.1875 (91.8600)  time: 0.1288  data: 0.0993  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1411 s / it)\n",
            "* Acc@1 76.850 Acc@5 91.860 loss 1.123\n",
            "Accuracy of the network on the 10000 test images: 76.9%\n",
            "Max accuracy: 76.85%\n",
            "[alpha-schedule=cosine] epoch=34 distillation_alpha=0.2763\n",
            "Epoch: [34]  [  0/781]  eta: 0:14:30  lr: 0.000045  loss: 2.4287 (2.4287)  time: 1.1149  data: 0.7729  max mem: 6459\n",
            "Epoch: [34]  [ 10/781]  eta: 0:05:11  lr: 0.000045  loss: 1.4393 (1.7384)  time: 0.4036  data: 0.0706  max mem: 6459\n",
            "Epoch: [34]  [ 20/781]  eta: 0:04:41  lr: 0.000045  loss: 1.3977 (1.6086)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 30/781]  eta: 0:04:28  lr: 0.000045  loss: 1.3931 (1.5545)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 40/781]  eta: 0:04:19  lr: 0.000045  loss: 1.4560 (1.6080)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 50/781]  eta: 0:04:13  lr: 0.000045  loss: 1.4564 (1.5826)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 60/781]  eta: 0:04:08  lr: 0.000045  loss: 1.4564 (1.6032)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 70/781]  eta: 0:04:03  lr: 0.000045  loss: 1.5327 (1.6135)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 80/781]  eta: 0:03:59  lr: 0.000045  loss: 1.4477 (1.6174)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [ 90/781]  eta: 0:03:55  lr: 0.000045  loss: 1.4929 (1.6031)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [100/781]  eta: 0:03:51  lr: 0.000045  loss: 1.4530 (1.5937)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [110/781]  eta: 0:03:47  lr: 0.000045  loss: 1.4409 (1.5995)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [120/781]  eta: 0:03:43  lr: 0.000045  loss: 1.4875 (1.6004)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [130/781]  eta: 0:03:39  lr: 0.000045  loss: 1.3984 (1.5929)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [140/781]  eta: 0:03:36  lr: 0.000045  loss: 1.4035 (1.5840)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [150/781]  eta: 0:03:32  lr: 0.000045  loss: 1.4335 (1.5830)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [160/781]  eta: 0:03:28  lr: 0.000045  loss: 1.3543 (1.5797)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [170/781]  eta: 0:03:25  lr: 0.000045  loss: 1.3543 (1.5702)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [180/781]  eta: 0:03:21  lr: 0.000045  loss: 1.4355 (1.5720)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [190/781]  eta: 0:03:18  lr: 0.000045  loss: 1.4957 (1.5813)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [200/781]  eta: 0:03:15  lr: 0.000045  loss: 1.4957 (1.5775)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [210/781]  eta: 0:03:11  lr: 0.000045  loss: 1.4916 (1.5784)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [220/781]  eta: 0:03:08  lr: 0.000045  loss: 1.4979 (1.5779)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [230/781]  eta: 0:03:04  lr: 0.000045  loss: 1.4232 (1.5787)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [240/781]  eta: 0:03:01  lr: 0.000045  loss: 1.4232 (1.5766)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [250/781]  eta: 0:02:57  lr: 0.000045  loss: 1.4089 (1.5691)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [260/781]  eta: 0:02:54  lr: 0.000045  loss: 1.3939 (1.5631)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [270/781]  eta: 0:02:51  lr: 0.000045  loss: 1.3939 (1.5605)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [280/781]  eta: 0:02:47  lr: 0.000045  loss: 1.4198 (1.5620)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [290/781]  eta: 0:02:44  lr: 0.000045  loss: 1.4979 (1.5700)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [300/781]  eta: 0:02:40  lr: 0.000045  loss: 1.4535 (1.5673)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [310/781]  eta: 0:02:37  lr: 0.000045  loss: 1.4000 (1.5636)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [320/781]  eta: 0:02:34  lr: 0.000045  loss: 1.4455 (1.5752)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [330/781]  eta: 0:02:30  lr: 0.000045  loss: 1.4395 (1.5734)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [340/781]  eta: 0:02:27  lr: 0.000045  loss: 1.4472 (1.5776)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [350/781]  eta: 0:02:23  lr: 0.000045  loss: 1.5066 (1.5812)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [360/781]  eta: 0:02:20  lr: 0.000045  loss: 1.5066 (1.5807)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [370/781]  eta: 0:02:17  lr: 0.000045  loss: 1.4261 (1.5764)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [380/781]  eta: 0:02:13  lr: 0.000045  loss: 1.4261 (1.5756)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [390/781]  eta: 0:02:10  lr: 0.000045  loss: 1.4681 (1.5736)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [400/781]  eta: 0:02:07  lr: 0.000045  loss: 1.4523 (1.5727)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [410/781]  eta: 0:02:03  lr: 0.000045  loss: 1.4860 (1.5727)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [420/781]  eta: 0:02:00  lr: 0.000045  loss: 1.4597 (1.5727)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [430/781]  eta: 0:01:57  lr: 0.000045  loss: 1.4594 (1.5766)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [440/781]  eta: 0:01:53  lr: 0.000045  loss: 1.4026 (1.5720)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [450/781]  eta: 0:01:50  lr: 0.000045  loss: 1.4003 (1.5731)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [460/781]  eta: 0:01:47  lr: 0.000045  loss: 1.4003 (1.5692)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [470/781]  eta: 0:01:43  lr: 0.000045  loss: 1.4074 (1.5729)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [480/781]  eta: 0:01:40  lr: 0.000045  loss: 1.4146 (1.5740)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [490/781]  eta: 0:01:37  lr: 0.000045  loss: 1.4145 (1.5734)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [500/781]  eta: 0:01:33  lr: 0.000045  loss: 1.4459 (1.5714)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [510/781]  eta: 0:01:30  lr: 0.000045  loss: 1.4160 (1.5679)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [520/781]  eta: 0:01:27  lr: 0.000045  loss: 1.3862 (1.5699)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [530/781]  eta: 0:01:23  lr: 0.000045  loss: 1.4467 (1.5692)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [540/781]  eta: 0:01:20  lr: 0.000045  loss: 1.4113 (1.5656)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [550/781]  eta: 0:01:16  lr: 0.000045  loss: 1.3684 (1.5667)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [560/781]  eta: 0:01:13  lr: 0.000045  loss: 1.3656 (1.5665)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [570/781]  eta: 0:01:10  lr: 0.000045  loss: 1.4646 (1.5646)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [580/781]  eta: 0:01:06  lr: 0.000045  loss: 1.4679 (1.5658)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [590/781]  eta: 0:01:03  lr: 0.000045  loss: 1.4679 (1.5659)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [600/781]  eta: 0:01:00  lr: 0.000045  loss: 1.4442 (1.5645)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [610/781]  eta: 0:00:56  lr: 0.000045  loss: 1.4312 (1.5655)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [620/781]  eta: 0:00:53  lr: 0.000045  loss: 1.5052 (1.5684)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [630/781]  eta: 0:00:50  lr: 0.000045  loss: 1.3999 (1.5665)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [34]  [640/781]  eta: 0:00:46  lr: 0.000045  loss: 1.3987 (1.5654)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [650/781]  eta: 0:00:43  lr: 0.000045  loss: 1.4011 (1.5647)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [660/781]  eta: 0:00:40  lr: 0.000045  loss: 1.4307 (1.5655)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [670/781]  eta: 0:00:36  lr: 0.000045  loss: 1.4594 (1.5645)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [680/781]  eta: 0:00:33  lr: 0.000045  loss: 1.4563 (1.5656)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [690/781]  eta: 0:00:30  lr: 0.000045  loss: 1.4575 (1.5652)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [700/781]  eta: 0:00:26  lr: 0.000045  loss: 1.4536 (1.5629)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [710/781]  eta: 0:00:23  lr: 0.000045  loss: 1.4349 (1.5620)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [720/781]  eta: 0:00:20  lr: 0.000045  loss: 1.4608 (1.5625)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [34]  [730/781]  eta: 0:00:16  lr: 0.000045  loss: 1.4643 (1.5638)  time: 0.3433  data: 0.0004  max mem: 6459\n",
            "Epoch: [34]  [740/781]  eta: 0:00:13  lr: 0.000045  loss: 1.4643 (1.5642)  time: 0.3430  data: 0.0004  max mem: 6459\n",
            "Epoch: [34]  [750/781]  eta: 0:00:10  lr: 0.000045  loss: 1.4387 (1.5632)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [760/781]  eta: 0:00:06  lr: 0.000045  loss: 1.4087 (1.5621)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [770/781]  eta: 0:00:03  lr: 0.000045  loss: 1.4411 (1.5609)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [34]  [780/781]  eta: 0:00:00  lr: 0.000045  loss: 1.4519 (1.5597)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [34] Total time: 0:04:20 (0.3333 s / it)\n",
            "Averaged stats: lr: 0.000045  loss: 1.4519 (1.5597)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3291592001914978, 'lambda_convnext_base': 0.25984904170036316, 'lambda_tf_efficientnetv2_l': 0.4109913110733032}\n",
            "Test:  [ 0/53]  eta: 0:00:48  loss: 0.8217 (0.8217)  acc1: 82.2917 (82.2917)  acc5: 94.7917 (94.7917)  time: 0.9097  data: 0.8790  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0004 (0.9542)  acc1: 80.7292 (79.3087)  acc5: 94.2708 (94.0814)  time: 0.1788  data: 0.1484  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0004 (1.0202)  acc1: 77.6042 (78.4226)  acc5: 93.2292 (93.0060)  time: 0.1260  data: 0.0955  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1694 (1.0796)  acc1: 74.4792 (77.4698)  acc5: 91.6667 (92.4563)  time: 0.1295  data: 0.0991  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2369 (1.1247)  acc1: 73.9583 (76.6895)  acc5: 91.6667 (91.9461)  time: 0.1342  data: 0.1038  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1531 (1.1326)  acc1: 72.3958 (76.2459)  acc5: 91.6667 (92.0241)  time: 0.1347  data: 0.1042  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1531 (1.1320)  acc1: 72.9167 (76.1800)  acc5: 92.1875 (92.0800)  time: 0.1135  data: 0.0839  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1386 s / it)\n",
            "* Acc@1 76.180 Acc@5 92.080 loss 1.132\n",
            "Accuracy of the network on the 10000 test images: 76.2%\n",
            "Max accuracy: 76.85%\n",
            "[alpha-schedule=cosine] epoch=35 distillation_alpha=0.2853\n",
            "Epoch: [35]  [  0/781]  eta: 0:15:06  lr: 0.000044  loss: 1.4087 (1.4087)  time: 1.1610  data: 0.8143  max mem: 6459\n",
            "Epoch: [35]  [ 10/781]  eta: 0:05:13  lr: 0.000044  loss: 1.4087 (1.5413)  time: 0.4070  data: 0.0743  max mem: 6459\n",
            "Epoch: [35]  [ 20/781]  eta: 0:04:42  lr: 0.000044  loss: 1.3820 (1.5855)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 30/781]  eta: 0:04:29  lr: 0.000044  loss: 1.4082 (1.5977)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 40/781]  eta: 0:04:20  lr: 0.000044  loss: 1.4356 (1.6153)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 50/781]  eta: 0:04:14  lr: 0.000044  loss: 1.4274 (1.5850)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 60/781]  eta: 0:04:08  lr: 0.000044  loss: 1.4560 (1.6044)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 70/781]  eta: 0:04:04  lr: 0.000044  loss: 1.4675 (1.6124)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 80/781]  eta: 0:03:59  lr: 0.000044  loss: 1.3799 (1.5896)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [ 90/781]  eta: 0:03:55  lr: 0.000044  loss: 1.3985 (1.5829)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [100/781]  eta: 0:03:51  lr: 0.000044  loss: 1.4077 (1.5703)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [110/781]  eta: 0:03:47  lr: 0.000044  loss: 1.4281 (1.5703)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [120/781]  eta: 0:03:43  lr: 0.000044  loss: 1.4057 (1.5577)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [130/781]  eta: 0:03:40  lr: 0.000044  loss: 1.4045 (1.5467)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [140/781]  eta: 0:03:36  lr: 0.000044  loss: 1.4114 (1.5461)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [150/781]  eta: 0:03:32  lr: 0.000044  loss: 1.4114 (1.5374)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [160/781]  eta: 0:03:29  lr: 0.000044  loss: 1.4310 (1.5401)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [170/781]  eta: 0:03:25  lr: 0.000044  loss: 1.4233 (1.5333)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [180/781]  eta: 0:03:22  lr: 0.000044  loss: 1.4099 (1.5304)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [190/781]  eta: 0:03:18  lr: 0.000044  loss: 1.4138 (1.5454)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [200/781]  eta: 0:03:15  lr: 0.000044  loss: 1.4402 (1.5462)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [210/781]  eta: 0:03:11  lr: 0.000044  loss: 1.4210 (1.5447)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [220/781]  eta: 0:03:08  lr: 0.000044  loss: 1.4369 (1.5560)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [230/781]  eta: 0:03:04  lr: 0.000044  loss: 1.4128 (1.5531)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [240/781]  eta: 0:03:01  lr: 0.000044  loss: 1.3672 (1.5469)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [250/781]  eta: 0:02:57  lr: 0.000044  loss: 1.3866 (1.5407)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [260/781]  eta: 0:02:54  lr: 0.000044  loss: 1.3986 (1.5372)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [270/781]  eta: 0:02:51  lr: 0.000044  loss: 1.4318 (1.5385)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [280/781]  eta: 0:02:47  lr: 0.000044  loss: 1.3935 (1.5347)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [290/781]  eta: 0:02:44  lr: 0.000044  loss: 1.3935 (1.5330)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [300/781]  eta: 0:02:40  lr: 0.000044  loss: 1.4010 (1.5317)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [310/781]  eta: 0:02:37  lr: 0.000044  loss: 1.4081 (1.5392)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [320/781]  eta: 0:02:34  lr: 0.000044  loss: 1.4896 (1.5444)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [330/781]  eta: 0:02:30  lr: 0.000044  loss: 1.4534 (1.5434)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [340/781]  eta: 0:02:27  lr: 0.000044  loss: 1.4304 (1.5409)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [350/781]  eta: 0:02:24  lr: 0.000044  loss: 1.4304 (1.5383)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [360/781]  eta: 0:02:20  lr: 0.000044  loss: 1.4543 (1.5445)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [370/781]  eta: 0:02:17  lr: 0.000044  loss: 1.4543 (1.5439)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [380/781]  eta: 0:02:13  lr: 0.000044  loss: 1.3960 (1.5417)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [390/781]  eta: 0:02:10  lr: 0.000044  loss: 1.4127 (1.5443)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [400/781]  eta: 0:02:07  lr: 0.000044  loss: 1.4239 (1.5490)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [410/781]  eta: 0:02:03  lr: 0.000044  loss: 1.4318 (1.5468)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [420/781]  eta: 0:02:00  lr: 0.000044  loss: 1.4398 (1.5549)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [430/781]  eta: 0:01:57  lr: 0.000044  loss: 1.4619 (1.5544)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [440/781]  eta: 0:01:53  lr: 0.000044  loss: 1.4345 (1.5552)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [450/781]  eta: 0:01:50  lr: 0.000044  loss: 1.4345 (1.5551)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [460/781]  eta: 0:01:47  lr: 0.000044  loss: 1.4060 (1.5531)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [470/781]  eta: 0:01:43  lr: 0.000044  loss: 1.4334 (1.5604)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [480/781]  eta: 0:01:40  lr: 0.000044  loss: 1.5589 (1.5642)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [490/781]  eta: 0:01:37  lr: 0.000044  loss: 1.4192 (1.5611)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [500/781]  eta: 0:01:33  lr: 0.000044  loss: 1.4114 (1.5583)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [510/781]  eta: 0:01:30  lr: 0.000044  loss: 1.4462 (1.5582)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [520/781]  eta: 0:01:26  lr: 0.000044  loss: 1.4846 (1.5620)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [530/781]  eta: 0:01:23  lr: 0.000044  loss: 1.4846 (1.5624)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [540/781]  eta: 0:01:20  lr: 0.000044  loss: 1.4217 (1.5638)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [550/781]  eta: 0:01:16  lr: 0.000044  loss: 1.4656 (1.5675)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [560/781]  eta: 0:01:13  lr: 0.000044  loss: 1.4647 (1.5697)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [570/781]  eta: 0:01:10  lr: 0.000044  loss: 1.4195 (1.5683)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [580/781]  eta: 0:01:06  lr: 0.000044  loss: 1.4233 (1.5687)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [590/781]  eta: 0:01:03  lr: 0.000044  loss: 1.4236 (1.5679)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [600/781]  eta: 0:01:00  lr: 0.000044  loss: 1.4782 (1.5698)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [610/781]  eta: 0:00:56  lr: 0.000044  loss: 1.4459 (1.5672)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [620/781]  eta: 0:00:53  lr: 0.000044  loss: 1.4236 (1.5704)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [630/781]  eta: 0:00:50  lr: 0.000044  loss: 1.4435 (1.5701)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [640/781]  eta: 0:00:46  lr: 0.000044  loss: 1.4756 (1.5730)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [650/781]  eta: 0:00:43  lr: 0.000044  loss: 1.5063 (1.5742)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [660/781]  eta: 0:00:40  lr: 0.000044  loss: 1.4738 (1.5733)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [670/781]  eta: 0:00:36  lr: 0.000044  loss: 1.4117 (1.5730)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [680/781]  eta: 0:00:33  lr: 0.000044  loss: 1.4117 (1.5738)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [690/781]  eta: 0:00:30  lr: 0.000044  loss: 1.4367 (1.5723)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [700/781]  eta: 0:00:26  lr: 0.000044  loss: 1.4110 (1.5719)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [710/781]  eta: 0:00:23  lr: 0.000044  loss: 1.4185 (1.5714)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [720/781]  eta: 0:00:20  lr: 0.000044  loss: 1.4025 (1.5694)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [730/781]  eta: 0:00:16  lr: 0.000044  loss: 1.4187 (1.5715)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [740/781]  eta: 0:00:13  lr: 0.000044  loss: 1.4187 (1.5702)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [750/781]  eta: 0:00:10  lr: 0.000044  loss: 1.4168 (1.5725)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [760/781]  eta: 0:00:06  lr: 0.000044  loss: 1.4401 (1.5732)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [770/781]  eta: 0:00:03  lr: 0.000044  loss: 1.4401 (1.5767)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [35]  [780/781]  eta: 0:00:00  lr: 0.000044  loss: 1.4531 (1.5755)  time: 0.3323  data: 0.0006  max mem: 6459\n",
            "Epoch: [35] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000044  loss: 1.4531 (1.5755)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32825347781181335, 'lambda_convnext_base': 0.2603854238986969, 'lambda_tf_efficientnetv2_l': 0.41136109828948975}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.6934 (0.6934)  acc1: 84.8958 (84.8958)  acc5: 95.3125 (95.3125)  time: 0.8426  data: 0.8119  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9931 (0.9640)  acc1: 80.7292 (78.9299)  acc5: 94.2708 (93.4659)  time: 0.1756  data: 0.1450  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0652 (1.0402)  acc1: 77.0833 (78.3730)  acc5: 92.7083 (92.7827)  time: 0.1301  data: 0.0996  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1622 (1.0885)  acc1: 75.0000 (77.6042)  acc5: 91.6667 (92.5235)  time: 0.1296  data: 0.0992  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2256 (1.1254)  acc1: 73.9583 (76.7912)  acc5: 91.6667 (92.1748)  time: 0.1309  data: 0.1004  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1032 (1.1266)  acc1: 73.4375 (76.5217)  acc5: 92.1875 (92.3509)  time: 0.1314  data: 0.1010  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1289 (1.1377)  acc1: 72.9167 (76.4400)  acc5: 92.1875 (92.3900)  time: 0.1109  data: 0.0812  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1368 s / it)\n",
            "* Acc@1 76.440 Acc@5 92.390 loss 1.138\n",
            "Accuracy of the network on the 10000 test images: 76.4%\n",
            "Max accuracy: 76.85%\n",
            "[alpha-schedule=cosine] epoch=36 distillation_alpha=0.2944\n",
            "Epoch: [36]  [  0/781]  eta: 0:14:27  lr: 0.000043  loss: 1.3687 (1.3687)  time: 1.1112  data: 0.7674  max mem: 6459\n",
            "Epoch: [36]  [ 10/781]  eta: 0:05:11  lr: 0.000043  loss: 1.4025 (1.4725)  time: 0.4036  data: 0.0701  max mem: 6459\n",
            "Epoch: [36]  [ 20/781]  eta: 0:04:41  lr: 0.000043  loss: 1.4384 (1.5728)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 30/781]  eta: 0:04:28  lr: 0.000043  loss: 1.5042 (1.6319)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 40/781]  eta: 0:04:20  lr: 0.000043  loss: 1.4749 (1.6145)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 50/781]  eta: 0:04:13  lr: 0.000043  loss: 1.4568 (1.6069)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 60/781]  eta: 0:04:08  lr: 0.000043  loss: 1.4427 (1.6159)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 70/781]  eta: 0:04:03  lr: 0.000043  loss: 1.4417 (1.6079)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 80/781]  eta: 0:03:59  lr: 0.000043  loss: 1.4333 (1.5955)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [ 90/781]  eta: 0:03:55  lr: 0.000043  loss: 1.4052 (1.5912)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [100/781]  eta: 0:03:51  lr: 0.000043  loss: 1.3888 (1.5793)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [110/781]  eta: 0:03:47  lr: 0.000043  loss: 1.4171 (1.5675)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [120/781]  eta: 0:03:43  lr: 0.000043  loss: 1.4383 (1.5662)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [130/781]  eta: 0:03:39  lr: 0.000043  loss: 1.4521 (1.5689)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [140/781]  eta: 0:03:36  lr: 0.000043  loss: 1.4521 (1.5646)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [150/781]  eta: 0:03:32  lr: 0.000043  loss: 1.4719 (1.5679)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [160/781]  eta: 0:03:29  lr: 0.000043  loss: 1.4742 (1.5732)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [170/781]  eta: 0:03:25  lr: 0.000043  loss: 1.4391 (1.5758)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [180/781]  eta: 0:03:22  lr: 0.000043  loss: 1.4494 (1.5901)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [190/781]  eta: 0:03:18  lr: 0.000043  loss: 1.4782 (1.5890)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [200/781]  eta: 0:03:15  lr: 0.000043  loss: 1.4764 (1.5902)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [210/781]  eta: 0:03:11  lr: 0.000043  loss: 1.4133 (1.5925)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [220/781]  eta: 0:03:08  lr: 0.000043  loss: 1.4393 (1.5901)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [230/781]  eta: 0:03:04  lr: 0.000043  loss: 1.4345 (1.5870)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [240/781]  eta: 0:03:01  lr: 0.000043  loss: 1.4147 (1.5831)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [250/781]  eta: 0:02:57  lr: 0.000043  loss: 1.4452 (1.5784)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [260/781]  eta: 0:02:54  lr: 0.000043  loss: 1.4833 (1.5838)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [270/781]  eta: 0:02:51  lr: 0.000043  loss: 1.4724 (1.5797)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [280/781]  eta: 0:02:47  lr: 0.000043  loss: 1.4056 (1.5737)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [290/781]  eta: 0:02:44  lr: 0.000043  loss: 1.3812 (1.5692)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [300/781]  eta: 0:02:40  lr: 0.000043  loss: 1.3920 (1.5666)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [310/781]  eta: 0:02:37  lr: 0.000043  loss: 1.4065 (1.5652)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [320/781]  eta: 0:02:34  lr: 0.000043  loss: 1.4467 (1.5673)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [330/781]  eta: 0:02:30  lr: 0.000043  loss: 1.4174 (1.5631)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [340/781]  eta: 0:02:27  lr: 0.000043  loss: 1.3826 (1.5588)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [350/781]  eta: 0:02:23  lr: 0.000043  loss: 1.3926 (1.5585)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [360/781]  eta: 0:02:20  lr: 0.000043  loss: 1.4338 (1.5642)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [370/781]  eta: 0:02:17  lr: 0.000043  loss: 1.4660 (1.5634)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [380/781]  eta: 0:02:13  lr: 0.000043  loss: 1.4147 (1.5599)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [390/781]  eta: 0:02:10  lr: 0.000043  loss: 1.4534 (1.5628)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [400/781]  eta: 0:02:07  lr: 0.000043  loss: 1.4017 (1.5580)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [410/781]  eta: 0:02:03  lr: 0.000043  loss: 1.3666 (1.5599)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [420/781]  eta: 0:02:00  lr: 0.000043  loss: 1.4613 (1.5606)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [430/781]  eta: 0:01:57  lr: 0.000043  loss: 1.3984 (1.5591)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [440/781]  eta: 0:01:53  lr: 0.000043  loss: 1.4428 (1.5617)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [450/781]  eta: 0:01:50  lr: 0.000043  loss: 1.4357 (1.5586)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [460/781]  eta: 0:01:47  lr: 0.000043  loss: 1.3788 (1.5561)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [470/781]  eta: 0:01:43  lr: 0.000043  loss: 1.4097 (1.5558)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [480/781]  eta: 0:01:40  lr: 0.000043  loss: 1.4270 (1.5570)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [490/781]  eta: 0:01:37  lr: 0.000043  loss: 1.4270 (1.5587)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [500/781]  eta: 0:01:33  lr: 0.000043  loss: 1.3857 (1.5570)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [510/781]  eta: 0:01:30  lr: 0.000043  loss: 1.4374 (1.5581)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [520/781]  eta: 0:01:26  lr: 0.000043  loss: 1.4478 (1.5581)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [530/781]  eta: 0:01:23  lr: 0.000043  loss: 1.3803 (1.5566)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [540/781]  eta: 0:01:20  lr: 0.000043  loss: 1.3803 (1.5547)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [550/781]  eta: 0:01:16  lr: 0.000043  loss: 1.3808 (1.5557)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [560/781]  eta: 0:01:13  lr: 0.000043  loss: 1.3808 (1.5563)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [570/781]  eta: 0:01:10  lr: 0.000043  loss: 1.4192 (1.5575)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [580/781]  eta: 0:01:06  lr: 0.000043  loss: 1.4169 (1.5562)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [590/781]  eta: 0:01:03  lr: 0.000043  loss: 1.4302 (1.5562)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [600/781]  eta: 0:01:00  lr: 0.000043  loss: 1.4983 (1.5581)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [610/781]  eta: 0:00:56  lr: 0.000043  loss: 1.4161 (1.5580)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [620/781]  eta: 0:00:53  lr: 0.000043  loss: 1.4715 (1.5610)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [630/781]  eta: 0:00:50  lr: 0.000043  loss: 1.4715 (1.5616)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [640/781]  eta: 0:00:46  lr: 0.000043  loss: 1.4317 (1.5612)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [650/781]  eta: 0:00:43  lr: 0.000043  loss: 1.4282 (1.5613)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [660/781]  eta: 0:00:40  lr: 0.000043  loss: 1.4314 (1.5596)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [670/781]  eta: 0:00:36  lr: 0.000043  loss: 1.4459 (1.5603)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [680/781]  eta: 0:00:33  lr: 0.000043  loss: 1.4267 (1.5614)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [690/781]  eta: 0:00:30  lr: 0.000043  loss: 1.3917 (1.5591)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [700/781]  eta: 0:00:26  lr: 0.000043  loss: 1.4439 (1.5588)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [710/781]  eta: 0:00:23  lr: 0.000043  loss: 1.4800 (1.5603)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [720/781]  eta: 0:00:20  lr: 0.000043  loss: 1.4506 (1.5614)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [730/781]  eta: 0:00:16  lr: 0.000043  loss: 1.4663 (1.5633)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [740/781]  eta: 0:00:13  lr: 0.000043  loss: 1.4663 (1.5644)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [750/781]  eta: 0:00:10  lr: 0.000043  loss: 1.4235 (1.5628)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [760/781]  eta: 0:00:06  lr: 0.000043  loss: 1.4260 (1.5636)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [770/781]  eta: 0:00:03  lr: 0.000043  loss: 1.4548 (1.5648)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [36]  [780/781]  eta: 0:00:00  lr: 0.000043  loss: 1.4070 (1.5638)  time: 0.3319  data: 0.0006  max mem: 6459\n",
            "Epoch: [36] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000043  loss: 1.4070 (1.5638)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32848063111305237, 'lambda_convnext_base': 0.26004791259765625, 'lambda_tf_efficientnetv2_l': 0.4114709198474884}\n",
            "Test:  [ 0/53]  eta: 0:00:47  loss: 0.7544 (0.7544)  acc1: 83.3333 (83.3333)  acc5: 96.3542 (96.3542)  time: 0.8888  data: 0.8581  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0096 (0.9802)  acc1: 81.7708 (80.0663)  acc5: 94.2708 (93.6553)  time: 0.1698  data: 0.1393  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0555 (1.0567)  acc1: 76.5625 (78.6706)  acc5: 93.2292 (92.8075)  time: 0.1126  data: 0.0821  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1658 (1.1037)  acc1: 75.5208 (77.9906)  acc5: 91.1458 (92.1875)  time: 0.1216  data: 0.0912  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2135 (1.1451)  acc1: 75.5208 (77.0579)  acc5: 90.6250 (91.8191)  time: 0.1146  data: 0.0831  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1214 (1.1427)  acc1: 73.9583 (76.7361)  acc5: 91.6667 (92.0650)  time: 0.1128  data: 0.0795  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1575 (1.1480)  acc1: 75.0000 (76.7100)  acc5: 93.2292 (92.1000)  time: 0.1107  data: 0.0780  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1281 s / it)\n",
            "* Acc@1 76.710 Acc@5 92.100 loss 1.148\n",
            "Accuracy of the network on the 10000 test images: 76.7%\n",
            "Max accuracy: 76.85%\n",
            "[alpha-schedule=cosine] epoch=37 distillation_alpha=0.3035\n",
            "Epoch: [37]  [  0/781]  eta: 0:15:05  lr: 0.000042  loss: 1.3524 (1.3524)  time: 1.1588  data: 0.7991  max mem: 6459\n",
            "Epoch: [37]  [ 10/781]  eta: 0:05:14  lr: 0.000042  loss: 1.4765 (1.5298)  time: 0.4074  data: 0.0730  max mem: 6459\n",
            "Epoch: [37]  [ 20/781]  eta: 0:04:42  lr: 0.000042  loss: 1.4162 (1.5131)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 30/781]  eta: 0:04:29  lr: 0.000042  loss: 1.4069 (1.5459)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 40/781]  eta: 0:04:20  lr: 0.000042  loss: 1.4069 (1.5303)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 50/781]  eta: 0:04:14  lr: 0.000042  loss: 1.4003 (1.5215)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 60/781]  eta: 0:04:09  lr: 0.000042  loss: 1.4067 (1.5595)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 70/781]  eta: 0:04:04  lr: 0.000042  loss: 1.4412 (1.5636)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 80/781]  eta: 0:03:59  lr: 0.000042  loss: 1.4196 (1.5480)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [ 90/781]  eta: 0:03:55  lr: 0.000042  loss: 1.4111 (1.5455)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [100/781]  eta: 0:03:51  lr: 0.000042  loss: 1.4203 (1.5333)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [110/781]  eta: 0:03:47  lr: 0.000042  loss: 1.4203 (1.5275)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [120/781]  eta: 0:03:43  lr: 0.000042  loss: 1.4208 (1.5337)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [130/781]  eta: 0:03:40  lr: 0.000042  loss: 1.4406 (1.5457)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [140/781]  eta: 0:03:36  lr: 0.000042  loss: 1.4071 (1.5426)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [150/781]  eta: 0:03:32  lr: 0.000042  loss: 1.4071 (1.5535)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [160/781]  eta: 0:03:29  lr: 0.000042  loss: 1.4349 (1.5523)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [170/781]  eta: 0:03:25  lr: 0.000042  loss: 1.4307 (1.5528)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [180/781]  eta: 0:03:22  lr: 0.000042  loss: 1.4492 (1.5494)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [190/781]  eta: 0:03:18  lr: 0.000042  loss: 1.4556 (1.5524)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [200/781]  eta: 0:03:15  lr: 0.000042  loss: 1.4314 (1.5492)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [210/781]  eta: 0:03:11  lr: 0.000042  loss: 1.3580 (1.5424)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [220/781]  eta: 0:03:08  lr: 0.000042  loss: 1.4160 (1.5438)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [230/781]  eta: 0:03:04  lr: 0.000042  loss: 1.4336 (1.5399)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [240/781]  eta: 0:03:01  lr: 0.000042  loss: 1.3882 (1.5336)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [250/781]  eta: 0:02:57  lr: 0.000042  loss: 1.3605 (1.5338)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [260/781]  eta: 0:02:54  lr: 0.000042  loss: 1.4088 (1.5365)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [270/781]  eta: 0:02:51  lr: 0.000042  loss: 1.4292 (1.5425)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [280/781]  eta: 0:02:47  lr: 0.000042  loss: 1.3934 (1.5409)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [290/781]  eta: 0:02:44  lr: 0.000042  loss: 1.3460 (1.5402)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [300/781]  eta: 0:02:40  lr: 0.000042  loss: 1.3933 (1.5434)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [310/781]  eta: 0:02:37  lr: 0.000042  loss: 1.4141 (1.5448)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [320/781]  eta: 0:02:34  lr: 0.000042  loss: 1.4207 (1.5479)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [330/781]  eta: 0:02:30  lr: 0.000042  loss: 1.3652 (1.5424)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [340/781]  eta: 0:02:27  lr: 0.000042  loss: 1.3652 (1.5400)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [350/781]  eta: 0:02:24  lr: 0.000042  loss: 1.3926 (1.5407)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [360/781]  eta: 0:02:20  lr: 0.000042  loss: 1.4215 (1.5418)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [370/781]  eta: 0:02:17  lr: 0.000042  loss: 1.4466 (1.5421)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [380/781]  eta: 0:02:13  lr: 0.000042  loss: 1.4487 (1.5470)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [390/781]  eta: 0:02:10  lr: 0.000042  loss: 1.3973 (1.5451)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [400/781]  eta: 0:02:07  lr: 0.000042  loss: 1.3973 (1.5451)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [410/781]  eta: 0:02:03  lr: 0.000042  loss: 1.4623 (1.5482)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [420/781]  eta: 0:02:00  lr: 0.000042  loss: 1.4177 (1.5483)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [430/781]  eta: 0:01:57  lr: 0.000042  loss: 1.4001 (1.5480)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [440/781]  eta: 0:01:53  lr: 0.000042  loss: 1.4001 (1.5451)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [450/781]  eta: 0:01:50  lr: 0.000042  loss: 1.3615 (1.5447)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [460/781]  eta: 0:01:47  lr: 0.000042  loss: 1.3533 (1.5443)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [470/781]  eta: 0:01:43  lr: 0.000042  loss: 1.3533 (1.5424)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [480/781]  eta: 0:01:40  lr: 0.000042  loss: 1.3957 (1.5413)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [490/781]  eta: 0:01:37  lr: 0.000042  loss: 1.3627 (1.5401)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [500/781]  eta: 0:01:33  lr: 0.000042  loss: 1.4035 (1.5400)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [510/781]  eta: 0:01:30  lr: 0.000042  loss: 1.4355 (1.5448)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [520/781]  eta: 0:01:27  lr: 0.000042  loss: 1.3585 (1.5445)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [530/781]  eta: 0:01:23  lr: 0.000042  loss: 1.4222 (1.5433)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [540/781]  eta: 0:01:20  lr: 0.000042  loss: 1.4705 (1.5414)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [550/781]  eta: 0:01:16  lr: 0.000042  loss: 1.4784 (1.5467)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [560/781]  eta: 0:01:13  lr: 0.000042  loss: 1.5114 (1.5494)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [570/781]  eta: 0:01:10  lr: 0.000042  loss: 1.4086 (1.5516)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [580/781]  eta: 0:01:07  lr: 0.000042  loss: 1.4375 (1.5514)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [590/781]  eta: 0:01:03  lr: 0.000042  loss: 1.4481 (1.5505)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [600/781]  eta: 0:01:00  lr: 0.000042  loss: 1.3798 (1.5472)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [610/781]  eta: 0:00:57  lr: 0.000042  loss: 1.3635 (1.5453)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [620/781]  eta: 0:00:53  lr: 0.000042  loss: 1.4304 (1.5458)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [630/781]  eta: 0:00:50  lr: 0.000042  loss: 1.3911 (1.5430)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [640/781]  eta: 0:00:47  lr: 0.000042  loss: 1.3927 (1.5444)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [650/781]  eta: 0:00:43  lr: 0.000042  loss: 1.4346 (1.5435)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [660/781]  eta: 0:00:40  lr: 0.000042  loss: 1.4281 (1.5428)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [670/781]  eta: 0:00:37  lr: 0.000042  loss: 1.4425 (1.5471)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [680/781]  eta: 0:00:33  lr: 0.000042  loss: 1.5280 (1.5511)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [690/781]  eta: 0:00:30  lr: 0.000042  loss: 1.4400 (1.5516)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [700/781]  eta: 0:00:26  lr: 0.000042  loss: 1.4295 (1.5525)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [710/781]  eta: 0:00:23  lr: 0.000042  loss: 1.4181 (1.5524)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [720/781]  eta: 0:00:20  lr: 0.000042  loss: 1.4617 (1.5534)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [730/781]  eta: 0:00:16  lr: 0.000042  loss: 1.4463 (1.5545)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [740/781]  eta: 0:00:13  lr: 0.000042  loss: 1.4262 (1.5529)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [750/781]  eta: 0:00:10  lr: 0.000042  loss: 1.4262 (1.5535)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [760/781]  eta: 0:00:06  lr: 0.000042  loss: 1.4511 (1.5552)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [770/781]  eta: 0:00:03  lr: 0.000042  loss: 1.4932 (1.5563)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [37]  [780/781]  eta: 0:00:00  lr: 0.000042  loss: 1.4623 (1.5561)  time: 0.3321  data: 0.0006  max mem: 6459\n",
            "Epoch: [37] Total time: 0:04:20 (0.3333 s / it)\n",
            "Averaged stats: lr: 0.000042  loss: 1.4623 (1.5561)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32926931977272034, 'lambda_convnext_base': 0.26043856143951416, 'lambda_tf_efficientnetv2_l': 0.41029229760169983}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7369 (0.7369)  acc1: 85.9375 (85.9375)  acc5: 95.8333 (95.8333)  time: 0.8500  data: 0.8192  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9898 (0.9394)  acc1: 81.2500 (80.7292)  acc5: 94.7917 (93.9867)  time: 0.1799  data: 0.1494  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0312 (1.0247)  acc1: 77.6042 (79.0179)  acc5: 93.7500 (93.2788)  time: 0.1320  data: 0.1016  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2441 (1.0940)  acc1: 74.4792 (77.9906)  acc5: 90.6250 (92.3891)  time: 0.1354  data: 0.1049  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2473 (1.1330)  acc1: 74.4792 (77.2358)  acc5: 90.1042 (91.9970)  time: 0.1347  data: 0.1043  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1645 (1.1350)  acc1: 74.4792 (76.8178)  acc5: 93.2292 (92.1773)  time: 0.1384  data: 0.1079  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1645 (1.1348)  acc1: 74.4792 (76.6900)  acc5: 93.2292 (92.2200)  time: 0.1201  data: 0.0905  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1424 s / it)\n",
            "* Acc@1 76.690 Acc@5 92.220 loss 1.135\n",
            "Accuracy of the network on the 10000 test images: 76.7%\n",
            "Max accuracy: 76.85%\n",
            "[alpha-schedule=cosine] epoch=38 distillation_alpha=0.3127\n",
            "Epoch: [38]  [  0/781]  eta: 0:14:24  lr: 0.000042  loss: 1.3841 (1.3841)  time: 1.1063  data: 0.7546  max mem: 6459\n",
            "Epoch: [38]  [ 10/781]  eta: 0:05:09  lr: 0.000042  loss: 1.4340 (1.7129)  time: 0.4020  data: 0.0689  max mem: 6459\n",
            "Epoch: [38]  [ 20/781]  eta: 0:04:40  lr: 0.000042  loss: 1.4121 (1.6260)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 30/781]  eta: 0:04:27  lr: 0.000042  loss: 1.3198 (1.5451)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 40/781]  eta: 0:04:19  lr: 0.000042  loss: 1.3576 (1.5568)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 50/781]  eta: 0:04:13  lr: 0.000042  loss: 1.3937 (1.5653)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 60/781]  eta: 0:04:08  lr: 0.000042  loss: 1.4252 (1.5633)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 70/781]  eta: 0:04:03  lr: 0.000042  loss: 1.4317 (1.5598)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 80/781]  eta: 0:03:59  lr: 0.000042  loss: 1.4317 (1.5725)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [ 90/781]  eta: 0:03:55  lr: 0.000042  loss: 1.3858 (1.5528)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [100/781]  eta: 0:03:51  lr: 0.000042  loss: 1.3858 (1.5381)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [110/781]  eta: 0:03:47  lr: 0.000042  loss: 1.4038 (1.5300)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [120/781]  eta: 0:03:43  lr: 0.000042  loss: 1.4102 (1.5275)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [130/781]  eta: 0:03:39  lr: 0.000042  loss: 1.4102 (1.5296)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [140/781]  eta: 0:03:36  lr: 0.000042  loss: 1.4379 (1.5464)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [150/781]  eta: 0:03:32  lr: 0.000042  loss: 1.4636 (1.5591)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [160/781]  eta: 0:03:29  lr: 0.000042  loss: 1.3957 (1.5607)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [170/781]  eta: 0:03:25  lr: 0.000042  loss: 1.4024 (1.5608)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [180/781]  eta: 0:03:22  lr: 0.000042  loss: 1.4310 (1.5664)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [190/781]  eta: 0:03:18  lr: 0.000042  loss: 1.4246 (1.5686)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [200/781]  eta: 0:03:15  lr: 0.000042  loss: 1.4417 (1.5681)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [210/781]  eta: 0:03:11  lr: 0.000042  loss: 1.4469 (1.5667)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [220/781]  eta: 0:03:08  lr: 0.000042  loss: 1.4150 (1.5622)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [230/781]  eta: 0:03:04  lr: 0.000042  loss: 1.3916 (1.5590)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [240/781]  eta: 0:03:01  lr: 0.000042  loss: 1.4429 (1.5676)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [250/781]  eta: 0:02:57  lr: 0.000042  loss: 1.5056 (1.5647)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [260/781]  eta: 0:02:54  lr: 0.000042  loss: 1.4211 (1.5688)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [270/781]  eta: 0:02:51  lr: 0.000042  loss: 1.3879 (1.5625)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [280/781]  eta: 0:02:47  lr: 0.000042  loss: 1.3879 (1.5663)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [290/781]  eta: 0:02:44  lr: 0.000042  loss: 1.4139 (1.5696)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [300/781]  eta: 0:02:40  lr: 0.000042  loss: 1.4139 (1.5706)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [310/781]  eta: 0:02:37  lr: 0.000042  loss: 1.4600 (1.5715)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [320/781]  eta: 0:02:34  lr: 0.000042  loss: 1.4199 (1.5671)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [330/781]  eta: 0:02:30  lr: 0.000042  loss: 1.4655 (1.5711)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [340/781]  eta: 0:02:27  lr: 0.000042  loss: 1.3799 (1.5665)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [350/781]  eta: 0:02:24  lr: 0.000042  loss: 1.3799 (1.5674)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [360/781]  eta: 0:02:20  lr: 0.000042  loss: 1.4430 (1.5655)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [370/781]  eta: 0:02:17  lr: 0.000042  loss: 1.4407 (1.5646)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [380/781]  eta: 0:02:13  lr: 0.000042  loss: 1.4068 (1.5658)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [390/781]  eta: 0:02:10  lr: 0.000042  loss: 1.3951 (1.5631)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [400/781]  eta: 0:02:07  lr: 0.000042  loss: 1.4167 (1.5593)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [410/781]  eta: 0:02:03  lr: 0.000042  loss: 1.4439 (1.5619)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [420/781]  eta: 0:02:00  lr: 0.000042  loss: 1.4109 (1.5578)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [430/781]  eta: 0:01:57  lr: 0.000042  loss: 1.3956 (1.5548)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [440/781]  eta: 0:01:53  lr: 0.000042  loss: 1.4267 (1.5554)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [450/781]  eta: 0:01:50  lr: 0.000042  loss: 1.4463 (1.5561)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [460/781]  eta: 0:01:47  lr: 0.000042  loss: 1.4463 (1.5543)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [470/781]  eta: 0:01:43  lr: 0.000042  loss: 1.4098 (1.5525)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [480/781]  eta: 0:01:40  lr: 0.000042  loss: 1.3896 (1.5522)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [490/781]  eta: 0:01:37  lr: 0.000042  loss: 1.4014 (1.5533)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [500/781]  eta: 0:01:33  lr: 0.000042  loss: 1.4014 (1.5548)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [510/781]  eta: 0:01:30  lr: 0.000042  loss: 1.4028 (1.5532)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [520/781]  eta: 0:01:27  lr: 0.000042  loss: 1.4028 (1.5532)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [530/781]  eta: 0:01:23  lr: 0.000042  loss: 1.4225 (1.5535)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [540/781]  eta: 0:01:20  lr: 0.000042  loss: 1.4845 (1.5543)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [550/781]  eta: 0:01:17  lr: 0.000042  loss: 1.4296 (1.5540)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [560/781]  eta: 0:01:13  lr: 0.000042  loss: 1.3894 (1.5514)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [570/781]  eta: 0:01:10  lr: 0.000042  loss: 1.3669 (1.5482)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [580/781]  eta: 0:01:07  lr: 0.000042  loss: 1.3992 (1.5499)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [590/781]  eta: 0:01:03  lr: 0.000042  loss: 1.4365 (1.5494)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [600/781]  eta: 0:01:00  lr: 0.000042  loss: 1.3994 (1.5484)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [610/781]  eta: 0:00:56  lr: 0.000042  loss: 1.3829 (1.5464)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [620/781]  eta: 0:00:53  lr: 0.000042  loss: 1.3632 (1.5443)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [630/781]  eta: 0:00:50  lr: 0.000042  loss: 1.3868 (1.5440)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [640/781]  eta: 0:00:46  lr: 0.000042  loss: 1.3741 (1.5412)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [650/781]  eta: 0:00:43  lr: 0.000042  loss: 1.3882 (1.5440)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [660/781]  eta: 0:00:40  lr: 0.000042  loss: 1.4216 (1.5430)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [670/781]  eta: 0:00:36  lr: 0.000042  loss: 1.3647 (1.5430)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [680/781]  eta: 0:00:33  lr: 0.000042  loss: 1.3981 (1.5446)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [690/781]  eta: 0:00:30  lr: 0.000042  loss: 1.4192 (1.5438)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [700/781]  eta: 0:00:26  lr: 0.000042  loss: 1.4192 (1.5430)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [710/781]  eta: 0:00:23  lr: 0.000042  loss: 1.4212 (1.5416)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [720/781]  eta: 0:00:20  lr: 0.000042  loss: 1.4781 (1.5470)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [730/781]  eta: 0:00:16  lr: 0.000042  loss: 1.4962 (1.5456)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [740/781]  eta: 0:00:13  lr: 0.000042  loss: 1.3784 (1.5461)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [750/781]  eta: 0:00:10  lr: 0.000042  loss: 1.4078 (1.5471)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [760/781]  eta: 0:00:06  lr: 0.000042  loss: 1.4533 (1.5490)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [770/781]  eta: 0:00:03  lr: 0.000042  loss: 1.3917 (1.5482)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [38]  [780/781]  eta: 0:00:00  lr: 0.000042  loss: 1.4204 (1.5489)  time: 0.3320  data: 0.0005  max mem: 6459\n",
            "Epoch: [38] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000042  loss: 1.4204 (1.5489)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3285168707370758, 'lambda_convnext_base': 0.26082339882850647, 'lambda_tf_efficientnetv2_l': 0.41065993905067444}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7501 (0.7501)  acc1: 85.4167 (85.4167)  acc5: 96.3542 (96.3542)  time: 0.8750  data: 0.8443  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9639 (0.9374)  acc1: 81.7708 (80.0663)  acc5: 94.7917 (94.0341)  time: 0.1856  data: 0.1551  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0044 (1.0244)  acc1: 79.1667 (78.7946)  acc5: 92.1875 (92.8323)  time: 0.1363  data: 0.1059  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0876 (1.0827)  acc1: 75.5208 (78.0074)  acc5: 91.6667 (92.2715)  time: 0.1351  data: 0.1047  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1632 (1.1213)  acc1: 75.5208 (77.4009)  acc5: 91.1458 (91.8318)  time: 0.1347  data: 0.1043  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1632 (1.1239)  acc1: 76.0417 (77.0731)  acc5: 92.7083 (92.0854)  time: 0.1345  data: 0.1041  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1665 (1.1334)  acc1: 75.0000 (76.9200)  acc5: 92.7083 (92.0800)  time: 0.1129  data: 0.0833  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1420 s / it)\n",
            "* Acc@1 76.920 Acc@5 92.080 loss 1.133\n",
            "Accuracy of the network on the 10000 test images: 76.9%\n",
            "Max accuracy: 76.92%\n",
            "[alpha-schedule=cosine] epoch=39 distillation_alpha=0.3220\n",
            "Epoch: [39]  [  0/781]  eta: 0:14:58  lr: 0.000041  loss: 1.2167 (1.2167)  time: 1.1503  data: 0.8029  max mem: 6459\n",
            "Epoch: [39]  [ 10/781]  eta: 0:05:13  lr: 0.000041  loss: 1.3593 (1.4643)  time: 0.4062  data: 0.0733  max mem: 6459\n",
            "Epoch: [39]  [ 20/781]  eta: 0:04:42  lr: 0.000041  loss: 1.4002 (1.4702)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 30/781]  eta: 0:04:29  lr: 0.000041  loss: 1.4162 (1.4859)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 40/781]  eta: 0:04:20  lr: 0.000041  loss: 1.4283 (1.5156)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 50/781]  eta: 0:04:14  lr: 0.000041  loss: 1.3662 (1.4894)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 60/781]  eta: 0:04:08  lr: 0.000041  loss: 1.3699 (1.4856)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 70/781]  eta: 0:04:04  lr: 0.000041  loss: 1.4204 (1.4882)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 80/781]  eta: 0:03:59  lr: 0.000041  loss: 1.3865 (1.4954)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [ 90/781]  eta: 0:03:55  lr: 0.000041  loss: 1.3865 (1.4880)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [100/781]  eta: 0:03:51  lr: 0.000041  loss: 1.3995 (1.5020)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [110/781]  eta: 0:03:47  lr: 0.000041  loss: 1.3985 (1.5034)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [120/781]  eta: 0:03:43  lr: 0.000041  loss: 1.4052 (1.5218)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [130/781]  eta: 0:03:40  lr: 0.000041  loss: 1.4231 (1.5289)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [140/781]  eta: 0:03:36  lr: 0.000041  loss: 1.4369 (1.5379)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [150/781]  eta: 0:03:32  lr: 0.000041  loss: 1.4001 (1.5271)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [160/781]  eta: 0:03:29  lr: 0.000041  loss: 1.3807 (1.5203)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [170/781]  eta: 0:03:25  lr: 0.000041  loss: 1.3807 (1.5160)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [180/781]  eta: 0:03:22  lr: 0.000041  loss: 1.3468 (1.5111)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [190/781]  eta: 0:03:18  lr: 0.000041  loss: 1.3844 (1.5132)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [200/781]  eta: 0:03:15  lr: 0.000041  loss: 1.4380 (1.5211)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [210/781]  eta: 0:03:11  lr: 0.000041  loss: 1.4330 (1.5196)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [220/781]  eta: 0:03:08  lr: 0.000041  loss: 1.4008 (1.5147)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [230/781]  eta: 0:03:04  lr: 0.000041  loss: 1.3905 (1.5115)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [240/781]  eta: 0:03:01  lr: 0.000041  loss: 1.3860 (1.5126)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [250/781]  eta: 0:02:57  lr: 0.000041  loss: 1.3765 (1.5077)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [260/781]  eta: 0:02:54  lr: 0.000041  loss: 1.3765 (1.5087)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [270/781]  eta: 0:02:51  lr: 0.000041  loss: 1.3734 (1.5080)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [280/781]  eta: 0:02:47  lr: 0.000041  loss: 1.4132 (1.5117)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [290/781]  eta: 0:02:44  lr: 0.000041  loss: 1.4065 (1.5086)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [300/781]  eta: 0:02:40  lr: 0.000041  loss: 1.4007 (1.5115)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [310/781]  eta: 0:02:37  lr: 0.000041  loss: 1.4187 (1.5131)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [320/781]  eta: 0:02:34  lr: 0.000041  loss: 1.4180 (1.5106)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [330/781]  eta: 0:02:30  lr: 0.000041  loss: 1.3529 (1.5078)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [340/781]  eta: 0:02:27  lr: 0.000041  loss: 1.4173 (1.5092)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [350/781]  eta: 0:02:24  lr: 0.000041  loss: 1.4600 (1.5088)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [360/781]  eta: 0:02:20  lr: 0.000041  loss: 1.3962 (1.5148)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [370/781]  eta: 0:02:17  lr: 0.000041  loss: 1.4140 (1.5142)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [380/781]  eta: 0:02:13  lr: 0.000041  loss: 1.4230 (1.5196)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [390/781]  eta: 0:02:10  lr: 0.000041  loss: 1.4262 (1.5185)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [400/781]  eta: 0:02:07  lr: 0.000041  loss: 1.4262 (1.5220)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [410/781]  eta: 0:02:03  lr: 0.000041  loss: 1.4100 (1.5206)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [420/781]  eta: 0:02:00  lr: 0.000041  loss: 1.4092 (1.5211)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [430/781]  eta: 0:01:57  lr: 0.000041  loss: 1.3987 (1.5184)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [440/781]  eta: 0:01:53  lr: 0.000041  loss: 1.3793 (1.5150)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [450/781]  eta: 0:01:50  lr: 0.000041  loss: 1.3905 (1.5144)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [460/781]  eta: 0:01:47  lr: 0.000041  loss: 1.3979 (1.5159)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [470/781]  eta: 0:01:43  lr: 0.000041  loss: 1.4069 (1.5161)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [480/781]  eta: 0:01:40  lr: 0.000041  loss: 1.3687 (1.5160)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [490/781]  eta: 0:01:37  lr: 0.000041  loss: 1.3549 (1.5135)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [500/781]  eta: 0:01:33  lr: 0.000041  loss: 1.3549 (1.5105)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [510/781]  eta: 0:01:30  lr: 0.000041  loss: 1.4176 (1.5102)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [520/781]  eta: 0:01:27  lr: 0.000041  loss: 1.4371 (1.5083)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [530/781]  eta: 0:01:23  lr: 0.000041  loss: 1.3916 (1.5090)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [540/781]  eta: 0:01:20  lr: 0.000041  loss: 1.4087 (1.5089)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [550/781]  eta: 0:01:17  lr: 0.000041  loss: 1.3942 (1.5075)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [560/781]  eta: 0:01:13  lr: 0.000041  loss: 1.4016 (1.5093)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [570/781]  eta: 0:01:10  lr: 0.000041  loss: 1.4600 (1.5096)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [580/781]  eta: 0:01:06  lr: 0.000041  loss: 1.3916 (1.5095)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [590/781]  eta: 0:01:03  lr: 0.000041  loss: 1.4552 (1.5108)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [600/781]  eta: 0:01:00  lr: 0.000041  loss: 1.4889 (1.5160)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [610/781]  eta: 0:00:56  lr: 0.000041  loss: 1.4362 (1.5152)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [620/781]  eta: 0:00:53  lr: 0.000041  loss: 1.4157 (1.5155)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [630/781]  eta: 0:00:50  lr: 0.000041  loss: 1.3889 (1.5169)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [640/781]  eta: 0:00:46  lr: 0.000041  loss: 1.3820 (1.5159)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [650/781]  eta: 0:00:43  lr: 0.000041  loss: 1.3915 (1.5145)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [660/781]  eta: 0:00:40  lr: 0.000041  loss: 1.4005 (1.5143)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [670/781]  eta: 0:00:36  lr: 0.000041  loss: 1.3854 (1.5138)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [680/781]  eta: 0:00:33  lr: 0.000041  loss: 1.3854 (1.5132)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [690/781]  eta: 0:00:30  lr: 0.000041  loss: 1.4339 (1.5149)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [700/781]  eta: 0:00:26  lr: 0.000041  loss: 1.4450 (1.5159)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [710/781]  eta: 0:00:23  lr: 0.000041  loss: 1.5059 (1.5184)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [720/781]  eta: 0:00:20  lr: 0.000041  loss: 1.4186 (1.5178)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [730/781]  eta: 0:00:16  lr: 0.000041  loss: 1.4570 (1.5192)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [740/781]  eta: 0:00:13  lr: 0.000041  loss: 1.4436 (1.5205)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [750/781]  eta: 0:00:10  lr: 0.000041  loss: 1.4408 (1.5222)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [760/781]  eta: 0:00:06  lr: 0.000041  loss: 1.4529 (1.5251)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [770/781]  eta: 0:00:03  lr: 0.000041  loss: 1.4422 (1.5259)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [39]  [780/781]  eta: 0:00:00  lr: 0.000041  loss: 1.3614 (1.5243)  time: 0.3325  data: 0.0005  max mem: 6459\n",
            "Epoch: [39] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000041  loss: 1.3614 (1.5243)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32890650629997253, 'lambda_convnext_base': 0.25952818989753723, 'lambda_tf_efficientnetv2_l': 0.4115654230117798}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8149 (0.8149)  acc1: 82.8125 (82.8125)  acc5: 95.8333 (95.8333)  time: 0.8469  data: 0.8161  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0640 (0.9638)  acc1: 81.2500 (80.4451)  acc5: 94.2708 (93.6080)  time: 0.1718  data: 0.1412  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0640 (1.0155)  acc1: 78.1250 (79.5387)  acc5: 92.7083 (92.8819)  time: 0.1247  data: 0.0942  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1325 (1.0763)  acc1: 75.5208 (78.2090)  acc5: 91.6667 (92.4227)  time: 0.1322  data: 0.1016  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1709 (1.1215)  acc1: 75.0000 (77.2739)  acc5: 91.6667 (91.9207)  time: 0.1325  data: 0.1020  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1341 (1.1206)  acc1: 74.4792 (77.0629)  acc5: 92.7083 (92.1875)  time: 0.1359  data: 0.1054  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1464 (1.1340)  acc1: 73.9583 (76.9200)  acc5: 92.7083 (92.2200)  time: 0.1185  data: 0.0889  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1386 s / it)\n",
            "* Acc@1 76.920 Acc@5 92.220 loss 1.134\n",
            "Accuracy of the network on the 10000 test images: 76.9%\n",
            "Max accuracy: 76.92%\n",
            "[alpha-schedule=cosine] epoch=40 distillation_alpha=0.3313\n",
            "Epoch: [40]  [  0/781]  eta: 0:14:54  lr: 0.000040  loss: 1.2420 (1.2420)  time: 1.1449  data: 0.8069  max mem: 6459\n",
            "Epoch: [40]  [ 10/781]  eta: 0:05:12  lr: 0.000040  loss: 1.3426 (1.4539)  time: 0.4057  data: 0.0737  max mem: 6459\n",
            "Epoch: [40]  [ 20/781]  eta: 0:04:41  lr: 0.000040  loss: 1.3436 (1.4755)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 30/781]  eta: 0:04:29  lr: 0.000040  loss: 1.3436 (1.5383)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 40/781]  eta: 0:04:20  lr: 0.000040  loss: 1.3581 (1.5242)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 50/781]  eta: 0:04:14  lr: 0.000040  loss: 1.3541 (1.5150)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 60/781]  eta: 0:04:08  lr: 0.000040  loss: 1.3803 (1.5130)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 70/781]  eta: 0:04:04  lr: 0.000040  loss: 1.4215 (1.5125)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 80/781]  eta: 0:03:59  lr: 0.000040  loss: 1.3988 (1.5035)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [ 90/781]  eta: 0:03:55  lr: 0.000040  loss: 1.3821 (1.4942)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [100/781]  eta: 0:03:51  lr: 0.000040  loss: 1.3900 (1.5202)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [110/781]  eta: 0:03:47  lr: 0.000040  loss: 1.3945 (1.5258)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [120/781]  eta: 0:03:43  lr: 0.000040  loss: 1.3866 (1.5213)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [130/781]  eta: 0:03:40  lr: 0.000040  loss: 1.3628 (1.5167)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [140/781]  eta: 0:03:36  lr: 0.000040  loss: 1.3634 (1.5152)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [150/781]  eta: 0:03:32  lr: 0.000040  loss: 1.4591 (1.5168)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [160/781]  eta: 0:03:29  lr: 0.000040  loss: 1.4738 (1.5315)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [170/781]  eta: 0:03:25  lr: 0.000040  loss: 1.3953 (1.5302)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [180/781]  eta: 0:03:22  lr: 0.000040  loss: 1.3574 (1.5291)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [190/781]  eta: 0:03:18  lr: 0.000040  loss: 1.3932 (1.5303)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [200/781]  eta: 0:03:15  lr: 0.000040  loss: 1.4272 (1.5332)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [210/781]  eta: 0:03:11  lr: 0.000040  loss: 1.4272 (1.5278)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [220/781]  eta: 0:03:08  lr: 0.000040  loss: 1.3715 (1.5225)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [230/781]  eta: 0:03:04  lr: 0.000040  loss: 1.3413 (1.5199)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [240/781]  eta: 0:03:01  lr: 0.000040  loss: 1.3559 (1.5198)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [250/781]  eta: 0:02:57  lr: 0.000040  loss: 1.3634 (1.5135)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [260/781]  eta: 0:02:54  lr: 0.000040  loss: 1.3751 (1.5152)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [270/781]  eta: 0:02:51  lr: 0.000040  loss: 1.4043 (1.5171)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [280/781]  eta: 0:02:47  lr: 0.000040  loss: 1.3786 (1.5109)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [290/781]  eta: 0:02:44  lr: 0.000040  loss: 1.3703 (1.5106)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [300/781]  eta: 0:02:40  lr: 0.000040  loss: 1.3852 (1.5077)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [310/781]  eta: 0:02:37  lr: 0.000040  loss: 1.4357 (1.5083)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [320/781]  eta: 0:02:34  lr: 0.000040  loss: 1.4332 (1.5076)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [330/781]  eta: 0:02:30  lr: 0.000040  loss: 1.4034 (1.5048)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [340/781]  eta: 0:02:27  lr: 0.000040  loss: 1.3631 (1.5083)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [350/781]  eta: 0:02:23  lr: 0.000040  loss: 1.5206 (1.5091)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [360/781]  eta: 0:02:20  lr: 0.000040  loss: 1.4338 (1.5094)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [370/781]  eta: 0:02:17  lr: 0.000040  loss: 1.3737 (1.5106)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [380/781]  eta: 0:02:13  lr: 0.000040  loss: 1.3515 (1.5079)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [390/781]  eta: 0:02:10  lr: 0.000040  loss: 1.4057 (1.5127)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [400/781]  eta: 0:02:07  lr: 0.000040  loss: 1.4796 (1.5157)  time: 0.3425  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [410/781]  eta: 0:02:04  lr: 0.000040  loss: 1.4421 (1.5167)  time: 0.3425  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [420/781]  eta: 0:02:00  lr: 0.000040  loss: 1.4149 (1.5170)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [430/781]  eta: 0:01:57  lr: 0.000040  loss: 1.4186 (1.5180)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [440/781]  eta: 0:01:53  lr: 0.000040  loss: 1.4006 (1.5188)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [450/781]  eta: 0:01:50  lr: 0.000040  loss: 1.4006 (1.5208)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [460/781]  eta: 0:01:47  lr: 0.000040  loss: 1.4390 (1.5210)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [470/781]  eta: 0:01:43  lr: 0.000040  loss: 1.3766 (1.5193)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [480/781]  eta: 0:01:40  lr: 0.000040  loss: 1.3440 (1.5188)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [490/781]  eta: 0:01:37  lr: 0.000040  loss: 1.4041 (1.5216)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [500/781]  eta: 0:01:33  lr: 0.000040  loss: 1.4569 (1.5215)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [510/781]  eta: 0:01:30  lr: 0.000040  loss: 1.4338 (1.5219)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [520/781]  eta: 0:01:27  lr: 0.000040  loss: 1.4157 (1.5224)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [530/781]  eta: 0:01:23  lr: 0.000040  loss: 1.4157 (1.5221)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [540/781]  eta: 0:01:20  lr: 0.000040  loss: 1.4443 (1.5234)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [550/781]  eta: 0:01:17  lr: 0.000040  loss: 1.4108 (1.5209)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [560/781]  eta: 0:01:13  lr: 0.000040  loss: 1.3825 (1.5183)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [570/781]  eta: 0:01:10  lr: 0.000040  loss: 1.4047 (1.5200)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [580/781]  eta: 0:01:07  lr: 0.000040  loss: 1.4709 (1.5229)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [590/781]  eta: 0:01:03  lr: 0.000040  loss: 1.4135 (1.5216)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [600/781]  eta: 0:01:00  lr: 0.000040  loss: 1.3897 (1.5197)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [610/781]  eta: 0:00:57  lr: 0.000040  loss: 1.4066 (1.5213)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [620/781]  eta: 0:00:53  lr: 0.000040  loss: 1.3956 (1.5188)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [630/781]  eta: 0:00:50  lr: 0.000040  loss: 1.3516 (1.5184)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [640/781]  eta: 0:00:46  lr: 0.000040  loss: 1.3660 (1.5160)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [650/781]  eta: 0:00:43  lr: 0.000040  loss: 1.3935 (1.5183)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [660/781]  eta: 0:00:40  lr: 0.000040  loss: 1.4341 (1.5202)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [670/781]  eta: 0:00:36  lr: 0.000040  loss: 1.4176 (1.5210)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [680/781]  eta: 0:00:33  lr: 0.000040  loss: 1.4176 (1.5230)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [690/781]  eta: 0:00:30  lr: 0.000040  loss: 1.3915 (1.5222)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [700/781]  eta: 0:00:26  lr: 0.000040  loss: 1.3915 (1.5239)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [710/781]  eta: 0:00:23  lr: 0.000040  loss: 1.4008 (1.5227)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [720/781]  eta: 0:00:20  lr: 0.000040  loss: 1.3911 (1.5213)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [730/781]  eta: 0:00:16  lr: 0.000040  loss: 1.4042 (1.5239)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [740/781]  eta: 0:00:13  lr: 0.000040  loss: 1.4698 (1.5246)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [750/781]  eta: 0:00:10  lr: 0.000040  loss: 1.4270 (1.5228)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [760/781]  eta: 0:00:06  lr: 0.000040  loss: 1.3692 (1.5207)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [770/781]  eta: 0:00:03  lr: 0.000040  loss: 1.4275 (1.5237)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [40]  [780/781]  eta: 0:00:00  lr: 0.000040  loss: 1.4275 (1.5236)  time: 0.3319  data: 0.0005  max mem: 6459\n",
            "Epoch: [40] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000040  loss: 1.4275 (1.5236)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.329770565032959, 'lambda_convnext_base': 0.25880762934684753, 'lambda_tf_efficientnetv2_l': 0.4114215672016144}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.8566 (0.8566)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8698  data: 0.8391  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9125 (0.9489)  acc1: 83.3333 (81.2027)  acc5: 94.7917 (93.9394)  time: 0.1843  data: 0.1537  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0339 (1.0358)  acc1: 76.0417 (79.3155)  acc5: 92.7083 (93.0308)  time: 0.1273  data: 0.0968  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2249 (1.0897)  acc1: 75.0000 (78.4610)  acc5: 91.6667 (92.5067)  time: 0.1324  data: 0.1019  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1957 (1.1302)  acc1: 75.5208 (77.6550)  acc5: 91.1458 (92.0224)  time: 0.1189  data: 0.0884  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1597 (1.1299)  acc1: 76.0417 (77.3897)  acc5: 92.1875 (92.2386)  time: 0.1288  data: 0.0984  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2221 (1.1415)  acc1: 74.4792 (77.2500)  acc5: 92.7083 (92.2600)  time: 0.1254  data: 0.0958  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1392 s / it)\n",
            "* Acc@1 77.250 Acc@5 92.260 loss 1.142\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.25%\n",
            "[alpha-schedule=cosine] epoch=41 distillation_alpha=0.3407\n",
            "Epoch: [41]  [  0/781]  eta: 0:14:57  lr: 0.000039  loss: 1.2293 (1.2293)  time: 1.1497  data: 0.7902  max mem: 6459\n",
            "Epoch: [41]  [ 10/781]  eta: 0:05:13  lr: 0.000039  loss: 1.3956 (1.4673)  time: 0.4060  data: 0.0721  max mem: 6459\n",
            "Epoch: [41]  [ 20/781]  eta: 0:04:42  lr: 0.000039  loss: 1.3991 (1.5545)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 30/781]  eta: 0:04:29  lr: 0.000039  loss: 1.3557 (1.5370)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 40/781]  eta: 0:04:20  lr: 0.000039  loss: 1.3640 (1.5467)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 50/781]  eta: 0:04:14  lr: 0.000039  loss: 1.4118 (1.5336)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 60/781]  eta: 0:04:09  lr: 0.000039  loss: 1.3801 (1.5202)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 70/781]  eta: 0:04:04  lr: 0.000039  loss: 1.3719 (1.5203)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 80/781]  eta: 0:03:59  lr: 0.000039  loss: 1.3629 (1.5025)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [ 90/781]  eta: 0:03:55  lr: 0.000039  loss: 1.3585 (1.5200)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [100/781]  eta: 0:03:51  lr: 0.000039  loss: 1.3587 (1.5150)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [110/781]  eta: 0:03:47  lr: 0.000039  loss: 1.4030 (1.5151)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [120/781]  eta: 0:03:43  lr: 0.000039  loss: 1.3734 (1.5157)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [130/781]  eta: 0:03:40  lr: 0.000039  loss: 1.3707 (1.5107)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [140/781]  eta: 0:03:36  lr: 0.000039  loss: 1.3834 (1.5078)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [150/781]  eta: 0:03:32  lr: 0.000039  loss: 1.3834 (1.5042)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [160/781]  eta: 0:03:29  lr: 0.000039  loss: 1.3634 (1.5156)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [170/781]  eta: 0:03:25  lr: 0.000039  loss: 1.3868 (1.5111)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [180/781]  eta: 0:03:22  lr: 0.000039  loss: 1.3654 (1.5079)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [190/781]  eta: 0:03:18  lr: 0.000039  loss: 1.3565 (1.5111)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [200/781]  eta: 0:03:15  lr: 0.000039  loss: 1.3490 (1.5055)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [210/781]  eta: 0:03:11  lr: 0.000039  loss: 1.3240 (1.5058)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [220/781]  eta: 0:03:08  lr: 0.000039  loss: 1.3287 (1.5114)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [230/781]  eta: 0:03:04  lr: 0.000039  loss: 1.4476 (1.5118)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [240/781]  eta: 0:03:01  lr: 0.000039  loss: 1.4050 (1.5078)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [250/781]  eta: 0:02:57  lr: 0.000039  loss: 1.3732 (1.5073)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [260/781]  eta: 0:02:54  lr: 0.000039  loss: 1.3621 (1.5027)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [270/781]  eta: 0:02:51  lr: 0.000039  loss: 1.3704 (1.5071)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [280/781]  eta: 0:02:47  lr: 0.000039  loss: 1.4208 (1.5074)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [290/781]  eta: 0:02:44  lr: 0.000039  loss: 1.3538 (1.5105)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [300/781]  eta: 0:02:40  lr: 0.000039  loss: 1.3811 (1.5101)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [310/781]  eta: 0:02:37  lr: 0.000039  loss: 1.3903 (1.5142)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [320/781]  eta: 0:02:34  lr: 0.000039  loss: 1.3911 (1.5140)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [330/781]  eta: 0:02:30  lr: 0.000039  loss: 1.3609 (1.5137)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [340/781]  eta: 0:02:27  lr: 0.000039  loss: 1.3841 (1.5164)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [350/781]  eta: 0:02:24  lr: 0.000039  loss: 1.4130 (1.5168)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [360/781]  eta: 0:02:20  lr: 0.000039  loss: 1.3724 (1.5149)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [370/781]  eta: 0:02:17  lr: 0.000039  loss: 1.3924 (1.5118)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [380/781]  eta: 0:02:13  lr: 0.000039  loss: 1.4305 (1.5114)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [390/781]  eta: 0:02:10  lr: 0.000039  loss: 1.4197 (1.5112)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [400/781]  eta: 0:02:07  lr: 0.000039  loss: 1.4197 (1.5153)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [410/781]  eta: 0:02:03  lr: 0.000039  loss: 1.4238 (1.5201)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [420/781]  eta: 0:02:00  lr: 0.000039  loss: 1.4003 (1.5195)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [430/781]  eta: 0:01:57  lr: 0.000039  loss: 1.4131 (1.5214)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [440/781]  eta: 0:01:53  lr: 0.000039  loss: 1.4193 (1.5225)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [450/781]  eta: 0:01:50  lr: 0.000039  loss: 1.3975 (1.5195)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [460/781]  eta: 0:01:47  lr: 0.000039  loss: 1.4071 (1.5222)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [470/781]  eta: 0:01:43  lr: 0.000039  loss: 1.4362 (1.5218)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [480/781]  eta: 0:01:40  lr: 0.000039  loss: 1.4101 (1.5206)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [490/781]  eta: 0:01:37  lr: 0.000039  loss: 1.4394 (1.5217)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [500/781]  eta: 0:01:33  lr: 0.000039  loss: 1.3919 (1.5190)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [510/781]  eta: 0:01:30  lr: 0.000039  loss: 1.3442 (1.5170)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [520/781]  eta: 0:01:26  lr: 0.000039  loss: 1.3677 (1.5161)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [530/781]  eta: 0:01:23  lr: 0.000039  loss: 1.4080 (1.5140)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [540/781]  eta: 0:01:20  lr: 0.000039  loss: 1.3867 (1.5137)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [550/781]  eta: 0:01:16  lr: 0.000039  loss: 1.4235 (1.5149)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [560/781]  eta: 0:01:13  lr: 0.000039  loss: 1.4235 (1.5154)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [570/781]  eta: 0:01:10  lr: 0.000039  loss: 1.4282 (1.5172)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [580/781]  eta: 0:01:06  lr: 0.000039  loss: 1.4575 (1.5177)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [590/781]  eta: 0:01:03  lr: 0.000039  loss: 1.3765 (1.5156)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [600/781]  eta: 0:01:00  lr: 0.000039  loss: 1.3840 (1.5157)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [610/781]  eta: 0:00:56  lr: 0.000039  loss: 1.4078 (1.5150)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [620/781]  eta: 0:00:53  lr: 0.000039  loss: 1.3626 (1.5140)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [630/781]  eta: 0:00:50  lr: 0.000039  loss: 1.3355 (1.5124)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [640/781]  eta: 0:00:46  lr: 0.000039  loss: 1.3374 (1.5128)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [650/781]  eta: 0:00:43  lr: 0.000039  loss: 1.4163 (1.5123)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [660/781]  eta: 0:00:40  lr: 0.000039  loss: 1.3813 (1.5106)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [670/781]  eta: 0:00:36  lr: 0.000039  loss: 1.3611 (1.5084)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [41]  [680/781]  eta: 0:00:33  lr: 0.000039  loss: 1.3672 (1.5108)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [690/781]  eta: 0:00:30  lr: 0.000039  loss: 1.4429 (1.5125)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [700/781]  eta: 0:00:26  lr: 0.000039  loss: 1.4080 (1.5118)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [710/781]  eta: 0:00:23  lr: 0.000039  loss: 1.3904 (1.5113)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [720/781]  eta: 0:00:20  lr: 0.000039  loss: 1.3904 (1.5125)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [730/781]  eta: 0:00:16  lr: 0.000039  loss: 1.4255 (1.5130)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [740/781]  eta: 0:00:13  lr: 0.000039  loss: 1.3928 (1.5129)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [750/781]  eta: 0:00:10  lr: 0.000039  loss: 1.3624 (1.5122)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [760/781]  eta: 0:00:06  lr: 0.000039  loss: 1.3624 (1.5116)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [770/781]  eta: 0:00:03  lr: 0.000039  loss: 1.3653 (1.5098)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [41]  [780/781]  eta: 0:00:00  lr: 0.000039  loss: 1.3653 (1.5091)  time: 0.3316  data: 0.0006  max mem: 6459\n",
            "Epoch: [41] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000039  loss: 1.3653 (1.5091)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3293275237083435, 'lambda_convnext_base': 0.25949186086654663, 'lambda_tf_efficientnetv2_l': 0.411180704832077}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7792 (0.7792)  acc1: 84.3750 (84.3750)  acc5: 94.7917 (94.7917)  time: 0.8433  data: 0.8126  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8958 (0.9788)  acc1: 83.3333 (80.5871)  acc5: 94.7917 (93.5133)  time: 0.1745  data: 0.1440  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0148 (1.0564)  acc1: 79.1667 (79.0923)  acc5: 93.2292 (92.8075)  time: 0.1290  data: 0.0985  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1770 (1.1084)  acc1: 77.0833 (78.1418)  acc5: 91.1458 (92.1875)  time: 0.1326  data: 0.1022  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2489 (1.1319)  acc1: 77.0833 (77.5152)  acc5: 90.6250 (91.8953)  time: 0.1346  data: 0.1042  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1331 (1.1356)  acc1: 76.5625 (77.1242)  acc5: 91.6667 (91.9833)  time: 0.1323  data: 0.1019  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1590 (1.1377)  acc1: 75.0000 (77.0800)  acc5: 92.1875 (92.0100)  time: 0.1108  data: 0.0812  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1379 s / it)\n",
            "* Acc@1 77.080 Acc@5 92.010 loss 1.138\n",
            "Accuracy of the network on the 10000 test images: 77.1%\n",
            "Max accuracy: 77.25%\n",
            "[alpha-schedule=cosine] epoch=42 distillation_alpha=0.3500\n",
            "Epoch: [42]  [  0/781]  eta: 0:14:51  lr: 0.000038  loss: 1.3370 (1.3370)  time: 1.1409  data: 0.8025  max mem: 6459\n",
            "Epoch: [42]  [ 10/781]  eta: 0:05:12  lr: 0.000038  loss: 1.4307 (1.5671)  time: 0.4049  data: 0.0732  max mem: 6459\n",
            "Epoch: [42]  [ 20/781]  eta: 0:04:41  lr: 0.000038  loss: 1.4126 (1.5853)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 30/781]  eta: 0:04:28  lr: 0.000038  loss: 1.3974 (1.5845)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 40/781]  eta: 0:04:20  lr: 0.000038  loss: 1.4141 (1.5742)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 50/781]  eta: 0:04:13  lr: 0.000038  loss: 1.4014 (1.5722)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 60/781]  eta: 0:04:08  lr: 0.000038  loss: 1.4014 (1.5630)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 70/781]  eta: 0:04:03  lr: 0.000038  loss: 1.4043 (1.5586)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 80/781]  eta: 0:03:59  lr: 0.000038  loss: 1.4281 (1.5741)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [ 90/781]  eta: 0:03:55  lr: 0.000038  loss: 1.4065 (1.5659)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [100/781]  eta: 0:03:51  lr: 0.000038  loss: 1.3900 (1.5572)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [110/781]  eta: 0:03:47  lr: 0.000038  loss: 1.3330 (1.5489)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [120/781]  eta: 0:03:43  lr: 0.000038  loss: 1.3931 (1.5464)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [130/781]  eta: 0:03:39  lr: 0.000038  loss: 1.3706 (1.5468)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [140/781]  eta: 0:03:36  lr: 0.000038  loss: 1.3918 (1.5556)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [150/781]  eta: 0:03:32  lr: 0.000038  loss: 1.4021 (1.5453)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [160/781]  eta: 0:03:28  lr: 0.000038  loss: 1.3848 (1.5371)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [170/781]  eta: 0:03:25  lr: 0.000038  loss: 1.3802 (1.5343)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [180/781]  eta: 0:03:21  lr: 0.000038  loss: 1.3967 (1.5354)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [190/781]  eta: 0:03:18  lr: 0.000038  loss: 1.3960 (1.5358)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [200/781]  eta: 0:03:14  lr: 0.000038  loss: 1.3856 (1.5293)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [210/781]  eta: 0:03:11  lr: 0.000038  loss: 1.3993 (1.5382)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [220/781]  eta: 0:03:07  lr: 0.000038  loss: 1.3930 (1.5340)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [230/781]  eta: 0:03:04  lr: 0.000038  loss: 1.3315 (1.5300)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [240/781]  eta: 0:03:01  lr: 0.000038  loss: 1.3609 (1.5284)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [250/781]  eta: 0:02:57  lr: 0.000038  loss: 1.3609 (1.5282)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [260/781]  eta: 0:02:54  lr: 0.000038  loss: 1.3692 (1.5226)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [270/781]  eta: 0:02:50  lr: 0.000038  loss: 1.4110 (1.5248)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [280/781]  eta: 0:02:47  lr: 0.000038  loss: 1.4256 (1.5295)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [290/781]  eta: 0:02:44  lr: 0.000038  loss: 1.4293 (1.5307)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [300/781]  eta: 0:02:40  lr: 0.000038  loss: 1.3891 (1.5270)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [310/781]  eta: 0:02:37  lr: 0.000038  loss: 1.3928 (1.5285)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [320/781]  eta: 0:02:33  lr: 0.000038  loss: 1.3928 (1.5298)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [330/781]  eta: 0:02:30  lr: 0.000038  loss: 1.3393 (1.5269)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [340/781]  eta: 0:02:27  lr: 0.000038  loss: 1.3332 (1.5223)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [350/781]  eta: 0:02:23  lr: 0.000038  loss: 1.3332 (1.5209)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [360/781]  eta: 0:02:20  lr: 0.000038  loss: 1.3890 (1.5272)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [370/781]  eta: 0:02:17  lr: 0.000038  loss: 1.4140 (1.5302)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [380/781]  eta: 0:02:13  lr: 0.000038  loss: 1.4002 (1.5297)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [390/781]  eta: 0:02:10  lr: 0.000038  loss: 1.4168 (1.5283)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [400/781]  eta: 0:02:07  lr: 0.000038  loss: 1.4168 (1.5296)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [410/781]  eta: 0:02:03  lr: 0.000038  loss: 1.4121 (1.5266)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [420/781]  eta: 0:02:00  lr: 0.000038  loss: 1.3416 (1.5255)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [430/781]  eta: 0:01:56  lr: 0.000038  loss: 1.4210 (1.5272)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [440/781]  eta: 0:01:53  lr: 0.000038  loss: 1.4437 (1.5321)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [450/781]  eta: 0:01:50  lr: 0.000038  loss: 1.3695 (1.5281)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [460/781]  eta: 0:01:46  lr: 0.000038  loss: 1.3721 (1.5282)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [470/781]  eta: 0:01:43  lr: 0.000038  loss: 1.3721 (1.5241)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [480/781]  eta: 0:01:40  lr: 0.000038  loss: 1.3735 (1.5299)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [490/781]  eta: 0:01:36  lr: 0.000038  loss: 1.3971 (1.5282)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [500/781]  eta: 0:01:33  lr: 0.000038  loss: 1.3421 (1.5249)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [510/781]  eta: 0:01:30  lr: 0.000038  loss: 1.3260 (1.5232)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [520/781]  eta: 0:01:26  lr: 0.000038  loss: 1.3974 (1.5206)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [530/781]  eta: 0:01:23  lr: 0.000038  loss: 1.3974 (1.5187)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [540/781]  eta: 0:01:20  lr: 0.000038  loss: 1.3933 (1.5183)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [550/781]  eta: 0:01:16  lr: 0.000038  loss: 1.3933 (1.5174)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [560/781]  eta: 0:01:13  lr: 0.000038  loss: 1.4042 (1.5180)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [570/781]  eta: 0:01:10  lr: 0.000038  loss: 1.4017 (1.5176)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [580/781]  eta: 0:01:06  lr: 0.000038  loss: 1.4017 (1.5201)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [590/781]  eta: 0:01:03  lr: 0.000038  loss: 1.4006 (1.5188)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [600/781]  eta: 0:01:00  lr: 0.000038  loss: 1.4006 (1.5185)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [610/781]  eta: 0:00:56  lr: 0.000038  loss: 1.4024 (1.5203)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [620/781]  eta: 0:00:53  lr: 0.000038  loss: 1.3984 (1.5200)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [630/781]  eta: 0:00:50  lr: 0.000038  loss: 1.3984 (1.5214)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [640/781]  eta: 0:00:46  lr: 0.000038  loss: 1.3974 (1.5203)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [650/781]  eta: 0:00:43  lr: 0.000038  loss: 1.3684 (1.5186)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [660/781]  eta: 0:00:40  lr: 0.000038  loss: 1.3684 (1.5206)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [670/781]  eta: 0:00:36  lr: 0.000038  loss: 1.4643 (1.5205)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [680/781]  eta: 0:00:33  lr: 0.000038  loss: 1.4643 (1.5238)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [690/781]  eta: 0:00:30  lr: 0.000038  loss: 1.4092 (1.5265)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [700/781]  eta: 0:00:26  lr: 0.000038  loss: 1.4236 (1.5254)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [710/781]  eta: 0:00:23  lr: 0.000038  loss: 1.4327 (1.5277)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [720/781]  eta: 0:00:20  lr: 0.000038  loss: 1.3784 (1.5274)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [730/781]  eta: 0:00:16  lr: 0.000038  loss: 1.3784 (1.5284)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [740/781]  eta: 0:00:13  lr: 0.000038  loss: 1.3674 (1.5275)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [750/781]  eta: 0:00:10  lr: 0.000038  loss: 1.3730 (1.5259)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [760/781]  eta: 0:00:06  lr: 0.000038  loss: 1.3915 (1.5271)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [770/781]  eta: 0:00:03  lr: 0.000038  loss: 1.3915 (1.5262)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [42]  [780/781]  eta: 0:00:00  lr: 0.000038  loss: 1.3701 (1.5244)  time: 0.3317  data: 0.0006  max mem: 6459\n",
            "Epoch: [42] Total time: 0:04:19 (0.3326 s / it)\n",
            "Averaged stats: lr: 0.000038  loss: 1.3701 (1.5244)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290572464466095, 'lambda_convnext_base': 0.2603316307067871, 'lambda_tf_efficientnetv2_l': 0.4106106162071228}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7627 (0.7627)  acc1: 85.9375 (85.9375)  acc5: 94.2708 (94.2708)  time: 0.8418  data: 0.8110  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0070 (0.9824)  acc1: 82.2917 (80.3030)  acc5: 94.7917 (93.7974)  time: 0.1684  data: 0.1379  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0890 (1.0574)  acc1: 77.6042 (79.1419)  acc5: 93.7500 (92.6587)  time: 0.1134  data: 0.0829  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1868 (1.0952)  acc1: 77.0833 (78.1754)  acc5: 91.6667 (92.2547)  time: 0.1253  data: 0.0931  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1970 (1.1244)  acc1: 75.0000 (77.6423)  acc5: 91.1458 (91.8064)  time: 0.1179  data: 0.0839  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1271 (1.1324)  acc1: 76.5625 (77.1038)  acc5: 91.6667 (92.0037)  time: 0.1141  data: 0.0799  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2020 (1.1450)  acc1: 75.0000 (77.0100)  acc5: 91.6667 (92.0200)  time: 0.1132  data: 0.0801  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1296 s / it)\n",
            "* Acc@1 77.010 Acc@5 92.020 loss 1.145\n",
            "Accuracy of the network on the 10000 test images: 77.0%\n",
            "Max accuracy: 77.25%\n",
            "[alpha-schedule=cosine] epoch=43 distillation_alpha=0.3593\n",
            "Epoch: [43]  [  0/781]  eta: 0:15:01  lr: 0.000037  loss: 1.4040 (1.4040)  time: 1.1537  data: 0.7873  max mem: 6459\n",
            "Epoch: [43]  [ 10/781]  eta: 0:05:13  lr: 0.000037  loss: 1.4382 (1.5818)  time: 0.4066  data: 0.0719  max mem: 6459\n",
            "Epoch: [43]  [ 20/781]  eta: 0:04:42  lr: 0.000037  loss: 1.4076 (1.5913)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 30/781]  eta: 0:04:29  lr: 0.000037  loss: 1.3952 (1.5673)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 40/781]  eta: 0:04:20  lr: 0.000037  loss: 1.4700 (1.6253)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 50/781]  eta: 0:04:14  lr: 0.000037  loss: 1.3846 (1.5888)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 60/781]  eta: 0:04:08  lr: 0.000037  loss: 1.3455 (1.5506)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 70/781]  eta: 0:04:04  lr: 0.000037  loss: 1.3665 (1.5304)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 80/781]  eta: 0:03:59  lr: 0.000037  loss: 1.3697 (1.5179)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [ 90/781]  eta: 0:03:55  lr: 0.000037  loss: 1.3018 (1.4928)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [100/781]  eta: 0:03:51  lr: 0.000037  loss: 1.3020 (1.5054)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [110/781]  eta: 0:03:47  lr: 0.000037  loss: 1.4465 (1.5478)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [120/781]  eta: 0:03:43  lr: 0.000037  loss: 1.4170 (1.5360)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [130/781]  eta: 0:03:40  lr: 0.000037  loss: 1.3192 (1.5293)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [140/781]  eta: 0:03:36  lr: 0.000037  loss: 1.3519 (1.5234)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [150/781]  eta: 0:03:32  lr: 0.000037  loss: 1.3917 (1.5169)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [160/781]  eta: 0:03:29  lr: 0.000037  loss: 1.3834 (1.5141)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [170/781]  eta: 0:03:25  lr: 0.000037  loss: 1.3737 (1.5086)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [180/781]  eta: 0:03:22  lr: 0.000037  loss: 1.3737 (1.5147)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [190/781]  eta: 0:03:18  lr: 0.000037  loss: 1.3591 (1.5217)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [200/781]  eta: 0:03:15  lr: 0.000037  loss: 1.4009 (1.5156)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [210/781]  eta: 0:03:12  lr: 0.000037  loss: 1.4071 (1.5240)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [220/781]  eta: 0:03:08  lr: 0.000037  loss: 1.4096 (1.5205)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [230/781]  eta: 0:03:05  lr: 0.000037  loss: 1.3906 (1.5213)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [240/781]  eta: 0:03:01  lr: 0.000037  loss: 1.3809 (1.5225)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [250/781]  eta: 0:02:58  lr: 0.000037  loss: 1.4413 (1.5239)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [260/781]  eta: 0:02:54  lr: 0.000037  loss: 1.4413 (1.5222)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [270/781]  eta: 0:02:51  lr: 0.000037  loss: 1.4057 (1.5222)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [280/781]  eta: 0:02:48  lr: 0.000037  loss: 1.4057 (1.5165)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [290/781]  eta: 0:02:44  lr: 0.000037  loss: 1.3659 (1.5137)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [300/781]  eta: 0:02:41  lr: 0.000037  loss: 1.4043 (1.5190)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [310/781]  eta: 0:02:37  lr: 0.000037  loss: 1.3974 (1.5156)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [320/781]  eta: 0:02:34  lr: 0.000037  loss: 1.4117 (1.5251)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [330/781]  eta: 0:02:31  lr: 0.000037  loss: 1.4276 (1.5244)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [340/781]  eta: 0:02:27  lr: 0.000037  loss: 1.4631 (1.5342)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [350/781]  eta: 0:02:24  lr: 0.000037  loss: 1.4423 (1.5333)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [360/781]  eta: 0:02:20  lr: 0.000037  loss: 1.3623 (1.5346)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [370/781]  eta: 0:02:17  lr: 0.000037  loss: 1.3856 (1.5343)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [380/781]  eta: 0:02:14  lr: 0.000037  loss: 1.4387 (1.5365)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [390/781]  eta: 0:02:10  lr: 0.000037  loss: 1.4185 (1.5323)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [400/781]  eta: 0:02:07  lr: 0.000037  loss: 1.3927 (1.5360)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [410/781]  eta: 0:02:03  lr: 0.000037  loss: 1.4139 (1.5370)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [420/781]  eta: 0:02:00  lr: 0.000037  loss: 1.3462 (1.5328)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [430/781]  eta: 0:01:57  lr: 0.000037  loss: 1.3450 (1.5316)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [440/781]  eta: 0:01:53  lr: 0.000037  loss: 1.4248 (1.5360)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [450/781]  eta: 0:01:50  lr: 0.000037  loss: 1.4248 (1.5347)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [460/781]  eta: 0:01:47  lr: 0.000037  loss: 1.3381 (1.5344)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [470/781]  eta: 0:01:43  lr: 0.000037  loss: 1.3478 (1.5308)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [480/781]  eta: 0:01:40  lr: 0.000037  loss: 1.3948 (1.5332)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [490/781]  eta: 0:01:37  lr: 0.000037  loss: 1.4237 (1.5307)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [500/781]  eta: 0:01:33  lr: 0.000037  loss: 1.4344 (1.5348)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [510/781]  eta: 0:01:30  lr: 0.000037  loss: 1.4421 (1.5349)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [520/781]  eta: 0:01:27  lr: 0.000037  loss: 1.3564 (1.5344)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [530/781]  eta: 0:01:23  lr: 0.000037  loss: 1.3411 (1.5336)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [540/781]  eta: 0:01:20  lr: 0.000037  loss: 1.3375 (1.5314)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [550/781]  eta: 0:01:17  lr: 0.000037  loss: 1.4014 (1.5318)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [560/781]  eta: 0:01:13  lr: 0.000037  loss: 1.4229 (1.5289)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [570/781]  eta: 0:01:10  lr: 0.000037  loss: 1.3731 (1.5306)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [580/781]  eta: 0:01:07  lr: 0.000037  loss: 1.3826 (1.5322)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [590/781]  eta: 0:01:03  lr: 0.000037  loss: 1.3473 (1.5304)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [600/781]  eta: 0:01:00  lr: 0.000037  loss: 1.3697 (1.5325)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [610/781]  eta: 0:00:57  lr: 0.000037  loss: 1.4027 (1.5310)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [620/781]  eta: 0:00:53  lr: 0.000037  loss: 1.4123 (1.5328)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [630/781]  eta: 0:00:50  lr: 0.000037  loss: 1.4002 (1.5300)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [640/781]  eta: 0:00:46  lr: 0.000037  loss: 1.3656 (1.5297)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [650/781]  eta: 0:00:43  lr: 0.000037  loss: 1.3738 (1.5300)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [660/781]  eta: 0:00:40  lr: 0.000037  loss: 1.3660 (1.5292)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [670/781]  eta: 0:00:36  lr: 0.000037  loss: 1.4039 (1.5284)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [680/781]  eta: 0:00:33  lr: 0.000037  loss: 1.4544 (1.5328)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [690/781]  eta: 0:00:30  lr: 0.000037  loss: 1.4383 (1.5318)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [700/781]  eta: 0:00:26  lr: 0.000037  loss: 1.3932 (1.5313)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [710/781]  eta: 0:00:23  lr: 0.000037  loss: 1.4329 (1.5318)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [720/781]  eta: 0:00:20  lr: 0.000037  loss: 1.4527 (1.5329)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [730/781]  eta: 0:00:16  lr: 0.000037  loss: 1.4042 (1.5316)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [740/781]  eta: 0:00:13  lr: 0.000037  loss: 1.3754 (1.5294)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [750/781]  eta: 0:00:10  lr: 0.000037  loss: 1.3388 (1.5274)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [760/781]  eta: 0:00:06  lr: 0.000037  loss: 1.3198 (1.5250)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [770/781]  eta: 0:00:03  lr: 0.000037  loss: 1.3371 (1.5241)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [43]  [780/781]  eta: 0:00:00  lr: 0.000037  loss: 1.4053 (1.5247)  time: 0.3316  data: 0.0006  max mem: 6459\n",
            "Epoch: [43] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000037  loss: 1.4053 (1.5247)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3284511864185333, 'lambda_convnext_base': 0.26028406620025635, 'lambda_tf_efficientnetv2_l': 0.41126495599746704}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7783 (0.7783)  acc1: 81.7708 (81.7708)  acc5: 95.8333 (95.8333)  time: 0.8187  data: 0.7880  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8191 (0.9267)  acc1: 81.7708 (80.8239)  acc5: 94.7917 (94.2708)  time: 0.1765  data: 0.1461  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0121 (1.0125)  acc1: 77.0833 (79.4643)  acc5: 94.2708 (93.4276)  time: 0.1195  data: 0.0890  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1986 (1.0697)  acc1: 76.5625 (78.5954)  acc5: 91.6667 (92.7923)  time: 0.1193  data: 0.0889  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2342 (1.1215)  acc1: 76.0417 (77.5279)  acc5: 90.1042 (92.2383)  time: 0.1140  data: 0.0835  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1230 (1.1178)  acc1: 77.0833 (77.4306)  acc5: 92.1875 (92.3713)  time: 0.1113  data: 0.0809  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1467 (1.1301)  acc1: 74.4792 (77.2800)  acc5: 92.7083 (92.4000)  time: 0.1014  data: 0.0718  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1255 s / it)\n",
            "* Acc@1 77.280 Acc@5 92.400 loss 1.130\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.28%\n",
            "[alpha-schedule=cosine] epoch=44 distillation_alpha=0.3687\n",
            "Epoch: [44]  [  0/781]  eta: 0:13:56  lr: 0.000036  loss: 1.2376 (1.2376)  time: 1.0711  data: 0.7255  max mem: 6459\n",
            "Epoch: [44]  [ 10/781]  eta: 0:05:07  lr: 0.000036  loss: 1.7686 (1.7248)  time: 0.3991  data: 0.0663  max mem: 6459\n",
            "Epoch: [44]  [ 20/781]  eta: 0:04:39  lr: 0.000036  loss: 1.3831 (1.5459)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 30/781]  eta: 0:04:26  lr: 0.000036  loss: 1.3355 (1.4956)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 40/781]  eta: 0:04:18  lr: 0.000036  loss: 1.3644 (1.5192)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 50/781]  eta: 0:04:12  lr: 0.000036  loss: 1.3762 (1.5318)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 60/781]  eta: 0:04:07  lr: 0.000036  loss: 1.3762 (1.5068)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 70/781]  eta: 0:04:02  lr: 0.000036  loss: 1.3739 (1.5093)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 80/781]  eta: 0:03:58  lr: 0.000036  loss: 1.3618 (1.5020)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [ 90/781]  eta: 0:03:54  lr: 0.000036  loss: 1.3655 (1.4943)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [100/781]  eta: 0:03:50  lr: 0.000036  loss: 1.3622 (1.4879)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [110/781]  eta: 0:03:46  lr: 0.000036  loss: 1.3622 (1.4776)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [120/781]  eta: 0:03:43  lr: 0.000036  loss: 1.3602 (1.4848)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [130/781]  eta: 0:03:39  lr: 0.000036  loss: 1.3285 (1.4785)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [140/781]  eta: 0:03:35  lr: 0.000036  loss: 1.3363 (1.4780)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [150/781]  eta: 0:03:32  lr: 0.000036  loss: 1.3704 (1.4781)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [160/781]  eta: 0:03:28  lr: 0.000036  loss: 1.3975 (1.4892)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [170/781]  eta: 0:03:25  lr: 0.000036  loss: 1.4362 (1.4935)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [180/781]  eta: 0:03:21  lr: 0.000036  loss: 1.3604 (1.4885)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [190/781]  eta: 0:03:18  lr: 0.000036  loss: 1.3437 (1.4883)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [200/781]  eta: 0:03:14  lr: 0.000036  loss: 1.4164 (1.5105)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [210/781]  eta: 0:03:11  lr: 0.000036  loss: 1.4071 (1.5052)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [220/781]  eta: 0:03:07  lr: 0.000036  loss: 1.4012 (1.5052)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [230/781]  eta: 0:03:04  lr: 0.000036  loss: 1.3861 (1.4995)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [240/781]  eta: 0:03:01  lr: 0.000036  loss: 1.3894 (1.5048)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [250/781]  eta: 0:02:57  lr: 0.000036  loss: 1.3907 (1.5025)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [260/781]  eta: 0:02:54  lr: 0.000036  loss: 1.3551 (1.4989)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [270/781]  eta: 0:02:50  lr: 0.000036  loss: 1.4007 (1.4994)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [280/781]  eta: 0:02:47  lr: 0.000036  loss: 1.3418 (1.4972)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [290/781]  eta: 0:02:44  lr: 0.000036  loss: 1.3418 (1.4980)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [300/781]  eta: 0:02:40  lr: 0.000036  loss: 1.3686 (1.4951)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [310/781]  eta: 0:02:37  lr: 0.000036  loss: 1.3467 (1.4909)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [320/781]  eta: 0:02:33  lr: 0.000036  loss: 1.4004 (1.4959)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [330/781]  eta: 0:02:30  lr: 0.000036  loss: 1.4004 (1.4993)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [340/781]  eta: 0:02:27  lr: 0.000036  loss: 1.3766 (1.4972)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [350/781]  eta: 0:02:23  lr: 0.000036  loss: 1.3894 (1.4969)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [360/781]  eta: 0:02:20  lr: 0.000036  loss: 1.3838 (1.5002)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [370/781]  eta: 0:02:17  lr: 0.000036  loss: 1.3808 (1.4979)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [380/781]  eta: 0:02:13  lr: 0.000036  loss: 1.3432 (1.4998)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [390/781]  eta: 0:02:10  lr: 0.000036  loss: 1.3944 (1.4988)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [400/781]  eta: 0:02:07  lr: 0.000036  loss: 1.3801 (1.5011)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [44]  [410/781]  eta: 0:02:03  lr: 0.000036  loss: 1.3859 (1.4999)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [420/781]  eta: 0:02:00  lr: 0.000036  loss: 1.4418 (1.5007)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [430/781]  eta: 0:01:57  lr: 0.000036  loss: 1.4131 (1.5021)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [440/781]  eta: 0:01:53  lr: 0.000036  loss: 1.3476 (1.4997)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [450/781]  eta: 0:01:50  lr: 0.000036  loss: 1.3778 (1.5010)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [460/781]  eta: 0:01:46  lr: 0.000036  loss: 1.4003 (1.5030)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [470/781]  eta: 0:01:43  lr: 0.000036  loss: 1.3691 (1.5018)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [480/781]  eta: 0:01:40  lr: 0.000036  loss: 1.3252 (1.5042)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [490/781]  eta: 0:01:36  lr: 0.000036  loss: 1.3828 (1.5027)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [500/781]  eta: 0:01:33  lr: 0.000036  loss: 1.4133 (1.5034)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [510/781]  eta: 0:01:30  lr: 0.000036  loss: 1.3986 (1.5034)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [520/781]  eta: 0:01:26  lr: 0.000036  loss: 1.4117 (1.5036)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [530/781]  eta: 0:01:23  lr: 0.000036  loss: 1.3788 (1.5031)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [540/781]  eta: 0:01:20  lr: 0.000036  loss: 1.3553 (1.5018)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [550/781]  eta: 0:01:16  lr: 0.000036  loss: 1.3667 (1.5010)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [560/781]  eta: 0:01:13  lr: 0.000036  loss: 1.3621 (1.5005)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [570/781]  eta: 0:01:10  lr: 0.000036  loss: 1.3481 (1.4986)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [580/781]  eta: 0:01:06  lr: 0.000036  loss: 1.3922 (1.5008)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [590/781]  eta: 0:01:03  lr: 0.000036  loss: 1.4299 (1.5043)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [600/781]  eta: 0:01:00  lr: 0.000036  loss: 1.4045 (1.5050)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [610/781]  eta: 0:00:56  lr: 0.000036  loss: 1.3995 (1.5078)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [620/781]  eta: 0:00:53  lr: 0.000036  loss: 1.3751 (1.5077)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [630/781]  eta: 0:00:50  lr: 0.000036  loss: 1.3541 (1.5051)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [640/781]  eta: 0:00:46  lr: 0.000036  loss: 1.3503 (1.5024)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [650/781]  eta: 0:00:43  lr: 0.000036  loss: 1.3642 (1.5011)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [660/781]  eta: 0:00:40  lr: 0.000036  loss: 1.3676 (1.5007)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [670/781]  eta: 0:00:36  lr: 0.000036  loss: 1.3458 (1.4999)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [680/781]  eta: 0:00:33  lr: 0.000036  loss: 1.3932 (1.5018)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [690/781]  eta: 0:00:30  lr: 0.000036  loss: 1.3947 (1.5029)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [700/781]  eta: 0:00:26  lr: 0.000036  loss: 1.3845 (1.5032)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [710/781]  eta: 0:00:23  lr: 0.000036  loss: 1.3631 (1.5028)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [720/781]  eta: 0:00:20  lr: 0.000036  loss: 1.3942 (1.5043)  time: 0.3312  data: 0.0004  max mem: 6459\n",
            "Epoch: [44]  [730/781]  eta: 0:00:16  lr: 0.000036  loss: 1.4072 (1.5041)  time: 0.3313  data: 0.0004  max mem: 6459\n",
            "Epoch: [44]  [740/781]  eta: 0:00:13  lr: 0.000036  loss: 1.4072 (1.5054)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [750/781]  eta: 0:00:10  lr: 0.000036  loss: 1.4200 (1.5075)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [760/781]  eta: 0:00:06  lr: 0.000036  loss: 1.4725 (1.5104)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [770/781]  eta: 0:00:03  lr: 0.000036  loss: 1.4123 (1.5114)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [44]  [780/781]  eta: 0:00:00  lr: 0.000036  loss: 1.3819 (1.5134)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [44] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000036  loss: 1.3819 (1.5134)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32826536893844604, 'lambda_convnext_base': 0.2604646682739258, 'lambda_tf_efficientnetv2_l': 0.4112702012062073}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7772 (0.7772)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 0.8221  data: 0.7915  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0309 (0.9524)  acc1: 82.2917 (80.6345)  acc5: 94.7917 (94.2235)  time: 0.1699  data: 0.1394  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0319 (1.0204)  acc1: 79.1667 (79.6875)  acc5: 93.7500 (93.1796)  time: 0.1149  data: 0.0844  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1690 (1.0903)  acc1: 76.0417 (78.4778)  acc5: 91.6667 (92.5067)  time: 0.1313  data: 0.1009  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2689 (1.1255)  acc1: 76.0417 (77.7185)  acc5: 90.6250 (92.0605)  time: 0.1277  data: 0.0972  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1134 (1.1297)  acc1: 76.0417 (77.2978)  acc5: 91.6667 (92.1671)  time: 0.1332  data: 0.1027  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1819 (1.1423)  acc1: 73.9583 (77.1300)  acc5: 91.6667 (92.2000)  time: 0.1322  data: 0.1027  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1369 s / it)\n",
            "* Acc@1 77.130 Acc@5 92.200 loss 1.142\n",
            "Accuracy of the network on the 10000 test images: 77.1%\n",
            "Max accuracy: 77.28%\n",
            "[alpha-schedule=cosine] epoch=45 distillation_alpha=0.3780\n",
            "Epoch: [45]  [  0/781]  eta: 0:14:31  lr: 0.000035  loss: 1.9885 (1.9885)  time: 1.1156  data: 0.7625  max mem: 6459\n",
            "Epoch: [45]  [ 10/781]  eta: 0:05:11  lr: 0.000035  loss: 1.3601 (1.5481)  time: 0.4035  data: 0.0696  max mem: 6459\n",
            "Epoch: [45]  [ 20/781]  eta: 0:04:40  lr: 0.000035  loss: 1.3626 (1.5170)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 30/781]  eta: 0:04:28  lr: 0.000035  loss: 1.3999 (1.5741)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 40/781]  eta: 0:04:19  lr: 0.000035  loss: 1.4188 (1.5583)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 50/781]  eta: 0:04:13  lr: 0.000035  loss: 1.3319 (1.5183)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 60/781]  eta: 0:04:08  lr: 0.000035  loss: 1.3319 (1.5090)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 70/781]  eta: 0:04:03  lr: 0.000035  loss: 1.3318 (1.5003)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 80/781]  eta: 0:03:59  lr: 0.000035  loss: 1.3782 (1.4910)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [ 90/781]  eta: 0:03:54  lr: 0.000035  loss: 1.3811 (1.4903)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [100/781]  eta: 0:03:50  lr: 0.000035  loss: 1.3994 (1.4999)  time: 0.3314  data: 0.0004  max mem: 6459\n",
            "Epoch: [45]  [110/781]  eta: 0:03:47  lr: 0.000035  loss: 1.3488 (1.4919)  time: 0.3314  data: 0.0004  max mem: 6459\n",
            "Epoch: [45]  [120/781]  eta: 0:03:43  lr: 0.000035  loss: 1.3759 (1.4984)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [130/781]  eta: 0:03:39  lr: 0.000035  loss: 1.3836 (1.4972)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [140/781]  eta: 0:03:36  lr: 0.000035  loss: 1.3810 (1.5041)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [150/781]  eta: 0:03:32  lr: 0.000035  loss: 1.3731 (1.5014)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [160/781]  eta: 0:03:28  lr: 0.000035  loss: 1.3457 (1.4978)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [170/781]  eta: 0:03:25  lr: 0.000035  loss: 1.4239 (1.5039)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [180/781]  eta: 0:03:21  lr: 0.000035  loss: 1.3922 (1.5000)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [190/781]  eta: 0:03:18  lr: 0.000035  loss: 1.3784 (1.4962)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [200/781]  eta: 0:03:14  lr: 0.000035  loss: 1.3634 (1.5010)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [210/781]  eta: 0:03:11  lr: 0.000035  loss: 1.4290 (1.5030)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [220/781]  eta: 0:03:07  lr: 0.000035  loss: 1.4559 (1.5111)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [230/781]  eta: 0:03:04  lr: 0.000035  loss: 1.3774 (1.5033)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [240/781]  eta: 0:03:01  lr: 0.000035  loss: 1.3683 (1.5092)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [250/781]  eta: 0:02:57  lr: 0.000035  loss: 1.4024 (1.5113)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [260/781]  eta: 0:02:54  lr: 0.000035  loss: 1.3456 (1.5076)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [270/781]  eta: 0:02:50  lr: 0.000035  loss: 1.4045 (1.5090)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [280/781]  eta: 0:02:47  lr: 0.000035  loss: 1.3912 (1.5083)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [290/781]  eta: 0:02:44  lr: 0.000035  loss: 1.3522 (1.5104)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [300/781]  eta: 0:02:40  lr: 0.000035  loss: 1.3904 (1.5057)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [310/781]  eta: 0:02:37  lr: 0.000035  loss: 1.3839 (1.5019)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [320/781]  eta: 0:02:33  lr: 0.000035  loss: 1.3575 (1.5006)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [330/781]  eta: 0:02:30  lr: 0.000035  loss: 1.3771 (1.5002)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [340/781]  eta: 0:02:27  lr: 0.000035  loss: 1.3625 (1.4961)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [350/781]  eta: 0:02:23  lr: 0.000035  loss: 1.3492 (1.4957)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [360/781]  eta: 0:02:20  lr: 0.000035  loss: 1.3648 (1.4969)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [370/781]  eta: 0:02:17  lr: 0.000035  loss: 1.3841 (1.4982)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [380/781]  eta: 0:02:13  lr: 0.000035  loss: 1.3724 (1.4960)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [390/781]  eta: 0:02:10  lr: 0.000035  loss: 1.3748 (1.5017)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [400/781]  eta: 0:02:07  lr: 0.000035  loss: 1.3788 (1.5001)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [410/781]  eta: 0:02:03  lr: 0.000035  loss: 1.3626 (1.5002)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [420/781]  eta: 0:02:00  lr: 0.000035  loss: 1.3831 (1.4990)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [430/781]  eta: 0:01:56  lr: 0.000035  loss: 1.3901 (1.5008)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [440/781]  eta: 0:01:53  lr: 0.000035  loss: 1.3135 (1.4977)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [450/781]  eta: 0:01:50  lr: 0.000035  loss: 1.3308 (1.4966)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [460/781]  eta: 0:01:46  lr: 0.000035  loss: 1.3561 (1.4958)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [470/781]  eta: 0:01:43  lr: 0.000035  loss: 1.3761 (1.4958)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [480/781]  eta: 0:01:40  lr: 0.000035  loss: 1.3772 (1.4927)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [490/781]  eta: 0:01:36  lr: 0.000035  loss: 1.3972 (1.4918)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [500/781]  eta: 0:01:33  lr: 0.000035  loss: 1.3746 (1.4903)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [510/781]  eta: 0:01:30  lr: 0.000035  loss: 1.3722 (1.4951)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [520/781]  eta: 0:01:26  lr: 0.000035  loss: 1.4148 (1.4981)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [530/781]  eta: 0:01:23  lr: 0.000035  loss: 1.4153 (1.5006)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [540/781]  eta: 0:01:20  lr: 0.000035  loss: 1.3937 (1.5012)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [550/781]  eta: 0:01:16  lr: 0.000035  loss: 1.3608 (1.5009)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [560/781]  eta: 0:01:13  lr: 0.000035  loss: 1.3337 (1.5000)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [570/781]  eta: 0:01:10  lr: 0.000035  loss: 1.3338 (1.5001)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [580/781]  eta: 0:01:06  lr: 0.000035  loss: 1.3389 (1.4994)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [590/781]  eta: 0:01:03  lr: 0.000035  loss: 1.3704 (1.5005)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [600/781]  eta: 0:01:00  lr: 0.000035  loss: 1.4177 (1.5008)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [610/781]  eta: 0:00:56  lr: 0.000035  loss: 1.4177 (1.4993)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [620/781]  eta: 0:00:53  lr: 0.000035  loss: 1.4168 (1.5004)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [630/781]  eta: 0:00:50  lr: 0.000035  loss: 1.3610 (1.4994)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [640/781]  eta: 0:00:46  lr: 0.000035  loss: 1.3500 (1.4972)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [650/781]  eta: 0:00:43  lr: 0.000035  loss: 1.3510 (1.4964)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [660/781]  eta: 0:00:40  lr: 0.000035  loss: 1.3714 (1.4965)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [670/781]  eta: 0:00:36  lr: 0.000035  loss: 1.3947 (1.4955)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [680/781]  eta: 0:00:33  lr: 0.000035  loss: 1.3911 (1.4934)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [690/781]  eta: 0:00:30  lr: 0.000035  loss: 1.3936 (1.4945)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [700/781]  eta: 0:00:26  lr: 0.000035  loss: 1.4744 (1.4952)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [710/781]  eta: 0:00:23  lr: 0.000035  loss: 1.4401 (1.4952)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [720/781]  eta: 0:00:20  lr: 0.000035  loss: 1.4401 (1.4951)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [730/781]  eta: 0:00:16  lr: 0.000035  loss: 1.3974 (1.4962)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [740/781]  eta: 0:00:13  lr: 0.000035  loss: 1.3673 (1.4975)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [750/781]  eta: 0:00:10  lr: 0.000035  loss: 1.3550 (1.4981)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [760/781]  eta: 0:00:06  lr: 0.000035  loss: 1.3511 (1.4988)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [770/781]  eta: 0:00:03  lr: 0.000035  loss: 1.3432 (1.4981)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [45]  [780/781]  eta: 0:00:00  lr: 0.000035  loss: 1.3432 (1.4969)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [45] Total time: 0:04:19 (0.3326 s / it)\n",
            "Averaged stats: lr: 0.000035  loss: 1.3432 (1.4969)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32914599776268005, 'lambda_convnext_base': 0.2590145170688629, 'lambda_tf_efficientnetv2_l': 0.4118397533893585}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.8063 (0.8063)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 0.8691  data: 0.8385  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8649 (0.9427)  acc1: 83.8542 (80.7292)  acc5: 94.2708 (93.8447)  time: 0.1769  data: 0.1464  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9968 (1.0227)  acc1: 80.7292 (79.6379)  acc5: 93.7500 (92.8819)  time: 0.1280  data: 0.0976  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2120 (1.0872)  acc1: 75.0000 (78.4442)  acc5: 91.1458 (92.2379)  time: 0.1276  data: 0.0972  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2558 (1.1308)  acc1: 74.4792 (77.5280)  acc5: 90.1042 (91.6667)  time: 0.1308  data: 0.1003  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1082 (1.1241)  acc1: 76.5625 (77.4612)  acc5: 92.7083 (91.9424)  time: 0.1289  data: 0.0985  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1112 (1.1376)  acc1: 76.0417 (77.3300)  acc5: 92.7083 (91.9600)  time: 0.1087  data: 0.0791  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1353 s / it)\n",
            "* Acc@1 77.330 Acc@5 91.960 loss 1.138\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.33%\n",
            "[alpha-schedule=cosine] epoch=46 distillation_alpha=0.3873\n",
            "Epoch: [46]  [  0/781]  eta: 0:14:26  lr: 0.000034  loss: 1.3375 (1.3375)  time: 1.1097  data: 0.7655  max mem: 6459\n",
            "Epoch: [46]  [ 10/781]  eta: 0:05:25  lr: 0.000034  loss: 1.3681 (1.4143)  time: 0.4226  data: 0.0699  max mem: 6459\n",
            "Epoch: [46]  [ 20/781]  eta: 0:04:48  lr: 0.000034  loss: 1.3681 (1.4261)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 30/781]  eta: 0:04:33  lr: 0.000034  loss: 1.3720 (1.4292)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 40/781]  eta: 0:04:23  lr: 0.000034  loss: 1.3861 (1.4687)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 50/781]  eta: 0:04:16  lr: 0.000034  loss: 1.3861 (1.4654)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 60/781]  eta: 0:04:10  lr: 0.000034  loss: 1.3702 (1.4801)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 70/781]  eta: 0:04:05  lr: 0.000034  loss: 1.3520 (1.4824)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 80/781]  eta: 0:04:01  lr: 0.000034  loss: 1.3503 (1.4649)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [ 90/781]  eta: 0:03:56  lr: 0.000034  loss: 1.3657 (1.4751)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [100/781]  eta: 0:03:52  lr: 0.000034  loss: 1.3281 (1.4620)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [110/781]  eta: 0:03:48  lr: 0.000034  loss: 1.3281 (1.4508)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [120/781]  eta: 0:03:44  lr: 0.000034  loss: 1.3613 (1.4584)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [130/781]  eta: 0:03:40  lr: 0.000034  loss: 1.3656 (1.4675)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [140/781]  eta: 0:03:37  lr: 0.000034  loss: 1.3590 (1.4737)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [150/781]  eta: 0:03:33  lr: 0.000034  loss: 1.3434 (1.4737)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [160/781]  eta: 0:03:29  lr: 0.000034  loss: 1.3625 (1.4775)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [170/781]  eta: 0:03:26  lr: 0.000034  loss: 1.4153 (1.4901)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [180/781]  eta: 0:03:22  lr: 0.000034  loss: 1.3200 (1.4791)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [190/781]  eta: 0:03:19  lr: 0.000034  loss: 1.2981 (1.4742)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [200/781]  eta: 0:03:15  lr: 0.000034  loss: 1.3151 (1.4716)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [210/781]  eta: 0:03:12  lr: 0.000034  loss: 1.3519 (1.4797)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [220/781]  eta: 0:03:08  lr: 0.000034  loss: 1.4206 (1.4823)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [230/781]  eta: 0:03:05  lr: 0.000034  loss: 1.4206 (1.4939)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [240/781]  eta: 0:03:01  lr: 0.000034  loss: 1.4131 (1.4942)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [250/781]  eta: 0:02:58  lr: 0.000034  loss: 1.3868 (1.4964)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [260/781]  eta: 0:02:54  lr: 0.000034  loss: 1.4480 (1.5003)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [270/781]  eta: 0:02:51  lr: 0.000034  loss: 1.4307 (1.4997)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [280/781]  eta: 0:02:47  lr: 0.000034  loss: 1.4008 (1.4965)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [290/781]  eta: 0:02:44  lr: 0.000034  loss: 1.3827 (1.4980)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [300/781]  eta: 0:02:41  lr: 0.000034  loss: 1.4316 (1.5066)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [310/781]  eta: 0:02:37  lr: 0.000034  loss: 1.4129 (1.5040)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [320/781]  eta: 0:02:34  lr: 0.000034  loss: 1.3453 (1.5012)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [330/781]  eta: 0:02:30  lr: 0.000034  loss: 1.3364 (1.5024)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [340/781]  eta: 0:02:27  lr: 0.000034  loss: 1.3413 (1.5048)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [350/781]  eta: 0:02:24  lr: 0.000034  loss: 1.3451 (1.5075)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [360/781]  eta: 0:02:20  lr: 0.000034  loss: 1.3778 (1.5164)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [370/781]  eta: 0:02:17  lr: 0.000034  loss: 1.4113 (1.5160)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [380/781]  eta: 0:02:14  lr: 0.000034  loss: 1.4468 (1.5233)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [390/781]  eta: 0:02:10  lr: 0.000034  loss: 1.4468 (1.5220)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [400/781]  eta: 0:02:07  lr: 0.000034  loss: 1.3572 (1.5216)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [410/781]  eta: 0:02:03  lr: 0.000034  loss: 1.3631 (1.5175)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [420/781]  eta: 0:02:00  lr: 0.000034  loss: 1.3698 (1.5200)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [430/781]  eta: 0:01:57  lr: 0.000034  loss: 1.3960 (1.5229)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [440/781]  eta: 0:01:53  lr: 0.000034  loss: 1.4246 (1.5251)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [450/781]  eta: 0:01:50  lr: 0.000034  loss: 1.4116 (1.5257)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [460/781]  eta: 0:01:47  lr: 0.000034  loss: 1.3633 (1.5269)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [470/781]  eta: 0:01:43  lr: 0.000034  loss: 1.3618 (1.5266)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [480/781]  eta: 0:01:40  lr: 0.000034  loss: 1.3770 (1.5276)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [490/781]  eta: 0:01:37  lr: 0.000034  loss: 1.3562 (1.5262)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [500/781]  eta: 0:01:33  lr: 0.000034  loss: 1.3699 (1.5256)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [510/781]  eta: 0:01:30  lr: 0.000034  loss: 1.3929 (1.5225)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [520/781]  eta: 0:01:27  lr: 0.000034  loss: 1.3929 (1.5215)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [530/781]  eta: 0:01:23  lr: 0.000034  loss: 1.3724 (1.5221)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [540/781]  eta: 0:01:20  lr: 0.000034  loss: 1.3704 (1.5245)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [550/781]  eta: 0:01:17  lr: 0.000034  loss: 1.3810 (1.5235)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [560/781]  eta: 0:01:13  lr: 0.000034  loss: 1.3637 (1.5234)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [570/781]  eta: 0:01:10  lr: 0.000034  loss: 1.3979 (1.5237)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [580/781]  eta: 0:01:06  lr: 0.000034  loss: 1.3932 (1.5223)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [590/781]  eta: 0:01:03  lr: 0.000034  loss: 1.3564 (1.5217)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [600/781]  eta: 0:01:00  lr: 0.000034  loss: 1.3452 (1.5202)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [610/781]  eta: 0:00:56  lr: 0.000034  loss: 1.3452 (1.5200)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [620/781]  eta: 0:00:53  lr: 0.000034  loss: 1.3773 (1.5210)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [630/781]  eta: 0:00:50  lr: 0.000034  loss: 1.4041 (1.5209)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [640/781]  eta: 0:00:46  lr: 0.000034  loss: 1.4041 (1.5198)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [650/781]  eta: 0:00:43  lr: 0.000034  loss: 1.3637 (1.5209)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [660/781]  eta: 0:00:40  lr: 0.000034  loss: 1.3529 (1.5192)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [670/781]  eta: 0:00:36  lr: 0.000034  loss: 1.3827 (1.5179)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [680/781]  eta: 0:00:33  lr: 0.000034  loss: 1.3801 (1.5184)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [690/781]  eta: 0:00:30  lr: 0.000034  loss: 1.4550 (1.5228)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [700/781]  eta: 0:00:26  lr: 0.000034  loss: 1.4749 (1.5218)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [710/781]  eta: 0:00:23  lr: 0.000034  loss: 1.3602 (1.5203)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [720/781]  eta: 0:00:20  lr: 0.000034  loss: 1.3564 (1.5193)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [730/781]  eta: 0:00:16  lr: 0.000034  loss: 1.3880 (1.5193)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [740/781]  eta: 0:00:13  lr: 0.000034  loss: 1.4289 (1.5203)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [750/781]  eta: 0:00:10  lr: 0.000034  loss: 1.3777 (1.5193)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [760/781]  eta: 0:00:06  lr: 0.000034  loss: 1.3437 (1.5202)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [770/781]  eta: 0:00:03  lr: 0.000034  loss: 1.3403 (1.5183)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [780/781]  eta: 0:00:00  lr: 0.000034  loss: 1.3427 (1.5174)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [46] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000034  loss: 1.3427 (1.5174)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3281283676624298, 'lambda_convnext_base': 0.2602401077747345, 'lambda_tf_efficientnetv2_l': 0.41163143515586853}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7287 (0.7287)  acc1: 85.9375 (85.9375)  acc5: 96.3542 (96.3542)  time: 0.8498  data: 0.8191  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8867 (0.9234)  acc1: 82.2917 (81.0606)  acc5: 95.8333 (94.4602)  time: 0.1699  data: 0.1394  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0079 (1.0127)  acc1: 77.0833 (79.4395)  acc5: 94.2708 (93.2044)  time: 0.1166  data: 0.0861  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1572 (1.0739)  acc1: 76.5625 (78.2090)  acc5: 92.1875 (92.7251)  time: 0.1183  data: 0.0878  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2007 (1.1133)  acc1: 74.4792 (77.5661)  acc5: 91.6667 (92.2383)  time: 0.1158  data: 0.0854  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0814 (1.1147)  acc1: 76.0417 (77.3999)  acc5: 92.7083 (92.4224)  time: 0.1135  data: 0.0830  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1372 (1.1319)  acc1: 74.4792 (77.2400)  acc5: 93.2292 (92.4400)  time: 0.0990  data: 0.0694  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1247 s / it)\n",
            "* Acc@1 77.240 Acc@5 92.440 loss 1.132\n",
            "Accuracy of the network on the 10000 test images: 77.2%\n",
            "Max accuracy: 77.33%\n",
            "[alpha-schedule=cosine] epoch=47 distillation_alpha=0.3965\n",
            "Epoch: [47]  [  0/781]  eta: 0:15:02  lr: 0.000033  loss: 1.7647 (1.7647)  time: 1.1553  data: 0.8078  max mem: 6459\n",
            "Epoch: [47]  [ 10/781]  eta: 0:05:13  lr: 0.000033  loss: 1.3977 (1.5933)  time: 0.4062  data: 0.0737  max mem: 6459\n",
            "Epoch: [47]  [ 20/781]  eta: 0:04:42  lr: 0.000033  loss: 1.3503 (1.5278)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 30/781]  eta: 0:04:29  lr: 0.000033  loss: 1.3569 (1.5095)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [47]  [ 40/781]  eta: 0:04:20  lr: 0.000033  loss: 1.3739 (1.5631)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 50/781]  eta: 0:04:14  lr: 0.000033  loss: 1.4243 (1.5403)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 60/781]  eta: 0:04:08  lr: 0.000033  loss: 1.4381 (1.5541)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 70/781]  eta: 0:04:04  lr: 0.000033  loss: 1.4209 (1.5584)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 80/781]  eta: 0:03:59  lr: 0.000033  loss: 1.3311 (1.5552)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 90/781]  eta: 0:03:55  lr: 0.000033  loss: 1.2939 (1.5323)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [100/781]  eta: 0:03:51  lr: 0.000033  loss: 1.3456 (1.5405)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [110/781]  eta: 0:03:47  lr: 0.000033  loss: 1.3411 (1.5279)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [120/781]  eta: 0:03:43  lr: 0.000033  loss: 1.3147 (1.5293)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [130/781]  eta: 0:03:39  lr: 0.000033  loss: 1.3852 (1.5267)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [140/781]  eta: 0:03:36  lr: 0.000033  loss: 1.3127 (1.5246)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [150/781]  eta: 0:03:32  lr: 0.000033  loss: 1.3508 (1.5212)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [160/781]  eta: 0:03:29  lr: 0.000033  loss: 1.3669 (1.5175)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [170/781]  eta: 0:03:25  lr: 0.000033  loss: 1.3682 (1.5082)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [180/781]  eta: 0:03:21  lr: 0.000033  loss: 1.3520 (1.5032)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [190/781]  eta: 0:03:18  lr: 0.000033  loss: 1.3835 (1.5003)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [200/781]  eta: 0:03:14  lr: 0.000033  loss: 1.3709 (1.5043)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [210/781]  eta: 0:03:11  lr: 0.000033  loss: 1.3645 (1.5015)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [220/781]  eta: 0:03:07  lr: 0.000033  loss: 1.3608 (1.4956)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [230/781]  eta: 0:03:04  lr: 0.000033  loss: 1.3547 (1.4889)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [240/781]  eta: 0:03:01  lr: 0.000033  loss: 1.3565 (1.4894)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [250/781]  eta: 0:02:57  lr: 0.000033  loss: 1.3617 (1.4918)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [260/781]  eta: 0:02:54  lr: 0.000033  loss: 1.4224 (1.4953)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [270/781]  eta: 0:02:50  lr: 0.000033  loss: 1.4224 (1.4960)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [280/781]  eta: 0:02:47  lr: 0.000033  loss: 1.3799 (1.4922)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [290/781]  eta: 0:02:44  lr: 0.000033  loss: 1.3506 (1.4900)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [300/781]  eta: 0:02:40  lr: 0.000033  loss: 1.3803 (1.4948)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [310/781]  eta: 0:02:37  lr: 0.000033  loss: 1.4306 (1.4953)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [320/781]  eta: 0:02:34  lr: 0.000033  loss: 1.4372 (1.4977)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [330/781]  eta: 0:02:30  lr: 0.000033  loss: 1.3803 (1.4941)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [340/781]  eta: 0:02:27  lr: 0.000033  loss: 1.3337 (1.4893)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [350/781]  eta: 0:02:23  lr: 0.000033  loss: 1.3554 (1.4917)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [360/781]  eta: 0:02:20  lr: 0.000033  loss: 1.3941 (1.4932)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [370/781]  eta: 0:02:17  lr: 0.000033  loss: 1.3267 (1.4909)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [380/781]  eta: 0:02:13  lr: 0.000033  loss: 1.3245 (1.4932)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [390/781]  eta: 0:02:10  lr: 0.000033  loss: 1.3621 (1.4935)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [400/781]  eta: 0:02:07  lr: 0.000033  loss: 1.3773 (1.4967)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [410/781]  eta: 0:02:03  lr: 0.000033  loss: 1.3749 (1.4965)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [420/781]  eta: 0:02:00  lr: 0.000033  loss: 1.3660 (1.4950)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [430/781]  eta: 0:01:57  lr: 0.000033  loss: 1.3478 (1.4948)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [440/781]  eta: 0:01:53  lr: 0.000033  loss: 1.3368 (1.4941)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [450/781]  eta: 0:01:50  lr: 0.000033  loss: 1.3444 (1.5005)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [460/781]  eta: 0:01:47  lr: 0.000033  loss: 1.3976 (1.5037)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [470/781]  eta: 0:01:43  lr: 0.000033  loss: 1.3728 (1.5008)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [480/781]  eta: 0:01:40  lr: 0.000033  loss: 1.3728 (1.5051)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [490/781]  eta: 0:01:37  lr: 0.000033  loss: 1.4541 (1.5071)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [500/781]  eta: 0:01:33  lr: 0.000033  loss: 1.3195 (1.5037)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [510/781]  eta: 0:01:30  lr: 0.000033  loss: 1.3185 (1.5040)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [520/781]  eta: 0:01:26  lr: 0.000033  loss: 1.3335 (1.5008)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [530/781]  eta: 0:01:23  lr: 0.000033  loss: 1.3439 (1.5003)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [540/781]  eta: 0:01:20  lr: 0.000033  loss: 1.3954 (1.5028)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [550/781]  eta: 0:01:16  lr: 0.000033  loss: 1.3954 (1.5013)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [560/781]  eta: 0:01:13  lr: 0.000033  loss: 1.3441 (1.4995)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [570/781]  eta: 0:01:10  lr: 0.000033  loss: 1.3678 (1.5020)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [580/781]  eta: 0:01:06  lr: 0.000033  loss: 1.3934 (1.5025)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [590/781]  eta: 0:01:03  lr: 0.000033  loss: 1.3853 (1.5007)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [600/781]  eta: 0:01:00  lr: 0.000033  loss: 1.3375 (1.5020)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [610/781]  eta: 0:00:56  lr: 0.000033  loss: 1.3978 (1.5046)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [620/781]  eta: 0:00:53  lr: 0.000033  loss: 1.4114 (1.5056)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [630/781]  eta: 0:00:50  lr: 0.000033  loss: 1.4210 (1.5069)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [640/781]  eta: 0:00:46  lr: 0.000033  loss: 1.3984 (1.5086)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [650/781]  eta: 0:00:43  lr: 0.000033  loss: 1.3749 (1.5073)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [660/781]  eta: 0:00:40  lr: 0.000033  loss: 1.3444 (1.5052)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [670/781]  eta: 0:00:36  lr: 0.000033  loss: 1.2888 (1.5063)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [680/781]  eta: 0:00:33  lr: 0.000033  loss: 1.3502 (1.5042)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [690/781]  eta: 0:00:30  lr: 0.000033  loss: 1.3760 (1.5051)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [700/781]  eta: 0:00:26  lr: 0.000033  loss: 1.4261 (1.5042)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [710/781]  eta: 0:00:23  lr: 0.000033  loss: 1.4077 (1.5057)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [720/781]  eta: 0:00:20  lr: 0.000033  loss: 1.4136 (1.5070)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [730/781]  eta: 0:00:16  lr: 0.000033  loss: 1.3556 (1.5047)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [740/781]  eta: 0:00:13  lr: 0.000033  loss: 1.3534 (1.5034)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [750/781]  eta: 0:00:10  lr: 0.000033  loss: 1.3902 (1.5065)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [760/781]  eta: 0:00:06  lr: 0.000033  loss: 1.3727 (1.5047)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [770/781]  eta: 0:00:03  lr: 0.000033  loss: 1.3720 (1.5046)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [780/781]  eta: 0:00:00  lr: 0.000033  loss: 1.3930 (1.5069)  time: 0.3322  data: 0.0006  max mem: 6459\n",
            "Epoch: [47] Total time: 0:04:20 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000033  loss: 1.3930 (1.5069)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3287958800792694, 'lambda_convnext_base': 0.2599506378173828, 'lambda_tf_efficientnetv2_l': 0.41125351190567017}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7318 (0.7318)  acc1: 85.4167 (85.4167)  acc5: 95.3125 (95.3125)  time: 0.8602  data: 0.8294  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9075 (0.9327)  acc1: 83.8542 (81.1553)  acc5: 95.8333 (94.6023)  time: 0.1845  data: 0.1540  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0094 (1.0199)  acc1: 77.6042 (79.3155)  acc5: 93.7500 (93.4524)  time: 0.1364  data: 0.1059  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2041 (1.0761)  acc1: 75.0000 (78.3098)  acc5: 91.6667 (92.8259)  time: 0.1348  data: 0.1043  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2179 (1.1246)  acc1: 75.0000 (77.4517)  acc5: 90.6250 (92.2383)  time: 0.1359  data: 0.1055  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1087 (1.1187)  acc1: 77.0833 (77.5123)  acc5: 91.6667 (92.3713)  time: 0.1359  data: 0.1055  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1516 (1.1262)  acc1: 75.0000 (77.4200)  acc5: 93.2292 (92.4000)  time: 0.1139  data: 0.0843  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1421 s / it)\n",
            "* Acc@1 77.420 Acc@5 92.400 loss 1.126\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.42%\n",
            "[alpha-schedule=cosine] epoch=48 distillation_alpha=0.4056\n",
            "Epoch: [48]  [  0/781]  eta: 0:14:51  lr: 0.000032  loss: 1.3070 (1.3070)  time: 1.1411  data: 0.7921  max mem: 6459\n",
            "Epoch: [48]  [ 10/781]  eta: 0:05:13  lr: 0.000032  loss: 1.3881 (1.5094)  time: 0.4060  data: 0.0724  max mem: 6459\n",
            "Epoch: [48]  [ 20/781]  eta: 0:04:42  lr: 0.000032  loss: 1.3607 (1.4481)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [48]  [ 30/781]  eta: 0:04:29  lr: 0.000032  loss: 1.3456 (1.4390)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 40/781]  eta: 0:04:20  lr: 0.000032  loss: 1.3391 (1.4104)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 50/781]  eta: 0:04:14  lr: 0.000032  loss: 1.3494 (1.4256)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 60/781]  eta: 0:04:09  lr: 0.000032  loss: 1.3522 (1.4524)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 70/781]  eta: 0:04:04  lr: 0.000032  loss: 1.3429 (1.4332)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 80/781]  eta: 0:03:59  lr: 0.000032  loss: 1.3034 (1.4574)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 90/781]  eta: 0:03:55  lr: 0.000032  loss: 1.3571 (1.4837)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [100/781]  eta: 0:03:51  lr: 0.000032  loss: 1.3616 (1.4791)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [110/781]  eta: 0:03:47  lr: 0.000032  loss: 1.3292 (1.4832)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [120/781]  eta: 0:03:44  lr: 0.000032  loss: 1.3672 (1.4779)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [130/781]  eta: 0:03:40  lr: 0.000032  loss: 1.3541 (1.4812)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [140/781]  eta: 0:03:36  lr: 0.000032  loss: 1.3210 (1.4776)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [150/781]  eta: 0:03:33  lr: 0.000032  loss: 1.3418 (1.4862)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [160/781]  eta: 0:03:29  lr: 0.000032  loss: 1.3418 (1.4926)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [170/781]  eta: 0:03:25  lr: 0.000032  loss: 1.3230 (1.4898)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [180/781]  eta: 0:03:22  lr: 0.000032  loss: 1.3564 (1.4931)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [190/781]  eta: 0:03:18  lr: 0.000032  loss: 1.4070 (1.4989)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [200/781]  eta: 0:03:15  lr: 0.000032  loss: 1.3391 (1.4899)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [210/781]  eta: 0:03:11  lr: 0.000032  loss: 1.3473 (1.4906)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [220/781]  eta: 0:03:08  lr: 0.000032  loss: 1.3892 (1.4933)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [230/781]  eta: 0:03:04  lr: 0.000032  loss: 1.3547 (1.4846)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [240/781]  eta: 0:03:01  lr: 0.000032  loss: 1.3326 (1.4851)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [250/781]  eta: 0:02:58  lr: 0.000032  loss: 1.3671 (1.4807)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [260/781]  eta: 0:02:54  lr: 0.000032  loss: 1.3913 (1.4914)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [270/781]  eta: 0:02:51  lr: 0.000032  loss: 1.4078 (1.4970)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [280/781]  eta: 0:02:47  lr: 0.000032  loss: 1.3469 (1.4967)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [290/781]  eta: 0:02:44  lr: 0.000032  loss: 1.3290 (1.4943)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [300/781]  eta: 0:02:41  lr: 0.000032  loss: 1.3141 (1.4932)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [310/781]  eta: 0:02:37  lr: 0.000032  loss: 1.3127 (1.4901)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [320/781]  eta: 0:02:34  lr: 0.000032  loss: 1.3430 (1.4862)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [330/781]  eta: 0:02:30  lr: 0.000032  loss: 1.3455 (1.4908)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [340/781]  eta: 0:02:27  lr: 0.000032  loss: 1.3617 (1.4898)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [350/781]  eta: 0:02:24  lr: 0.000032  loss: 1.3685 (1.4950)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [360/781]  eta: 0:02:20  lr: 0.000032  loss: 1.4366 (1.4988)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [370/781]  eta: 0:02:17  lr: 0.000032  loss: 1.3812 (1.4945)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [380/781]  eta: 0:02:14  lr: 0.000032  loss: 1.3596 (1.4937)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [390/781]  eta: 0:02:10  lr: 0.000032  loss: 1.3436 (1.4905)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [400/781]  eta: 0:02:07  lr: 0.000032  loss: 1.3512 (1.4907)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [410/781]  eta: 0:02:03  lr: 0.000032  loss: 1.3262 (1.4860)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [420/781]  eta: 0:02:00  lr: 0.000032  loss: 1.3420 (1.4836)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [430/781]  eta: 0:01:57  lr: 0.000032  loss: 1.3716 (1.4802)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [440/781]  eta: 0:01:53  lr: 0.000032  loss: 1.3291 (1.4805)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [450/781]  eta: 0:01:50  lr: 0.000032  loss: 1.3410 (1.4783)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [460/781]  eta: 0:01:47  lr: 0.000032  loss: 1.3543 (1.4811)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [470/781]  eta: 0:01:43  lr: 0.000032  loss: 1.3773 (1.4788)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [480/781]  eta: 0:01:40  lr: 0.000032  loss: 1.3527 (1.4757)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [490/781]  eta: 0:01:37  lr: 0.000032  loss: 1.3177 (1.4801)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [500/781]  eta: 0:01:33  lr: 0.000032  loss: 1.3767 (1.4791)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [510/781]  eta: 0:01:30  lr: 0.000032  loss: 1.3789 (1.4810)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [520/781]  eta: 0:01:27  lr: 0.000032  loss: 1.3813 (1.4810)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [530/781]  eta: 0:01:23  lr: 0.000032  loss: 1.3267 (1.4791)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [540/781]  eta: 0:01:20  lr: 0.000032  loss: 1.3773 (1.4806)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [550/781]  eta: 0:01:17  lr: 0.000032  loss: 1.4822 (1.4849)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [560/781]  eta: 0:01:13  lr: 0.000032  loss: 1.4568 (1.4845)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [570/781]  eta: 0:01:10  lr: 0.000032  loss: 1.3620 (1.4837)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [580/781]  eta: 0:01:07  lr: 0.000032  loss: 1.3428 (1.4849)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [590/781]  eta: 0:01:03  lr: 0.000032  loss: 1.3115 (1.4844)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [600/781]  eta: 0:01:00  lr: 0.000032  loss: 1.3119 (1.4819)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [610/781]  eta: 0:00:57  lr: 0.000032  loss: 1.3395 (1.4806)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [620/781]  eta: 0:00:53  lr: 0.000032  loss: 1.3780 (1.4815)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [630/781]  eta: 0:00:50  lr: 0.000032  loss: 1.4319 (1.4859)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [640/781]  eta: 0:00:47  lr: 0.000032  loss: 1.4132 (1.4861)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [650/781]  eta: 0:00:43  lr: 0.000032  loss: 1.4077 (1.4883)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [660/781]  eta: 0:00:40  lr: 0.000032  loss: 1.4228 (1.4890)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [670/781]  eta: 0:00:37  lr: 0.000032  loss: 1.3604 (1.4883)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [680/781]  eta: 0:00:33  lr: 0.000032  loss: 1.3315 (1.4876)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [690/781]  eta: 0:00:30  lr: 0.000032  loss: 1.3993 (1.4892)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [700/781]  eta: 0:00:27  lr: 0.000032  loss: 1.4126 (1.4891)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [710/781]  eta: 0:00:23  lr: 0.000032  loss: 1.3683 (1.4897)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [720/781]  eta: 0:00:20  lr: 0.000032  loss: 1.3402 (1.4874)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [730/781]  eta: 0:00:17  lr: 0.000032  loss: 1.3378 (1.4860)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [740/781]  eta: 0:00:13  lr: 0.000032  loss: 1.3457 (1.4868)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [750/781]  eta: 0:00:10  lr: 0.000032  loss: 1.3450 (1.4866)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [760/781]  eta: 0:00:07  lr: 0.000032  loss: 1.3582 (1.4860)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [770/781]  eta: 0:00:03  lr: 0.000032  loss: 1.3965 (1.4865)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [780/781]  eta: 0:00:00  lr: 0.000032  loss: 1.4212 (1.4885)  time: 0.3323  data: 0.0006  max mem: 6459\n",
            "Epoch: [48] Total time: 0:04:20 (0.3335 s / it)\n",
            "Averaged stats: lr: 0.000032  loss: 1.4212 (1.4885)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32869529724121094, 'lambda_convnext_base': 0.25993576645851135, 'lambda_tf_efficientnetv2_l': 0.41136908531188965}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7990 (0.7990)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8146  data: 0.7833  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9162 (0.9505)  acc1: 82.8125 (80.9186)  acc5: 95.8333 (94.3655)  time: 0.1712  data: 0.1405  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0023 (1.0175)  acc1: 78.1250 (79.6131)  acc5: 93.7500 (93.1796)  time: 0.1302  data: 0.0997  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1656 (1.0771)  acc1: 76.0417 (78.5450)  acc5: 91.6667 (92.5907)  time: 0.1386  data: 0.1081  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2115 (1.1239)  acc1: 76.0417 (77.7185)  acc5: 90.6250 (92.1113)  time: 0.1368  data: 0.1063  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1309 (1.1306)  acc1: 76.0417 (77.3999)  acc5: 91.6667 (92.2488)  time: 0.1333  data: 0.1028  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1517 (1.1399)  acc1: 75.5208 (77.2500)  acc5: 92.1875 (92.2700)  time: 0.1154  data: 0.0857  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1400 s / it)\n",
            "* Acc@1 77.250 Acc@5 92.270 loss 1.140\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.42%\n",
            "[alpha-schedule=cosine] epoch=49 distillation_alpha=0.4147\n",
            "Epoch: [49]  [  0/781]  eta: 0:14:33  lr: 0.000031  loss: 1.3159 (1.3159)  time: 1.1189  data: 0.7565  max mem: 6459\n",
            "Epoch: [49]  [ 10/781]  eta: 0:05:11  lr: 0.000031  loss: 1.2983 (1.4587)  time: 0.4034  data: 0.0691  max mem: 6459\n",
            "Epoch: [49]  [ 20/781]  eta: 0:04:41  lr: 0.000031  loss: 1.2983 (1.4017)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [49]  [ 30/781]  eta: 0:04:28  lr: 0.000031  loss: 1.3184 (1.3925)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 40/781]  eta: 0:04:20  lr: 0.000031  loss: 1.3309 (1.3935)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 50/781]  eta: 0:04:14  lr: 0.000031  loss: 1.3765 (1.4297)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 60/781]  eta: 0:04:08  lr: 0.000031  loss: 1.3993 (1.4293)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [49]  [ 70/781]  eta: 0:04:04  lr: 0.000031  loss: 1.3190 (1.4276)  time: 0.3326  data: 0.0004  max mem: 6459\n",
            "Epoch: [49]  [ 80/781]  eta: 0:03:59  lr: 0.000031  loss: 1.4079 (1.4551)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 90/781]  eta: 0:03:55  lr: 0.000031  loss: 1.5151 (1.4697)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [100/781]  eta: 0:03:51  lr: 0.000031  loss: 1.3796 (1.4620)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [110/781]  eta: 0:03:47  lr: 0.000031  loss: 1.3247 (1.4485)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [120/781]  eta: 0:03:43  lr: 0.000031  loss: 1.3247 (1.4513)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [130/781]  eta: 0:03:40  lr: 0.000031  loss: 1.3676 (1.4480)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [140/781]  eta: 0:03:36  lr: 0.000031  loss: 1.3405 (1.4445)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [150/781]  eta: 0:03:32  lr: 0.000031  loss: 1.3259 (1.4455)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [160/781]  eta: 0:03:29  lr: 0.000031  loss: 1.3782 (1.4565)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [170/781]  eta: 0:03:25  lr: 0.000031  loss: 1.3654 (1.4519)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [180/781]  eta: 0:03:22  lr: 0.000031  loss: 1.3654 (1.4601)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [190/781]  eta: 0:03:18  lr: 0.000031  loss: 1.3831 (1.4552)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [200/781]  eta: 0:03:15  lr: 0.000031  loss: 1.3602 (1.4592)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [210/781]  eta: 0:03:11  lr: 0.000031  loss: 1.3175 (1.4599)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [220/781]  eta: 0:03:08  lr: 0.000031  loss: 1.3958 (1.4710)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [230/781]  eta: 0:03:04  lr: 0.000031  loss: 1.4427 (1.4680)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [240/781]  eta: 0:03:01  lr: 0.000031  loss: 1.3267 (1.4667)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [250/781]  eta: 0:02:57  lr: 0.000031  loss: 1.3032 (1.4605)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [49]  [260/781]  eta: 0:02:54  lr: 0.000031  loss: 1.3032 (1.4660)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [270/781]  eta: 0:02:51  lr: 0.000031  loss: 1.3502 (1.4706)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [280/781]  eta: 0:02:47  lr: 0.000031  loss: 1.3634 (1.4685)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [290/781]  eta: 0:02:44  lr: 0.000031  loss: 1.4395 (1.4723)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [300/781]  eta: 0:02:40  lr: 0.000031  loss: 1.4194 (1.4770)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [310/781]  eta: 0:02:37  lr: 0.000031  loss: 1.3730 (1.4765)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [320/781]  eta: 0:02:34  lr: 0.000031  loss: 1.3973 (1.4739)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [330/781]  eta: 0:02:30  lr: 0.000031  loss: 1.3891 (1.4709)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [340/781]  eta: 0:02:27  lr: 0.000031  loss: 1.3039 (1.4670)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [350/781]  eta: 0:02:24  lr: 0.000031  loss: 1.3548 (1.4656)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [360/781]  eta: 0:02:20  lr: 0.000031  loss: 1.3432 (1.4641)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [370/781]  eta: 0:02:17  lr: 0.000031  loss: 1.3232 (1.4678)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [380/781]  eta: 0:02:13  lr: 0.000031  loss: 1.3134 (1.4658)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [390/781]  eta: 0:02:10  lr: 0.000031  loss: 1.2950 (1.4630)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [400/781]  eta: 0:02:07  lr: 0.000031  loss: 1.3117 (1.4637)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [410/781]  eta: 0:02:03  lr: 0.000031  loss: 1.3321 (1.4652)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [420/781]  eta: 0:02:00  lr: 0.000031  loss: 1.3393 (1.4650)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [430/781]  eta: 0:01:57  lr: 0.000031  loss: 1.3393 (1.4648)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [440/781]  eta: 0:01:53  lr: 0.000031  loss: 1.3464 (1.4663)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [450/781]  eta: 0:01:50  lr: 0.000031  loss: 1.3482 (1.4673)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [460/781]  eta: 0:01:47  lr: 0.000031  loss: 1.3596 (1.4717)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [470/781]  eta: 0:01:43  lr: 0.000031  loss: 1.3910 (1.4722)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [480/781]  eta: 0:01:40  lr: 0.000031  loss: 1.3609 (1.4696)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [490/781]  eta: 0:01:37  lr: 0.000031  loss: 1.3612 (1.4683)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [500/781]  eta: 0:01:33  lr: 0.000031  loss: 1.3653 (1.4689)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [510/781]  eta: 0:01:30  lr: 0.000031  loss: 1.3254 (1.4663)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [520/781]  eta: 0:01:27  lr: 0.000031  loss: 1.3117 (1.4640)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [530/781]  eta: 0:01:23  lr: 0.000031  loss: 1.3692 (1.4687)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [49]  [540/781]  eta: 0:01:20  lr: 0.000031  loss: 1.3889 (1.4684)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [550/781]  eta: 0:01:16  lr: 0.000031  loss: 1.3599 (1.4653)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [560/781]  eta: 0:01:13  lr: 0.000031  loss: 1.3103 (1.4634)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [570/781]  eta: 0:01:10  lr: 0.000031  loss: 1.3273 (1.4642)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [580/781]  eta: 0:01:06  lr: 0.000031  loss: 1.3871 (1.4664)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [590/781]  eta: 0:01:03  lr: 0.000031  loss: 1.4215 (1.4692)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [600/781]  eta: 0:01:00  lr: 0.000031  loss: 1.3211 (1.4700)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [610/781]  eta: 0:00:56  lr: 0.000031  loss: 1.3086 (1.4697)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [620/781]  eta: 0:00:53  lr: 0.000031  loss: 1.3487 (1.4716)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [630/781]  eta: 0:00:50  lr: 0.000031  loss: 1.3472 (1.4692)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [640/781]  eta: 0:00:46  lr: 0.000031  loss: 1.3727 (1.4678)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [650/781]  eta: 0:00:43  lr: 0.000031  loss: 1.3761 (1.4656)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [660/781]  eta: 0:00:40  lr: 0.000031  loss: 1.3346 (1.4645)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [670/781]  eta: 0:00:36  lr: 0.000031  loss: 1.3277 (1.4657)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [680/781]  eta: 0:00:33  lr: 0.000031  loss: 1.3457 (1.4640)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [690/781]  eta: 0:00:30  lr: 0.000031  loss: 1.3675 (1.4622)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [700/781]  eta: 0:00:26  lr: 0.000031  loss: 1.3529 (1.4624)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [710/781]  eta: 0:00:23  lr: 0.000031  loss: 1.3163 (1.4616)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [720/781]  eta: 0:00:20  lr: 0.000031  loss: 1.3833 (1.4620)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [730/781]  eta: 0:00:16  lr: 0.000031  loss: 1.3833 (1.4610)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [740/781]  eta: 0:00:13  lr: 0.000031  loss: 1.3551 (1.4599)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [750/781]  eta: 0:00:10  lr: 0.000031  loss: 1.4136 (1.4615)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [760/781]  eta: 0:00:06  lr: 0.000031  loss: 1.4249 (1.4603)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [770/781]  eta: 0:00:03  lr: 0.000031  loss: 1.3459 (1.4609)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [780/781]  eta: 0:00:00  lr: 0.000031  loss: 1.3926 (1.4609)  time: 0.3318  data: 0.0005  max mem: 6459\n",
            "Epoch: [49] Total time: 0:04:20 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000031  loss: 1.3926 (1.4609)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32998862862586975, 'lambda_convnext_base': 0.25997301936149597, 'lambda_tf_efficientnetv2_l': 0.41003862023353577}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7948 (0.7948)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8480  data: 0.8172  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9295 (0.9315)  acc1: 81.2500 (81.1553)  acc5: 95.3125 (94.2235)  time: 0.1814  data: 0.1510  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9410 (0.9893)  acc1: 79.1667 (80.3571)  acc5: 93.7500 (93.3284)  time: 0.1273  data: 0.0969  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1476 (1.0634)  acc1: 77.0833 (78.7130)  acc5: 92.1875 (92.7587)  time: 0.1345  data: 0.1040  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2782 (1.1095)  acc1: 76.0417 (77.8455)  acc5: 91.1458 (92.1621)  time: 0.1326  data: 0.1013  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1220 (1.1137)  acc1: 77.0833 (77.5429)  acc5: 92.1875 (92.3101)  time: 0.1354  data: 0.1022  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1733 (1.1260)  acc1: 74.4792 (77.4200)  acc5: 92.1875 (92.3300)  time: 0.1225  data: 0.0900  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1414 s / it)\n",
            "* Acc@1 77.420 Acc@5 92.330 loss 1.126\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.42%\n",
            "[alpha-schedule=cosine] epoch=50 distillation_alpha=0.4237\n",
            "Epoch: [50]  [  0/781]  eta: 0:14:56  lr: 0.000030  loss: 1.3294 (1.3294)  time: 1.1476  data: 0.7911  max mem: 6459\n",
            "Epoch: [50]  [ 10/781]  eta: 0:05:12  lr: 0.000030  loss: 1.3171 (1.3224)  time: 0.4059  data: 0.0722  max mem: 6459\n",
            "Epoch: [50]  [ 20/781]  eta: 0:04:41  lr: 0.000030  loss: 1.3234 (1.3483)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 30/781]  eta: 0:04:28  lr: 0.000030  loss: 1.3428 (1.3703)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 40/781]  eta: 0:04:20  lr: 0.000030  loss: 1.3428 (1.3868)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 50/781]  eta: 0:04:13  lr: 0.000030  loss: 1.2978 (1.3954)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 60/781]  eta: 0:04:08  lr: 0.000030  loss: 1.3435 (1.4586)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 70/781]  eta: 0:04:03  lr: 0.000030  loss: 1.3435 (1.4718)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 80/781]  eta: 0:03:59  lr: 0.000030  loss: 1.3181 (1.4621)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 90/781]  eta: 0:03:55  lr: 0.000030  loss: 1.3179 (1.4612)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [100/781]  eta: 0:03:51  lr: 0.000030  loss: 1.3175 (1.4564)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [110/781]  eta: 0:03:47  lr: 0.000030  loss: 1.3175 (1.4524)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [120/781]  eta: 0:03:43  lr: 0.000030  loss: 1.3212 (1.4544)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [130/781]  eta: 0:03:39  lr: 0.000030  loss: 1.3543 (1.4549)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [140/781]  eta: 0:03:36  lr: 0.000030  loss: 1.3722 (1.4590)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [150/781]  eta: 0:03:32  lr: 0.000030  loss: 1.3770 (1.4784)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [160/781]  eta: 0:03:29  lr: 0.000030  loss: 1.4058 (1.4871)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [170/781]  eta: 0:03:25  lr: 0.000030  loss: 1.3735 (1.4845)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [180/781]  eta: 0:03:21  lr: 0.000030  loss: 1.3494 (1.4880)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [190/781]  eta: 0:03:18  lr: 0.000030  loss: 1.4206 (1.4971)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [200/781]  eta: 0:03:15  lr: 0.000030  loss: 1.3544 (1.4931)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [210/781]  eta: 0:03:11  lr: 0.000030  loss: 1.2996 (1.4907)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [220/781]  eta: 0:03:08  lr: 0.000030  loss: 1.3223 (1.4891)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [230/781]  eta: 0:03:04  lr: 0.000030  loss: 1.3370 (1.4883)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [240/781]  eta: 0:03:01  lr: 0.000030  loss: 1.3333 (1.4828)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [250/781]  eta: 0:02:57  lr: 0.000030  loss: 1.3285 (1.4821)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [260/781]  eta: 0:02:54  lr: 0.000030  loss: 1.3198 (1.4771)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [270/781]  eta: 0:02:50  lr: 0.000030  loss: 1.3198 (1.4799)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [280/781]  eta: 0:02:47  lr: 0.000030  loss: 1.3404 (1.4820)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [290/781]  eta: 0:02:44  lr: 0.000030  loss: 1.3611 (1.4841)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [300/781]  eta: 0:02:40  lr: 0.000030  loss: 1.3927 (1.4959)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [310/781]  eta: 0:02:37  lr: 0.000030  loss: 1.4072 (1.5008)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [320/781]  eta: 0:02:34  lr: 0.000030  loss: 1.3488 (1.5022)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [330/781]  eta: 0:02:30  lr: 0.000030  loss: 1.3086 (1.4991)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [340/781]  eta: 0:02:27  lr: 0.000030  loss: 1.3026 (1.4965)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [350/781]  eta: 0:02:23  lr: 0.000030  loss: 1.3048 (1.4976)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [360/781]  eta: 0:02:20  lr: 0.000030  loss: 1.3319 (1.4990)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [370/781]  eta: 0:02:17  lr: 0.000030  loss: 1.3426 (1.4992)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [380/781]  eta: 0:02:13  lr: 0.000030  loss: 1.3389 (1.4983)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [390/781]  eta: 0:02:10  lr: 0.000030  loss: 1.3294 (1.4982)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [400/781]  eta: 0:02:07  lr: 0.000030  loss: 1.4376 (1.5019)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [410/781]  eta: 0:02:03  lr: 0.000030  loss: 1.4625 (1.5049)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [420/781]  eta: 0:02:00  lr: 0.000030  loss: 1.4238 (1.5043)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [430/781]  eta: 0:01:57  lr: 0.000030  loss: 1.4238 (1.5094)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [440/781]  eta: 0:01:53  lr: 0.000030  loss: 1.3868 (1.5088)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [450/781]  eta: 0:01:50  lr: 0.000030  loss: 1.3573 (1.5066)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [460/781]  eta: 0:01:47  lr: 0.000030  loss: 1.3040 (1.5034)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [470/781]  eta: 0:01:43  lr: 0.000030  loss: 1.3321 (1.5038)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [480/781]  eta: 0:01:40  lr: 0.000030  loss: 1.3373 (1.5040)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [490/781]  eta: 0:01:36  lr: 0.000030  loss: 1.3130 (1.5005)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [500/781]  eta: 0:01:33  lr: 0.000030  loss: 1.3327 (1.4981)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [510/781]  eta: 0:01:30  lr: 0.000030  loss: 1.3581 (1.5021)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [520/781]  eta: 0:01:26  lr: 0.000030  loss: 1.3485 (1.5033)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [530/781]  eta: 0:01:23  lr: 0.000030  loss: 1.3270 (1.5039)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [540/781]  eta: 0:01:20  lr: 0.000030  loss: 1.2897 (1.5004)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [550/781]  eta: 0:01:16  lr: 0.000030  loss: 1.2828 (1.4972)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [560/781]  eta: 0:01:13  lr: 0.000030  loss: 1.3064 (1.4956)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [570/781]  eta: 0:01:10  lr: 0.000030  loss: 1.3525 (1.4971)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [580/781]  eta: 0:01:06  lr: 0.000030  loss: 1.4089 (1.4973)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [590/781]  eta: 0:01:03  lr: 0.000030  loss: 1.3876 (1.4960)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [600/781]  eta: 0:01:00  lr: 0.000030  loss: 1.4503 (1.4993)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [610/781]  eta: 0:00:56  lr: 0.000030  loss: 1.4559 (1.5001)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [620/781]  eta: 0:00:53  lr: 0.000030  loss: 1.3539 (1.4996)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [50]  [630/781]  eta: 0:00:50  lr: 0.000030  loss: 1.3135 (1.4973)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [50]  [640/781]  eta: 0:00:46  lr: 0.000030  loss: 1.3521 (1.4964)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [650/781]  eta: 0:00:43  lr: 0.000030  loss: 1.3647 (1.4950)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [660/781]  eta: 0:00:40  lr: 0.000030  loss: 1.3855 (1.4948)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [670/781]  eta: 0:00:36  lr: 0.000030  loss: 1.4034 (1.4992)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [680/781]  eta: 0:00:33  lr: 0.000030  loss: 1.4111 (1.4986)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [690/781]  eta: 0:00:30  lr: 0.000030  loss: 1.3369 (1.4957)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [700/781]  eta: 0:00:26  lr: 0.000030  loss: 1.3369 (1.4952)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [710/781]  eta: 0:00:23  lr: 0.000030  loss: 1.3591 (1.4933)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [720/781]  eta: 0:00:20  lr: 0.000030  loss: 1.3631 (1.4928)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [730/781]  eta: 0:00:16  lr: 0.000030  loss: 1.3631 (1.4910)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [740/781]  eta: 0:00:13  lr: 0.000030  loss: 1.3689 (1.4897)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [750/781]  eta: 0:00:10  lr: 0.000030  loss: 1.3347 (1.4882)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [760/781]  eta: 0:00:06  lr: 0.000030  loss: 1.3487 (1.4890)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [770/781]  eta: 0:00:03  lr: 0.000030  loss: 1.3391 (1.4878)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [780/781]  eta: 0:00:00  lr: 0.000030  loss: 1.3282 (1.4871)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [50] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000030  loss: 1.3282 (1.4871)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3279372453689575, 'lambda_convnext_base': 0.2596881687641144, 'lambda_tf_efficientnetv2_l': 0.4123746156692505}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7641 (0.7641)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8547  data: 0.8240  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8337 (0.9353)  acc1: 83.8542 (81.1553)  acc5: 94.7917 (93.9867)  time: 0.1818  data: 0.1513  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9852 (1.0019)  acc1: 80.7292 (80.1835)  acc5: 93.7500 (93.0556)  time: 0.1333  data: 0.1028  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1691 (1.0684)  acc1: 77.0833 (78.9987)  acc5: 91.1458 (92.4563)  time: 0.1317  data: 0.1012  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2667 (1.1097)  acc1: 76.0417 (78.2647)  acc5: 90.6250 (92.0224)  time: 0.1326  data: 0.1021  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1478 (1.1151)  acc1: 76.0417 (77.8391)  acc5: 92.7083 (92.1977)  time: 0.1346  data: 0.1042  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1605 (1.1268)  acc1: 75.0000 (77.6900)  acc5: 92.7083 (92.2300)  time: 0.1136  data: 0.0840  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1402 s / it)\n",
            "* Acc@1 77.690 Acc@5 92.230 loss 1.127\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.69%\n",
            "[alpha-schedule=cosine] epoch=51 distillation_alpha=0.4326\n",
            "Epoch: [51]  [  0/781]  eta: 0:14:15  lr: 0.000029  loss: 1.3130 (1.3130)  time: 1.0950  data: 0.7473  max mem: 6459\n",
            "Epoch: [51]  [ 10/781]  eta: 0:05:09  lr: 0.000029  loss: 1.3093 (1.4600)  time: 0.4015  data: 0.0683  max mem: 6459\n",
            "Epoch: [51]  [ 20/781]  eta: 0:04:40  lr: 0.000029  loss: 1.3343 (1.4887)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 30/781]  eta: 0:04:27  lr: 0.000029  loss: 1.3566 (1.4950)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 40/781]  eta: 0:04:19  lr: 0.000029  loss: 1.3611 (1.4977)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 50/781]  eta: 0:04:13  lr: 0.000029  loss: 1.3032 (1.4893)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 60/781]  eta: 0:04:08  lr: 0.000029  loss: 1.3700 (1.5349)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 70/781]  eta: 0:04:03  lr: 0.000029  loss: 1.3538 (1.5167)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 80/781]  eta: 0:03:59  lr: 0.000029  loss: 1.3222 (1.5064)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 90/781]  eta: 0:03:55  lr: 0.000029  loss: 1.3568 (1.5141)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [100/781]  eta: 0:03:51  lr: 0.000029  loss: 1.3568 (1.5184)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [110/781]  eta: 0:03:47  lr: 0.000029  loss: 1.3410 (1.5210)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [120/781]  eta: 0:03:43  lr: 0.000029  loss: 1.3290 (1.5133)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [130/781]  eta: 0:03:39  lr: 0.000029  loss: 1.3180 (1.5045)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [140/781]  eta: 0:03:36  lr: 0.000029  loss: 1.3180 (1.4926)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [150/781]  eta: 0:03:32  lr: 0.000029  loss: 1.3578 (1.4968)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [160/781]  eta: 0:03:28  lr: 0.000029  loss: 1.3566 (1.4914)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [170/781]  eta: 0:03:25  lr: 0.000029  loss: 1.3462 (1.4939)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [180/781]  eta: 0:03:21  lr: 0.000029  loss: 1.3462 (1.4894)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [190/781]  eta: 0:03:18  lr: 0.000029  loss: 1.3271 (1.4947)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [200/781]  eta: 0:03:14  lr: 0.000029  loss: 1.2874 (1.4965)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [210/781]  eta: 0:03:11  lr: 0.000029  loss: 1.3457 (1.4977)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [220/781]  eta: 0:03:08  lr: 0.000029  loss: 1.3575 (1.5025)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [230/781]  eta: 0:03:04  lr: 0.000029  loss: 1.3825 (1.5029)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [240/781]  eta: 0:03:01  lr: 0.000029  loss: 1.3235 (1.4971)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [250/781]  eta: 0:02:57  lr: 0.000029  loss: 1.3131 (1.4931)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [260/781]  eta: 0:02:54  lr: 0.000029  loss: 1.3131 (1.4958)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [270/781]  eta: 0:02:50  lr: 0.000029  loss: 1.3828 (1.5014)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [280/781]  eta: 0:02:47  lr: 0.000029  loss: 1.3805 (1.5047)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [290/781]  eta: 0:02:44  lr: 0.000029  loss: 1.5753 (1.5194)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [300/781]  eta: 0:02:40  lr: 0.000029  loss: 1.5313 (1.5154)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [310/781]  eta: 0:02:37  lr: 0.000029  loss: 1.3537 (1.5192)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [320/781]  eta: 0:02:34  lr: 0.000029  loss: 1.4370 (1.5202)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [330/781]  eta: 0:02:30  lr: 0.000029  loss: 1.3672 (1.5211)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [340/781]  eta: 0:02:27  lr: 0.000029  loss: 1.3925 (1.5189)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [350/781]  eta: 0:02:23  lr: 0.000029  loss: 1.3279 (1.5169)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [360/781]  eta: 0:02:20  lr: 0.000029  loss: 1.3259 (1.5116)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [370/781]  eta: 0:02:17  lr: 0.000029  loss: 1.2999 (1.5062)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [380/781]  eta: 0:02:13  lr: 0.000029  loss: 1.2869 (1.5041)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [390/781]  eta: 0:02:10  lr: 0.000029  loss: 1.3379 (1.5021)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [400/781]  eta: 0:02:07  lr: 0.000029  loss: 1.3443 (1.5047)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [410/781]  eta: 0:02:03  lr: 0.000029  loss: 1.3813 (1.5031)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [420/781]  eta: 0:02:00  lr: 0.000029  loss: 1.3652 (1.4999)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [430/781]  eta: 0:01:57  lr: 0.000029  loss: 1.3070 (1.4960)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [440/781]  eta: 0:01:53  lr: 0.000029  loss: 1.3714 (1.5019)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [450/781]  eta: 0:01:50  lr: 0.000029  loss: 1.3503 (1.4980)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [460/781]  eta: 0:01:47  lr: 0.000029  loss: 1.3396 (1.5018)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [470/781]  eta: 0:01:43  lr: 0.000029  loss: 1.3424 (1.5030)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [480/781]  eta: 0:01:40  lr: 0.000029  loss: 1.3237 (1.4991)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [490/781]  eta: 0:01:37  lr: 0.000029  loss: 1.3419 (1.5023)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [500/781]  eta: 0:01:33  lr: 0.000029  loss: 1.4031 (1.5009)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [510/781]  eta: 0:01:30  lr: 0.000029  loss: 1.3806 (1.4997)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [520/781]  eta: 0:01:27  lr: 0.000029  loss: 1.3395 (1.4967)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [530/781]  eta: 0:01:23  lr: 0.000029  loss: 1.3395 (1.4961)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [540/781]  eta: 0:01:20  lr: 0.000029  loss: 1.3615 (1.4978)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [550/781]  eta: 0:01:17  lr: 0.000029  loss: 1.3470 (1.4983)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [560/781]  eta: 0:01:13  lr: 0.000029  loss: 1.3372 (1.4996)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [570/781]  eta: 0:01:10  lr: 0.000029  loss: 1.3372 (1.4977)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [580/781]  eta: 0:01:07  lr: 0.000029  loss: 1.3466 (1.4987)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [590/781]  eta: 0:01:03  lr: 0.000029  loss: 1.3677 (1.4982)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [600/781]  eta: 0:01:00  lr: 0.000029  loss: 1.3206 (1.4967)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [610/781]  eta: 0:00:57  lr: 0.000029  loss: 1.2904 (1.4955)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [620/781]  eta: 0:00:53  lr: 0.000029  loss: 1.3827 (1.4955)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [630/781]  eta: 0:00:50  lr: 0.000029  loss: 1.3484 (1.4952)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [640/781]  eta: 0:00:46  lr: 0.000029  loss: 1.3850 (1.4941)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [650/781]  eta: 0:00:43  lr: 0.000029  loss: 1.3980 (1.4938)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [660/781]  eta: 0:00:40  lr: 0.000029  loss: 1.3978 (1.4934)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [670/781]  eta: 0:00:36  lr: 0.000029  loss: 1.3978 (1.4923)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [680/781]  eta: 0:00:33  lr: 0.000029  loss: 1.3607 (1.4901)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [690/781]  eta: 0:00:30  lr: 0.000029  loss: 1.3279 (1.4920)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [700/781]  eta: 0:00:26  lr: 0.000029  loss: 1.3410 (1.4924)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [710/781]  eta: 0:00:23  lr: 0.000029  loss: 1.3410 (1.4911)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [720/781]  eta: 0:00:20  lr: 0.000029  loss: 1.3089 (1.4922)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [730/781]  eta: 0:00:16  lr: 0.000029  loss: 1.3439 (1.4903)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [740/781]  eta: 0:00:13  lr: 0.000029  loss: 1.3607 (1.4914)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [750/781]  eta: 0:00:10  lr: 0.000029  loss: 1.3555 (1.4896)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [760/781]  eta: 0:00:06  lr: 0.000029  loss: 1.3555 (1.4892)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [770/781]  eta: 0:00:03  lr: 0.000029  loss: 1.3497 (1.4893)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [780/781]  eta: 0:00:00  lr: 0.000029  loss: 1.3497 (1.4897)  time: 0.3320  data: 0.0005  max mem: 6459\n",
            "Epoch: [51] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000029  loss: 1.3497 (1.4897)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32840496301651, 'lambda_convnext_base': 0.2604110538959503, 'lambda_tf_efficientnetv2_l': 0.4111836552619934}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7443 (0.7443)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8533  data: 0.8225  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9700 (0.9485)  acc1: 82.8125 (81.1553)  acc5: 94.7917 (94.2235)  time: 0.1720  data: 0.1416  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0048 (1.0121)  acc1: 79.6875 (79.8859)  acc5: 93.7500 (93.1796)  time: 0.1249  data: 0.0945  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1523 (1.0714)  acc1: 76.0417 (78.8642)  acc5: 91.6667 (92.5235)  time: 0.1306  data: 0.1002  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2537 (1.1084)  acc1: 75.5208 (78.1504)  acc5: 90.6250 (92.1240)  time: 0.1275  data: 0.0962  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0601 (1.1105)  acc1: 76.5625 (77.8186)  acc5: 91.6667 (92.2488)  time: 0.1346  data: 0.1014  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1573 (1.1184)  acc1: 76.5625 (77.6700)  acc5: 91.6667 (92.2900)  time: 0.1190  data: 0.0865  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1377 s / it)\n",
            "* Acc@1 77.670 Acc@5 92.290 loss 1.118\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.69%\n",
            "[alpha-schedule=cosine] epoch=52 distillation_alpha=0.4413\n",
            "Epoch: [52]  [  0/781]  eta: 0:14:25  lr: 0.000028  loss: 1.2841 (1.2841)  time: 1.1085  data: 0.7306  max mem: 6459\n",
            "Epoch: [52]  [ 10/781]  eta: 0:05:10  lr: 0.000028  loss: 1.3609 (1.4192)  time: 0.4021  data: 0.0667  max mem: 6459\n",
            "Epoch: [52]  [ 20/781]  eta: 0:04:40  lr: 0.000028  loss: 1.2840 (1.4200)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 30/781]  eta: 0:04:27  lr: 0.000028  loss: 1.3303 (1.4929)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 40/781]  eta: 0:04:19  lr: 0.000028  loss: 1.3389 (1.4504)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 50/781]  eta: 0:04:13  lr: 0.000028  loss: 1.3496 (1.4965)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 60/781]  eta: 0:04:08  lr: 0.000028  loss: 1.3616 (1.4813)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 70/781]  eta: 0:04:03  lr: 0.000028  loss: 1.3022 (1.4572)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 80/781]  eta: 0:03:59  lr: 0.000028  loss: 1.3217 (1.4417)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 90/781]  eta: 0:03:55  lr: 0.000028  loss: 1.3257 (1.4387)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [100/781]  eta: 0:03:51  lr: 0.000028  loss: 1.3319 (1.4393)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [110/781]  eta: 0:03:47  lr: 0.000028  loss: 1.3265 (1.4282)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [120/781]  eta: 0:03:43  lr: 0.000028  loss: 1.3181 (1.4224)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [130/781]  eta: 0:03:39  lr: 0.000028  loss: 1.3076 (1.4226)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [140/781]  eta: 0:03:36  lr: 0.000028  loss: 1.3140 (1.4185)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [150/781]  eta: 0:03:32  lr: 0.000028  loss: 1.3475 (1.4144)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [160/781]  eta: 0:03:28  lr: 0.000028  loss: 1.3045 (1.4285)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [170/781]  eta: 0:03:25  lr: 0.000028  loss: 1.3244 (1.4359)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [180/781]  eta: 0:03:21  lr: 0.000028  loss: 1.3244 (1.4320)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [190/781]  eta: 0:03:18  lr: 0.000028  loss: 1.3015 (1.4348)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [200/781]  eta: 0:03:14  lr: 0.000028  loss: 1.2969 (1.4322)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [210/781]  eta: 0:03:11  lr: 0.000028  loss: 1.3172 (1.4299)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [220/781]  eta: 0:03:08  lr: 0.000028  loss: 1.3608 (1.4330)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [230/781]  eta: 0:03:04  lr: 0.000028  loss: 1.3608 (1.4424)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [240/781]  eta: 0:03:01  lr: 0.000028  loss: 1.3317 (1.4435)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [250/781]  eta: 0:02:57  lr: 0.000028  loss: 1.3773 (1.4589)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [260/781]  eta: 0:02:54  lr: 0.000028  loss: 1.3824 (1.4599)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [270/781]  eta: 0:02:50  lr: 0.000028  loss: 1.3373 (1.4549)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [280/781]  eta: 0:02:47  lr: 0.000028  loss: 1.3489 (1.4667)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [290/781]  eta: 0:02:44  lr: 0.000028  loss: 1.3723 (1.4685)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [300/781]  eta: 0:02:40  lr: 0.000028  loss: 1.3590 (1.4691)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [310/781]  eta: 0:02:37  lr: 0.000028  loss: 1.3977 (1.4742)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [320/781]  eta: 0:02:34  lr: 0.000028  loss: 1.4132 (1.4755)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [330/781]  eta: 0:02:30  lr: 0.000028  loss: 1.3488 (1.4763)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [340/781]  eta: 0:02:27  lr: 0.000028  loss: 1.3488 (1.4805)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [350/781]  eta: 0:02:23  lr: 0.000028  loss: 1.3317 (1.4781)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [360/781]  eta: 0:02:20  lr: 0.000028  loss: 1.3317 (1.4792)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [370/781]  eta: 0:02:17  lr: 0.000028  loss: 1.3762 (1.4793)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [380/781]  eta: 0:02:13  lr: 0.000028  loss: 1.3641 (1.4835)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [390/781]  eta: 0:02:10  lr: 0.000028  loss: 1.3284 (1.4862)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [400/781]  eta: 0:02:07  lr: 0.000028  loss: 1.3285 (1.4825)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [410/781]  eta: 0:02:03  lr: 0.000028  loss: 1.3468 (1.4843)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [420/781]  eta: 0:02:00  lr: 0.000028  loss: 1.3469 (1.4812)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [430/781]  eta: 0:01:57  lr: 0.000028  loss: 1.3469 (1.4807)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [440/781]  eta: 0:01:53  lr: 0.000028  loss: 1.3462 (1.4772)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [450/781]  eta: 0:01:50  lr: 0.000028  loss: 1.3226 (1.4742)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [460/781]  eta: 0:01:47  lr: 0.000028  loss: 1.3227 (1.4728)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [470/781]  eta: 0:01:43  lr: 0.000028  loss: 1.3220 (1.4718)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [480/781]  eta: 0:01:40  lr: 0.000028  loss: 1.3192 (1.4740)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [490/781]  eta: 0:01:36  lr: 0.000028  loss: 1.3428 (1.4730)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [500/781]  eta: 0:01:33  lr: 0.000028  loss: 1.3605 (1.4742)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [510/781]  eta: 0:01:30  lr: 0.000028  loss: 1.3409 (1.4732)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [520/781]  eta: 0:01:26  lr: 0.000028  loss: 1.3334 (1.4719)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [530/781]  eta: 0:01:23  lr: 0.000028  loss: 1.3325 (1.4734)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [540/781]  eta: 0:01:20  lr: 0.000028  loss: 1.3717 (1.4731)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [550/781]  eta: 0:01:16  lr: 0.000028  loss: 1.4579 (1.4759)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [560/781]  eta: 0:01:13  lr: 0.000028  loss: 1.3669 (1.4732)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [570/781]  eta: 0:01:10  lr: 0.000028  loss: 1.3097 (1.4704)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [580/781]  eta: 0:01:06  lr: 0.000028  loss: 1.3097 (1.4695)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [590/781]  eta: 0:01:03  lr: 0.000028  loss: 1.3587 (1.4702)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [600/781]  eta: 0:01:00  lr: 0.000028  loss: 1.3532 (1.4706)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [610/781]  eta: 0:00:56  lr: 0.000028  loss: 1.3211 (1.4700)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [620/781]  eta: 0:00:53  lr: 0.000028  loss: 1.3560 (1.4700)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [630/781]  eta: 0:00:50  lr: 0.000028  loss: 1.3778 (1.4717)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [640/781]  eta: 0:00:46  lr: 0.000028  loss: 1.3489 (1.4748)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [650/781]  eta: 0:00:43  lr: 0.000028  loss: 1.3648 (1.4743)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [660/781]  eta: 0:00:40  lr: 0.000028  loss: 1.3703 (1.4783)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [670/781]  eta: 0:00:36  lr: 0.000028  loss: 1.3731 (1.4803)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [680/781]  eta: 0:00:33  lr: 0.000028  loss: 1.3731 (1.4810)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [690/781]  eta: 0:00:30  lr: 0.000028  loss: 1.3348 (1.4805)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [700/781]  eta: 0:00:26  lr: 0.000028  loss: 1.3710 (1.4815)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [710/781]  eta: 0:00:23  lr: 0.000028  loss: 1.3558 (1.4829)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [720/781]  eta: 0:00:20  lr: 0.000028  loss: 1.2642 (1.4808)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [730/781]  eta: 0:00:16  lr: 0.000028  loss: 1.3564 (1.4819)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [740/781]  eta: 0:00:13  lr: 0.000028  loss: 1.3564 (1.4805)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [750/781]  eta: 0:00:10  lr: 0.000028  loss: 1.3404 (1.4806)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [760/781]  eta: 0:00:06  lr: 0.000028  loss: 1.3605 (1.4798)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [770/781]  eta: 0:00:03  lr: 0.000028  loss: 1.3882 (1.4810)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [780/781]  eta: 0:00:00  lr: 0.000028  loss: 1.3922 (1.4804)  time: 0.3319  data: 0.0006  max mem: 6459\n",
            "Epoch: [52] Total time: 0:04:19 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000028  loss: 1.3922 (1.4804)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32851266860961914, 'lambda_convnext_base': 0.260545939207077, 'lambda_tf_efficientnetv2_l': 0.4109416604042053}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7080 (0.7080)  acc1: 85.9375 (85.9375)  acc5: 95.3125 (95.3125)  time: 0.8422  data: 0.8116  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8474 (0.9453)  acc1: 83.8542 (81.3447)  acc5: 95.3125 (93.7973)  time: 0.1705  data: 0.1401  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0498 (1.0307)  acc1: 78.1250 (79.7123)  acc5: 93.2292 (92.8819)  time: 0.1291  data: 0.0986  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1329 (1.0755)  acc1: 76.0417 (78.7298)  acc5: 91.6667 (92.4227)  time: 0.1358  data: 0.1054  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1644 (1.1207)  acc1: 76.0417 (77.9218)  acc5: 90.6250 (91.8191)  time: 0.1367  data: 0.1062  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1377 (1.1197)  acc1: 76.0417 (77.7165)  acc5: 92.1875 (92.1364)  time: 0.1333  data: 0.1028  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1738 (1.1336)  acc1: 75.0000 (77.6200)  acc5: 92.1875 (92.1600)  time: 0.1134  data: 0.0838  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1388 s / it)\n",
            "* Acc@1 77.620 Acc@5 92.160 loss 1.134\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.69%\n",
            "[alpha-schedule=cosine] epoch=53 distillation_alpha=0.4500\n",
            "Epoch: [53]  [  0/781]  eta: 0:14:48  lr: 0.000027  loss: 1.2825 (1.2825)  time: 1.1370  data: 0.7975  max mem: 6459\n",
            "Epoch: [53]  [ 10/781]  eta: 0:05:13  lr: 0.000027  loss: 1.3676 (1.5030)  time: 0.4066  data: 0.0728  max mem: 6459\n",
            "Epoch: [53]  [ 20/781]  eta: 0:04:42  lr: 0.000027  loss: 1.3665 (1.4213)  time: 0.3328  data: 0.0004  max mem: 6459\n",
            "Epoch: [53]  [ 30/781]  eta: 0:04:29  lr: 0.000027  loss: 1.3665 (1.4261)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 40/781]  eta: 0:04:20  lr: 0.000027  loss: 1.3991 (1.5163)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 50/781]  eta: 0:04:14  lr: 0.000027  loss: 1.3947 (1.5031)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 60/781]  eta: 0:04:09  lr: 0.000027  loss: 1.3296 (1.4905)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 70/781]  eta: 0:04:04  lr: 0.000027  loss: 1.3038 (1.4790)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 80/781]  eta: 0:03:59  lr: 0.000027  loss: 1.3011 (1.4664)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 90/781]  eta: 0:03:55  lr: 0.000027  loss: 1.3198 (1.4733)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [100/781]  eta: 0:03:51  lr: 0.000027  loss: 1.3311 (1.4639)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [110/781]  eta: 0:03:47  lr: 0.000027  loss: 1.3274 (1.4570)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [120/781]  eta: 0:03:43  lr: 0.000027  loss: 1.3077 (1.4440)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [130/781]  eta: 0:03:40  lr: 0.000027  loss: 1.3139 (1.4453)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [140/781]  eta: 0:03:36  lr: 0.000027  loss: 1.3639 (1.4406)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [150/781]  eta: 0:03:32  lr: 0.000027  loss: 1.3901 (1.4520)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [160/781]  eta: 0:03:29  lr: 0.000027  loss: 1.4313 (1.4667)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [170/781]  eta: 0:03:25  lr: 0.000027  loss: 1.4014 (1.4844)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [180/781]  eta: 0:03:22  lr: 0.000027  loss: 1.4203 (1.4904)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [190/781]  eta: 0:03:18  lr: 0.000027  loss: 1.4057 (1.4907)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [200/781]  eta: 0:03:15  lr: 0.000027  loss: 1.3906 (1.4870)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [210/781]  eta: 0:03:11  lr: 0.000027  loss: 1.3858 (1.4888)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [220/781]  eta: 0:03:08  lr: 0.000027  loss: 1.3710 (1.4944)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [230/781]  eta: 0:03:04  lr: 0.000027  loss: 1.3589 (1.4876)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [240/781]  eta: 0:03:01  lr: 0.000027  loss: 1.3853 (1.4913)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [250/781]  eta: 0:02:58  lr: 0.000027  loss: 1.4239 (1.4951)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [260/781]  eta: 0:02:54  lr: 0.000027  loss: 1.4101 (1.4923)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [270/781]  eta: 0:02:51  lr: 0.000027  loss: 1.3711 (1.5000)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [280/781]  eta: 0:02:47  lr: 0.000027  loss: 1.3660 (1.5026)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [290/781]  eta: 0:02:44  lr: 0.000027  loss: 1.4137 (1.5079)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [300/781]  eta: 0:02:40  lr: 0.000027  loss: 1.3734 (1.5030)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [310/781]  eta: 0:02:37  lr: 0.000027  loss: 1.3734 (1.5032)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [320/781]  eta: 0:02:34  lr: 0.000027  loss: 1.4096 (1.4981)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [330/781]  eta: 0:02:30  lr: 0.000027  loss: 1.3284 (1.4944)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [340/781]  eta: 0:02:27  lr: 0.000027  loss: 1.3433 (1.4914)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [350/781]  eta: 0:02:24  lr: 0.000027  loss: 1.3675 (1.4905)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [360/781]  eta: 0:02:20  lr: 0.000027  loss: 1.3743 (1.4971)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [370/781]  eta: 0:02:17  lr: 0.000027  loss: 1.4029 (1.5015)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [380/781]  eta: 0:02:13  lr: 0.000027  loss: 1.3445 (1.5001)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [390/781]  eta: 0:02:10  lr: 0.000027  loss: 1.3445 (1.4975)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [400/781]  eta: 0:02:07  lr: 0.000027  loss: 1.3547 (1.4968)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [410/781]  eta: 0:02:03  lr: 0.000027  loss: 1.3542 (1.4942)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [420/781]  eta: 0:02:00  lr: 0.000027  loss: 1.3116 (1.4921)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [430/781]  eta: 0:01:57  lr: 0.000027  loss: 1.3465 (1.4907)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [440/781]  eta: 0:01:53  lr: 0.000027  loss: 1.3568 (1.4932)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [450/781]  eta: 0:01:50  lr: 0.000027  loss: 1.3386 (1.4938)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [460/781]  eta: 0:01:47  lr: 0.000027  loss: 1.3107 (1.4909)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [470/781]  eta: 0:01:43  lr: 0.000027  loss: 1.2801 (1.4865)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [480/781]  eta: 0:01:40  lr: 0.000027  loss: 1.3304 (1.4888)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [490/781]  eta: 0:01:37  lr: 0.000027  loss: 1.3422 (1.4856)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [500/781]  eta: 0:01:33  lr: 0.000027  loss: 1.3353 (1.4852)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [510/781]  eta: 0:01:30  lr: 0.000027  loss: 1.3405 (1.4891)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [520/781]  eta: 0:01:27  lr: 0.000027  loss: 1.3395 (1.4898)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [530/781]  eta: 0:01:23  lr: 0.000027  loss: 1.3349 (1.4905)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [540/781]  eta: 0:01:20  lr: 0.000027  loss: 1.3784 (1.4943)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [550/781]  eta: 0:01:17  lr: 0.000027  loss: 1.4021 (1.4939)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [560/781]  eta: 0:01:13  lr: 0.000027  loss: 1.3564 (1.4920)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [570/781]  eta: 0:01:10  lr: 0.000027  loss: 1.3564 (1.4901)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [580/781]  eta: 0:01:07  lr: 0.000027  loss: 1.3722 (1.4926)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [590/781]  eta: 0:01:03  lr: 0.000027  loss: 1.3608 (1.4930)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [600/781]  eta: 0:01:00  lr: 0.000027  loss: 1.3504 (1.4925)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [610/781]  eta: 0:00:56  lr: 0.000027  loss: 1.3207 (1.4893)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [620/781]  eta: 0:00:53  lr: 0.000027  loss: 1.3141 (1.4900)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [630/781]  eta: 0:00:50  lr: 0.000027  loss: 1.3458 (1.4889)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [640/781]  eta: 0:00:46  lr: 0.000027  loss: 1.3357 (1.4881)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [650/781]  eta: 0:00:43  lr: 0.000027  loss: 1.3352 (1.4905)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [660/781]  eta: 0:00:40  lr: 0.000027  loss: 1.3796 (1.4910)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [670/781]  eta: 0:00:36  lr: 0.000027  loss: 1.3350 (1.4917)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [680/781]  eta: 0:00:33  lr: 0.000027  loss: 1.3292 (1.4909)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [690/781]  eta: 0:00:30  lr: 0.000027  loss: 1.3324 (1.4894)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [700/781]  eta: 0:00:26  lr: 0.000027  loss: 1.3416 (1.4900)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [710/781]  eta: 0:00:23  lr: 0.000027  loss: 1.3114 (1.4875)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [720/781]  eta: 0:00:20  lr: 0.000027  loss: 1.3101 (1.4856)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [730/781]  eta: 0:00:16  lr: 0.000027  loss: 1.3440 (1.4837)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [740/781]  eta: 0:00:13  lr: 0.000027  loss: 1.3211 (1.4819)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [750/781]  eta: 0:00:10  lr: 0.000027  loss: 1.3353 (1.4832)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [760/781]  eta: 0:00:06  lr: 0.000027  loss: 1.3480 (1.4837)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [770/781]  eta: 0:00:03  lr: 0.000027  loss: 1.3415 (1.4856)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [780/781]  eta: 0:00:00  lr: 0.000027  loss: 1.3046 (1.4829)  time: 0.3322  data: 0.0006  max mem: 6459\n",
            "Epoch: [53] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000027  loss: 1.3046 (1.4829)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32869240641593933, 'lambda_convnext_base': 0.2602234482765198, 'lambda_tf_efficientnetv2_l': 0.41108447313308716}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7323 (0.7323)  acc1: 82.8125 (82.8125)  acc5: 96.3542 (96.3542)  time: 0.8558  data: 0.8251  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8495 (0.9265)  acc1: 82.2917 (80.9186)  acc5: 94.7917 (93.8447)  time: 0.1690  data: 0.1385  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 0.9842 (0.9985)  acc1: 79.1667 (79.6627)  acc5: 94.2708 (93.0556)  time: 0.1101  data: 0.0796  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0643 (1.0462)  acc1: 76.5625 (78.8474)  acc5: 92.1875 (92.6411)  time: 0.1222  data: 0.0916  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1496 (1.0993)  acc1: 76.5625 (78.0742)  acc5: 91.1458 (92.0859)  time: 0.1175  data: 0.0869  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0733 (1.0996)  acc1: 76.5625 (77.8288)  acc5: 91.6667 (92.2590)  time: 0.1155  data: 0.0849  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1217 (1.1166)  acc1: 75.5208 (77.6300)  acc5: 92.1875 (92.2600)  time: 0.1070  data: 0.0772  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1266 s / it)\n",
            "* Acc@1 77.630 Acc@5 92.260 loss 1.117\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.69%\n",
            "[alpha-schedule=cosine] epoch=54 distillation_alpha=0.4585\n",
            "Epoch: [54]  [  0/781]  eta: 0:15:22  lr: 0.000026  loss: 2.2671 (2.2671)  time: 1.1812  data: 0.8362  max mem: 6459\n",
            "Epoch: [54]  [ 10/781]  eta: 0:05:15  lr: 0.000026  loss: 1.3288 (1.6059)  time: 0.4093  data: 0.0763  max mem: 6459\n",
            "Epoch: [54]  [ 20/781]  eta: 0:04:43  lr: 0.000026  loss: 1.3140 (1.4650)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 30/781]  eta: 0:04:29  lr: 0.000026  loss: 1.3175 (1.4385)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 40/781]  eta: 0:04:21  lr: 0.000026  loss: 1.3573 (1.4919)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 50/781]  eta: 0:04:14  lr: 0.000026  loss: 1.3225 (1.4528)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 60/781]  eta: 0:04:09  lr: 0.000026  loss: 1.3009 (1.4580)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 70/781]  eta: 0:04:04  lr: 0.000026  loss: 1.3515 (1.4560)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 80/781]  eta: 0:03:59  lr: 0.000026  loss: 1.3087 (1.4389)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 90/781]  eta: 0:03:55  lr: 0.000026  loss: 1.3161 (1.4507)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [100/781]  eta: 0:03:51  lr: 0.000026  loss: 1.3249 (1.4415)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [110/781]  eta: 0:03:47  lr: 0.000026  loss: 1.3249 (1.4490)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [120/781]  eta: 0:03:43  lr: 0.000026  loss: 1.3280 (1.4478)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [130/781]  eta: 0:03:40  lr: 0.000026  loss: 1.3224 (1.4386)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [140/781]  eta: 0:03:36  lr: 0.000026  loss: 1.3215 (1.4336)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [150/781]  eta: 0:03:32  lr: 0.000026  loss: 1.3293 (1.4359)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [160/781]  eta: 0:03:29  lr: 0.000026  loss: 1.3340 (1.4291)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [170/781]  eta: 0:03:25  lr: 0.000026  loss: 1.3431 (1.4288)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [180/781]  eta: 0:03:22  lr: 0.000026  loss: 1.3188 (1.4219)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [190/781]  eta: 0:03:18  lr: 0.000026  loss: 1.2793 (1.4156)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [200/781]  eta: 0:03:15  lr: 0.000026  loss: 1.3432 (1.4324)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [210/781]  eta: 0:03:11  lr: 0.000026  loss: 1.4188 (1.4332)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [220/781]  eta: 0:03:08  lr: 0.000026  loss: 1.3415 (1.4340)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [230/781]  eta: 0:03:04  lr: 0.000026  loss: 1.3418 (1.4335)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [240/781]  eta: 0:03:01  lr: 0.000026  loss: 1.3212 (1.4316)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [250/781]  eta: 0:02:58  lr: 0.000026  loss: 1.3279 (1.4347)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [260/781]  eta: 0:02:55  lr: 0.000026  loss: 1.3590 (1.4355)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [270/781]  eta: 0:02:51  lr: 0.000026  loss: 1.3499 (1.4370)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [280/781]  eta: 0:02:48  lr: 0.000026  loss: 1.3564 (1.4400)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [290/781]  eta: 0:02:44  lr: 0.000026  loss: 1.3691 (1.4428)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [300/781]  eta: 0:02:41  lr: 0.000026  loss: 1.3656 (1.4495)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [310/781]  eta: 0:02:37  lr: 0.000026  loss: 1.3604 (1.4496)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [320/781]  eta: 0:02:34  lr: 0.000026  loss: 1.3367 (1.4508)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [330/781]  eta: 0:02:31  lr: 0.000026  loss: 1.3834 (1.4508)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [340/781]  eta: 0:02:27  lr: 0.000026  loss: 1.3829 (1.4484)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [350/781]  eta: 0:02:24  lr: 0.000026  loss: 1.3325 (1.4515)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [54]  [360/781]  eta: 0:02:20  lr: 0.000026  loss: 1.3282 (1.4489)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [370/781]  eta: 0:02:17  lr: 0.000026  loss: 1.3282 (1.4536)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [380/781]  eta: 0:02:14  lr: 0.000026  loss: 1.3300 (1.4552)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [390/781]  eta: 0:02:10  lr: 0.000026  loss: 1.3300 (1.4607)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [400/781]  eta: 0:02:07  lr: 0.000026  loss: 1.4019 (1.4638)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [410/781]  eta: 0:02:04  lr: 0.000026  loss: 1.3676 (1.4635)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [420/781]  eta: 0:02:00  lr: 0.000026  loss: 1.3306 (1.4619)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [430/781]  eta: 0:01:57  lr: 0.000026  loss: 1.3329 (1.4621)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [440/781]  eta: 0:01:53  lr: 0.000026  loss: 1.4161 (1.4649)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [450/781]  eta: 0:01:50  lr: 0.000026  loss: 1.3862 (1.4645)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [460/781]  eta: 0:01:47  lr: 0.000026  loss: 1.3687 (1.4667)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [470/781]  eta: 0:01:43  lr: 0.000026  loss: 1.3591 (1.4675)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [480/781]  eta: 0:01:40  lr: 0.000026  loss: 1.3591 (1.4688)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [490/781]  eta: 0:01:37  lr: 0.000026  loss: 1.3197 (1.4654)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [500/781]  eta: 0:01:33  lr: 0.000026  loss: 1.3628 (1.4684)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [510/781]  eta: 0:01:30  lr: 0.000026  loss: 1.3911 (1.4691)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [520/781]  eta: 0:01:27  lr: 0.000026  loss: 1.3601 (1.4669)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [530/781]  eta: 0:01:23  lr: 0.000026  loss: 1.3802 (1.4720)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [540/781]  eta: 0:01:20  lr: 0.000026  loss: 1.3981 (1.4721)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [550/781]  eta: 0:01:17  lr: 0.000026  loss: 1.3749 (1.4733)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [560/781]  eta: 0:01:13  lr: 0.000026  loss: 1.3522 (1.4736)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [570/781]  eta: 0:01:10  lr: 0.000026  loss: 1.3306 (1.4735)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [580/781]  eta: 0:01:07  lr: 0.000026  loss: 1.3579 (1.4735)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [590/781]  eta: 0:01:03  lr: 0.000026  loss: 1.3666 (1.4746)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [600/781]  eta: 0:01:00  lr: 0.000026  loss: 1.3588 (1.4743)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [610/781]  eta: 0:00:57  lr: 0.000026  loss: 1.3587 (1.4761)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [620/781]  eta: 0:00:53  lr: 0.000026  loss: 1.3476 (1.4739)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [630/781]  eta: 0:00:50  lr: 0.000026  loss: 1.3115 (1.4729)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [640/781]  eta: 0:00:47  lr: 0.000026  loss: 1.2936 (1.4720)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [650/781]  eta: 0:00:43  lr: 0.000026  loss: 1.3143 (1.4714)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [660/781]  eta: 0:00:40  lr: 0.000026  loss: 1.3038 (1.4693)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [670/781]  eta: 0:00:37  lr: 0.000026  loss: 1.3038 (1.4701)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [680/781]  eta: 0:00:33  lr: 0.000026  loss: 1.3505 (1.4703)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [690/781]  eta: 0:00:30  lr: 0.000026  loss: 1.3505 (1.4699)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [700/781]  eta: 0:00:27  lr: 0.000026  loss: 1.3584 (1.4702)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [710/781]  eta: 0:00:23  lr: 0.000026  loss: 1.3277 (1.4710)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [720/781]  eta: 0:00:20  lr: 0.000026  loss: 1.3103 (1.4718)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [730/781]  eta: 0:00:16  lr: 0.000026  loss: 1.3399 (1.4719)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [740/781]  eta: 0:00:13  lr: 0.000026  loss: 1.3399 (1.4733)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [750/781]  eta: 0:00:10  lr: 0.000026  loss: 1.3076 (1.4710)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [760/781]  eta: 0:00:06  lr: 0.000026  loss: 1.3076 (1.4692)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [770/781]  eta: 0:00:03  lr: 0.000026  loss: 1.3337 (1.4692)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [780/781]  eta: 0:00:00  lr: 0.000026  loss: 1.3609 (1.4717)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [54] Total time: 0:04:20 (0.3333 s / it)\n",
            "Averaged stats: lr: 0.000026  loss: 1.3609 (1.4717)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3284680247306824, 'lambda_convnext_base': 0.2598763704299927, 'lambda_tf_efficientnetv2_l': 0.4116555154323578}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8299 (0.8299)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8338  data: 0.8031  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8591 (0.9493)  acc1: 83.3333 (81.3447)  acc5: 94.7917 (93.9867)  time: 0.1799  data: 0.1495  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9769 (1.0144)  acc1: 77.6042 (80.0347)  acc5: 93.7500 (92.9564)  time: 0.1352  data: 0.1048  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1827 (1.0760)  acc1: 75.0000 (78.8474)  acc5: 91.6667 (92.3723)  time: 0.1283  data: 0.0979  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2419 (1.1175)  acc1: 74.4792 (78.0996)  acc5: 90.6250 (91.9461)  time: 0.1136  data: 0.0832  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0903 (1.1163)  acc1: 75.5208 (77.7778)  acc5: 92.1875 (92.1569)  time: 0.1356  data: 0.1051  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1000 (1.1253)  acc1: 75.0000 (77.5700)  acc5: 92.7083 (92.1800)  time: 0.1208  data: 0.0912  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1391 s / it)\n",
            "* Acc@1 77.570 Acc@5 92.180 loss 1.125\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.69%\n",
            "[alpha-schedule=cosine] epoch=55 distillation_alpha=0.4668\n",
            "Epoch: [55]  [  0/781]  eta: 0:14:29  lr: 0.000025  loss: 1.2563 (1.2563)  time: 1.1138  data: 0.7729  max mem: 6459\n",
            "Epoch: [55]  [ 10/781]  eta: 0:05:11  lr: 0.000025  loss: 1.3445 (1.5583)  time: 0.4036  data: 0.0706  max mem: 6459\n",
            "Epoch: [55]  [ 20/781]  eta: 0:04:41  lr: 0.000025  loss: 1.3542 (1.5888)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 30/781]  eta: 0:04:28  lr: 0.000025  loss: 1.3542 (1.5284)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 40/781]  eta: 0:04:20  lr: 0.000025  loss: 1.3447 (1.4922)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 50/781]  eta: 0:04:14  lr: 0.000025  loss: 1.3198 (1.4731)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 60/781]  eta: 0:04:08  lr: 0.000025  loss: 1.3198 (1.4675)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 70/781]  eta: 0:04:03  lr: 0.000025  loss: 1.2909 (1.4594)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 80/781]  eta: 0:03:59  lr: 0.000025  loss: 1.3037 (1.4419)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 90/781]  eta: 0:03:55  lr: 0.000025  loss: 1.3065 (1.4399)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [100/781]  eta: 0:03:51  lr: 0.000025  loss: 1.3134 (1.4345)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [110/781]  eta: 0:03:47  lr: 0.000025  loss: 1.3920 (1.4476)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [120/781]  eta: 0:03:43  lr: 0.000025  loss: 1.3426 (1.4532)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [130/781]  eta: 0:03:40  lr: 0.000025  loss: 1.3342 (1.4467)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [140/781]  eta: 0:03:36  lr: 0.000025  loss: 1.3155 (1.4446)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [150/781]  eta: 0:03:32  lr: 0.000025  loss: 1.2949 (1.4389)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [55]  [160/781]  eta: 0:03:29  lr: 0.000025  loss: 1.2483 (1.4270)  time: 0.3316  data: 0.0004  max mem: 6459\n",
            "Epoch: [55]  [170/781]  eta: 0:03:25  lr: 0.000025  loss: 1.2716 (1.4286)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [180/781]  eta: 0:03:22  lr: 0.000025  loss: 1.3607 (1.4316)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [190/781]  eta: 0:03:18  lr: 0.000025  loss: 1.3767 (1.4340)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [200/781]  eta: 0:03:15  lr: 0.000025  loss: 1.3329 (1.4394)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [210/781]  eta: 0:03:11  lr: 0.000025  loss: 1.3677 (1.4496)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [220/781]  eta: 0:03:08  lr: 0.000025  loss: 1.3579 (1.4485)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [230/781]  eta: 0:03:04  lr: 0.000025  loss: 1.3492 (1.4547)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [240/781]  eta: 0:03:01  lr: 0.000025  loss: 1.3659 (1.4510)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [250/781]  eta: 0:02:57  lr: 0.000025  loss: 1.3369 (1.4505)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [260/781]  eta: 0:02:54  lr: 0.000025  loss: 1.3358 (1.4482)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [270/781]  eta: 0:02:51  lr: 0.000025  loss: 1.3284 (1.4484)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [280/781]  eta: 0:02:47  lr: 0.000025  loss: 1.3051 (1.4443)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [290/781]  eta: 0:02:44  lr: 0.000025  loss: 1.3379 (1.4459)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [300/781]  eta: 0:02:40  lr: 0.000025  loss: 1.3518 (1.4424)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [310/781]  eta: 0:02:37  lr: 0.000025  loss: 1.2881 (1.4370)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [320/781]  eta: 0:02:34  lr: 0.000025  loss: 1.2526 (1.4373)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [330/781]  eta: 0:02:30  lr: 0.000025  loss: 1.3333 (1.4381)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [340/781]  eta: 0:02:27  lr: 0.000025  loss: 1.3876 (1.4502)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [350/781]  eta: 0:02:24  lr: 0.000025  loss: 1.3562 (1.4462)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [360/781]  eta: 0:02:20  lr: 0.000025  loss: 1.3264 (1.4446)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [370/781]  eta: 0:02:17  lr: 0.000025  loss: 1.3586 (1.4440)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [380/781]  eta: 0:02:13  lr: 0.000025  loss: 1.3559 (1.4441)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [390/781]  eta: 0:02:10  lr: 0.000025  loss: 1.3385 (1.4439)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [400/781]  eta: 0:02:07  lr: 0.000025  loss: 1.3330 (1.4430)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [410/781]  eta: 0:02:03  lr: 0.000025  loss: 1.2959 (1.4393)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [420/781]  eta: 0:02:00  lr: 0.000025  loss: 1.2998 (1.4376)  time: 0.3315  data: 0.0004  max mem: 6459\n",
            "Epoch: [55]  [430/781]  eta: 0:01:57  lr: 0.000025  loss: 1.3579 (1.4383)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [55]  [440/781]  eta: 0:01:53  lr: 0.000025  loss: 1.3579 (1.4395)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [450/781]  eta: 0:01:50  lr: 0.000025  loss: 1.2999 (1.4370)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [460/781]  eta: 0:01:47  lr: 0.000025  loss: 1.3023 (1.4341)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [470/781]  eta: 0:01:43  lr: 0.000025  loss: 1.3286 (1.4352)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [480/781]  eta: 0:01:40  lr: 0.000025  loss: 1.3261 (1.4333)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [490/781]  eta: 0:01:37  lr: 0.000025  loss: 1.3603 (1.4359)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [500/781]  eta: 0:01:33  lr: 0.000025  loss: 1.3662 (1.4362)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [510/781]  eta: 0:01:30  lr: 0.000025  loss: 1.3472 (1.4360)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [520/781]  eta: 0:01:27  lr: 0.000025  loss: 1.2752 (1.4354)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [530/781]  eta: 0:01:23  lr: 0.000025  loss: 1.3392 (1.4344)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [540/781]  eta: 0:01:20  lr: 0.000025  loss: 1.3797 (1.4396)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [550/781]  eta: 0:01:16  lr: 0.000025  loss: 1.3785 (1.4386)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [560/781]  eta: 0:01:13  lr: 0.000025  loss: 1.3278 (1.4395)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [570/781]  eta: 0:01:10  lr: 0.000025  loss: 1.3278 (1.4372)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [580/781]  eta: 0:01:06  lr: 0.000025  loss: 1.3203 (1.4368)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [590/781]  eta: 0:01:03  lr: 0.000025  loss: 1.2986 (1.4380)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [600/781]  eta: 0:01:00  lr: 0.000025  loss: 1.3067 (1.4367)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [610/781]  eta: 0:00:56  lr: 0.000025  loss: 1.3110 (1.4383)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [620/781]  eta: 0:00:53  lr: 0.000025  loss: 1.4061 (1.4408)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [630/781]  eta: 0:00:50  lr: 0.000025  loss: 1.3436 (1.4416)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [640/781]  eta: 0:00:46  lr: 0.000025  loss: 1.3140 (1.4402)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [650/781]  eta: 0:00:43  lr: 0.000025  loss: 1.3342 (1.4381)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [660/781]  eta: 0:00:40  lr: 0.000025  loss: 1.3054 (1.4374)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [670/781]  eta: 0:00:36  lr: 0.000025  loss: 1.3397 (1.4375)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [680/781]  eta: 0:00:33  lr: 0.000025  loss: 1.3423 (1.4364)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [690/781]  eta: 0:00:30  lr: 0.000025  loss: 1.3293 (1.4388)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [700/781]  eta: 0:00:26  lr: 0.000025  loss: 1.2814 (1.4372)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [710/781]  eta: 0:00:23  lr: 0.000025  loss: 1.2563 (1.4381)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [720/781]  eta: 0:00:20  lr: 0.000025  loss: 1.2989 (1.4387)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [730/781]  eta: 0:00:16  lr: 0.000025  loss: 1.3300 (1.4395)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [740/781]  eta: 0:00:13  lr: 0.000025  loss: 1.3348 (1.4406)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [750/781]  eta: 0:00:10  lr: 0.000025  loss: 1.3525 (1.4406)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [760/781]  eta: 0:00:06  lr: 0.000025  loss: 1.3717 (1.4399)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [770/781]  eta: 0:00:03  lr: 0.000025  loss: 1.2742 (1.4396)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [780/781]  eta: 0:00:00  lr: 0.000025  loss: 1.3091 (1.4395)  time: 0.3321  data: 0.0006  max mem: 6459\n",
            "Epoch: [55] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000025  loss: 1.3091 (1.4395)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3296688497066498, 'lambda_convnext_base': 0.2595517039299011, 'lambda_tf_efficientnetv2_l': 0.4107796251773834}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7472 (0.7472)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8473  data: 0.8166  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8543 (0.9362)  acc1: 83.3333 (81.4867)  acc5: 94.7917 (94.1288)  time: 0.1768  data: 0.1463  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9521 (1.0059)  acc1: 79.6875 (80.0099)  acc5: 94.2708 (93.1300)  time: 0.1222  data: 0.0917  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1495 (1.0706)  acc1: 76.5625 (78.9987)  acc5: 90.6250 (92.4059)  time: 0.1341  data: 0.1036  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2357 (1.1190)  acc1: 76.5625 (78.0742)  acc5: 90.6250 (91.9461)  time: 0.1257  data: 0.0953  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1100 (1.1130)  acc1: 74.4792 (77.9003)  acc5: 92.7083 (92.2794)  time: 0.1370  data: 0.1066  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1283 (1.1232)  acc1: 74.4792 (77.7500)  acc5: 93.2292 (92.3100)  time: 0.1417  data: 0.1121  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1431 s / it)\n",
            "* Acc@1 77.750 Acc@5 92.310 loss 1.123\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.75%\n",
            "[alpha-schedule=cosine] epoch=56 distillation_alpha=0.4750\n",
            "Epoch: [56]  [  0/781]  eta: 0:14:30  lr: 0.000025  loss: 2.4975 (2.4975)  time: 1.1142  data: 0.7679  max mem: 6459\n",
            "Epoch: [56]  [ 10/781]  eta: 0:05:11  lr: 0.000025  loss: 1.3201 (1.4551)  time: 0.4035  data: 0.0701  max mem: 6459\n",
            "Epoch: [56]  [ 20/781]  eta: 0:04:41  lr: 0.000025  loss: 1.3137 (1.3887)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 30/781]  eta: 0:04:28  lr: 0.000025  loss: 1.3183 (1.3975)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 40/781]  eta: 0:04:20  lr: 0.000025  loss: 1.3011 (1.3766)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 50/781]  eta: 0:04:13  lr: 0.000025  loss: 1.2954 (1.3838)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 60/781]  eta: 0:04:08  lr: 0.000025  loss: 1.3209 (1.3997)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 70/781]  eta: 0:04:03  lr: 0.000025  loss: 1.3590 (1.4227)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [56]  [ 80/781]  eta: 0:03:59  lr: 0.000025  loss: 1.4007 (1.4443)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [56]  [ 90/781]  eta: 0:03:55  lr: 0.000025  loss: 1.4007 (1.4419)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [100/781]  eta: 0:03:51  lr: 0.000025  loss: 1.3591 (1.4444)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [110/781]  eta: 0:03:47  lr: 0.000025  loss: 1.3721 (1.4505)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [120/781]  eta: 0:03:43  lr: 0.000025  loss: 1.3547 (1.4414)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [130/781]  eta: 0:03:39  lr: 0.000025  loss: 1.3387 (1.4366)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [140/781]  eta: 0:03:36  lr: 0.000025  loss: 1.2998 (1.4336)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [150/781]  eta: 0:03:32  lr: 0.000025  loss: 1.2952 (1.4370)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [160/781]  eta: 0:03:29  lr: 0.000025  loss: 1.2978 (1.4330)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [170/781]  eta: 0:03:25  lr: 0.000025  loss: 1.3230 (1.4276)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [180/781]  eta: 0:03:22  lr: 0.000025  loss: 1.2655 (1.4192)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [190/781]  eta: 0:03:18  lr: 0.000025  loss: 1.2688 (1.4169)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [200/781]  eta: 0:03:15  lr: 0.000025  loss: 1.2976 (1.4139)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [210/781]  eta: 0:03:11  lr: 0.000025  loss: 1.3356 (1.4195)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [220/781]  eta: 0:03:08  lr: 0.000025  loss: 1.3365 (1.4170)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [230/781]  eta: 0:03:04  lr: 0.000025  loss: 1.3143 (1.4141)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [240/781]  eta: 0:03:01  lr: 0.000025  loss: 1.2741 (1.4089)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [250/781]  eta: 0:02:57  lr: 0.000025  loss: 1.2711 (1.4088)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [260/781]  eta: 0:02:54  lr: 0.000025  loss: 1.3383 (1.4110)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [270/781]  eta: 0:02:51  lr: 0.000025  loss: 1.3225 (1.4100)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [280/781]  eta: 0:02:47  lr: 0.000025  loss: 1.2910 (1.4093)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [290/781]  eta: 0:02:44  lr: 0.000025  loss: 1.3491 (1.4138)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [300/781]  eta: 0:02:40  lr: 0.000025  loss: 1.3791 (1.4143)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [310/781]  eta: 0:02:37  lr: 0.000025  loss: 1.3428 (1.4220)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [320/781]  eta: 0:02:34  lr: 0.000025  loss: 1.3550 (1.4226)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [330/781]  eta: 0:02:30  lr: 0.000025  loss: 1.3550 (1.4285)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [340/781]  eta: 0:02:27  lr: 0.000025  loss: 1.3308 (1.4250)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [350/781]  eta: 0:02:23  lr: 0.000025  loss: 1.3230 (1.4264)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [360/781]  eta: 0:02:20  lr: 0.000025  loss: 1.3259 (1.4292)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [370/781]  eta: 0:02:17  lr: 0.000025  loss: 1.2805 (1.4287)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [380/781]  eta: 0:02:13  lr: 0.000025  loss: 1.2994 (1.4282)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [390/781]  eta: 0:02:10  lr: 0.000025  loss: 1.3440 (1.4276)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [400/781]  eta: 0:02:07  lr: 0.000025  loss: 1.3528 (1.4298)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [410/781]  eta: 0:02:03  lr: 0.000025  loss: 1.3786 (1.4325)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [420/781]  eta: 0:02:00  lr: 0.000025  loss: 1.3621 (1.4302)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [430/781]  eta: 0:01:57  lr: 0.000025  loss: 1.3522 (1.4298)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [440/781]  eta: 0:01:53  lr: 0.000025  loss: 1.3464 (1.4285)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [450/781]  eta: 0:01:50  lr: 0.000025  loss: 1.3349 (1.4274)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [460/781]  eta: 0:01:47  lr: 0.000025  loss: 1.3277 (1.4268)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [470/781]  eta: 0:01:43  lr: 0.000025  loss: 1.3219 (1.4296)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [480/781]  eta: 0:01:40  lr: 0.000025  loss: 1.3178 (1.4285)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [490/781]  eta: 0:01:37  lr: 0.000025  loss: 1.3386 (1.4312)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [500/781]  eta: 0:01:33  lr: 0.000025  loss: 1.3152 (1.4297)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [510/781]  eta: 0:01:30  lr: 0.000025  loss: 1.3152 (1.4315)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [520/781]  eta: 0:01:27  lr: 0.000025  loss: 1.3243 (1.4339)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [530/781]  eta: 0:01:23  lr: 0.000025  loss: 1.2837 (1.4332)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [540/781]  eta: 0:01:20  lr: 0.000025  loss: 1.2817 (1.4323)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [550/781]  eta: 0:01:16  lr: 0.000025  loss: 1.3068 (1.4301)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [560/781]  eta: 0:01:13  lr: 0.000025  loss: 1.3314 (1.4347)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [570/781]  eta: 0:01:10  lr: 0.000025  loss: 1.3525 (1.4363)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [580/781]  eta: 0:01:06  lr: 0.000025  loss: 1.3487 (1.4377)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [590/781]  eta: 0:01:03  lr: 0.000025  loss: 1.3349 (1.4385)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [600/781]  eta: 0:01:00  lr: 0.000025  loss: 1.3152 (1.4411)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [610/781]  eta: 0:00:56  lr: 0.000025  loss: 1.3727 (1.4426)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [620/781]  eta: 0:00:53  lr: 0.000025  loss: 1.3680 (1.4417)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [630/781]  eta: 0:00:50  lr: 0.000025  loss: 1.3497 (1.4434)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [640/781]  eta: 0:00:46  lr: 0.000025  loss: 1.3531 (1.4439)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [650/781]  eta: 0:00:43  lr: 0.000025  loss: 1.3473 (1.4443)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [660/781]  eta: 0:00:40  lr: 0.000025  loss: 1.3443 (1.4433)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [56]  [670/781]  eta: 0:00:36  lr: 0.000025  loss: 1.3422 (1.4433)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [680/781]  eta: 0:00:33  lr: 0.000025  loss: 1.3500 (1.4455)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [690/781]  eta: 0:00:30  lr: 0.000025  loss: 1.3500 (1.4468)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [700/781]  eta: 0:00:26  lr: 0.000025  loss: 1.3368 (1.4498)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [710/781]  eta: 0:00:23  lr: 0.000025  loss: 1.3231 (1.4497)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [720/781]  eta: 0:00:20  lr: 0.000025  loss: 1.3304 (1.4515)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [730/781]  eta: 0:00:16  lr: 0.000025  loss: 1.3430 (1.4533)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [740/781]  eta: 0:00:13  lr: 0.000025  loss: 1.3368 (1.4541)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [750/781]  eta: 0:00:10  lr: 0.000025  loss: 1.3332 (1.4526)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [760/781]  eta: 0:00:06  lr: 0.000025  loss: 1.3800 (1.4565)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [770/781]  eta: 0:00:03  lr: 0.000025  loss: 1.4150 (1.4566)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [780/781]  eta: 0:00:00  lr: 0.000025  loss: 1.3786 (1.4584)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [56] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000025  loss: 1.3786 (1.4584)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32843080163002014, 'lambda_convnext_base': 0.2596531808376312, 'lambda_tf_efficientnetv2_l': 0.41191595792770386}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7034 (0.7034)  acc1: 85.4167 (85.4167)  acc5: 96.8750 (96.8750)  time: 0.8271  data: 0.7949  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8967 (0.9449)  acc1: 83.8542 (81.6761)  acc5: 95.3125 (94.1761)  time: 0.1735  data: 0.1429  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0053 (1.0226)  acc1: 79.1667 (79.7123)  acc5: 94.2708 (93.2292)  time: 0.1250  data: 0.0946  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1338 (1.0785)  acc1: 77.0833 (78.7634)  acc5: 91.6667 (92.5571)  time: 0.1286  data: 0.0981  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2241 (1.1193)  acc1: 76.0417 (78.0361)  acc5: 90.6250 (92.0605)  time: 0.1150  data: 0.0845  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1192 (1.1212)  acc1: 76.5625 (77.6961)  acc5: 92.1875 (92.2794)  time: 0.1287  data: 0.0982  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1700 (1.1325)  acc1: 75.0000 (77.5600)  acc5: 92.1875 (92.2900)  time: 0.1195  data: 0.0899  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1349 s / it)\n",
            "* Acc@1 77.560 Acc@5 92.290 loss 1.133\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.75%\n",
            "[alpha-schedule=cosine] epoch=57 distillation_alpha=0.4830\n",
            "Epoch: [57]  [  0/781]  eta: 0:14:51  lr: 0.000024  loss: 1.2794 (1.2794)  time: 1.1419  data: 0.8030  max mem: 6459\n",
            "Epoch: [57]  [ 10/781]  eta: 0:05:12  lr: 0.000024  loss: 1.2906 (1.3464)  time: 0.4056  data: 0.0733  max mem: 6459\n",
            "Epoch: [57]  [ 20/781]  eta: 0:04:42  lr: 0.000024  loss: 1.3107 (1.4735)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [57]  [ 30/781]  eta: 0:04:28  lr: 0.000024  loss: 1.3260 (1.4403)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 40/781]  eta: 0:04:20  lr: 0.000024  loss: 1.3260 (1.4554)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 50/781]  eta: 0:04:14  lr: 0.000024  loss: 1.3292 (1.4259)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 60/781]  eta: 0:04:08  lr: 0.000024  loss: 1.3519 (1.4668)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 70/781]  eta: 0:04:06  lr: 0.000024  loss: 1.3648 (1.4621)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 80/781]  eta: 0:04:01  lr: 0.000024  loss: 1.2937 (1.4409)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 90/781]  eta: 0:03:57  lr: 0.000024  loss: 1.2842 (1.4497)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [100/781]  eta: 0:03:52  lr: 0.000024  loss: 1.3023 (1.4450)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [110/781]  eta: 0:03:48  lr: 0.000024  loss: 1.3057 (1.4414)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [120/781]  eta: 0:03:44  lr: 0.000024  loss: 1.3364 (1.4371)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [130/781]  eta: 0:03:41  lr: 0.000024  loss: 1.3237 (1.4359)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [140/781]  eta: 0:03:37  lr: 0.000024  loss: 1.3237 (1.4364)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [150/781]  eta: 0:03:33  lr: 0.000024  loss: 1.3689 (1.4468)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [160/781]  eta: 0:03:30  lr: 0.000024  loss: 1.3263 (1.4455)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [170/781]  eta: 0:03:26  lr: 0.000024  loss: 1.3044 (1.4367)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [180/781]  eta: 0:03:22  lr: 0.000024  loss: 1.2846 (1.4485)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [190/781]  eta: 0:03:19  lr: 0.000024  loss: 1.2918 (1.4477)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [200/781]  eta: 0:03:15  lr: 0.000024  loss: 1.3282 (1.4503)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [210/781]  eta: 0:03:12  lr: 0.000024  loss: 1.3874 (1.4586)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [220/781]  eta: 0:03:08  lr: 0.000024  loss: 1.3812 (1.4575)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [230/781]  eta: 0:03:05  lr: 0.000024  loss: 1.3175 (1.4596)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [240/781]  eta: 0:03:01  lr: 0.000024  loss: 1.3140 (1.4602)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [250/781]  eta: 0:02:58  lr: 0.000024  loss: 1.3140 (1.4628)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [260/781]  eta: 0:02:54  lr: 0.000024  loss: 1.3775 (1.4638)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [270/781]  eta: 0:02:51  lr: 0.000024  loss: 1.3785 (1.4656)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [280/781]  eta: 0:02:48  lr: 0.000024  loss: 1.3307 (1.4627)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [290/781]  eta: 0:02:44  lr: 0.000024  loss: 1.3307 (1.4626)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [300/781]  eta: 0:02:41  lr: 0.000024  loss: 1.2633 (1.4598)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [310/781]  eta: 0:02:37  lr: 0.000024  loss: 1.2585 (1.4566)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [320/781]  eta: 0:02:34  lr: 0.000024  loss: 1.2822 (1.4562)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [330/781]  eta: 0:02:31  lr: 0.000024  loss: 1.2470 (1.4498)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [340/781]  eta: 0:02:27  lr: 0.000024  loss: 1.2470 (1.4445)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [350/781]  eta: 0:02:24  lr: 0.000024  loss: 1.3042 (1.4450)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [360/781]  eta: 0:02:20  lr: 0.000024  loss: 1.3741 (1.4503)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [370/781]  eta: 0:02:17  lr: 0.000024  loss: 1.3678 (1.4492)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [380/781]  eta: 0:02:14  lr: 0.000024  loss: 1.2799 (1.4495)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [390/781]  eta: 0:02:10  lr: 0.000024  loss: 1.2799 (1.4481)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [400/781]  eta: 0:02:07  lr: 0.000024  loss: 1.3230 (1.4487)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [410/781]  eta: 0:02:04  lr: 0.000024  loss: 1.3291 (1.4480)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [420/781]  eta: 0:02:00  lr: 0.000024  loss: 1.3340 (1.4504)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [430/781]  eta: 0:01:57  lr: 0.000024  loss: 1.3405 (1.4482)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [440/781]  eta: 0:01:53  lr: 0.000024  loss: 1.3200 (1.4452)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [450/781]  eta: 0:01:50  lr: 0.000024  loss: 1.2870 (1.4441)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [460/781]  eta: 0:01:47  lr: 0.000024  loss: 1.3538 (1.4454)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [470/781]  eta: 0:01:43  lr: 0.000024  loss: 1.3041 (1.4471)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [480/781]  eta: 0:01:40  lr: 0.000024  loss: 1.3026 (1.4482)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [490/781]  eta: 0:01:37  lr: 0.000024  loss: 1.3856 (1.4495)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [500/781]  eta: 0:01:33  lr: 0.000024  loss: 1.3860 (1.4512)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [510/781]  eta: 0:01:30  lr: 0.000024  loss: 1.3371 (1.4528)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [520/781]  eta: 0:01:27  lr: 0.000024  loss: 1.3152 (1.4509)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [530/781]  eta: 0:01:23  lr: 0.000024  loss: 1.3389 (1.4522)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [540/781]  eta: 0:01:20  lr: 0.000024  loss: 1.3691 (1.4546)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [550/781]  eta: 0:01:17  lr: 0.000024  loss: 1.3498 (1.4556)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [560/781]  eta: 0:01:13  lr: 0.000024  loss: 1.3347 (1.4550)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [570/781]  eta: 0:01:10  lr: 0.000024  loss: 1.3394 (1.4551)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [580/781]  eta: 0:01:07  lr: 0.000024  loss: 1.3394 (1.4535)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [590/781]  eta: 0:01:03  lr: 0.000024  loss: 1.2861 (1.4536)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [600/781]  eta: 0:01:00  lr: 0.000024  loss: 1.3054 (1.4518)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [610/781]  eta: 0:00:57  lr: 0.000024  loss: 1.3125 (1.4513)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [620/781]  eta: 0:00:53  lr: 0.000024  loss: 1.3430 (1.4541)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [630/781]  eta: 0:00:50  lr: 0.000024  loss: 1.3445 (1.4525)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [640/781]  eta: 0:00:46  lr: 0.000024  loss: 1.2967 (1.4527)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [650/781]  eta: 0:00:43  lr: 0.000024  loss: 1.3609 (1.4512)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [660/781]  eta: 0:00:40  lr: 0.000024  loss: 1.3499 (1.4512)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [670/781]  eta: 0:00:36  lr: 0.000024  loss: 1.2976 (1.4515)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [680/781]  eta: 0:00:33  lr: 0.000024  loss: 1.2764 (1.4505)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [690/781]  eta: 0:00:30  lr: 0.000024  loss: 1.3247 (1.4513)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [700/781]  eta: 0:00:26  lr: 0.000024  loss: 1.3595 (1.4504)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [710/781]  eta: 0:00:23  lr: 0.000024  loss: 1.3340 (1.4483)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [720/781]  eta: 0:00:20  lr: 0.000024  loss: 1.3043 (1.4479)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [730/781]  eta: 0:00:16  lr: 0.000024  loss: 1.3322 (1.4483)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [740/781]  eta: 0:00:13  lr: 0.000024  loss: 1.3782 (1.4505)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [750/781]  eta: 0:00:10  lr: 0.000024  loss: 1.3680 (1.4516)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [760/781]  eta: 0:00:06  lr: 0.000024  loss: 1.3427 (1.4529)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [770/781]  eta: 0:00:03  lr: 0.000024  loss: 1.3296 (1.4560)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [780/781]  eta: 0:00:00  lr: 0.000024  loss: 1.3458 (1.4584)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [57] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000024  loss: 1.3458 (1.4584)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3288961350917816, 'lambda_convnext_base': 0.2591155469417572, 'lambda_tf_efficientnetv2_l': 0.4119880199432373}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7821 (0.7821)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8569  data: 0.8262  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8868 (0.9516)  acc1: 83.8542 (81.3447)  acc5: 94.2708 (93.3239)  time: 0.1759  data: 0.1454  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9270 (1.0195)  acc1: 80.2083 (79.7619)  acc5: 93.2292 (92.6835)  time: 0.1309  data: 0.1004  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1638 (1.0840)  acc1: 75.5208 (78.7298)  acc5: 90.6250 (92.2043)  time: 0.1359  data: 0.1055  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2370 (1.1263)  acc1: 75.5208 (78.0488)  acc5: 90.1042 (91.5904)  time: 0.1395  data: 0.1091  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1043 (1.1208)  acc1: 75.5208 (77.9105)  acc5: 91.6667 (91.9118)  time: 0.1350  data: 0.1045  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1297 (1.1266)  acc1: 75.0000 (77.7900)  acc5: 91.6667 (91.9800)  time: 0.1136  data: 0.0840  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1404 s / it)\n",
            "* Acc@1 77.790 Acc@5 91.980 loss 1.127\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.79%\n",
            "[alpha-schedule=cosine] epoch=58 distillation_alpha=0.4908\n",
            "Epoch: [58]  [  0/781]  eta: 0:14:31  lr: 0.000023  loss: 1.1870 (1.1870)  time: 1.1165  data: 0.7563  max mem: 6459\n",
            "Epoch: [58]  [ 10/781]  eta: 0:05:10  lr: 0.000023  loss: 1.3433 (1.5609)  time: 0.4031  data: 0.0691  max mem: 6459\n",
            "Epoch: [58]  [ 20/781]  eta: 0:04:40  lr: 0.000023  loss: 1.3442 (1.5706)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 30/781]  eta: 0:04:28  lr: 0.000023  loss: 1.3442 (1.5370)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 40/781]  eta: 0:04:20  lr: 0.000023  loss: 1.3127 (1.5078)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 50/781]  eta: 0:04:13  lr: 0.000023  loss: 1.2581 (1.4912)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 60/781]  eta: 0:04:08  lr: 0.000023  loss: 1.2934 (1.4810)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 70/781]  eta: 0:04:03  lr: 0.000023  loss: 1.2865 (1.4668)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 80/781]  eta: 0:03:59  lr: 0.000023  loss: 1.2820 (1.4574)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 90/781]  eta: 0:03:55  lr: 0.000023  loss: 1.3228 (1.4622)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [100/781]  eta: 0:03:51  lr: 0.000023  loss: 1.3631 (1.4684)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [110/781]  eta: 0:03:47  lr: 0.000023  loss: 1.3631 (1.4679)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [120/781]  eta: 0:03:43  lr: 0.000023  loss: 1.3337 (1.4571)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [130/781]  eta: 0:03:39  lr: 0.000023  loss: 1.3005 (1.4657)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [140/781]  eta: 0:03:36  lr: 0.000023  loss: 1.3313 (1.4654)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [150/781]  eta: 0:03:32  lr: 0.000023  loss: 1.2966 (1.4597)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [58]  [160/781]  eta: 0:03:29  lr: 0.000023  loss: 1.2966 (1.4560)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [58]  [170/781]  eta: 0:03:25  lr: 0.000023  loss: 1.3087 (1.4612)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [180/781]  eta: 0:03:21  lr: 0.000023  loss: 1.3112 (1.4648)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [190/781]  eta: 0:03:18  lr: 0.000023  loss: 1.3529 (1.4627)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [200/781]  eta: 0:03:15  lr: 0.000023  loss: 1.3549 (1.4649)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [210/781]  eta: 0:03:11  lr: 0.000023  loss: 1.3476 (1.4609)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [220/781]  eta: 0:03:08  lr: 0.000023  loss: 1.3088 (1.4628)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [230/781]  eta: 0:03:04  lr: 0.000023  loss: 1.2958 (1.4611)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [240/781]  eta: 0:03:01  lr: 0.000023  loss: 1.2876 (1.4605)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [250/781]  eta: 0:02:57  lr: 0.000023  loss: 1.3435 (1.4626)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [260/781]  eta: 0:02:54  lr: 0.000023  loss: 1.3731 (1.4726)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [270/781]  eta: 0:02:51  lr: 0.000023  loss: 1.3911 (1.4726)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [280/781]  eta: 0:02:47  lr: 0.000023  loss: 1.3920 (1.4740)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [290/781]  eta: 0:02:44  lr: 0.000023  loss: 1.3107 (1.4705)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [300/781]  eta: 0:02:40  lr: 0.000023  loss: 1.3304 (1.4770)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [310/781]  eta: 0:02:37  lr: 0.000023  loss: 1.3400 (1.4771)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [320/781]  eta: 0:02:34  lr: 0.000023  loss: 1.3347 (1.4766)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [330/781]  eta: 0:02:30  lr: 0.000023  loss: 1.3563 (1.4801)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [340/781]  eta: 0:02:27  lr: 0.000023  loss: 1.3312 (1.4757)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [350/781]  eta: 0:02:23  lr: 0.000023  loss: 1.3337 (1.4723)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [360/781]  eta: 0:02:20  lr: 0.000023  loss: 1.3060 (1.4661)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [370/781]  eta: 0:02:17  lr: 0.000023  loss: 1.2644 (1.4627)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [380/781]  eta: 0:02:13  lr: 0.000023  loss: 1.2986 (1.4621)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [390/781]  eta: 0:02:10  lr: 0.000023  loss: 1.2986 (1.4612)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [400/781]  eta: 0:02:07  lr: 0.000023  loss: 1.3158 (1.4594)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [410/781]  eta: 0:02:03  lr: 0.000023  loss: 1.3276 (1.4567)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [420/781]  eta: 0:02:00  lr: 0.000023  loss: 1.3632 (1.4689)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [430/781]  eta: 0:01:57  lr: 0.000023  loss: 1.3178 (1.4665)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [440/781]  eta: 0:01:53  lr: 0.000023  loss: 1.2965 (1.4640)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [450/781]  eta: 0:01:50  lr: 0.000023  loss: 1.3182 (1.4706)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [460/781]  eta: 0:01:47  lr: 0.000023  loss: 1.3571 (1.4722)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [470/781]  eta: 0:01:43  lr: 0.000023  loss: 1.3311 (1.4712)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [480/781]  eta: 0:01:40  lr: 0.000023  loss: 1.3330 (1.4717)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [490/781]  eta: 0:01:36  lr: 0.000023  loss: 1.3469 (1.4695)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [500/781]  eta: 0:01:33  lr: 0.000023  loss: 1.3590 (1.4709)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [510/781]  eta: 0:01:30  lr: 0.000023  loss: 1.3590 (1.4721)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [520/781]  eta: 0:01:26  lr: 0.000023  loss: 1.3365 (1.4741)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [530/781]  eta: 0:01:23  lr: 0.000023  loss: 1.3903 (1.4761)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [540/781]  eta: 0:01:20  lr: 0.000023  loss: 1.3488 (1.4734)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [550/781]  eta: 0:01:16  lr: 0.000023  loss: 1.3019 (1.4710)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [560/781]  eta: 0:01:13  lr: 0.000023  loss: 1.3081 (1.4685)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [570/781]  eta: 0:01:10  lr: 0.000023  loss: 1.3261 (1.4720)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [580/781]  eta: 0:01:06  lr: 0.000023  loss: 1.3818 (1.4717)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [590/781]  eta: 0:01:03  lr: 0.000023  loss: 1.4134 (1.4733)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [600/781]  eta: 0:01:00  lr: 0.000023  loss: 1.3666 (1.4720)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [610/781]  eta: 0:00:56  lr: 0.000023  loss: 1.2977 (1.4696)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [620/781]  eta: 0:00:53  lr: 0.000023  loss: 1.2772 (1.4672)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [630/781]  eta: 0:00:50  lr: 0.000023  loss: 1.2951 (1.4665)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [640/781]  eta: 0:00:46  lr: 0.000023  loss: 1.3325 (1.4667)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [650/781]  eta: 0:00:43  lr: 0.000023  loss: 1.3325 (1.4672)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [660/781]  eta: 0:00:40  lr: 0.000023  loss: 1.3522 (1.4685)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [670/781]  eta: 0:00:36  lr: 0.000023  loss: 1.3409 (1.4701)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [680/781]  eta: 0:00:33  lr: 0.000023  loss: 1.3409 (1.4692)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [690/781]  eta: 0:00:30  lr: 0.000023  loss: 1.3485 (1.4719)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [700/781]  eta: 0:00:26  lr: 0.000023  loss: 1.3525 (1.4720)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [710/781]  eta: 0:00:23  lr: 0.000023  loss: 1.3028 (1.4713)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [720/781]  eta: 0:00:20  lr: 0.000023  loss: 1.3002 (1.4696)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [730/781]  eta: 0:00:16  lr: 0.000023  loss: 1.3566 (1.4743)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [740/781]  eta: 0:00:13  lr: 0.000023  loss: 1.4072 (1.4757)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [750/781]  eta: 0:00:10  lr: 0.000023  loss: 1.3248 (1.4738)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [760/781]  eta: 0:00:06  lr: 0.000023  loss: 1.3062 (1.4737)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [770/781]  eta: 0:00:03  lr: 0.000023  loss: 1.3540 (1.4736)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [780/781]  eta: 0:00:00  lr: 0.000023  loss: 1.3540 (1.4743)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [58] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000023  loss: 1.3540 (1.4743)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32880911231040955, 'lambda_convnext_base': 0.26001277565956116, 'lambda_tf_efficientnetv2_l': 0.41117823123931885}\n",
            "Test:  [ 0/53]  eta: 0:00:48  loss: 0.8096 (0.8096)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.9130  data: 0.8823  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9677 (0.9391)  acc1: 81.7708 (81.5341)  acc5: 94.7917 (93.8447)  time: 0.1725  data: 0.1420  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0043 (1.0100)  acc1: 80.7292 (80.1091)  acc5: 94.2708 (93.0308)  time: 0.1211  data: 0.0906  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1247 (1.0648)  acc1: 76.5625 (79.1835)  acc5: 92.1875 (92.5571)  time: 0.1252  data: 0.0948  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2158 (1.1110)  acc1: 75.5208 (78.1885)  acc5: 90.6250 (91.9970)  time: 0.1259  data: 0.0954  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0959 (1.1116)  acc1: 77.0833 (77.9412)  acc5: 92.1875 (92.1467)  time: 0.1251  data: 0.0947  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1444 (1.1199)  acc1: 75.0000 (77.8200)  acc5: 92.7083 (92.1900)  time: 0.1054  data: 0.0759  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1321 s / it)\n",
            "* Acc@1 77.820 Acc@5 92.190 loss 1.120\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.82%\n",
            "[alpha-schedule=cosine] epoch=59 distillation_alpha=0.4985\n",
            "Epoch: [59]  [  0/781]  eta: 0:15:07  lr: 0.000022  loss: 1.3331 (1.3331)  time: 1.1620  data: 0.8178  max mem: 6459\n",
            "Epoch: [59]  [ 10/781]  eta: 0:05:14  lr: 0.000022  loss: 1.3258 (1.3945)  time: 0.4073  data: 0.0747  max mem: 6459\n",
            "Epoch: [59]  [ 20/781]  eta: 0:04:42  lr: 0.000022  loss: 1.3258 (1.4232)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [ 30/781]  eta: 0:04:29  lr: 0.000022  loss: 1.3505 (1.4753)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 40/781]  eta: 0:04:20  lr: 0.000022  loss: 1.3284 (1.4737)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 50/781]  eta: 0:04:14  lr: 0.000022  loss: 1.3228 (1.4904)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 60/781]  eta: 0:04:09  lr: 0.000022  loss: 1.2850 (1.4629)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 70/781]  eta: 0:04:04  lr: 0.000022  loss: 1.2757 (1.4433)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 80/781]  eta: 0:03:59  lr: 0.000022  loss: 1.3418 (1.4406)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [ 90/781]  eta: 0:03:55  lr: 0.000022  loss: 1.3172 (1.4270)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [100/781]  eta: 0:03:51  lr: 0.000022  loss: 1.3236 (1.4439)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [110/781]  eta: 0:03:47  lr: 0.000022  loss: 1.3298 (1.4390)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [120/781]  eta: 0:03:43  lr: 0.000022  loss: 1.3173 (1.4394)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [130/781]  eta: 0:03:40  lr: 0.000022  loss: 1.3069 (1.4302)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [140/781]  eta: 0:03:36  lr: 0.000022  loss: 1.2821 (1.4220)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [150/781]  eta: 0:03:32  lr: 0.000022  loss: 1.3116 (1.4164)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [160/781]  eta: 0:03:29  lr: 0.000022  loss: 1.3317 (1.4175)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [170/781]  eta: 0:03:25  lr: 0.000022  loss: 1.3361 (1.4212)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [180/781]  eta: 0:03:22  lr: 0.000022  loss: 1.3270 (1.4179)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [190/781]  eta: 0:03:18  lr: 0.000022  loss: 1.2891 (1.4143)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [200/781]  eta: 0:03:15  lr: 0.000022  loss: 1.2891 (1.4194)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [210/781]  eta: 0:03:11  lr: 0.000022  loss: 1.3296 (1.4185)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [220/781]  eta: 0:03:08  lr: 0.000022  loss: 1.2984 (1.4151)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [230/781]  eta: 0:03:04  lr: 0.000022  loss: 1.2987 (1.4160)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [240/781]  eta: 0:03:01  lr: 0.000022  loss: 1.3100 (1.4131)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [250/781]  eta: 0:02:57  lr: 0.000022  loss: 1.3120 (1.4137)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [260/781]  eta: 0:02:54  lr: 0.000022  loss: 1.3188 (1.4133)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [270/781]  eta: 0:02:51  lr: 0.000022  loss: 1.3629 (1.4305)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [280/781]  eta: 0:02:47  lr: 0.000022  loss: 1.3352 (1.4259)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [290/781]  eta: 0:02:44  lr: 0.000022  loss: 1.3112 (1.4240)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [300/781]  eta: 0:02:40  lr: 0.000022  loss: 1.3160 (1.4292)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [310/781]  eta: 0:02:37  lr: 0.000022  loss: 1.3566 (1.4321)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [320/781]  eta: 0:02:34  lr: 0.000022  loss: 1.3566 (1.4334)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [330/781]  eta: 0:02:30  lr: 0.000022  loss: 1.2948 (1.4346)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [340/781]  eta: 0:02:27  lr: 0.000022  loss: 1.2970 (1.4370)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [350/781]  eta: 0:02:24  lr: 0.000022  loss: 1.3201 (1.4402)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [360/781]  eta: 0:02:20  lr: 0.000022  loss: 1.3201 (1.4376)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [370/781]  eta: 0:02:17  lr: 0.000022  loss: 1.3122 (1.4388)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [380/781]  eta: 0:02:13  lr: 0.000022  loss: 1.2882 (1.4379)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [390/781]  eta: 0:02:10  lr: 0.000022  loss: 1.2940 (1.4395)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [400/781]  eta: 0:02:07  lr: 0.000022  loss: 1.3098 (1.4388)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [410/781]  eta: 0:02:03  lr: 0.000022  loss: 1.3237 (1.4366)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [420/781]  eta: 0:02:00  lr: 0.000022  loss: 1.3265 (1.4343)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [430/781]  eta: 0:01:57  lr: 0.000022  loss: 1.3081 (1.4334)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [440/781]  eta: 0:01:53  lr: 0.000022  loss: 1.2912 (1.4349)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [450/781]  eta: 0:01:50  lr: 0.000022  loss: 1.3520 (1.4418)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [460/781]  eta: 0:01:47  lr: 0.000022  loss: 1.3238 (1.4408)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [470/781]  eta: 0:01:43  lr: 0.000022  loss: 1.2774 (1.4434)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [480/781]  eta: 0:01:40  lr: 0.000022  loss: 1.3414 (1.4460)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [490/781]  eta: 0:01:37  lr: 0.000022  loss: 1.3407 (1.4458)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [500/781]  eta: 0:01:33  lr: 0.000022  loss: 1.3222 (1.4457)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [510/781]  eta: 0:01:30  lr: 0.000022  loss: 1.3358 (1.4476)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [520/781]  eta: 0:01:27  lr: 0.000022  loss: 1.3491 (1.4499)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [530/781]  eta: 0:01:23  lr: 0.000022  loss: 1.3110 (1.4475)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [540/781]  eta: 0:01:20  lr: 0.000022  loss: 1.2892 (1.4494)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [550/781]  eta: 0:01:16  lr: 0.000022  loss: 1.3350 (1.4480)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [560/781]  eta: 0:01:13  lr: 0.000022  loss: 1.2940 (1.4495)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [570/781]  eta: 0:01:10  lr: 0.000022  loss: 1.3198 (1.4492)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [580/781]  eta: 0:01:06  lr: 0.000022  loss: 1.3338 (1.4518)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [590/781]  eta: 0:01:03  lr: 0.000022  loss: 1.3848 (1.4522)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [600/781]  eta: 0:01:00  lr: 0.000022  loss: 1.2931 (1.4496)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [610/781]  eta: 0:00:56  lr: 0.000022  loss: 1.2970 (1.4502)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [620/781]  eta: 0:00:53  lr: 0.000022  loss: 1.3220 (1.4479)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [630/781]  eta: 0:00:50  lr: 0.000022  loss: 1.2970 (1.4455)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [640/781]  eta: 0:00:46  lr: 0.000022  loss: 1.3244 (1.4470)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [650/781]  eta: 0:00:43  lr: 0.000022  loss: 1.2918 (1.4443)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [660/781]  eta: 0:00:40  lr: 0.000022  loss: 1.2617 (1.4436)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [670/781]  eta: 0:00:37  lr: 0.000022  loss: 1.2959 (1.4455)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [680/781]  eta: 0:00:33  lr: 0.000022  loss: 1.3325 (1.4499)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [690/781]  eta: 0:00:30  lr: 0.000022  loss: 1.3246 (1.4486)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [700/781]  eta: 0:00:27  lr: 0.000022  loss: 1.3206 (1.4472)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [710/781]  eta: 0:00:23  lr: 0.000022  loss: 1.2884 (1.4449)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [720/781]  eta: 0:00:20  lr: 0.000022  loss: 1.2884 (1.4457)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [730/781]  eta: 0:00:16  lr: 0.000022  loss: 1.2919 (1.4447)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [740/781]  eta: 0:00:13  lr: 0.000022  loss: 1.3202 (1.4453)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [750/781]  eta: 0:00:10  lr: 0.000022  loss: 1.3327 (1.4437)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [760/781]  eta: 0:00:06  lr: 0.000022  loss: 1.2877 (1.4417)  time: 0.3316  data: 0.0004  max mem: 6459\n",
            "Epoch: [59]  [770/781]  eta: 0:00:03  lr: 0.000022  loss: 1.3213 (1.4425)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [780/781]  eta: 0:00:00  lr: 0.000022  loss: 1.3787 (1.4438)  time: 0.3323  data: 0.0006  max mem: 6459\n",
            "Epoch: [59] Total time: 0:04:20 (0.3334 s / it)\n",
            "Averaged stats: lr: 0.000022  loss: 1.3787 (1.4438)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32913196086883545, 'lambda_convnext_base': 0.25886934995651245, 'lambda_tf_efficientnetv2_l': 0.4119984805583954}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7321 (0.7321)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8185  data: 0.7878  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9022 (0.9610)  acc1: 82.8125 (81.2974)  acc5: 93.7500 (93.7027)  time: 0.1646  data: 0.1341  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 0.9908 (1.0186)  acc1: 79.1667 (80.0099)  acc5: 93.7500 (92.9564)  time: 0.1130  data: 0.0826  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2169 (1.0828)  acc1: 76.5625 (78.9819)  acc5: 91.6667 (92.5403)  time: 0.1117  data: 0.0812  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2452 (1.1254)  acc1: 76.0417 (78.1504)  acc5: 91.1458 (92.1113)  time: 0.1130  data: 0.0825  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0717 (1.1197)  acc1: 76.5625 (77.8391)  acc5: 92.1875 (92.3611)  time: 0.1145  data: 0.0839  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1276 (1.1331)  acc1: 76.0417 (77.7400)  acc5: 92.7083 (92.3800)  time: 0.1026  data: 0.0729  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1234 s / it)\n",
            "* Acc@1 77.740 Acc@5 92.380 loss 1.133\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.82%\n",
            "[alpha-schedule=cosine] epoch=60 distillation_alpha=0.5059\n",
            "Epoch: [60]  [  0/781]  eta: 0:15:31  lr: 0.000021  loss: 1.3698 (1.3698)  time: 1.1926  data: 0.8542  max mem: 6459\n",
            "Epoch: [60]  [ 10/781]  eta: 0:05:15  lr: 0.000021  loss: 1.2972 (1.2942)  time: 0.4099  data: 0.0780  max mem: 6459\n",
            "Epoch: [60]  [ 20/781]  eta: 0:04:43  lr: 0.000021  loss: 1.2730 (1.3436)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 30/781]  eta: 0:04:29  lr: 0.000021  loss: 1.2689 (1.3467)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 40/781]  eta: 0:04:21  lr: 0.000021  loss: 1.2711 (1.3893)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 50/781]  eta: 0:04:14  lr: 0.000021  loss: 1.3075 (1.3842)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 60/781]  eta: 0:04:09  lr: 0.000021  loss: 1.2720 (1.3639)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 70/781]  eta: 0:04:04  lr: 0.000021  loss: 1.2644 (1.3633)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 80/781]  eta: 0:03:59  lr: 0.000021  loss: 1.3099 (1.3991)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 90/781]  eta: 0:03:55  lr: 0.000021  loss: 1.3238 (1.3965)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [100/781]  eta: 0:03:51  lr: 0.000021  loss: 1.3324 (1.3900)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [110/781]  eta: 0:03:47  lr: 0.000021  loss: 1.3138 (1.3907)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [120/781]  eta: 0:03:43  lr: 0.000021  loss: 1.2766 (1.3873)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [130/781]  eta: 0:03:40  lr: 0.000021  loss: 1.3068 (1.3935)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [140/781]  eta: 0:03:36  lr: 0.000021  loss: 1.3296 (1.3916)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [150/781]  eta: 0:03:32  lr: 0.000021  loss: 1.3389 (1.3989)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [160/781]  eta: 0:03:29  lr: 0.000021  loss: 1.2828 (1.3933)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [170/781]  eta: 0:03:25  lr: 0.000021  loss: 1.2828 (1.3929)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [180/781]  eta: 0:03:22  lr: 0.000021  loss: 1.3058 (1.3948)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [190/781]  eta: 0:03:18  lr: 0.000021  loss: 1.3099 (1.3967)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [200/781]  eta: 0:03:15  lr: 0.000021  loss: 1.3211 (1.3927)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [210/781]  eta: 0:03:11  lr: 0.000021  loss: 1.3097 (1.3915)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [220/781]  eta: 0:03:08  lr: 0.000021  loss: 1.2851 (1.3871)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [230/781]  eta: 0:03:04  lr: 0.000021  loss: 1.2856 (1.3853)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [240/781]  eta: 0:03:01  lr: 0.000021  loss: 1.2935 (1.3859)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [250/781]  eta: 0:02:57  lr: 0.000021  loss: 1.2987 (1.3842)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [260/781]  eta: 0:02:54  lr: 0.000021  loss: 1.2835 (1.3803)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [270/781]  eta: 0:02:51  lr: 0.000021  loss: 1.2937 (1.3887)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [280/781]  eta: 0:02:47  lr: 0.000021  loss: 1.3548 (1.3966)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [290/781]  eta: 0:02:44  lr: 0.000021  loss: 1.3277 (1.3929)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [300/781]  eta: 0:02:40  lr: 0.000021  loss: 1.2512 (1.3928)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [310/781]  eta: 0:02:37  lr: 0.000021  loss: 1.2497 (1.3884)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [320/781]  eta: 0:02:34  lr: 0.000021  loss: 1.2975 (1.3888)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [330/781]  eta: 0:02:30  lr: 0.000021  loss: 1.3172 (1.3877)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [340/781]  eta: 0:02:27  lr: 0.000021  loss: 1.2967 (1.3877)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [350/781]  eta: 0:02:23  lr: 0.000021  loss: 1.2865 (1.3927)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [360/781]  eta: 0:02:20  lr: 0.000021  loss: 1.2913 (1.3931)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [370/781]  eta: 0:02:17  lr: 0.000021  loss: 1.3035 (1.3991)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [380/781]  eta: 0:02:13  lr: 0.000021  loss: 1.3645 (1.4005)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [390/781]  eta: 0:02:10  lr: 0.000021  loss: 1.3645 (1.4092)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [400/781]  eta: 0:02:07  lr: 0.000021  loss: 1.4322 (1.4124)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [410/781]  eta: 0:02:03  lr: 0.000021  loss: 1.3777 (1.4184)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [420/781]  eta: 0:02:00  lr: 0.000021  loss: 1.3245 (1.4171)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [430/781]  eta: 0:01:57  lr: 0.000021  loss: 1.3050 (1.4162)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [440/781]  eta: 0:01:53  lr: 0.000021  loss: 1.3112 (1.4204)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [450/781]  eta: 0:01:50  lr: 0.000021  loss: 1.3432 (1.4215)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [460/781]  eta: 0:01:47  lr: 0.000021  loss: 1.2993 (1.4233)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [470/781]  eta: 0:01:43  lr: 0.000021  loss: 1.2953 (1.4212)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [480/781]  eta: 0:01:40  lr: 0.000021  loss: 1.3112 (1.4200)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [490/781]  eta: 0:01:37  lr: 0.000021  loss: 1.3564 (1.4256)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [500/781]  eta: 0:01:33  lr: 0.000021  loss: 1.3751 (1.4257)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [510/781]  eta: 0:01:30  lr: 0.000021  loss: 1.3392 (1.4246)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [520/781]  eta: 0:01:26  lr: 0.000021  loss: 1.3312 (1.4246)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [530/781]  eta: 0:01:23  lr: 0.000021  loss: 1.3042 (1.4245)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [540/781]  eta: 0:01:20  lr: 0.000021  loss: 1.3012 (1.4246)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [550/781]  eta: 0:01:16  lr: 0.000021  loss: 1.3011 (1.4257)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [560/781]  eta: 0:01:13  lr: 0.000021  loss: 1.2639 (1.4251)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [570/781]  eta: 0:01:10  lr: 0.000021  loss: 1.3093 (1.4272)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [580/781]  eta: 0:01:06  lr: 0.000021  loss: 1.3288 (1.4277)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [590/781]  eta: 0:01:03  lr: 0.000021  loss: 1.3472 (1.4337)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [600/781]  eta: 0:01:00  lr: 0.000021  loss: 1.3547 (1.4362)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [610/781]  eta: 0:00:56  lr: 0.000021  loss: 1.3363 (1.4350)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [620/781]  eta: 0:00:53  lr: 0.000021  loss: 1.2945 (1.4346)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [630/781]  eta: 0:00:50  lr: 0.000021  loss: 1.3106 (1.4368)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [640/781]  eta: 0:00:46  lr: 0.000021  loss: 1.3659 (1.4392)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [650/781]  eta: 0:00:43  lr: 0.000021  loss: 1.3659 (1.4392)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [660/781]  eta: 0:00:40  lr: 0.000021  loss: 1.3558 (1.4392)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [670/781]  eta: 0:00:36  lr: 0.000021  loss: 1.3558 (1.4408)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [60]  [680/781]  eta: 0:00:33  lr: 0.000021  loss: 1.3438 (1.4397)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [60]  [690/781]  eta: 0:00:30  lr: 0.000021  loss: 1.3058 (1.4375)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [700/781]  eta: 0:00:26  lr: 0.000021  loss: 1.2921 (1.4378)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [710/781]  eta: 0:00:23  lr: 0.000021  loss: 1.2775 (1.4372)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [60]  [720/781]  eta: 0:00:20  lr: 0.000021  loss: 1.2955 (1.4375)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [60]  [730/781]  eta: 0:00:16  lr: 0.000021  loss: 1.3399 (1.4381)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [740/781]  eta: 0:00:13  lr: 0.000021  loss: 1.3382 (1.4369)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [750/781]  eta: 0:00:10  lr: 0.000021  loss: 1.3549 (1.4372)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [760/781]  eta: 0:00:06  lr: 0.000021  loss: 1.3834 (1.4388)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [770/781]  eta: 0:00:03  lr: 0.000021  loss: 1.3496 (1.4397)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [780/781]  eta: 0:00:00  lr: 0.000021  loss: 1.3198 (1.4408)  time: 0.3322  data: 0.0006  max mem: 6459\n",
            "Epoch: [60] Total time: 0:04:19 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000021  loss: 1.3198 (1.4408)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32863035798072815, 'lambda_convnext_base': 0.2592189908027649, 'lambda_tf_efficientnetv2_l': 0.41215068101882935}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8437 (0.8437)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 0.8488  data: 0.8180  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9251 (0.9435)  acc1: 83.3333 (81.3447)  acc5: 93.7500 (93.8920)  time: 0.1831  data: 0.1526  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9532 (1.0386)  acc1: 80.2083 (79.5635)  acc5: 93.2292 (92.7579)  time: 0.1307  data: 0.1002  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1705 (1.0866)  acc1: 76.5625 (78.9819)  acc5: 92.1875 (92.2715)  time: 0.1361  data: 0.1056  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2534 (1.1243)  acc1: 76.5625 (78.1250)  acc5: 91.1458 (91.8699)  time: 0.1349  data: 0.1035  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0939 (1.1240)  acc1: 76.5625 (77.8186)  acc5: 92.1875 (92.1467)  time: 0.1369  data: 0.1037  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1274 (1.1354)  acc1: 76.0417 (77.6900)  acc5: 93.2292 (92.1700)  time: 0.1229  data: 0.0903  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1430 s / it)\n",
            "* Acc@1 77.690 Acc@5 92.170 loss 1.135\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.82%\n",
            "[alpha-schedule=cosine] epoch=61 distillation_alpha=0.5131\n",
            "Epoch: [61]  [  0/781]  eta: 0:15:18  lr: 0.000020  loss: 1.3133 (1.3133)  time: 1.1765  data: 0.8241  max mem: 6459\n",
            "Epoch: [61]  [ 10/781]  eta: 0:05:14  lr: 0.000020  loss: 1.2834 (1.4554)  time: 0.4084  data: 0.0752  max mem: 6459\n",
            "Epoch: [61]  [ 20/781]  eta: 0:04:42  lr: 0.000020  loss: 1.2834 (1.4337)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 30/781]  eta: 0:04:29  lr: 0.000020  loss: 1.3256 (1.4274)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 40/781]  eta: 0:04:20  lr: 0.000020  loss: 1.3195 (1.4235)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 50/781]  eta: 0:04:14  lr: 0.000020  loss: 1.3251 (1.4567)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 60/781]  eta: 0:04:09  lr: 0.000020  loss: 1.2891 (1.4337)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 70/781]  eta: 0:04:04  lr: 0.000020  loss: 1.2625 (1.4434)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 80/781]  eta: 0:03:59  lr: 0.000020  loss: 1.2825 (1.4448)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 90/781]  eta: 0:03:55  lr: 0.000020  loss: 1.3009 (1.4460)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [100/781]  eta: 0:03:51  lr: 0.000020  loss: 1.3179 (1.4437)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [110/781]  eta: 0:03:47  lr: 0.000020  loss: 1.3654 (1.4497)  time: 0.3315  data: 0.0004  max mem: 6459\n",
            "Epoch: [61]  [120/781]  eta: 0:03:43  lr: 0.000020  loss: 1.3633 (1.4612)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [130/781]  eta: 0:03:40  lr: 0.000020  loss: 1.3057 (1.4528)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [140/781]  eta: 0:03:36  lr: 0.000020  loss: 1.3416 (1.4558)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [150/781]  eta: 0:03:32  lr: 0.000020  loss: 1.3270 (1.4435)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [160/781]  eta: 0:03:29  lr: 0.000020  loss: 1.3434 (1.4559)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [170/781]  eta: 0:03:25  lr: 0.000020  loss: 1.3616 (1.4542)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [180/781]  eta: 0:03:22  lr: 0.000020  loss: 1.3158 (1.4576)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [190/781]  eta: 0:03:18  lr: 0.000020  loss: 1.3004 (1.4480)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [200/781]  eta: 0:03:15  lr: 0.000020  loss: 1.2893 (1.4553)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [210/781]  eta: 0:03:11  lr: 0.000020  loss: 1.3256 (1.4531)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [220/781]  eta: 0:03:08  lr: 0.000020  loss: 1.3256 (1.4565)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [230/781]  eta: 0:03:04  lr: 0.000020  loss: 1.3447 (1.4524)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [240/781]  eta: 0:03:01  lr: 0.000020  loss: 1.3447 (1.4545)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [250/781]  eta: 0:02:57  lr: 0.000020  loss: 1.3437 (1.4535)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [260/781]  eta: 0:02:54  lr: 0.000020  loss: 1.2912 (1.4551)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [270/781]  eta: 0:02:51  lr: 0.000020  loss: 1.3209 (1.4508)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [280/781]  eta: 0:02:47  lr: 0.000020  loss: 1.3034 (1.4449)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [290/781]  eta: 0:02:44  lr: 0.000020  loss: 1.3048 (1.4470)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [300/781]  eta: 0:02:40  lr: 0.000020  loss: 1.3333 (1.4504)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [310/781]  eta: 0:02:37  lr: 0.000020  loss: 1.3125 (1.4474)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [320/781]  eta: 0:02:34  lr: 0.000020  loss: 1.3307 (1.4485)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [330/781]  eta: 0:02:30  lr: 0.000020  loss: 1.3307 (1.4468)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [340/781]  eta: 0:02:27  lr: 0.000020  loss: 1.2753 (1.4466)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [350/781]  eta: 0:02:23  lr: 0.000020  loss: 1.3371 (1.4471)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [360/781]  eta: 0:02:20  lr: 0.000020  loss: 1.3266 (1.4515)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [370/781]  eta: 0:02:17  lr: 0.000020  loss: 1.3253 (1.4524)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [380/781]  eta: 0:02:13  lr: 0.000020  loss: 1.2960 (1.4529)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [390/781]  eta: 0:02:10  lr: 0.000020  loss: 1.2686 (1.4482)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.2486 (1.4444)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [410/781]  eta: 0:02:03  lr: 0.000020  loss: 1.2910 (1.4419)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [420/781]  eta: 0:02:00  lr: 0.000020  loss: 1.2910 (1.4388)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.3082 (1.4385)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [440/781]  eta: 0:01:53  lr: 0.000020  loss: 1.3229 (1.4373)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [450/781]  eta: 0:01:50  lr: 0.000020  loss: 1.3209 (1.4384)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.3584 (1.4404)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [470/781]  eta: 0:01:43  lr: 0.000020  loss: 1.3205 (1.4382)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.2436 (1.4343)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.2574 (1.4362)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [500/781]  eta: 0:01:33  lr: 0.000020  loss: 1.3416 (1.4370)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.3089 (1.4386)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [520/781]  eta: 0:01:26  lr: 0.000020  loss: 1.3228 (1.4413)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [530/781]  eta: 0:01:23  lr: 0.000020  loss: 1.5024 (1.4484)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.3802 (1.4481)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [550/781]  eta: 0:01:16  lr: 0.000020  loss: 1.3070 (1.4469)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [560/781]  eta: 0:01:13  lr: 0.000020  loss: 1.3365 (1.4489)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.3396 (1.4489)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [580/781]  eta: 0:01:06  lr: 0.000020  loss: 1.3322 (1.4498)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.3320 (1.4485)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.3338 (1.4515)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [610/781]  eta: 0:00:56  lr: 0.000020  loss: 1.3885 (1.4522)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.3457 (1.4514)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.3581 (1.4546)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [640/781]  eta: 0:00:46  lr: 0.000020  loss: 1.3428 (1.4555)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.3379 (1.4573)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.2827 (1.4553)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [670/781]  eta: 0:00:36  lr: 0.000020  loss: 1.2929 (1.4589)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.3069 (1.4591)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3010 (1.4581)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [700/781]  eta: 0:00:26  lr: 0.000020  loss: 1.2848 (1.4561)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.2930 (1.4595)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.3238 (1.4598)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [730/781]  eta: 0:00:16  lr: 0.000020  loss: 1.2925 (1.4574)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.3234 (1.4582)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.3652 (1.4608)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [760/781]  eta: 0:00:06  lr: 0.000020  loss: 1.4326 (1.4636)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.3251 (1.4629)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.2802 (1.4635)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [61] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.2802 (1.4635)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3281601369380951, 'lambda_convnext_base': 0.2599789798259735, 'lambda_tf_efficientnetv2_l': 0.41186070442199707}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8335 (0.8335)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8401  data: 0.8095  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9057 (0.9667)  acc1: 83.3333 (81.2500)  acc5: 95.3125 (94.0814)  time: 0.1663  data: 0.1358  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9729 (1.0197)  acc1: 79.1667 (80.0099)  acc5: 93.7500 (92.9812)  time: 0.1187  data: 0.0883  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1854 (1.0812)  acc1: 76.0417 (78.7130)  acc5: 91.6667 (92.4227)  time: 0.1189  data: 0.0885  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2642 (1.1204)  acc1: 73.9583 (77.8582)  acc5: 90.6250 (91.9334)  time: 0.1181  data: 0.0877  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1078 (1.1120)  acc1: 75.5208 (77.7369)  acc5: 92.7083 (92.1671)  time: 0.1190  data: 0.0885  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1164 (1.1274)  acc1: 74.4792 (77.5900)  acc5: 92.7083 (92.2000)  time: 0.1029  data: 0.0733  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1264 s / it)\n",
            "* Acc@1 77.590 Acc@5 92.200 loss 1.127\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.82%\n",
            "[alpha-schedule=cosine] epoch=62 distillation_alpha=0.5200\n",
            "Epoch: [62]  [  0/781]  eta: 0:14:12  lr: 0.000020  loss: 1.2020 (1.2020)  time: 1.0915  data: 0.7465  max mem: 6459\n",
            "Epoch: [62]  [ 10/781]  eta: 0:05:09  lr: 0.000020  loss: 1.3422 (1.3555)  time: 0.4010  data: 0.0682  max mem: 6459\n",
            "Epoch: [62]  [ 20/781]  eta: 0:04:40  lr: 0.000020  loss: 1.3051 (1.3437)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 30/781]  eta: 0:04:27  lr: 0.000020  loss: 1.2431 (1.3478)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 40/781]  eta: 0:04:19  lr: 0.000020  loss: 1.2931 (1.3794)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 50/781]  eta: 0:04:13  lr: 0.000020  loss: 1.3599 (1.4517)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 60/781]  eta: 0:04:08  lr: 0.000020  loss: 1.2829 (1.4483)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 70/781]  eta: 0:04:03  lr: 0.000020  loss: 1.2955 (1.4596)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 80/781]  eta: 0:03:59  lr: 0.000020  loss: 1.3170 (1.4539)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 90/781]  eta: 0:03:54  lr: 0.000020  loss: 1.3262 (1.4789)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [100/781]  eta: 0:03:50  lr: 0.000020  loss: 1.3592 (1.4792)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [110/781]  eta: 0:03:47  lr: 0.000020  loss: 1.3473 (1.4763)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [120/781]  eta: 0:03:43  lr: 0.000020  loss: 1.3398 (1.4850)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [130/781]  eta: 0:03:39  lr: 0.000020  loss: 1.3238 (1.4822)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [140/781]  eta: 0:03:36  lr: 0.000020  loss: 1.3021 (1.4772)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [150/781]  eta: 0:03:32  lr: 0.000020  loss: 1.3030 (1.4752)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [160/781]  eta: 0:03:28  lr: 0.000020  loss: 1.3378 (1.4856)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [170/781]  eta: 0:03:25  lr: 0.000020  loss: 1.3236 (1.4850)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [180/781]  eta: 0:03:21  lr: 0.000020  loss: 1.2814 (1.4728)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [190/781]  eta: 0:03:18  lr: 0.000020  loss: 1.2697 (1.4675)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [200/781]  eta: 0:03:14  lr: 0.000020  loss: 1.3021 (1.4662)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [210/781]  eta: 0:03:11  lr: 0.000020  loss: 1.3116 (1.4652)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [220/781]  eta: 0:03:07  lr: 0.000020  loss: 1.2843 (1.4578)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [230/781]  eta: 0:03:04  lr: 0.000020  loss: 1.2801 (1.4564)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [240/781]  eta: 0:03:01  lr: 0.000020  loss: 1.3469 (1.4523)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [250/781]  eta: 0:02:57  lr: 0.000020  loss: 1.2954 (1.4445)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [260/781]  eta: 0:02:54  lr: 0.000020  loss: 1.2612 (1.4451)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [270/781]  eta: 0:02:50  lr: 0.000020  loss: 1.2675 (1.4443)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [280/781]  eta: 0:02:47  lr: 0.000020  loss: 1.3469 (1.4456)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [290/781]  eta: 0:02:44  lr: 0.000020  loss: 1.3175 (1.4447)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [300/781]  eta: 0:02:40  lr: 0.000020  loss: 1.3053 (1.4416)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [310/781]  eta: 0:02:37  lr: 0.000020  loss: 1.3200 (1.4409)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [320/781]  eta: 0:02:33  lr: 0.000020  loss: 1.3165 (1.4362)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [330/781]  eta: 0:02:30  lr: 0.000020  loss: 1.3240 (1.4378)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [340/781]  eta: 0:02:27  lr: 0.000020  loss: 1.3285 (1.4363)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [350/781]  eta: 0:02:23  lr: 0.000020  loss: 1.3268 (1.4444)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [360/781]  eta: 0:02:20  lr: 0.000020  loss: 1.3268 (1.4454)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [370/781]  eta: 0:02:17  lr: 0.000020  loss: 1.3388 (1.4446)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [380/781]  eta: 0:02:13  lr: 0.000020  loss: 1.3435 (1.4422)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [390/781]  eta: 0:02:10  lr: 0.000020  loss: 1.3309 (1.4486)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.3251 (1.4453)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [410/781]  eta: 0:02:03  lr: 0.000020  loss: 1.3419 (1.4465)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [420/781]  eta: 0:02:00  lr: 0.000020  loss: 1.2912 (1.4421)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.3005 (1.4469)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [440/781]  eta: 0:01:53  lr: 0.000020  loss: 1.3364 (1.4447)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [450/781]  eta: 0:01:50  lr: 0.000020  loss: 1.3000 (1.4418)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.2894 (1.4381)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [470/781]  eta: 0:01:43  lr: 0.000020  loss: 1.3050 (1.4384)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.3740 (1.4426)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.3913 (1.4458)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [500/781]  eta: 0:01:33  lr: 0.000020  loss: 1.2933 (1.4465)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.2929 (1.4485)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [62]  [520/781]  eta: 0:01:27  lr: 0.000020  loss: 1.3252 (1.4489)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [530/781]  eta: 0:01:23  lr: 0.000020  loss: 1.3512 (1.4523)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.3505 (1.4515)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [550/781]  eta: 0:01:17  lr: 0.000020  loss: 1.3248 (1.4492)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [560/781]  eta: 0:01:13  lr: 0.000020  loss: 1.2786 (1.4469)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.2596 (1.4445)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [580/781]  eta: 0:01:07  lr: 0.000020  loss: 1.2596 (1.4419)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.3119 (1.4451)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.3106 (1.4427)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [610/781]  eta: 0:00:56  lr: 0.000020  loss: 1.2932 (1.4408)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.3064 (1.4386)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.3064 (1.4383)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [640/781]  eta: 0:00:46  lr: 0.000020  loss: 1.2989 (1.4387)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.3337 (1.4395)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.3345 (1.4396)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [670/781]  eta: 0:00:36  lr: 0.000020  loss: 1.3331 (1.4395)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.2952 (1.4397)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3190 (1.4396)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [700/781]  eta: 0:00:26  lr: 0.000020  loss: 1.3120 (1.4381)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.3023 (1.4367)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.3177 (1.4351)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [730/781]  eta: 0:00:16  lr: 0.000020  loss: 1.2858 (1.4349)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.2894 (1.4331)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.3230 (1.4383)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [760/781]  eta: 0:00:06  lr: 0.000020  loss: 1.3567 (1.4406)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.2838 (1.4399)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.2679 (1.4388)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [62] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.2679 (1.4388)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3291584849357605, 'lambda_convnext_base': 0.25995033979415894, 'lambda_tf_efficientnetv2_l': 0.4108909070491791}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7986 (0.7986)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 0.8618  data: 0.8311  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8866 (0.9441)  acc1: 82.2917 (81.0606)  acc5: 94.2708 (93.7500)  time: 0.1783  data: 0.1478  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9887 (1.0077)  acc1: 80.2083 (80.0595)  acc5: 93.7500 (92.9564)  time: 0.1361  data: 0.1056  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1515 (1.0679)  acc1: 76.5625 (79.0827)  acc5: 91.6667 (92.4731)  time: 0.1354  data: 0.1050  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1964 (1.1119)  acc1: 76.5625 (78.2012)  acc5: 91.1458 (91.9970)  time: 0.1344  data: 0.1040  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1277 (1.1097)  acc1: 78.1250 (78.0433)  acc5: 91.6667 (92.1569)  time: 0.1386  data: 0.1081  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1529 (1.1175)  acc1: 75.0000 (77.9300)  acc5: 92.1875 (92.2100)  time: 0.1173  data: 0.0877  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1421 s / it)\n",
            "* Acc@1 77.930 Acc@5 92.210 loss 1.118\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.93%\n",
            "[alpha-schedule=cosine] epoch=63 distillation_alpha=0.5268\n",
            "Epoch: [63]  [  0/781]  eta: 0:15:07  lr: 0.000019  loss: 2.4708 (2.4708)  time: 1.1621  data: 0.8083  max mem: 6459\n",
            "Epoch: [63]  [ 10/781]  eta: 0:05:14  lr: 0.000019  loss: 1.2948 (1.5408)  time: 0.4075  data: 0.0738  max mem: 6459\n",
            "Epoch: [63]  [ 20/781]  eta: 0:04:42  lr: 0.000019  loss: 1.2881 (1.4390)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 30/781]  eta: 0:04:29  lr: 0.000019  loss: 1.2769 (1.4081)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 40/781]  eta: 0:04:20  lr: 0.000019  loss: 1.3334 (1.4192)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 50/781]  eta: 0:04:14  lr: 0.000019  loss: 1.3334 (1.4107)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 60/781]  eta: 0:04:08  lr: 0.000019  loss: 1.2873 (1.3937)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 70/781]  eta: 0:04:04  lr: 0.000019  loss: 1.2904 (1.3936)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 80/781]  eta: 0:03:59  lr: 0.000019  loss: 1.3295 (1.4006)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 90/781]  eta: 0:03:55  lr: 0.000019  loss: 1.3295 (1.4045)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [100/781]  eta: 0:03:51  lr: 0.000019  loss: 1.3072 (1.4148)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [110/781]  eta: 0:03:47  lr: 0.000019  loss: 1.2822 (1.4019)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [120/781]  eta: 0:03:43  lr: 0.000019  loss: 1.2994 (1.4159)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [130/781]  eta: 0:03:40  lr: 0.000019  loss: 1.3272 (1.4084)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [140/781]  eta: 0:03:36  lr: 0.000019  loss: 1.3109 (1.4076)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [150/781]  eta: 0:03:32  lr: 0.000019  loss: 1.2974 (1.4091)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [160/781]  eta: 0:03:29  lr: 0.000019  loss: 1.2620 (1.4095)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [170/781]  eta: 0:03:25  lr: 0.000019  loss: 1.2592 (1.4152)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [180/781]  eta: 0:03:22  lr: 0.000019  loss: 1.3341 (1.4212)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [190/781]  eta: 0:03:18  lr: 0.000019  loss: 1.3107 (1.4145)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [200/781]  eta: 0:03:15  lr: 0.000019  loss: 1.3107 (1.4149)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [210/781]  eta: 0:03:11  lr: 0.000019  loss: 1.2997 (1.4081)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [220/781]  eta: 0:03:08  lr: 0.000019  loss: 1.2708 (1.4083)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [230/781]  eta: 0:03:04  lr: 0.000019  loss: 1.3103 (1.4113)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [240/781]  eta: 0:03:01  lr: 0.000019  loss: 1.3685 (1.4140)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [250/781]  eta: 0:02:57  lr: 0.000019  loss: 1.3005 (1.4133)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [260/781]  eta: 0:02:54  lr: 0.000019  loss: 1.3323 (1.4136)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [270/781]  eta: 0:02:51  lr: 0.000019  loss: 1.3422 (1.4168)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [280/781]  eta: 0:02:47  lr: 0.000019  loss: 1.3078 (1.4162)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [290/781]  eta: 0:02:44  lr: 0.000019  loss: 1.2848 (1.4193)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [300/781]  eta: 0:02:40  lr: 0.000019  loss: 1.3408 (1.4182)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [310/781]  eta: 0:02:37  lr: 0.000019  loss: 1.3334 (1.4239)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [320/781]  eta: 0:02:34  lr: 0.000019  loss: 1.3267 (1.4228)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [330/781]  eta: 0:02:30  lr: 0.000019  loss: 1.3042 (1.4236)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [340/781]  eta: 0:02:27  lr: 0.000019  loss: 1.2966 (1.4270)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [350/781]  eta: 0:02:24  lr: 0.000019  loss: 1.2900 (1.4233)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [360/781]  eta: 0:02:20  lr: 0.000019  loss: 1.2854 (1.4245)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [370/781]  eta: 0:02:17  lr: 0.000019  loss: 1.2786 (1.4246)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [380/781]  eta: 0:02:13  lr: 0.000019  loss: 1.2896 (1.4249)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [390/781]  eta: 0:02:10  lr: 0.000019  loss: 1.2896 (1.4218)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [400/781]  eta: 0:02:07  lr: 0.000019  loss: 1.2547 (1.4178)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [410/781]  eta: 0:02:03  lr: 0.000019  loss: 1.2900 (1.4165)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [420/781]  eta: 0:02:00  lr: 0.000019  loss: 1.3285 (1.4141)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [430/781]  eta: 0:01:57  lr: 0.000019  loss: 1.2941 (1.4120)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [440/781]  eta: 0:01:53  lr: 0.000019  loss: 1.2796 (1.4084)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [450/781]  eta: 0:01:50  lr: 0.000019  loss: 1.2796 (1.4071)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [460/781]  eta: 0:01:47  lr: 0.000019  loss: 1.3263 (1.4054)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [470/781]  eta: 0:01:43  lr: 0.000019  loss: 1.3057 (1.4049)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [480/781]  eta: 0:01:40  lr: 0.000019  loss: 1.2676 (1.4053)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [490/781]  eta: 0:01:37  lr: 0.000019  loss: 1.2807 (1.4029)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [500/781]  eta: 0:01:33  lr: 0.000019  loss: 1.3001 (1.4014)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [510/781]  eta: 0:01:30  lr: 0.000019  loss: 1.3049 (1.4012)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [520/781]  eta: 0:01:27  lr: 0.000019  loss: 1.3243 (1.4055)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [530/781]  eta: 0:01:23  lr: 0.000019  loss: 1.3243 (1.4039)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [540/781]  eta: 0:01:20  lr: 0.000019  loss: 1.2731 (1.4016)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [550/781]  eta: 0:01:17  lr: 0.000019  loss: 1.2731 (1.3992)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [560/781]  eta: 0:01:13  lr: 0.000019  loss: 1.2836 (1.3974)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [570/781]  eta: 0:01:10  lr: 0.000019  loss: 1.3437 (1.3988)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [580/781]  eta: 0:01:06  lr: 0.000019  loss: 1.3377 (1.4002)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [590/781]  eta: 0:01:03  lr: 0.000019  loss: 1.3076 (1.4008)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [600/781]  eta: 0:01:00  lr: 0.000019  loss: 1.3076 (1.3996)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [610/781]  eta: 0:00:56  lr: 0.000019  loss: 1.3184 (1.4056)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [620/781]  eta: 0:00:53  lr: 0.000019  loss: 1.3731 (1.4077)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [630/781]  eta: 0:00:50  lr: 0.000019  loss: 1.3004 (1.4057)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [640/781]  eta: 0:00:46  lr: 0.000019  loss: 1.2671 (1.4089)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [650/781]  eta: 0:00:43  lr: 0.000019  loss: 1.2874 (1.4073)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [660/781]  eta: 0:00:40  lr: 0.000019  loss: 1.2981 (1.4077)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [670/781]  eta: 0:00:36  lr: 0.000019  loss: 1.3067 (1.4073)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [680/781]  eta: 0:00:33  lr: 0.000019  loss: 1.3067 (1.4080)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [690/781]  eta: 0:00:30  lr: 0.000019  loss: 1.3431 (1.4102)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [700/781]  eta: 0:00:26  lr: 0.000019  loss: 1.3497 (1.4099)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [710/781]  eta: 0:00:23  lr: 0.000019  loss: 1.3749 (1.4102)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [720/781]  eta: 0:00:20  lr: 0.000019  loss: 1.3598 (1.4126)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [730/781]  eta: 0:00:16  lr: 0.000019  loss: 1.2938 (1.4136)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [740/781]  eta: 0:00:13  lr: 0.000019  loss: 1.2938 (1.4140)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [750/781]  eta: 0:00:10  lr: 0.000019  loss: 1.3196 (1.4152)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [760/781]  eta: 0:00:06  lr: 0.000019  loss: 1.3126 (1.4138)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [770/781]  eta: 0:00:03  lr: 0.000019  loss: 1.3031 (1.4135)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [780/781]  eta: 0:00:00  lr: 0.000019  loss: 1.3147 (1.4155)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [63] Total time: 0:04:20 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000019  loss: 1.3147 (1.4155)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3292103409767151, 'lambda_convnext_base': 0.2592989504337311, 'lambda_tf_efficientnetv2_l': 0.4114908277988434}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8002 (0.8002)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 0.8352  data: 0.8029  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9753 (0.9435)  acc1: 83.3333 (81.2027)  acc5: 94.7917 (93.7974)  time: 0.1712  data: 0.1405  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9753 (1.0090)  acc1: 80.2083 (79.9355)  acc5: 93.7500 (93.0060)  time: 0.1226  data: 0.0921  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1584 (1.0643)  acc1: 76.5625 (79.0827)  acc5: 92.1875 (92.5067)  time: 0.1246  data: 0.0941  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2271 (1.1066)  acc1: 76.5625 (78.0996)  acc5: 91.1458 (92.1494)  time: 0.1231  data: 0.0926  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1078 (1.1026)  acc1: 76.0417 (77.9514)  acc5: 92.1875 (92.3407)  time: 0.1249  data: 0.0945  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1483 (1.1134)  acc1: 75.5208 (77.8200)  acc5: 92.1875 (92.3600)  time: 0.1093  data: 0.0797  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1314 s / it)\n",
            "* Acc@1 77.820 Acc@5 92.360 loss 1.113\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.93%\n",
            "[alpha-schedule=cosine] epoch=64 distillation_alpha=0.5333\n",
            "Epoch: [64]  [  0/781]  eta: 0:15:44  lr: 0.000018  loss: 1.4357 (1.4357)  time: 1.2094  data: 0.8639  max mem: 6459\n",
            "Epoch: [64]  [ 10/781]  eta: 0:05:17  lr: 0.000018  loss: 1.3117 (1.4114)  time: 0.4117  data: 0.0788  max mem: 6459\n",
            "Epoch: [64]  [ 20/781]  eta: 0:04:44  lr: 0.000018  loss: 1.2937 (1.3553)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 30/781]  eta: 0:04:30  lr: 0.000018  loss: 1.3098 (1.4264)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 40/781]  eta: 0:04:21  lr: 0.000018  loss: 1.3107 (1.3908)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 50/781]  eta: 0:04:15  lr: 0.000018  loss: 1.2806 (1.3883)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 60/781]  eta: 0:04:09  lr: 0.000018  loss: 1.2995 (1.4397)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 70/781]  eta: 0:04:04  lr: 0.000018  loss: 1.3290 (1.4450)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 80/781]  eta: 0:04:00  lr: 0.000018  loss: 1.3289 (1.4580)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 90/781]  eta: 0:03:55  lr: 0.000018  loss: 1.3599 (1.4893)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [100/781]  eta: 0:03:51  lr: 0.000018  loss: 1.3680 (1.4941)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [110/781]  eta: 0:03:47  lr: 0.000018  loss: 1.3297 (1.4888)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [120/781]  eta: 0:03:43  lr: 0.000018  loss: 1.2756 (1.4754)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [130/781]  eta: 0:03:40  lr: 0.000018  loss: 1.2756 (1.4643)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [140/781]  eta: 0:03:36  lr: 0.000018  loss: 1.2926 (1.4756)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [150/781]  eta: 0:03:32  lr: 0.000018  loss: 1.3065 (1.4685)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [160/781]  eta: 0:03:29  lr: 0.000018  loss: 1.2741 (1.4619)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [170/781]  eta: 0:03:25  lr: 0.000018  loss: 1.2731 (1.4544)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [180/781]  eta: 0:03:22  lr: 0.000018  loss: 1.2825 (1.4524)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [190/781]  eta: 0:03:18  lr: 0.000018  loss: 1.3319 (1.4583)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [200/781]  eta: 0:03:15  lr: 0.000018  loss: 1.2819 (1.4514)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [210/781]  eta: 0:03:11  lr: 0.000018  loss: 1.2628 (1.4502)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [220/781]  eta: 0:03:08  lr: 0.000018  loss: 1.2363 (1.4428)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [230/781]  eta: 0:03:04  lr: 0.000018  loss: 1.2470 (1.4404)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [240/781]  eta: 0:03:01  lr: 0.000018  loss: 1.3124 (1.4410)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [250/781]  eta: 0:02:57  lr: 0.000018  loss: 1.3124 (1.4417)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [260/781]  eta: 0:02:54  lr: 0.000018  loss: 1.2813 (1.4392)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.2696 (1.4374)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [280/781]  eta: 0:02:47  lr: 0.000018  loss: 1.2779 (1.4321)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [290/781]  eta: 0:02:44  lr: 0.000018  loss: 1.2734 (1.4321)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [300/781]  eta: 0:02:40  lr: 0.000018  loss: 1.3093 (1.4332)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [310/781]  eta: 0:02:37  lr: 0.000018  loss: 1.3473 (1.4352)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.3020 (1.4346)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [330/781]  eta: 0:02:30  lr: 0.000018  loss: 1.2797 (1.4323)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [340/781]  eta: 0:02:27  lr: 0.000018  loss: 1.2721 (1.4295)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [350/781]  eta: 0:02:23  lr: 0.000018  loss: 1.2721 (1.4283)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [360/781]  eta: 0:02:20  lr: 0.000018  loss: 1.2916 (1.4294)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [370/781]  eta: 0:02:17  lr: 0.000018  loss: 1.3267 (1.4283)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [380/781]  eta: 0:02:13  lr: 0.000018  loss: 1.3173 (1.4299)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [390/781]  eta: 0:02:10  lr: 0.000018  loss: 1.3173 (1.4314)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [400/781]  eta: 0:02:07  lr: 0.000018  loss: 1.3361 (1.4353)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [410/781]  eta: 0:02:03  lr: 0.000018  loss: 1.3758 (1.4383)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [420/781]  eta: 0:02:00  lr: 0.000018  loss: 1.3406 (1.4400)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.3406 (1.4431)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [440/781]  eta: 0:01:53  lr: 0.000018  loss: 1.3575 (1.4437)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [450/781]  eta: 0:01:50  lr: 0.000018  loss: 1.3014 (1.4413)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.3053 (1.4406)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [470/781]  eta: 0:01:43  lr: 0.000018  loss: 1.3158 (1.4430)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [480/781]  eta: 0:01:40  lr: 0.000018  loss: 1.3158 (1.4417)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.3805 (1.4480)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [500/781]  eta: 0:01:33  lr: 0.000018  loss: 1.3453 (1.4498)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.3134 (1.4503)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [520/781]  eta: 0:01:26  lr: 0.000018  loss: 1.3134 (1.4524)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [530/781]  eta: 0:01:23  lr: 0.000018  loss: 1.2872 (1.4494)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.2731 (1.4525)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [550/781]  eta: 0:01:16  lr: 0.000018  loss: 1.3033 (1.4505)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [560/781]  eta: 0:01:13  lr: 0.000018  loss: 1.3239 (1.4483)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.3255 (1.4479)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [580/781]  eta: 0:01:06  lr: 0.000018  loss: 1.3255 (1.4487)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [590/781]  eta: 0:01:03  lr: 0.000018  loss: 1.3212 (1.4484)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.2856 (1.4458)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [610/781]  eta: 0:00:56  lr: 0.000018  loss: 1.2621 (1.4433)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.2728 (1.4413)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3166 (1.4463)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [640/781]  eta: 0:00:46  lr: 0.000018  loss: 1.5040 (1.4511)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.3701 (1.4510)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.3239 (1.4493)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [670/781]  eta: 0:00:36  lr: 0.000018  loss: 1.3051 (1.4490)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.3364 (1.4512)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.3209 (1.4489)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [700/781]  eta: 0:00:26  lr: 0.000018  loss: 1.2629 (1.4473)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.2810 (1.4472)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.2938 (1.4493)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [730/781]  eta: 0:00:16  lr: 0.000018  loss: 1.3426 (1.4517)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.3183 (1.4495)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.3116 (1.4489)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [760/781]  eta: 0:00:06  lr: 0.000018  loss: 1.3152 (1.4487)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.3111 (1.4486)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.2796 (1.4481)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [64] Total time: 0:04:20 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.2796 (1.4481)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32836562395095825, 'lambda_convnext_base': 0.25973883271217346, 'lambda_tf_efficientnetv2_l': 0.4118957221508026}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.7845 (0.7845)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.7944  data: 0.7637  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9408 (0.9637)  acc1: 82.8125 (81.0606)  acc5: 93.7500 (93.3239)  time: 0.1711  data: 0.1407  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0239 (1.0066)  acc1: 78.1250 (80.2083)  acc5: 93.7500 (93.0308)  time: 0.1278  data: 0.0972  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1113 (1.0623)  acc1: 76.5625 (79.1331)  acc5: 91.6667 (92.5907)  time: 0.1347  data: 0.1041  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2309 (1.1121)  acc1: 75.0000 (78.1123)  acc5: 91.1458 (92.1367)  time: 0.1312  data: 0.1007  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1253 (1.1116)  acc1: 75.5208 (77.9003)  acc5: 92.7083 (92.2794)  time: 0.1294  data: 0.0990  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1569 (1.1203)  acc1: 73.9583 (77.7800)  acc5: 92.7083 (92.3300)  time: 0.1144  data: 0.0848  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1370 s / it)\n",
            "* Acc@1 77.780 Acc@5 92.330 loss 1.120\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.93%\n",
            "[alpha-schedule=cosine] epoch=65 distillation_alpha=0.5395\n",
            "Epoch: [65]  [  0/781]  eta: 0:14:48  lr: 0.000018  loss: 1.2155 (1.2155)  time: 1.1378  data: 0.7969  max mem: 6459\n",
            "Epoch: [65]  [ 10/781]  eta: 0:05:12  lr: 0.000018  loss: 1.3298 (1.5230)  time: 0.4052  data: 0.0728  max mem: 6459\n",
            "Epoch: [65]  [ 20/781]  eta: 0:04:41  lr: 0.000018  loss: 1.3022 (1.4639)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 30/781]  eta: 0:04:28  lr: 0.000018  loss: 1.2925 (1.4646)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 40/781]  eta: 0:04:20  lr: 0.000018  loss: 1.2752 (1.4503)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 50/781]  eta: 0:04:14  lr: 0.000018  loss: 1.2935 (1.4207)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 60/781]  eta: 0:04:08  lr: 0.000018  loss: 1.3295 (1.4396)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 70/781]  eta: 0:04:04  lr: 0.000018  loss: 1.2776 (1.4283)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 80/781]  eta: 0:03:59  lr: 0.000018  loss: 1.2762 (1.4109)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 90/781]  eta: 0:03:55  lr: 0.000018  loss: 1.2960 (1.4207)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [100/781]  eta: 0:03:51  lr: 0.000018  loss: 1.3160 (1.4350)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [110/781]  eta: 0:03:47  lr: 0.000018  loss: 1.2821 (1.4312)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [120/781]  eta: 0:03:43  lr: 0.000018  loss: 1.2705 (1.4337)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [130/781]  eta: 0:03:40  lr: 0.000018  loss: 1.3122 (1.4313)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [140/781]  eta: 0:03:36  lr: 0.000018  loss: 1.3252 (1.4373)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [150/781]  eta: 0:03:32  lr: 0.000018  loss: 1.3075 (1.4272)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [160/781]  eta: 0:03:29  lr: 0.000018  loss: 1.2706 (1.4394)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [170/781]  eta: 0:03:25  lr: 0.000018  loss: 1.2705 (1.4362)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [180/781]  eta: 0:03:22  lr: 0.000018  loss: 1.2910 (1.4338)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [190/781]  eta: 0:03:18  lr: 0.000018  loss: 1.2999 (1.4306)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [200/781]  eta: 0:03:15  lr: 0.000018  loss: 1.2786 (1.4300)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [210/781]  eta: 0:03:11  lr: 0.000018  loss: 1.2824 (1.4296)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [220/781]  eta: 0:03:08  lr: 0.000018  loss: 1.2546 (1.4279)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [230/781]  eta: 0:03:05  lr: 0.000018  loss: 1.2529 (1.4265)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [240/781]  eta: 0:03:01  lr: 0.000018  loss: 1.2493 (1.4206)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [250/781]  eta: 0:02:58  lr: 0.000018  loss: 1.2410 (1.4139)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [260/781]  eta: 0:02:54  lr: 0.000018  loss: 1.3103 (1.4185)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.3677 (1.4233)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [280/781]  eta: 0:02:48  lr: 0.000018  loss: 1.3363 (1.4247)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [290/781]  eta: 0:02:44  lr: 0.000018  loss: 1.2780 (1.4236)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [300/781]  eta: 0:02:41  lr: 0.000018  loss: 1.3325 (1.4225)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [310/781]  eta: 0:02:37  lr: 0.000018  loss: 1.2984 (1.4272)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.3129 (1.4285)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [330/781]  eta: 0:02:31  lr: 0.000018  loss: 1.3593 (1.4304)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [340/781]  eta: 0:02:27  lr: 0.000018  loss: 1.3236 (1.4269)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [350/781]  eta: 0:02:24  lr: 0.000018  loss: 1.2981 (1.4249)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [360/781]  eta: 0:02:20  lr: 0.000018  loss: 1.2614 (1.4239)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [370/781]  eta: 0:02:17  lr: 0.000018  loss: 1.2936 (1.4228)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [380/781]  eta: 0:02:14  lr: 0.000018  loss: 1.3079 (1.4233)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [390/781]  eta: 0:02:10  lr: 0.000018  loss: 1.3405 (1.4249)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [400/781]  eta: 0:02:07  lr: 0.000018  loss: 1.3086 (1.4260)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [410/781]  eta: 0:02:04  lr: 0.000018  loss: 1.3619 (1.4305)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [420/781]  eta: 0:02:00  lr: 0.000018  loss: 1.3619 (1.4327)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.2885 (1.4288)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [440/781]  eta: 0:01:54  lr: 0.000018  loss: 1.2716 (1.4250)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [450/781]  eta: 0:01:50  lr: 0.000018  loss: 1.2855 (1.4266)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.3377 (1.4293)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [470/781]  eta: 0:01:43  lr: 0.000018  loss: 1.3167 (1.4281)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [480/781]  eta: 0:01:40  lr: 0.000018  loss: 1.3242 (1.4303)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.3707 (1.4355)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [500/781]  eta: 0:01:33  lr: 0.000018  loss: 1.3827 (1.4364)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.2987 (1.4360)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [520/781]  eta: 0:01:27  lr: 0.000018  loss: 1.2650 (1.4373)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [530/781]  eta: 0:01:23  lr: 0.000018  loss: 1.3502 (1.4381)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.2975 (1.4354)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [550/781]  eta: 0:01:17  lr: 0.000018  loss: 1.2863 (1.4331)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [560/781]  eta: 0:01:13  lr: 0.000018  loss: 1.2959 (1.4332)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.3260 (1.4350)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [580/781]  eta: 0:01:07  lr: 0.000018  loss: 1.2934 (1.4328)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [590/781]  eta: 0:01:03  lr: 0.000018  loss: 1.3276 (1.4313)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.3339 (1.4342)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [610/781]  eta: 0:00:57  lr: 0.000018  loss: 1.3171 (1.4341)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.3062 (1.4316)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3205 (1.4324)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [640/781]  eta: 0:00:47  lr: 0.000018  loss: 1.3176 (1.4305)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.3113 (1.4293)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.3314 (1.4301)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [670/781]  eta: 0:00:37  lr: 0.000018  loss: 1.3028 (1.4289)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.3158 (1.4285)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.3783 (1.4321)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [700/781]  eta: 0:00:27  lr: 0.000018  loss: 1.3900 (1.4338)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.2786 (1.4321)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.2786 (1.4322)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [730/781]  eta: 0:00:16  lr: 0.000018  loss: 1.2891 (1.4322)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.2788 (1.4332)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.2700 (1.4310)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [760/781]  eta: 0:00:06  lr: 0.000018  loss: 1.3263 (1.4350)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.3638 (1.4355)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [65]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.3432 (1.4371)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [65] Total time: 0:04:20 (0.3334 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.3432 (1.4371)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290931284427643, 'lambda_convnext_base': 0.2595139741897583, 'lambda_tf_efficientnetv2_l': 0.4113928973674774}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7959 (0.7959)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8607  data: 0.8300  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9373 (0.9584)  acc1: 83.8542 (81.7235)  acc5: 94.7917 (93.6553)  time: 0.1781  data: 0.1477  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0319 (1.0160)  acc1: 78.1250 (80.4812)  acc5: 93.7500 (93.0308)  time: 0.1282  data: 0.0977  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1118 (1.0677)  acc1: 77.0833 (79.4019)  acc5: 92.1875 (92.6075)  time: 0.1317  data: 0.1013  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2098 (1.1105)  acc1: 76.0417 (78.4553)  acc5: 91.1458 (92.2256)  time: 0.1343  data: 0.1039  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0742 (1.1106)  acc1: 75.0000 (78.0229)  acc5: 92.7083 (92.4428)  time: 0.1322  data: 0.1018  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1751 (1.1179)  acc1: 75.0000 (77.9700)  acc5: 93.2292 (92.4900)  time: 0.1127  data: 0.0832  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1384 s / it)\n",
            "* Acc@1 77.970 Acc@5 92.490 loss 1.118\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 77.97%\n",
            "[alpha-schedule=cosine] epoch=66 distillation_alpha=0.5455\n",
            "Epoch: [66]  [  0/781]  eta: 0:14:49  lr: 0.000017  loss: 1.6110 (1.6110)  time: 1.1389  data: 0.7853  max mem: 6459\n",
            "Epoch: [66]  [ 10/781]  eta: 0:05:12  lr: 0.000017  loss: 1.2546 (1.3208)  time: 0.4053  data: 0.0717  max mem: 6459\n",
            "Epoch: [66]  [ 20/781]  eta: 0:04:41  lr: 0.000017  loss: 1.2778 (1.3637)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 30/781]  eta: 0:04:28  lr: 0.000017  loss: 1.2859 (1.4061)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 40/781]  eta: 0:04:20  lr: 0.000017  loss: 1.2853 (1.3863)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 50/781]  eta: 0:04:14  lr: 0.000017  loss: 1.2853 (1.3743)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 60/781]  eta: 0:04:08  lr: 0.000017  loss: 1.2692 (1.3680)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 70/781]  eta: 0:04:03  lr: 0.000017  loss: 1.2702 (1.3689)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 80/781]  eta: 0:03:59  lr: 0.000017  loss: 1.2899 (1.3787)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 90/781]  eta: 0:03:55  lr: 0.000017  loss: 1.2387 (1.3759)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [100/781]  eta: 0:03:51  lr: 0.000017  loss: 1.2247 (1.3862)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [110/781]  eta: 0:03:47  lr: 0.000017  loss: 1.3117 (1.4214)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [120/781]  eta: 0:03:43  lr: 0.000017  loss: 1.3091 (1.4161)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [130/781]  eta: 0:03:39  lr: 0.000017  loss: 1.2651 (1.4105)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [140/781]  eta: 0:03:36  lr: 0.000017  loss: 1.2842 (1.4144)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [150/781]  eta: 0:03:32  lr: 0.000017  loss: 1.2884 (1.4236)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [160/781]  eta: 0:03:29  lr: 0.000017  loss: 1.3065 (1.4261)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [170/781]  eta: 0:03:25  lr: 0.000017  loss: 1.3052 (1.4255)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [180/781]  eta: 0:03:21  lr: 0.000017  loss: 1.2984 (1.4199)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [190/781]  eta: 0:03:18  lr: 0.000017  loss: 1.2965 (1.4204)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [200/781]  eta: 0:03:14  lr: 0.000017  loss: 1.2638 (1.4133)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [210/781]  eta: 0:03:11  lr: 0.000017  loss: 1.2741 (1.4114)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [220/781]  eta: 0:03:08  lr: 0.000017  loss: 1.2633 (1.4040)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [230/781]  eta: 0:03:04  lr: 0.000017  loss: 1.2633 (1.3993)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [240/781]  eta: 0:03:01  lr: 0.000017  loss: 1.3210 (1.3995)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [250/781]  eta: 0:02:57  lr: 0.000017  loss: 1.3024 (1.4028)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [260/781]  eta: 0:02:54  lr: 0.000017  loss: 1.3280 (1.4046)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [270/781]  eta: 0:02:50  lr: 0.000017  loss: 1.2981 (1.4037)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [280/781]  eta: 0:02:47  lr: 0.000017  loss: 1.2981 (1.4075)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [290/781]  eta: 0:02:44  lr: 0.000017  loss: 1.3303 (1.4039)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [300/781]  eta: 0:02:40  lr: 0.000017  loss: 1.3278 (1.4030)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [310/781]  eta: 0:02:37  lr: 0.000017  loss: 1.3159 (1.4056)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [320/781]  eta: 0:02:33  lr: 0.000017  loss: 1.2847 (1.4030)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [330/781]  eta: 0:02:30  lr: 0.000017  loss: 1.2491 (1.3988)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [340/781]  eta: 0:02:27  lr: 0.000017  loss: 1.2686 (1.4022)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [350/781]  eta: 0:02:23  lr: 0.000017  loss: 1.2949 (1.4014)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [360/781]  eta: 0:02:20  lr: 0.000017  loss: 1.3028 (1.4018)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [370/781]  eta: 0:02:17  lr: 0.000017  loss: 1.2739 (1.3998)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [380/781]  eta: 0:02:13  lr: 0.000017  loss: 1.2668 (1.4000)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [390/781]  eta: 0:02:10  lr: 0.000017  loss: 1.3082 (1.4010)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [400/781]  eta: 0:02:07  lr: 0.000017  loss: 1.3012 (1.3981)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [410/781]  eta: 0:02:03  lr: 0.000017  loss: 1.2775 (1.3957)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [420/781]  eta: 0:02:00  lr: 0.000017  loss: 1.3370 (1.4004)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [430/781]  eta: 0:01:57  lr: 0.000017  loss: 1.3510 (1.4021)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [440/781]  eta: 0:01:53  lr: 0.000017  loss: 1.2693 (1.4015)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [450/781]  eta: 0:01:50  lr: 0.000017  loss: 1.2450 (1.3998)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [460/781]  eta: 0:01:46  lr: 0.000017  loss: 1.2414 (1.3968)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [470/781]  eta: 0:01:43  lr: 0.000017  loss: 1.2414 (1.3948)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [480/781]  eta: 0:01:40  lr: 0.000017  loss: 1.2586 (1.3934)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [490/781]  eta: 0:01:36  lr: 0.000017  loss: 1.2786 (1.3944)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [500/781]  eta: 0:01:33  lr: 0.000017  loss: 1.3083 (1.3996)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [510/781]  eta: 0:01:30  lr: 0.000017  loss: 1.3249 (1.3989)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [520/781]  eta: 0:01:26  lr: 0.000017  loss: 1.3132 (1.4031)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [530/781]  eta: 0:01:23  lr: 0.000017  loss: 1.2999 (1.4031)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [540/781]  eta: 0:01:20  lr: 0.000017  loss: 1.3085 (1.4036)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [550/781]  eta: 0:01:16  lr: 0.000017  loss: 1.3120 (1.4070)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [560/781]  eta: 0:01:13  lr: 0.000017  loss: 1.3317 (1.4073)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [570/781]  eta: 0:01:10  lr: 0.000017  loss: 1.2974 (1.4051)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [580/781]  eta: 0:01:06  lr: 0.000017  loss: 1.2921 (1.4086)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [590/781]  eta: 0:01:03  lr: 0.000017  loss: 1.2921 (1.4082)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [600/781]  eta: 0:01:00  lr: 0.000017  loss: 1.3048 (1.4092)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [610/781]  eta: 0:00:56  lr: 0.000017  loss: 1.3377 (1.4093)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [620/781]  eta: 0:00:53  lr: 0.000017  loss: 1.2826 (1.4094)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [630/781]  eta: 0:00:50  lr: 0.000017  loss: 1.3132 (1.4086)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [640/781]  eta: 0:00:46  lr: 0.000017  loss: 1.3132 (1.4102)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [650/781]  eta: 0:00:43  lr: 0.000017  loss: 1.2987 (1.4112)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [660/781]  eta: 0:00:40  lr: 0.000017  loss: 1.2735 (1.4124)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [670/781]  eta: 0:00:36  lr: 0.000017  loss: 1.2977 (1.4114)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [680/781]  eta: 0:00:33  lr: 0.000017  loss: 1.2882 (1.4102)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [690/781]  eta: 0:00:30  lr: 0.000017  loss: 1.3091 (1.4103)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [700/781]  eta: 0:00:26  lr: 0.000017  loss: 1.3410 (1.4105)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [710/781]  eta: 0:00:23  lr: 0.000017  loss: 1.3007 (1.4110)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [720/781]  eta: 0:00:20  lr: 0.000017  loss: 1.2393 (1.4083)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [730/781]  eta: 0:00:16  lr: 0.000017  loss: 1.2922 (1.4111)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [740/781]  eta: 0:00:13  lr: 0.000017  loss: 1.3511 (1.4112)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [750/781]  eta: 0:00:10  lr: 0.000017  loss: 1.2697 (1.4096)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [760/781]  eta: 0:00:06  lr: 0.000017  loss: 1.3082 (1.4098)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [770/781]  eta: 0:00:03  lr: 0.000017  loss: 1.3218 (1.4129)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [780/781]  eta: 0:00:00  lr: 0.000017  loss: 1.2996 (1.4145)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [66] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000017  loss: 1.2996 (1.4145)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32899004220962524, 'lambda_convnext_base': 0.25938892364501953, 'lambda_tf_efficientnetv2_l': 0.4116208255290985}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7339 (0.7339)  acc1: 84.3750 (84.3750)  acc5: 96.8750 (96.8750)  time: 0.8811  data: 0.8503  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9326 (0.9528)  acc1: 82.8125 (80.9186)  acc5: 94.7917 (94.2708)  time: 0.1751  data: 0.1446  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0039 (1.0243)  acc1: 79.6875 (80.0595)  acc5: 94.2708 (93.3532)  time: 0.1269  data: 0.0964  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1379 (1.0729)  acc1: 76.5625 (79.1163)  acc5: 91.6667 (92.7251)  time: 0.1288  data: 0.0983  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1721 (1.1092)  acc1: 75.0000 (78.2774)  acc5: 91.1458 (92.3018)  time: 0.1274  data: 0.0970  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0895 (1.1056)  acc1: 75.0000 (78.0331)  acc5: 92.7083 (92.5143)  time: 0.1255  data: 0.0950  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1044 (1.1171)  acc1: 75.0000 (77.9200)  acc5: 92.7083 (92.5400)  time: 0.1057  data: 0.0762  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1341 s / it)\n",
            "* Acc@1 77.920 Acc@5 92.540 loss 1.117\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.97%\n",
            "[alpha-schedule=cosine] epoch=67 distillation_alpha=0.5511\n",
            "Epoch: [67]  [  0/781]  eta: 0:15:05  lr: 0.000016  loss: 1.2521 (1.2521)  time: 1.1588  data: 0.8198  max mem: 6459\n",
            "Epoch: [67]  [ 10/781]  eta: 0:05:13  lr: 0.000016  loss: 1.3610 (1.4139)  time: 0.4070  data: 0.0748  max mem: 6459\n",
            "Epoch: [67]  [ 20/781]  eta: 0:04:42  lr: 0.000016  loss: 1.3069 (1.3853)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 30/781]  eta: 0:04:29  lr: 0.000016  loss: 1.2619 (1.3705)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 40/781]  eta: 0:04:20  lr: 0.000016  loss: 1.2619 (1.4041)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 50/781]  eta: 0:04:14  lr: 0.000016  loss: 1.2597 (1.3970)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 60/781]  eta: 0:04:08  lr: 0.000016  loss: 1.2781 (1.4079)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 70/781]  eta: 0:04:04  lr: 0.000016  loss: 1.2972 (1.4384)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 80/781]  eta: 0:03:59  lr: 0.000016  loss: 1.3117 (1.4388)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 90/781]  eta: 0:03:55  lr: 0.000016  loss: 1.3109 (1.4430)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [100/781]  eta: 0:03:51  lr: 0.000016  loss: 1.2645 (1.4279)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [110/781]  eta: 0:03:47  lr: 0.000016  loss: 1.2734 (1.4248)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [120/781]  eta: 0:03:43  lr: 0.000016  loss: 1.2606 (1.4256)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.2709 (1.4345)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [140/781]  eta: 0:03:36  lr: 0.000016  loss: 1.2827 (1.4222)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [150/781]  eta: 0:03:32  lr: 0.000016  loss: 1.3365 (1.4399)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [160/781]  eta: 0:03:29  lr: 0.000016  loss: 1.3089 (1.4388)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [170/781]  eta: 0:03:25  lr: 0.000016  loss: 1.2915 (1.4428)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [180/781]  eta: 0:03:22  lr: 0.000016  loss: 1.3122 (1.4430)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [190/781]  eta: 0:03:18  lr: 0.000016  loss: 1.3120 (1.4439)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [200/781]  eta: 0:03:15  lr: 0.000016  loss: 1.2800 (1.4375)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [210/781]  eta: 0:03:11  lr: 0.000016  loss: 1.2773 (1.4322)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [220/781]  eta: 0:03:08  lr: 0.000016  loss: 1.3262 (1.4366)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [230/781]  eta: 0:03:04  lr: 0.000016  loss: 1.3289 (1.4392)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [240/781]  eta: 0:03:01  lr: 0.000016  loss: 1.2692 (1.4349)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [250/781]  eta: 0:02:57  lr: 0.000016  loss: 1.2411 (1.4323)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [260/781]  eta: 0:02:54  lr: 0.000016  loss: 1.2565 (1.4267)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.2846 (1.4303)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [280/781]  eta: 0:02:47  lr: 0.000016  loss: 1.2560 (1.4317)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [290/781]  eta: 0:02:44  lr: 0.000016  loss: 1.2637 (1.4283)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [300/781]  eta: 0:02:40  lr: 0.000016  loss: 1.2989 (1.4337)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [310/781]  eta: 0:02:37  lr: 0.000016  loss: 1.3046 (1.4325)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.2846 (1.4312)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [330/781]  eta: 0:02:30  lr: 0.000016  loss: 1.2846 (1.4315)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [340/781]  eta: 0:02:27  lr: 0.000016  loss: 1.2884 (1.4337)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.3202 (1.4333)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [360/781]  eta: 0:02:20  lr: 0.000016  loss: 1.3617 (1.4368)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.3505 (1.4344)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [380/781]  eta: 0:02:13  lr: 0.000016  loss: 1.3403 (1.4376)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [390/781]  eta: 0:02:10  lr: 0.000016  loss: 1.3220 (1.4405)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.2688 (1.4408)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [410/781]  eta: 0:02:03  lr: 0.000016  loss: 1.2730 (1.4417)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [420/781]  eta: 0:02:00  lr: 0.000016  loss: 1.2679 (1.4393)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.2555 (1.4372)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [440/781]  eta: 0:01:53  lr: 0.000016  loss: 1.2868 (1.4396)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.3239 (1.4442)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.3280 (1.4486)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [470/781]  eta: 0:01:43  lr: 0.000016  loss: 1.2982 (1.4469)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.2553 (1.4453)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.2607 (1.4427)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [500/781]  eta: 0:01:33  lr: 0.000016  loss: 1.2567 (1.4428)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.2423 (1.4421)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.2542 (1.4420)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [530/781]  eta: 0:01:23  lr: 0.000016  loss: 1.2919 (1.4398)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.3238 (1.4395)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [550/781]  eta: 0:01:16  lr: 0.000016  loss: 1.2992 (1.4382)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [560/781]  eta: 0:01:13  lr: 0.000016  loss: 1.2630 (1.4352)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.2627 (1.4343)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [580/781]  eta: 0:01:06  lr: 0.000016  loss: 1.2590 (1.4330)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.2853 (1.4335)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.3073 (1.4335)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [610/781]  eta: 0:00:56  lr: 0.000016  loss: 1.3724 (1.4383)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.3666 (1.4394)  time: 0.3325  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.3616 (1.4423)  time: 0.3326  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [640/781]  eta: 0:00:46  lr: 0.000016  loss: 1.3603 (1.4421)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.3280 (1.4432)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.2758 (1.4405)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [670/781]  eta: 0:00:36  lr: 0.000016  loss: 1.2969 (1.4402)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.3162 (1.4384)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.2668 (1.4367)  time: 0.3325  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [700/781]  eta: 0:00:26  lr: 0.000016  loss: 1.2567 (1.4342)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.2881 (1.4356)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.2782 (1.4354)  time: 0.3326  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [730/781]  eta: 0:00:16  lr: 0.000016  loss: 1.2782 (1.4335)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.2941 (1.4316)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.2769 (1.4299)  time: 0.3326  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [760/781]  eta: 0:00:06  lr: 0.000016  loss: 1.2485 (1.4282)  time: 0.3327  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.2896 (1.4263)  time: 0.3325  data: 0.0004  max mem: 6459\n",
            "Epoch: [67]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.3092 (1.4258)  time: 0.3323  data: 0.0006  max mem: 6459\n",
            "Epoch: [67] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.3092 (1.4258)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32908207178115845, 'lambda_convnext_base': 0.2596954107284546, 'lambda_tf_efficientnetv2_l': 0.41122251749038696}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8230 (0.8230)  acc1: 82.2917 (82.2917)  acc5: 95.3125 (95.3125)  time: 0.8513  data: 0.8205  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9691 (0.9481)  acc1: 82.2917 (81.0133)  acc5: 94.2708 (94.2235)  time: 0.1824  data: 0.1520  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9905 (0.9996)  acc1: 79.6875 (80.2827)  acc5: 93.2292 (93.3036)  time: 0.1334  data: 0.1030  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0979 (1.0588)  acc1: 77.0833 (79.3515)  acc5: 91.1458 (92.6411)  time: 0.1326  data: 0.1022  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1890 (1.1053)  acc1: 75.5208 (78.3156)  acc5: 90.6250 (92.2383)  time: 0.1354  data: 0.1050  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0911 (1.1054)  acc1: 77.0833 (78.0535)  acc5: 92.7083 (92.4224)  time: 0.1372  data: 0.1067  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1273 (1.1132)  acc1: 76.0417 (78.0100)  acc5: 92.7083 (92.4600)  time: 0.1185  data: 0.0890  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1413 s / it)\n",
            "* Acc@1 78.010 Acc@5 92.460 loss 1.113\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.01%\n",
            "[alpha-schedule=cosine] epoch=68 distillation_alpha=0.5566\n",
            "Epoch: [68]  [  0/781]  eta: 0:14:22  lr: 0.000016  loss: 1.1836 (1.1836)  time: 1.1042  data: 0.7584  max mem: 6459\n",
            "Epoch: [68]  [ 10/781]  eta: 0:05:26  lr: 0.000016  loss: 1.2706 (1.3097)  time: 0.4235  data: 0.0693  max mem: 6459\n",
            "Epoch: [68]  [ 20/781]  eta: 0:04:48  lr: 0.000016  loss: 1.2865 (1.2961)  time: 0.3435  data: 0.0004  max mem: 6459\n",
            "Epoch: [68]  [ 30/781]  eta: 0:04:33  lr: 0.000016  loss: 1.2885 (1.3263)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 40/781]  eta: 0:04:23  lr: 0.000016  loss: 1.2885 (1.3249)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 50/781]  eta: 0:04:16  lr: 0.000016  loss: 1.2902 (1.3511)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 60/781]  eta: 0:04:11  lr: 0.000016  loss: 1.3026 (1.3567)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 70/781]  eta: 0:04:05  lr: 0.000016  loss: 1.2813 (1.3634)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 80/781]  eta: 0:04:01  lr: 0.000016  loss: 1.2771 (1.3692)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 90/781]  eta: 0:03:56  lr: 0.000016  loss: 1.3117 (1.3849)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [100/781]  eta: 0:03:52  lr: 0.000016  loss: 1.3117 (1.3953)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [110/781]  eta: 0:03:48  lr: 0.000016  loss: 1.3112 (1.3937)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [120/781]  eta: 0:03:44  lr: 0.000016  loss: 1.3018 (1.3918)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.2839 (1.3916)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [140/781]  eta: 0:03:37  lr: 0.000016  loss: 1.2729 (1.3907)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [150/781]  eta: 0:03:33  lr: 0.000016  loss: 1.2976 (1.3843)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [160/781]  eta: 0:03:29  lr: 0.000016  loss: 1.2976 (1.4015)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [170/781]  eta: 0:03:26  lr: 0.000016  loss: 1.2858 (1.3956)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [180/781]  eta: 0:03:22  lr: 0.000016  loss: 1.2835 (1.3909)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [190/781]  eta: 0:03:19  lr: 0.000016  loss: 1.2980 (1.3907)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [200/781]  eta: 0:03:15  lr: 0.000016  loss: 1.3261 (1.3968)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [210/781]  eta: 0:03:12  lr: 0.000016  loss: 1.3261 (1.3994)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [220/781]  eta: 0:03:08  lr: 0.000016  loss: 1.3831 (1.4121)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [230/781]  eta: 0:03:05  lr: 0.000016  loss: 1.3637 (1.4142)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [240/781]  eta: 0:03:01  lr: 0.000016  loss: 1.2861 (1.4078)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [250/781]  eta: 0:02:58  lr: 0.000016  loss: 1.2779 (1.4036)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [260/781]  eta: 0:02:54  lr: 0.000016  loss: 1.2779 (1.4031)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.3316 (1.4051)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [280/781]  eta: 0:02:47  lr: 0.000016  loss: 1.3403 (1.4052)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [290/781]  eta: 0:02:44  lr: 0.000016  loss: 1.2666 (1.4004)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [300/781]  eta: 0:02:41  lr: 0.000016  loss: 1.2756 (1.3993)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [310/781]  eta: 0:02:37  lr: 0.000016  loss: 1.2927 (1.4028)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.2953 (1.4029)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [330/781]  eta: 0:02:30  lr: 0.000016  loss: 1.2826 (1.4022)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [340/781]  eta: 0:02:27  lr: 0.000016  loss: 1.2390 (1.3976)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.2390 (1.3960)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [360/781]  eta: 0:02:20  lr: 0.000016  loss: 1.2404 (1.3963)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.2236 (1.3939)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [380/781]  eta: 0:02:14  lr: 0.000016  loss: 1.2424 (1.3913)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [390/781]  eta: 0:02:10  lr: 0.000016  loss: 1.3049 (1.3910)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.3049 (1.3920)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [410/781]  eta: 0:02:03  lr: 0.000016  loss: 1.2431 (1.3879)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [420/781]  eta: 0:02:00  lr: 0.000016  loss: 1.2137 (1.3850)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.2969 (1.3908)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [440/781]  eta: 0:01:53  lr: 0.000016  loss: 1.3378 (1.3932)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.3113 (1.3953)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.3147 (1.3969)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [470/781]  eta: 0:01:43  lr: 0.000016  loss: 1.3330 (1.3974)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.2572 (1.3944)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.2517 (1.3961)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [500/781]  eta: 0:01:33  lr: 0.000016  loss: 1.3070 (1.3997)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.3130 (1.4005)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.3036 (1.4024)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [530/781]  eta: 0:01:23  lr: 0.000016  loss: 1.3222 (1.4033)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.3541 (1.4032)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [550/781]  eta: 0:01:17  lr: 0.000016  loss: 1.2910 (1.4016)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [560/781]  eta: 0:01:13  lr: 0.000016  loss: 1.2295 (1.4006)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.2999 (1.4040)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [580/781]  eta: 0:01:07  lr: 0.000016  loss: 1.3115 (1.4030)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.3064 (1.4042)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [68]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.2909 (1.4027)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [610/781]  eta: 0:00:56  lr: 0.000016  loss: 1.3022 (1.4034)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.2430 (1.4014)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.2430 (1.4039)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [640/781]  eta: 0:00:46  lr: 0.000016  loss: 1.3020 (1.4044)  time: 0.3316  data: 0.0004  max mem: 6459\n",
            "Epoch: [68]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.3025 (1.4054)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.3025 (1.4051)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [670/781]  eta: 0:00:36  lr: 0.000016  loss: 1.3332 (1.4096)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.4031 (1.4103)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.2590 (1.4086)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [700/781]  eta: 0:00:26  lr: 0.000016  loss: 1.2888 (1.4102)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [68]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.3083 (1.4099)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.3025 (1.4123)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [730/781]  eta: 0:00:16  lr: 0.000016  loss: 1.2994 (1.4108)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.3030 (1.4136)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.4066 (1.4165)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [760/781]  eta: 0:00:06  lr: 0.000016  loss: 1.3039 (1.4152)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.2716 (1.4138)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.2909 (1.4145)  time: 0.3317  data: 0.0006  max mem: 6459\n",
            "Epoch: [68] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.2909 (1.4145)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3280594050884247, 'lambda_convnext_base': 0.25917771458625793, 'lambda_tf_efficientnetv2_l': 0.41276276111602783}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7907 (0.7907)  acc1: 84.3750 (84.3750)  acc5: 95.3125 (95.3125)  time: 0.8567  data: 0.8260  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8881 (0.9311)  acc1: 83.8542 (81.7708)  acc5: 93.2292 (93.7974)  time: 0.1688  data: 0.1384  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9930 (0.9961)  acc1: 76.5625 (80.2827)  acc5: 93.2292 (93.0060)  time: 0.1173  data: 0.0869  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1174 (1.0517)  acc1: 75.5208 (79.2003)  acc5: 91.6667 (92.5235)  time: 0.1362  data: 0.1057  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2236 (1.0962)  acc1: 75.0000 (78.3028)  acc5: 91.1458 (92.0732)  time: 0.1277  data: 0.0973  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0792 (1.0976)  acc1: 75.5208 (77.8901)  acc5: 93.2292 (92.3509)  time: 0.1320  data: 0.1015  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1365 (1.1105)  acc1: 75.0000 (77.8000)  acc5: 93.2292 (92.3900)  time: 0.1311  data: 0.1015  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1380 s / it)\n",
            "* Acc@1 77.800 Acc@5 92.390 loss 1.110\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.01%\n",
            "[alpha-schedule=cosine] epoch=69 distillation_alpha=0.5617\n",
            "Epoch: [69]  [  0/781]  eta: 0:14:42  lr: 0.000015  loss: 1.2001 (1.2001)  time: 1.1300  data: 0.7769  max mem: 6459\n",
            "Epoch: [69]  [ 10/781]  eta: 0:05:11  lr: 0.000015  loss: 1.2584 (1.3883)  time: 0.4042  data: 0.0709  max mem: 6459\n",
            "Epoch: [69]  [ 20/781]  eta: 0:04:41  lr: 0.000015  loss: 1.2876 (1.4186)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 30/781]  eta: 0:04:28  lr: 0.000015  loss: 1.2876 (1.3899)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 40/781]  eta: 0:04:20  lr: 0.000015  loss: 1.2521 (1.3981)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 50/781]  eta: 0:04:13  lr: 0.000015  loss: 1.2254 (1.3651)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 60/781]  eta: 0:04:08  lr: 0.000015  loss: 1.2298 (1.3611)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 70/781]  eta: 0:04:03  lr: 0.000015  loss: 1.2721 (1.3668)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 80/781]  eta: 0:03:59  lr: 0.000015  loss: 1.3079 (1.3670)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 90/781]  eta: 0:03:55  lr: 0.000015  loss: 1.2672 (1.3633)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [100/781]  eta: 0:03:51  lr: 0.000015  loss: 1.2916 (1.3772)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [110/781]  eta: 0:03:47  lr: 0.000015  loss: 1.3059 (1.3692)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [120/781]  eta: 0:03:43  lr: 0.000015  loss: 1.2727 (1.3877)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [130/781]  eta: 0:03:39  lr: 0.000015  loss: 1.2672 (1.3935)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [140/781]  eta: 0:03:36  lr: 0.000015  loss: 1.2721 (1.3928)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [150/781]  eta: 0:03:32  lr: 0.000015  loss: 1.2898 (1.3864)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [160/781]  eta: 0:03:28  lr: 0.000015  loss: 1.2949 (1.3871)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [170/781]  eta: 0:03:25  lr: 0.000015  loss: 1.2949 (1.3971)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [69]  [180/781]  eta: 0:03:21  lr: 0.000015  loss: 1.2385 (1.3937)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [69]  [190/781]  eta: 0:03:18  lr: 0.000015  loss: 1.2288 (1.3916)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [200/781]  eta: 0:03:14  lr: 0.000015  loss: 1.2362 (1.3897)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [210/781]  eta: 0:03:11  lr: 0.000015  loss: 1.2362 (1.3885)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [220/781]  eta: 0:03:08  lr: 0.000015  loss: 1.2500 (1.3924)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [230/781]  eta: 0:03:04  lr: 0.000015  loss: 1.2920 (1.4031)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [240/781]  eta: 0:03:01  lr: 0.000015  loss: 1.2920 (1.4015)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [250/781]  eta: 0:02:57  lr: 0.000015  loss: 1.2578 (1.4014)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [260/781]  eta: 0:02:54  lr: 0.000015  loss: 1.2840 (1.4062)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [270/781]  eta: 0:02:51  lr: 0.000015  loss: 1.3007 (1.4034)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [280/781]  eta: 0:02:47  lr: 0.000015  loss: 1.2578 (1.3989)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [290/781]  eta: 0:02:44  lr: 0.000015  loss: 1.2470 (1.4016)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [300/781]  eta: 0:02:40  lr: 0.000015  loss: 1.2552 (1.4040)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [310/781]  eta: 0:02:37  lr: 0.000015  loss: 1.3062 (1.4096)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.3520 (1.4126)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [330/781]  eta: 0:02:30  lr: 0.000015  loss: 1.3520 (1.4096)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [340/781]  eta: 0:02:27  lr: 0.000015  loss: 1.3252 (1.4164)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [350/781]  eta: 0:02:23  lr: 0.000015  loss: 1.2850 (1.4147)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [360/781]  eta: 0:02:20  lr: 0.000015  loss: 1.2850 (1.4192)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [370/781]  eta: 0:02:17  lr: 0.000015  loss: 1.3287 (1.4200)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [380/781]  eta: 0:02:13  lr: 0.000015  loss: 1.2787 (1.4167)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [390/781]  eta: 0:02:10  lr: 0.000015  loss: 1.3065 (1.4184)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.3390 (1.4198)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [410/781]  eta: 0:02:03  lr: 0.000015  loss: 1.3761 (1.4285)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [420/781]  eta: 0:02:00  lr: 0.000015  loss: 1.4269 (1.4318)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.2837 (1.4342)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [440/781]  eta: 0:01:53  lr: 0.000015  loss: 1.2973 (1.4372)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [450/781]  eta: 0:01:50  lr: 0.000015  loss: 1.2725 (1.4337)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.2409 (1.4297)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [470/781]  eta: 0:01:43  lr: 0.000015  loss: 1.2390 (1.4301)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.2715 (1.4295)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.2853 (1.4279)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [500/781]  eta: 0:01:33  lr: 0.000015  loss: 1.2961 (1.4322)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.2813 (1.4294)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.2813 (1.4326)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [530/781]  eta: 0:01:23  lr: 0.000015  loss: 1.2973 (1.4318)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.2864 (1.4318)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [550/781]  eta: 0:01:16  lr: 0.000015  loss: 1.2816 (1.4327)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [560/781]  eta: 0:01:13  lr: 0.000015  loss: 1.3021 (1.4334)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.2655 (1.4327)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [580/781]  eta: 0:01:06  lr: 0.000015  loss: 1.2457 (1.4304)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.2506 (1.4289)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.3457 (1.4303)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [610/781]  eta: 0:00:56  lr: 0.000015  loss: 1.3457 (1.4292)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.3452 (1.4323)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.3330 (1.4335)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [640/781]  eta: 0:00:46  lr: 0.000015  loss: 1.2997 (1.4317)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.3526 (1.4330)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.3528 (1.4333)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [670/781]  eta: 0:00:36  lr: 0.000015  loss: 1.2777 (1.4339)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.2486 (1.4313)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.2585 (1.4339)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [700/781]  eta: 0:00:26  lr: 0.000015  loss: 1.3128 (1.4339)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.3724 (1.4366)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.3830 (1.4373)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [730/781]  eta: 0:00:16  lr: 0.000015  loss: 1.3173 (1.4364)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.3242 (1.4385)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.3129 (1.4369)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [760/781]  eta: 0:00:06  lr: 0.000015  loss: 1.3129 (1.4383)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.3122 (1.4377)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.3038 (1.4389)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [69] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.3038 (1.4389)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.329003244638443, 'lambda_convnext_base': 0.25955930352211, 'lambda_tf_efficientnetv2_l': 0.41143733263015747}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.7976 (0.7976)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8107  data: 0.7800  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8736 (0.9358)  acc1: 83.8542 (81.7235)  acc5: 95.3125 (94.1761)  time: 0.1758  data: 0.1454  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9754 (1.0028)  acc1: 78.1250 (80.1835)  acc5: 93.7500 (93.1548)  time: 0.1320  data: 0.1016  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1448 (1.0700)  acc1: 76.0417 (79.2339)  acc5: 92.1875 (92.6243)  time: 0.1289  data: 0.0985  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2800 (1.1070)  acc1: 76.0417 (78.3791)  acc5: 91.1458 (92.2510)  time: 0.1285  data: 0.0981  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0892 (1.1052)  acc1: 75.5208 (78.0739)  acc5: 92.1875 (92.5143)  time: 0.1310  data: 0.1006  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1414 (1.1152)  acc1: 75.5208 (77.9900)  acc5: 93.2292 (92.5400)  time: 0.1102  data: 0.0806  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1364 s / it)\n",
            "* Acc@1 77.990 Acc@5 92.540 loss 1.115\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.01%\n",
            "[alpha-schedule=cosine] epoch=70 distillation_alpha=0.5665\n",
            "Epoch: [70]  [  0/781]  eta: 0:14:49  lr: 0.000014  loss: 1.2595 (1.2595)  time: 1.1390  data: 0.7942  max mem: 6459\n",
            "Epoch: [70]  [ 10/781]  eta: 0:05:12  lr: 0.000014  loss: 1.2780 (1.4230)  time: 0.4057  data: 0.0725  max mem: 6459\n",
            "Epoch: [70]  [ 20/781]  eta: 0:04:42  lr: 0.000014  loss: 1.2909 (1.4295)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 30/781]  eta: 0:04:29  lr: 0.000014  loss: 1.3292 (1.4698)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 40/781]  eta: 0:04:20  lr: 0.000014  loss: 1.3183 (1.4516)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.2859 (1.4198)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 60/781]  eta: 0:04:08  lr: 0.000014  loss: 1.2364 (1.4142)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.2430 (1.4079)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 80/781]  eta: 0:03:59  lr: 0.000014  loss: 1.2302 (1.4070)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 90/781]  eta: 0:03:55  lr: 0.000014  loss: 1.2827 (1.3998)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [100/781]  eta: 0:03:51  lr: 0.000014  loss: 1.2724 (1.3923)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [110/781]  eta: 0:03:47  lr: 0.000014  loss: 1.2947 (1.3891)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [120/781]  eta: 0:03:43  lr: 0.000014  loss: 1.3035 (1.3887)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.2904 (1.3962)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [140/781]  eta: 0:03:36  lr: 0.000014  loss: 1.2580 (1.3928)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [150/781]  eta: 0:03:32  lr: 0.000014  loss: 1.2717 (1.4086)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [160/781]  eta: 0:03:29  lr: 0.000014  loss: 1.2950 (1.3990)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [170/781]  eta: 0:03:25  lr: 0.000014  loss: 1.2579 (1.3922)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2579 (1.3855)  time: 0.3329  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [190/781]  eta: 0:03:18  lr: 0.000014  loss: 1.2608 (1.3918)  time: 0.3333  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.2838 (1.3967)  time: 0.3328  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [210/781]  eta: 0:03:11  lr: 0.000014  loss: 1.2884 (1.3953)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.3072 (1.3948)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [230/781]  eta: 0:03:04  lr: 0.000014  loss: 1.2936 (1.3947)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [240/781]  eta: 0:03:01  lr: 0.000014  loss: 1.2981 (1.3954)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.3134 (1.3970)  time: 0.3328  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [260/781]  eta: 0:02:54  lr: 0.000014  loss: 1.2636 (1.3933)  time: 0.3328  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.3035 (1.4011)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [280/781]  eta: 0:02:47  lr: 0.000014  loss: 1.3035 (1.4035)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.2901 (1.4082)  time: 0.3327  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.3034 (1.4124)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [310/781]  eta: 0:02:37  lr: 0.000014  loss: 1.3096 (1.4117)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.3236 (1.4090)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [330/781]  eta: 0:02:30  lr: 0.000014  loss: 1.3596 (1.4160)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.3578 (1.4181)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.3578 (1.4220)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [360/781]  eta: 0:02:20  lr: 0.000014  loss: 1.3056 (1.4245)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.2984 (1.4222)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.3036 (1.4190)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [390/781]  eta: 0:02:10  lr: 0.000014  loss: 1.3036 (1.4207)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.3281 (1.4240)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [410/781]  eta: 0:02:03  lr: 0.000014  loss: 1.2870 (1.4197)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.2355 (1.4165)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.3021 (1.4201)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [440/781]  eta: 0:01:53  lr: 0.000014  loss: 1.3261 (1.4182)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.2793 (1.4184)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2141 (1.4132)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [470/781]  eta: 0:01:43  lr: 0.000014  loss: 1.1801 (1.4130)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2566 (1.4142)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.3083 (1.4144)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [500/781]  eta: 0:01:33  lr: 0.000014  loss: 1.3086 (1.4142)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.2951 (1.4158)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.2846 (1.4135)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [530/781]  eta: 0:01:23  lr: 0.000014  loss: 1.2702 (1.4125)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.3144 (1.4151)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.2737 (1.4128)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [560/781]  eta: 0:01:13  lr: 0.000014  loss: 1.2737 (1.4134)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.2802 (1.4138)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2738 (1.4116)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2738 (1.4127)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.2685 (1.4132)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2685 (1.4112)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.3303 (1.4137)  time: 0.3436  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.3252 (1.4127)  time: 0.3438  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.2960 (1.4106)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.2940 (1.4113)  time: 0.3316  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.3134 (1.4107)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.2811 (1.4125)  time: 0.3319  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2969 (1.4131)  time: 0.3316  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.2884 (1.4113)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.2575 (1.4095)  time: 0.3317  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.2538 (1.4082)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [70]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.2340 (1.4075)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.2239 (1.4069)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.2836 (1.4107)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.2934 (1.4087)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [760/781]  eta: 0:00:06  lr: 0.000014  loss: 1.2869 (1.4082)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.3057 (1.4111)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.3091 (1.4101)  time: 0.3319  data: 0.0006  max mem: 6459\n",
            "Epoch: [70] Total time: 0:04:20 (0.3334 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.3091 (1.4101)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3287595808506012, 'lambda_convnext_base': 0.25967082381248474, 'lambda_tf_efficientnetv2_l': 0.411569744348526}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8249 (0.8249)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8369  data: 0.8063  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8586 (0.9359)  acc1: 83.8542 (81.5814)  acc5: 95.3125 (94.2708)  time: 0.1628  data: 0.1324  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0189 (1.0000)  acc1: 77.6042 (80.2331)  acc5: 93.7500 (93.1052)  time: 0.1111  data: 0.0806  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1412 (1.0596)  acc1: 76.5625 (79.4187)  acc5: 92.1875 (92.4059)  time: 0.1161  data: 0.0856  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2514 (1.1018)  acc1: 76.5625 (78.6331)  acc5: 90.6250 (91.9461)  time: 0.1130  data: 0.0825  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0618 (1.1029)  acc1: 75.5208 (78.2476)  acc5: 92.1875 (92.2590)  time: 0.1218  data: 0.0913  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0902 (1.1180)  acc1: 75.0000 (78.1500)  acc5: 93.2292 (92.2900)  time: 0.1099  data: 0.0802  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1254 s / it)\n",
            "* Acc@1 78.150 Acc@5 92.290 loss 1.118\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.15%\n",
            "[alpha-schedule=cosine] epoch=71 distillation_alpha=0.5710\n",
            "Epoch: [71]  [  0/781]  eta: 0:14:17  lr: 0.000014  loss: 2.3114 (2.3114)  time: 1.0973  data: 0.7513  max mem: 6459\n",
            "Epoch: [71]  [ 10/781]  eta: 0:05:09  lr: 0.000014  loss: 1.2482 (1.3766)  time: 0.4020  data: 0.0686  max mem: 6459\n",
            "Epoch: [71]  [ 20/781]  eta: 0:04:40  lr: 0.000014  loss: 1.2500 (1.3911)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 30/781]  eta: 0:04:27  lr: 0.000014  loss: 1.2500 (1.4032)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 40/781]  eta: 0:04:19  lr: 0.000014  loss: 1.2368 (1.4128)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 50/781]  eta: 0:04:13  lr: 0.000014  loss: 1.2609 (1.4259)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 60/781]  eta: 0:04:08  lr: 0.000014  loss: 1.2837 (1.4068)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 70/781]  eta: 0:04:03  lr: 0.000014  loss: 1.2974 (1.4134)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [71]  [ 80/781]  eta: 0:03:59  lr: 0.000014  loss: 1.2926 (1.4137)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 90/781]  eta: 0:03:55  lr: 0.000014  loss: 1.3369 (1.4450)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [100/781]  eta: 0:03:51  lr: 0.000014  loss: 1.3369 (1.4443)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [110/781]  eta: 0:03:47  lr: 0.000014  loss: 1.2283 (1.4283)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [120/781]  eta: 0:03:43  lr: 0.000014  loss: 1.2799 (1.4343)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [130/781]  eta: 0:03:39  lr: 0.000014  loss: 1.3636 (1.4376)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [140/781]  eta: 0:03:36  lr: 0.000014  loss: 1.3192 (1.4424)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [150/781]  eta: 0:03:32  lr: 0.000014  loss: 1.2780 (1.4355)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [160/781]  eta: 0:03:28  lr: 0.000014  loss: 1.2860 (1.4389)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [170/781]  eta: 0:03:25  lr: 0.000014  loss: 1.2943 (1.4332)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [180/781]  eta: 0:03:21  lr: 0.000014  loss: 1.2943 (1.4276)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [190/781]  eta: 0:03:18  lr: 0.000014  loss: 1.2909 (1.4235)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [200/781]  eta: 0:03:14  lr: 0.000014  loss: 1.2909 (1.4240)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [210/781]  eta: 0:03:11  lr: 0.000014  loss: 1.2803 (1.4181)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.2803 (1.4221)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [230/781]  eta: 0:03:04  lr: 0.000014  loss: 1.3057 (1.4218)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [240/781]  eta: 0:03:01  lr: 0.000014  loss: 1.2709 (1.4213)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [250/781]  eta: 0:02:57  lr: 0.000014  loss: 1.2753 (1.4164)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [260/781]  eta: 0:02:54  lr: 0.000014  loss: 1.2239 (1.4124)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [270/781]  eta: 0:02:50  lr: 0.000014  loss: 1.2129 (1.4106)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [280/781]  eta: 0:02:47  lr: 0.000014  loss: 1.2584 (1.4129)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.3112 (1.4129)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [300/781]  eta: 0:02:40  lr: 0.000014  loss: 1.3112 (1.4193)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [310/781]  eta: 0:02:37  lr: 0.000014  loss: 1.3574 (1.4245)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.3358 (1.4229)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [330/781]  eta: 0:02:30  lr: 0.000014  loss: 1.2725 (1.4257)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.3097 (1.4226)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [350/781]  eta: 0:02:23  lr: 0.000014  loss: 1.2582 (1.4175)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [360/781]  eta: 0:02:20  lr: 0.000014  loss: 1.2554 (1.4181)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.3208 (1.4153)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [380/781]  eta: 0:02:13  lr: 0.000014  loss: 1.3121 (1.4174)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [390/781]  eta: 0:02:10  lr: 0.000014  loss: 1.2842 (1.4166)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.2693 (1.4159)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [410/781]  eta: 0:02:03  lr: 0.000014  loss: 1.2636 (1.4172)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.2829 (1.4186)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.2655 (1.4152)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [440/781]  eta: 0:01:53  lr: 0.000014  loss: 1.2797 (1.4155)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.2911 (1.4141)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.3073 (1.4137)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [470/781]  eta: 0:01:43  lr: 0.000014  loss: 1.2966 (1.4109)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2759 (1.4106)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.2759 (1.4106)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [500/781]  eta: 0:01:33  lr: 0.000014  loss: 1.2898 (1.4129)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.3398 (1.4144)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [520/781]  eta: 0:01:26  lr: 0.000014  loss: 1.3387 (1.4141)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [530/781]  eta: 0:01:23  lr: 0.000014  loss: 1.3023 (1.4148)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.3023 (1.4174)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [550/781]  eta: 0:01:16  lr: 0.000014  loss: 1.3065 (1.4156)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [560/781]  eta: 0:01:13  lr: 0.000014  loss: 1.2725 (1.4161)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.2725 (1.4171)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [580/781]  eta: 0:01:06  lr: 0.000014  loss: 1.3058 (1.4173)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2805 (1.4166)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.2610 (1.4161)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [610/781]  eta: 0:00:56  lr: 0.000014  loss: 1.2864 (1.4145)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.3003 (1.4138)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.3103 (1.4153)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [640/781]  eta: 0:00:46  lr: 0.000014  loss: 1.3519 (1.4174)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.2852 (1.4188)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.2707 (1.4180)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [670/781]  eta: 0:00:36  lr: 0.000014  loss: 1.2912 (1.4188)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2940 (1.4180)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.2940 (1.4177)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [700/781]  eta: 0:00:26  lr: 0.000014  loss: 1.2957 (1.4188)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.2957 (1.4197)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.2726 (1.4208)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [730/781]  eta: 0:00:16  lr: 0.000014  loss: 1.2831 (1.4199)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.3199 (1.4187)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.3009 (1.4168)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [760/781]  eta: 0:00:06  lr: 0.000014  loss: 1.2679 (1.4159)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.2857 (1.4189)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.2857 (1.4182)  time: 0.3316  data: 0.0006  max mem: 6459\n",
            "Epoch: [71] Total time: 0:04:19 (0.3327 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.2857 (1.4182)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3286792039871216, 'lambda_convnext_base': 0.259543240070343, 'lambda_tf_efficientnetv2_l': 0.41177740693092346}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8011 (0.8011)  acc1: 82.8125 (82.8125)  acc5: 95.8333 (95.8333)  time: 0.8499  data: 0.8193  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8598 (0.9284)  acc1: 82.8125 (81.7708)  acc5: 95.3125 (94.0341)  time: 0.1742  data: 0.1437  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9675 (0.9986)  acc1: 80.2083 (80.5556)  acc5: 94.2708 (93.0556)  time: 0.1226  data: 0.0921  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1784 (1.0552)  acc1: 75.5208 (79.3851)  acc5: 92.1875 (92.4731)  time: 0.1276  data: 0.0971  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1890 (1.1060)  acc1: 75.5208 (78.3283)  acc5: 91.1458 (92.0351)  time: 0.1151  data: 0.0843  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1283 (1.1051)  acc1: 75.5208 (77.9922)  acc5: 92.7083 (92.3101)  time: 0.1285  data: 0.0976  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1301 (1.1149)  acc1: 75.5208 (77.9000)  acc5: 92.7083 (92.3300)  time: 0.1213  data: 0.0913  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1348 s / it)\n",
            "* Acc@1 77.900 Acc@5 92.330 loss 1.115\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 78.15%\n",
            "[alpha-schedule=cosine] epoch=72 distillation_alpha=0.5752\n",
            "Epoch: [72]  [  0/781]  eta: 0:14:30  lr: 0.000013  loss: 1.1469 (1.1469)  time: 1.1142  data: 0.7749  max mem: 6459\n",
            "Epoch: [72]  [ 10/781]  eta: 0:05:10  lr: 0.000013  loss: 1.3420 (1.5148)  time: 0.4027  data: 0.0708  max mem: 6459\n",
            "Epoch: [72]  [ 20/781]  eta: 0:04:40  lr: 0.000013  loss: 1.3420 (1.5465)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 30/781]  eta: 0:04:27  lr: 0.000013  loss: 1.3710 (1.6255)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 40/781]  eta: 0:04:19  lr: 0.000013  loss: 1.3015 (1.5403)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 50/781]  eta: 0:04:13  lr: 0.000013  loss: 1.3001 (1.5119)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 60/781]  eta: 0:04:08  lr: 0.000013  loss: 1.3244 (1.4938)  time: 0.3309  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 70/781]  eta: 0:04:03  lr: 0.000013  loss: 1.2634 (1.4996)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 80/781]  eta: 0:03:58  lr: 0.000013  loss: 1.3101 (1.5052)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 90/781]  eta: 0:03:54  lr: 0.000013  loss: 1.3161 (1.5200)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [100/781]  eta: 0:03:50  lr: 0.000013  loss: 1.3333 (1.5296)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [110/781]  eta: 0:03:47  lr: 0.000013  loss: 1.2926 (1.5140)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [120/781]  eta: 0:03:43  lr: 0.000013  loss: 1.2763 (1.4996)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [130/781]  eta: 0:03:39  lr: 0.000013  loss: 1.2561 (1.4880)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [140/781]  eta: 0:03:35  lr: 0.000013  loss: 1.2530 (1.4844)  time: 0.3310  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [150/781]  eta: 0:03:32  lr: 0.000013  loss: 1.2783 (1.4912)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [160/781]  eta: 0:03:28  lr: 0.000013  loss: 1.2918 (1.4943)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [170/781]  eta: 0:03:25  lr: 0.000013  loss: 1.2867 (1.4920)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [180/781]  eta: 0:03:21  lr: 0.000013  loss: 1.2760 (1.4862)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [190/781]  eta: 0:03:18  lr: 0.000013  loss: 1.2554 (1.4769)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [200/781]  eta: 0:03:14  lr: 0.000013  loss: 1.2396 (1.4715)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [210/781]  eta: 0:03:11  lr: 0.000013  loss: 1.2885 (1.4673)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [220/781]  eta: 0:03:07  lr: 0.000013  loss: 1.3002 (1.4583)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [230/781]  eta: 0:03:04  lr: 0.000013  loss: 1.2501 (1.4527)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [240/781]  eta: 0:03:01  lr: 0.000013  loss: 1.2294 (1.4472)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [250/781]  eta: 0:02:57  lr: 0.000013  loss: 1.2377 (1.4396)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [260/781]  eta: 0:02:54  lr: 0.000013  loss: 1.2981 (1.4398)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [270/781]  eta: 0:02:50  lr: 0.000013  loss: 1.2761 (1.4362)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [280/781]  eta: 0:02:47  lr: 0.000013  loss: 1.2828 (1.4425)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.2691 (1.4420)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [300/781]  eta: 0:02:40  lr: 0.000013  loss: 1.2490 (1.4405)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [310/781]  eta: 0:02:37  lr: 0.000013  loss: 1.2661 (1.4353)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [320/781]  eta: 0:02:33  lr: 0.000013  loss: 1.2661 (1.4317)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [330/781]  eta: 0:02:30  lr: 0.000013  loss: 1.2718 (1.4323)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [340/781]  eta: 0:02:27  lr: 0.000013  loss: 1.2964 (1.4384)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [350/781]  eta: 0:02:23  lr: 0.000013  loss: 1.3489 (1.4439)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [360/781]  eta: 0:02:20  lr: 0.000013  loss: 1.3035 (1.4411)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.3210 (1.4437)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [380/781]  eta: 0:02:13  lr: 0.000013  loss: 1.3607 (1.4471)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [390/781]  eta: 0:02:10  lr: 0.000013  loss: 1.2961 (1.4426)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2766 (1.4398)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [410/781]  eta: 0:02:03  lr: 0.000013  loss: 1.2682 (1.4363)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [420/781]  eta: 0:02:00  lr: 0.000013  loss: 1.2663 (1.4373)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2779 (1.4385)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [440/781]  eta: 0:01:53  lr: 0.000013  loss: 1.2924 (1.4377)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.3173 (1.4410)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [460/781]  eta: 0:01:46  lr: 0.000013  loss: 1.3062 (1.4379)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [470/781]  eta: 0:01:43  lr: 0.000013  loss: 1.3159 (1.4393)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2882 (1.4380)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [490/781]  eta: 0:01:36  lr: 0.000013  loss: 1.2645 (1.4393)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [500/781]  eta: 0:01:33  lr: 0.000013  loss: 1.2912 (1.4372)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2912 (1.4357)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [520/781]  eta: 0:01:26  lr: 0.000013  loss: 1.2916 (1.4348)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [530/781]  eta: 0:01:23  lr: 0.000013  loss: 1.2993 (1.4331)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.3210 (1.4321)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [550/781]  eta: 0:01:16  lr: 0.000013  loss: 1.3210 (1.4307)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.3041 (1.4330)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.3039 (1.4335)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [580/781]  eta: 0:01:06  lr: 0.000013  loss: 1.3063 (1.4325)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.3529 (1.4345)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.3062 (1.4327)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [610/781]  eta: 0:00:56  lr: 0.000013  loss: 1.2932 (1.4314)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.3381 (1.4304)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.3493 (1.4292)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [640/781]  eta: 0:00:46  lr: 0.000013  loss: 1.2758 (1.4266)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2748 (1.4259)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2942 (1.4258)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [670/781]  eta: 0:00:36  lr: 0.000013  loss: 1.2942 (1.4239)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.2838 (1.4224)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.3267 (1.4242)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [700/781]  eta: 0:00:26  lr: 0.000013  loss: 1.3362 (1.4238)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.3362 (1.4276)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.3391 (1.4289)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [730/781]  eta: 0:00:16  lr: 0.000013  loss: 1.2984 (1.4287)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.2668 (1.4274)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.2959 (1.4303)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [760/781]  eta: 0:00:06  lr: 0.000013  loss: 1.3070 (1.4318)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.3137 (1.4310)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.3177 (1.4318)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [72] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.3177 (1.4318)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.328583300113678, 'lambda_convnext_base': 0.25975850224494934, 'lambda_tf_efficientnetv2_l': 0.41165825724601746}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8074 (0.8074)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8468  data: 0.8161  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9158 (0.9453)  acc1: 83.3333 (81.5814)  acc5: 94.7917 (93.7974)  time: 0.1706  data: 0.1401  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9696 (1.0078)  acc1: 81.2500 (80.3571)  acc5: 93.2292 (92.7331)  time: 0.1285  data: 0.0980  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1258 (1.0553)  acc1: 77.6042 (79.8219)  acc5: 91.6667 (92.4227)  time: 0.1357  data: 0.1053  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1903 (1.1040)  acc1: 76.5625 (78.5696)  acc5: 90.6250 (92.0605)  time: 0.1440  data: 0.1135  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1228 (1.1077)  acc1: 76.5625 (78.1454)  acc5: 92.7083 (92.2998)  time: 0.1424  data: 0.1119  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1294 (1.1208)  acc1: 76.5625 (78.0800)  acc5: 93.2292 (92.3200)  time: 0.1155  data: 0.0859  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1423 s / it)\n",
            "* Acc@1 78.080 Acc@5 92.320 loss 1.121\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.15%\n",
            "[alpha-schedule=cosine] epoch=73 distillation_alpha=0.5791\n",
            "Epoch: [73]  [  0/781]  eta: 0:14:29  lr: 0.000013  loss: 1.3471 (1.3471)  time: 1.1131  data: 0.7653  max mem: 6459\n",
            "Epoch: [73]  [ 10/781]  eta: 0:05:10  lr: 0.000013  loss: 1.3471 (1.5796)  time: 0.4032  data: 0.0699  max mem: 6459\n",
            "Epoch: [73]  [ 20/781]  eta: 0:04:40  lr: 0.000013  loss: 1.3118 (1.4975)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 30/781]  eta: 0:04:28  lr: 0.000013  loss: 1.3118 (1.5009)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 40/781]  eta: 0:04:20  lr: 0.000013  loss: 1.2740 (1.4496)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 50/781]  eta: 0:04:14  lr: 0.000013  loss: 1.2581 (1.4258)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 60/781]  eta: 0:04:08  lr: 0.000013  loss: 1.2537 (1.4264)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 70/781]  eta: 0:04:04  lr: 0.000013  loss: 1.2976 (1.4469)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 80/781]  eta: 0:03:59  lr: 0.000013  loss: 1.2998 (1.4531)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 90/781]  eta: 0:03:55  lr: 0.000013  loss: 1.2488 (1.4460)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [100/781]  eta: 0:03:51  lr: 0.000013  loss: 1.2777 (1.4300)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [110/781]  eta: 0:03:47  lr: 0.000013  loss: 1.2970 (1.4395)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [73]  [120/781]  eta: 0:03:43  lr: 0.000013  loss: 1.2884 (1.4358)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.2655 (1.4220)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [140/781]  eta: 0:03:36  lr: 0.000013  loss: 1.2394 (1.4264)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [150/781]  eta: 0:03:32  lr: 0.000013  loss: 1.3071 (1.4267)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [160/781]  eta: 0:03:29  lr: 0.000013  loss: 1.2991 (1.4273)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [170/781]  eta: 0:03:25  lr: 0.000013  loss: 1.2991 (1.4214)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [180/781]  eta: 0:03:22  lr: 0.000013  loss: 1.2562 (1.4150)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [190/781]  eta: 0:03:18  lr: 0.000013  loss: 1.2400 (1.4087)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [200/781]  eta: 0:03:15  lr: 0.000013  loss: 1.2449 (1.4025)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [210/781]  eta: 0:03:11  lr: 0.000013  loss: 1.2630 (1.4029)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [220/781]  eta: 0:03:08  lr: 0.000013  loss: 1.3089 (1.4000)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [230/781]  eta: 0:03:04  lr: 0.000013  loss: 1.2744 (1.3980)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [240/781]  eta: 0:03:01  lr: 0.000013  loss: 1.2735 (1.3984)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [250/781]  eta: 0:02:57  lr: 0.000013  loss: 1.2944 (1.4064)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [260/781]  eta: 0:02:54  lr: 0.000013  loss: 1.3770 (1.4112)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.3324 (1.4103)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [280/781]  eta: 0:02:47  lr: 0.000013  loss: 1.2729 (1.4146)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.2739 (1.4103)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [300/781]  eta: 0:02:40  lr: 0.000013  loss: 1.2757 (1.4102)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [310/781]  eta: 0:02:37  lr: 0.000013  loss: 1.2532 (1.4112)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.2350 (1.4077)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [330/781]  eta: 0:02:30  lr: 0.000013  loss: 1.3028 (1.4098)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [340/781]  eta: 0:02:27  lr: 0.000013  loss: 1.3456 (1.4103)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [350/781]  eta: 0:02:23  lr: 0.000013  loss: 1.3067 (1.4088)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [360/781]  eta: 0:02:20  lr: 0.000013  loss: 1.2774 (1.4100)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.3199 (1.4081)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [380/781]  eta: 0:02:13  lr: 0.000013  loss: 1.2758 (1.4109)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [390/781]  eta: 0:02:10  lr: 0.000013  loss: 1.2946 (1.4092)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2729 (1.4083)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [410/781]  eta: 0:02:03  lr: 0.000013  loss: 1.2718 (1.4094)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [420/781]  eta: 0:02:00  lr: 0.000013  loss: 1.2452 (1.4063)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.3027 (1.4093)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [440/781]  eta: 0:01:53  lr: 0.000013  loss: 1.3798 (1.4121)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.3171 (1.4121)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.2755 (1.4135)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [470/781]  eta: 0:01:43  lr: 0.000013  loss: 1.2755 (1.4113)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2858 (1.4136)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.3040 (1.4171)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [500/781]  eta: 0:01:33  lr: 0.000013  loss: 1.3007 (1.4149)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2688 (1.4162)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.2518 (1.4132)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [530/781]  eta: 0:01:23  lr: 0.000013  loss: 1.2457 (1.4132)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.2751 (1.4119)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.2353 (1.4112)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.2866 (1.4122)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.2436 (1.4119)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2436 (1.4090)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.2415 (1.4086)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.2346 (1.4065)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.2790 (1.4078)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.3048 (1.4082)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2911 (1.4071)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.2911 (1.4064)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2804 (1.4045)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2804 (1.4027)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [670/781]  eta: 0:00:36  lr: 0.000013  loss: 1.3019 (1.4053)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.3019 (1.4086)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.3152 (1.4098)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [700/781]  eta: 0:00:26  lr: 0.000013  loss: 1.2598 (1.4089)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.2840 (1.4121)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.3007 (1.4129)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [730/781]  eta: 0:00:16  lr: 0.000013  loss: 1.2800 (1.4137)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.2679 (1.4129)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.2679 (1.4118)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [760/781]  eta: 0:00:06  lr: 0.000013  loss: 1.2819 (1.4118)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.3102 (1.4124)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2481 (1.4098)  time: 0.3317  data: 0.0006  max mem: 6459\n",
            "Epoch: [73] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2481 (1.4098)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3297525644302368, 'lambda_convnext_base': 0.25927552580833435, 'lambda_tf_efficientnetv2_l': 0.4109719693660736}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7258 (0.7258)  acc1: 84.3750 (84.3750)  acc5: 96.8750 (96.8750)  time: 0.8475  data: 0.8169  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9203 (0.9118)  acc1: 84.3750 (82.3390)  acc5: 94.7917 (94.3655)  time: 0.1749  data: 0.1444  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9522 (0.9943)  acc1: 80.2083 (80.6300)  acc5: 94.2708 (93.1300)  time: 0.1236  data: 0.0932  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1354 (1.0512)  acc1: 76.5625 (79.6707)  acc5: 91.1458 (92.5235)  time: 0.1200  data: 0.0896  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2216 (1.0984)  acc1: 76.0417 (78.7602)  acc5: 90.6250 (92.0859)  time: 0.1155  data: 0.0850  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1160 (1.0989)  acc1: 76.0417 (78.3088)  acc5: 92.1875 (92.4326)  time: 0.1133  data: 0.0829  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1613 (1.1090)  acc1: 75.0000 (78.1900)  acc5: 92.7083 (92.4500)  time: 0.0960  data: 0.0664  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1262 s / it)\n",
            "* Acc@1 78.190 Acc@5 92.450 loss 1.109\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.19%\n",
            "[alpha-schedule=cosine] epoch=74 distillation_alpha=0.5827\n",
            "Epoch: [74]  [  0/781]  eta: 0:14:25  lr: 0.000013  loss: 1.2508 (1.2508)  time: 1.1086  data: 0.7651  max mem: 6459\n",
            "Epoch: [74]  [ 10/781]  eta: 0:05:11  lr: 0.000013  loss: 1.2707 (1.4821)  time: 0.4034  data: 0.0699  max mem: 6459\n",
            "Epoch: [74]  [ 20/781]  eta: 0:04:40  lr: 0.000013  loss: 1.2851 (1.4605)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [74]  [ 30/781]  eta: 0:04:28  lr: 0.000013  loss: 1.2851 (1.4699)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 40/781]  eta: 0:04:20  lr: 0.000013  loss: 1.2682 (1.4371)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 50/781]  eta: 0:04:13  lr: 0.000013  loss: 1.2413 (1.4187)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 60/781]  eta: 0:04:08  lr: 0.000013  loss: 1.3153 (1.4187)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 70/781]  eta: 0:04:03  lr: 0.000013  loss: 1.3104 (1.3990)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 80/781]  eta: 0:03:59  lr: 0.000013  loss: 1.2759 (1.3954)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 90/781]  eta: 0:03:55  lr: 0.000013  loss: 1.2530 (1.3964)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [100/781]  eta: 0:03:51  lr: 0.000013  loss: 1.2496 (1.3824)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [110/781]  eta: 0:03:47  lr: 0.000013  loss: 1.2677 (1.3847)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [120/781]  eta: 0:03:43  lr: 0.000013  loss: 1.3108 (1.3819)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [130/781]  eta: 0:03:39  lr: 0.000013  loss: 1.3108 (1.3867)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [140/781]  eta: 0:03:36  lr: 0.000013  loss: 1.2874 (1.3894)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [150/781]  eta: 0:03:32  lr: 0.000013  loss: 1.2863 (1.3825)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [160/781]  eta: 0:03:29  lr: 0.000013  loss: 1.2447 (1.3784)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [170/781]  eta: 0:03:25  lr: 0.000013  loss: 1.2716 (1.3840)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [180/781]  eta: 0:03:21  lr: 0.000013  loss: 1.3071 (1.3869)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [190/781]  eta: 0:03:18  lr: 0.000013  loss: 1.3265 (1.3938)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [200/781]  eta: 0:03:15  lr: 0.000013  loss: 1.2883 (1.3975)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [210/781]  eta: 0:03:11  lr: 0.000013  loss: 1.2548 (1.3963)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [220/781]  eta: 0:03:08  lr: 0.000013  loss: 1.2330 (1.3947)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [230/781]  eta: 0:03:04  lr: 0.000013  loss: 1.2366 (1.3922)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [240/781]  eta: 0:03:01  lr: 0.000013  loss: 1.2388 (1.3871)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [250/781]  eta: 0:02:57  lr: 0.000013  loss: 1.2997 (1.3957)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [260/781]  eta: 0:02:54  lr: 0.000013  loss: 1.3781 (1.3930)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.3132 (1.3936)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [280/781]  eta: 0:02:47  lr: 0.000013  loss: 1.2710 (1.3900)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.2408 (1.3884)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [300/781]  eta: 0:02:40  lr: 0.000013  loss: 1.2044 (1.3871)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [310/781]  eta: 0:02:37  lr: 0.000013  loss: 1.2605 (1.3913)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.2273 (1.3856)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [330/781]  eta: 0:02:30  lr: 0.000013  loss: 1.2364 (1.3871)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [340/781]  eta: 0:02:27  lr: 0.000013  loss: 1.2639 (1.3876)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [350/781]  eta: 0:02:23  lr: 0.000013  loss: 1.2948 (1.3891)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [360/781]  eta: 0:02:20  lr: 0.000013  loss: 1.2833 (1.3861)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.2833 (1.3848)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [380/781]  eta: 0:02:13  lr: 0.000013  loss: 1.2599 (1.3833)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [390/781]  eta: 0:02:10  lr: 0.000013  loss: 1.2573 (1.3826)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2463 (1.3846)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [410/781]  eta: 0:02:03  lr: 0.000013  loss: 1.2517 (1.3830)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [420/781]  eta: 0:02:00  lr: 0.000013  loss: 1.2418 (1.3799)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2471 (1.3779)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [440/781]  eta: 0:01:53  lr: 0.000013  loss: 1.2949 (1.3799)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.3047 (1.3801)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.2947 (1.3822)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [470/781]  eta: 0:01:43  lr: 0.000013  loss: 1.3244 (1.3826)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2490 (1.3801)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [490/781]  eta: 0:01:36  lr: 0.000013  loss: 1.2470 (1.3813)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [500/781]  eta: 0:01:33  lr: 0.000013  loss: 1.2463 (1.3807)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.3046 (1.3856)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [520/781]  eta: 0:01:26  lr: 0.000013  loss: 1.3088 (1.3849)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [530/781]  eta: 0:01:23  lr: 0.000013  loss: 1.2595 (1.3827)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.2575 (1.3807)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [550/781]  eta: 0:01:16  lr: 0.000013  loss: 1.2740 (1.3837)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.3184 (1.3850)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.3014 (1.3846)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [580/781]  eta: 0:01:06  lr: 0.000013  loss: 1.2557 (1.3839)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.2482 (1.3830)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.2442 (1.3824)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [610/781]  eta: 0:00:56  lr: 0.000013  loss: 1.2654 (1.3822)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.2621 (1.3817)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2621 (1.3818)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [640/781]  eta: 0:00:46  lr: 0.000013  loss: 1.3190 (1.3841)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2362 (1.3815)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2377 (1.3818)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [670/781]  eta: 0:00:36  lr: 0.000013  loss: 1.3372 (1.3826)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.3774 (1.3850)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.2824 (1.3831)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [700/781]  eta: 0:00:26  lr: 0.000013  loss: 1.2434 (1.3852)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.2282 (1.3847)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.2573 (1.3846)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [730/781]  eta: 0:00:16  lr: 0.000013  loss: 1.2717 (1.3862)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.2892 (1.3877)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.3008 (1.3882)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [760/781]  eta: 0:00:06  lr: 0.000013  loss: 1.3239 (1.3878)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.3225 (1.3885)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2964 (1.3877)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [74] Total time: 0:04:19 (0.3328 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2964 (1.3877)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32853907346725464, 'lambda_convnext_base': 0.25914862751960754, 'lambda_tf_efficientnetv2_l': 0.41231241822242737}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8242 (0.8242)  acc1: 84.3750 (84.3750)  acc5: 96.3542 (96.3542)  time: 0.8604  data: 0.8298  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8820 (0.9380)  acc1: 82.8125 (81.7708)  acc5: 94.7917 (94.3182)  time: 0.1798  data: 0.1494  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9778 (1.0024)  acc1: 79.6875 (80.6300)  acc5: 94.2708 (93.0804)  time: 0.1326  data: 0.1022  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1409 (1.0696)  acc1: 76.5625 (79.4187)  acc5: 90.6250 (92.3555)  time: 0.1351  data: 0.1047  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2760 (1.1146)  acc1: 76.0417 (78.3918)  acc5: 89.5833 (91.9207)  time: 0.1348  data: 0.1044  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1432 (1.1102)  acc1: 77.0833 (78.1250)  acc5: 91.6667 (92.2998)  time: 0.1328  data: 0.1023  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1500 (1.1190)  acc1: 76.0417 (78.0200)  acc5: 92.7083 (92.3300)  time: 0.1098  data: 0.0803  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1401 s / it)\n",
            "* Acc@1 78.020 Acc@5 92.330 loss 1.119\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.19%\n",
            "[alpha-schedule=cosine] epoch=75 distillation_alpha=0.5860\n",
            "Epoch: [75]  [  0/781]  eta: 0:14:37  lr: 0.000012  loss: 1.3234 (1.3234)  time: 1.1240  data: 0.7847  max mem: 6459\n",
            "Epoch: [75]  [ 10/781]  eta: 0:05:11  lr: 0.000012  loss: 1.3452 (1.4811)  time: 0.4041  data: 0.0717  max mem: 6459\n",
            "Epoch: [75]  [ 20/781]  eta: 0:04:41  lr: 0.000012  loss: 1.2655 (1.4271)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 30/781]  eta: 0:04:28  lr: 0.000012  loss: 1.2655 (1.4635)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 40/781]  eta: 0:04:20  lr: 0.000012  loss: 1.2602 (1.4097)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2485 (1.4172)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 60/781]  eta: 0:04:08  lr: 0.000012  loss: 1.2631 (1.4442)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.2495 (1.4420)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 80/781]  eta: 0:03:59  lr: 0.000012  loss: 1.2316 (1.4145)  time: 0.3321  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [ 90/781]  eta: 0:03:55  lr: 0.000012  loss: 1.2268 (1.4199)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [100/781]  eta: 0:03:51  lr: 0.000012  loss: 1.3177 (1.4376)  time: 0.3324  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [110/781]  eta: 0:03:47  lr: 0.000012  loss: 1.3147 (1.4355)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [120/781]  eta: 0:03:43  lr: 0.000012  loss: 1.3034 (1.4314)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.3134 (1.4415)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [140/781]  eta: 0:03:36  lr: 0.000012  loss: 1.3140 (1.4309)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [150/781]  eta: 0:03:32  lr: 0.000012  loss: 1.3140 (1.4431)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [160/781]  eta: 0:03:29  lr: 0.000012  loss: 1.5289 (1.4677)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [170/781]  eta: 0:03:25  lr: 0.000012  loss: 1.4111 (1.4664)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2850 (1.4561)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [190/781]  eta: 0:03:18  lr: 0.000012  loss: 1.2735 (1.4527)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.2700 (1.4510)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [210/781]  eta: 0:03:11  lr: 0.000012  loss: 1.3071 (1.4506)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.2887 (1.4525)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [230/781]  eta: 0:03:04  lr: 0.000012  loss: 1.2442 (1.4475)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [240/781]  eta: 0:03:01  lr: 0.000012  loss: 1.2442 (1.4517)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.3162 (1.4591)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [260/781]  eta: 0:02:54  lr: 0.000012  loss: 1.3250 (1.4605)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2645 (1.4528)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [280/781]  eta: 0:02:47  lr: 0.000012  loss: 1.2556 (1.4514)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2976 (1.4534)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.3280 (1.4521)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [310/781]  eta: 0:02:37  lr: 0.000012  loss: 1.2673 (1.4471)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.2856 (1.4465)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [330/781]  eta: 0:02:30  lr: 0.000012  loss: 1.2973 (1.4439)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.3009 (1.4415)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2567 (1.4360)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [360/781]  eta: 0:02:20  lr: 0.000012  loss: 1.2511 (1.4416)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.3141 (1.4407)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [380/781]  eta: 0:02:13  lr: 0.000012  loss: 1.3328 (1.4442)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [390/781]  eta: 0:02:10  lr: 0.000012  loss: 1.3041 (1.4428)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2775 (1.4469)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [410/781]  eta: 0:02:03  lr: 0.000012  loss: 1.2577 (1.4435)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2679 (1.4392)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2735 (1.4381)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [440/781]  eta: 0:01:53  lr: 0.000012  loss: 1.2964 (1.4371)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.2616 (1.4376)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.2923 (1.4373)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [470/781]  eta: 0:01:43  lr: 0.000012  loss: 1.2852 (1.4355)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.2347 (1.4333)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.2370 (1.4313)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [500/781]  eta: 0:01:33  lr: 0.000012  loss: 1.2394 (1.4295)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2331 (1.4286)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.2917 (1.4300)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [530/781]  eta: 0:01:23  lr: 0.000012  loss: 1.3185 (1.4298)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.3378 (1.4387)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.3592 (1.4392)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2969 (1.4389)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.3273 (1.4407)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.3425 (1.4404)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2744 (1.4394)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2739 (1.4367)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2814 (1.4352)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.2770 (1.4345)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2770 (1.4344)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.2940 (1.4333)  time: 0.3322  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2996 (1.4333)  time: 0.3323  data: 0.0004  max mem: 6459\n",
            "Epoch: [75]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.3032 (1.4360)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [670/781]  eta: 0:00:36  lr: 0.000012  loss: 1.2754 (1.4348)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2653 (1.4352)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.3110 (1.4354)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [700/781]  eta: 0:00:26  lr: 0.000012  loss: 1.3115 (1.4346)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.3216 (1.4353)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.3114 (1.4331)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [730/781]  eta: 0:00:16  lr: 0.000012  loss: 1.2767 (1.4334)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.2685 (1.4337)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.2429 (1.4323)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [760/781]  eta: 0:00:06  lr: 0.000012  loss: 1.3032 (1.4356)  time: 0.3325  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.4008 (1.4370)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.3385 (1.4369)  time: 0.3323  data: 0.0006  max mem: 6459\n",
            "Epoch: [75] Total time: 0:04:20 (0.3333 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.3385 (1.4369)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3285040259361267, 'lambda_convnext_base': 0.2607310116291046, 'lambda_tf_efficientnetv2_l': 0.41076526045799255}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8043 (0.8043)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8576  data: 0.8270  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8813 (0.9454)  acc1: 83.8542 (81.7235)  acc5: 94.7917 (94.0341)  time: 0.1632  data: 0.1327  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0007 (1.0009)  acc1: 79.1667 (81.0516)  acc5: 93.7500 (93.0556)  time: 0.1122  data: 0.0818  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1743 (1.0673)  acc1: 77.0833 (79.7547)  acc5: 90.6250 (92.3891)  time: 0.1349  data: 0.1043  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2477 (1.1129)  acc1: 75.5208 (78.7856)  acc5: 90.1042 (91.9715)  time: 0.1258  data: 0.0948  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0586 (1.1124)  acc1: 76.5625 (78.5641)  acc5: 92.7083 (92.2386)  time: 0.1335  data: 0.1026  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2103 (1.1262)  acc1: 76.0417 (78.4300)  acc5: 93.2292 (92.2600)  time: 0.1322  data: 0.1026  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1370 s / it)\n",
            "* Acc@1 78.430 Acc@5 92.260 loss 1.126\n",
            "Accuracy of the network on the 10000 test images: 78.4%\n",
            "Max accuracy: 78.43%\n",
            "[alpha-schedule=cosine] epoch=76 distillation_alpha=0.5889\n",
            "Epoch: [76]  [  0/781]  eta: 0:14:16  lr: 0.000012  loss: 1.2154 (1.2154)  time: 1.0966  data: 0.7547  max mem: 6459\n",
            "Epoch: [76]  [ 10/781]  eta: 0:05:09  lr: 0.000012  loss: 1.2588 (1.3657)  time: 0.4015  data: 0.0689  max mem: 6459\n",
            "Epoch: [76]  [ 20/781]  eta: 0:04:40  lr: 0.000012  loss: 1.2588 (1.3117)  time: 0.3318  data: 0.0004  max mem: 6459\n",
            "Epoch: [76]  [ 30/781]  eta: 0:04:27  lr: 0.000012  loss: 1.2648 (1.3140)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 40/781]  eta: 0:04:19  lr: 0.000012  loss: 1.2871 (1.3644)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 50/781]  eta: 0:04:13  lr: 0.000012  loss: 1.2404 (1.3384)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 60/781]  eta: 0:04:08  lr: 0.000012  loss: 1.2288 (1.3563)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 70/781]  eta: 0:04:03  lr: 0.000012  loss: 1.2697 (1.3565)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 80/781]  eta: 0:03:59  lr: 0.000012  loss: 1.2455 (1.3552)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 90/781]  eta: 0:03:55  lr: 0.000012  loss: 1.2420 (1.3605)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [100/781]  eta: 0:03:51  lr: 0.000012  loss: 1.2584 (1.3706)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [110/781]  eta: 0:03:47  lr: 0.000012  loss: 1.2584 (1.3686)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [120/781]  eta: 0:03:43  lr: 0.000012  loss: 1.2568 (1.3851)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [130/781]  eta: 0:03:39  lr: 0.000012  loss: 1.3009 (1.3907)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [140/781]  eta: 0:03:36  lr: 0.000012  loss: 1.3009 (1.3907)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [150/781]  eta: 0:03:32  lr: 0.000012  loss: 1.3099 (1.3983)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [160/781]  eta: 0:03:28  lr: 0.000012  loss: 1.3015 (1.4009)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [170/781]  eta: 0:03:25  lr: 0.000012  loss: 1.2267 (1.4054)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2807 (1.4026)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.2663 (1.3951)  time: 0.3429  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.2693 (1.4000)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.3024 (1.4040)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.2695 (1.3970)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.2475 (1.3916)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [240/781]  eta: 0:03:01  lr: 0.000012  loss: 1.2619 (1.3904)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.2701 (1.3881)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [260/781]  eta: 0:02:54  lr: 0.000012  loss: 1.2820 (1.3881)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2868 (1.3915)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [280/781]  eta: 0:02:47  lr: 0.000012  loss: 1.2415 (1.3918)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2352 (1.3917)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2398 (1.3944)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [310/781]  eta: 0:02:37  lr: 0.000012  loss: 1.2760 (1.3946)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.2776 (1.3953)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [330/781]  eta: 0:02:30  lr: 0.000012  loss: 1.3017 (1.3942)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.3033 (1.3938)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2509 (1.3891)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [360/781]  eta: 0:02:20  lr: 0.000012  loss: 1.2444 (1.3868)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.2928 (1.3854)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.2950 (1.3859)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [390/781]  eta: 0:02:10  lr: 0.000012  loss: 1.2558 (1.3842)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.3140 (1.3831)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [410/781]  eta: 0:02:03  lr: 0.000012  loss: 1.2862 (1.3826)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2499 (1.3796)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2583 (1.3787)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [440/781]  eta: 0:01:53  lr: 0.000012  loss: 1.2882 (1.3795)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.2882 (1.3783)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.3117 (1.3802)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [470/781]  eta: 0:01:43  lr: 0.000012  loss: 1.4416 (1.3892)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.3558 (1.3909)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.3335 (1.3943)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [500/781]  eta: 0:01:33  lr: 0.000012  loss: 1.3335 (1.3958)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.3076 (1.4004)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.3184 (1.4029)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [530/781]  eta: 0:01:23  lr: 0.000012  loss: 1.3824 (1.4037)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.3276 (1.4049)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.2920 (1.4037)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2726 (1.4046)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2416 (1.4027)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2416 (1.4030)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2876 (1.4043)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2823 (1.4049)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [610/781]  eta: 0:00:56  lr: 0.000012  loss: 1.3065 (1.4046)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.3033 (1.4050)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.3102 (1.4060)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [640/781]  eta: 0:00:46  lr: 0.000012  loss: 1.2744 (1.4044)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2310 (1.4032)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2917 (1.4037)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [670/781]  eta: 0:00:36  lr: 0.000012  loss: 1.2784 (1.4030)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2408 (1.4013)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.2481 (1.4024)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [700/781]  eta: 0:00:26  lr: 0.000012  loss: 1.2792 (1.4038)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2613 (1.4016)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2446 (1.4017)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [730/781]  eta: 0:00:16  lr: 0.000012  loss: 1.2617 (1.4007)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.3120 (1.4009)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.3071 (1.4029)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [760/781]  eta: 0:00:06  lr: 0.000012  loss: 1.2652 (1.4024)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2652 (1.4045)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.3248 (1.4048)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [76] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.3248 (1.4048)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3296155035495758, 'lambda_convnext_base': 0.25897449254989624, 'lambda_tf_efficientnetv2_l': 0.41141021251678467}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7550 (0.7550)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8436  data: 0.8129  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8917 (0.9411)  acc1: 84.3750 (81.7235)  acc5: 95.3125 (94.1288)  time: 0.1716  data: 0.1411  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9711 (1.0042)  acc1: 81.2500 (80.8780)  acc5: 94.2708 (93.0060)  time: 0.1274  data: 0.0969  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1877 (1.0619)  acc1: 76.5625 (79.5531)  acc5: 90.6250 (92.3723)  time: 0.1317  data: 0.1012  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2356 (1.1021)  acc1: 75.0000 (78.7348)  acc5: 90.1042 (91.9334)  time: 0.1348  data: 0.1044  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1105 (1.1029)  acc1: 77.0833 (78.4416)  acc5: 92.1875 (92.1977)  time: 0.1336  data: 0.1031  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1639 (1.1124)  acc1: 77.0833 (78.3400)  acc5: 92.1875 (92.2200)  time: 0.1117  data: 0.0821  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1377 s / it)\n",
            "* Acc@1 78.340 Acc@5 92.220 loss 1.112\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.43%\n",
            "[alpha-schedule=cosine] epoch=77 distillation_alpha=0.5915\n",
            "Epoch: [77]  [  0/781]  eta: 0:15:05  lr: 0.000011  loss: 1.2425 (1.2425)  time: 1.1595  data: 0.8116  max mem: 6459\n",
            "Epoch: [77]  [ 10/781]  eta: 0:05:13  lr: 0.000011  loss: 1.2866 (1.3879)  time: 0.4070  data: 0.0741  max mem: 6459\n",
            "Epoch: [77]  [ 20/781]  eta: 0:04:42  lr: 0.000011  loss: 1.3133 (1.5060)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 30/781]  eta: 0:04:29  lr: 0.000011  loss: 1.3190 (1.4803)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 40/781]  eta: 0:04:20  lr: 0.000011  loss: 1.3190 (1.4586)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 50/781]  eta: 0:04:14  lr: 0.000011  loss: 1.2392 (1.4139)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 60/781]  eta: 0:04:08  lr: 0.000011  loss: 1.2322 (1.4101)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 70/781]  eta: 0:04:04  lr: 0.000011  loss: 1.2375 (1.4031)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 80/781]  eta: 0:03:59  lr: 0.000011  loss: 1.2545 (1.3872)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 90/781]  eta: 0:03:55  lr: 0.000011  loss: 1.2677 (1.3836)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [100/781]  eta: 0:03:51  lr: 0.000011  loss: 1.2431 (1.3954)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [110/781]  eta: 0:03:47  lr: 0.000011  loss: 1.2535 (1.3883)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [120/781]  eta: 0:03:43  lr: 0.000011  loss: 1.2989 (1.4027)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [130/781]  eta: 0:03:40  lr: 0.000011  loss: 1.2968 (1.3993)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [140/781]  eta: 0:03:36  lr: 0.000011  loss: 1.3003 (1.4106)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [150/781]  eta: 0:03:32  lr: 0.000011  loss: 1.2678 (1.4031)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [160/781]  eta: 0:03:29  lr: 0.000011  loss: 1.2292 (1.4023)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [170/781]  eta: 0:03:25  lr: 0.000011  loss: 1.2380 (1.3926)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [180/781]  eta: 0:03:22  lr: 0.000011  loss: 1.2541 (1.4054)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [190/781]  eta: 0:03:18  lr: 0.000011  loss: 1.2932 (1.4079)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [200/781]  eta: 0:03:15  lr: 0.000011  loss: 1.2824 (1.4143)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [210/781]  eta: 0:03:11  lr: 0.000011  loss: 1.3211 (1.4217)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [220/781]  eta: 0:03:08  lr: 0.000011  loss: 1.3119 (1.4185)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [230/781]  eta: 0:03:04  lr: 0.000011  loss: 1.3119 (1.4300)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [240/781]  eta: 0:03:01  lr: 0.000011  loss: 1.3983 (1.4339)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [250/781]  eta: 0:02:57  lr: 0.000011  loss: 1.2767 (1.4298)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [260/781]  eta: 0:02:54  lr: 0.000011  loss: 1.2689 (1.4336)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.3104 (1.4321)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [280/781]  eta: 0:02:47  lr: 0.000011  loss: 1.2534 (1.4345)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [290/781]  eta: 0:02:44  lr: 0.000011  loss: 1.2694 (1.4361)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [300/781]  eta: 0:02:40  lr: 0.000011  loss: 1.2953 (1.4421)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [310/781]  eta: 0:02:37  lr: 0.000011  loss: 1.3527 (1.4412)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.3312 (1.4462)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [330/781]  eta: 0:02:30  lr: 0.000011  loss: 1.2457 (1.4467)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [340/781]  eta: 0:02:27  lr: 0.000011  loss: 1.2379 (1.4414)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [350/781]  eta: 0:02:23  lr: 0.000011  loss: 1.2476 (1.4414)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [360/781]  eta: 0:02:20  lr: 0.000011  loss: 1.2965 (1.4367)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2689 (1.4377)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [380/781]  eta: 0:02:13  lr: 0.000011  loss: 1.2923 (1.4364)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [390/781]  eta: 0:02:10  lr: 0.000011  loss: 1.2885 (1.4376)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.3238 (1.4445)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [410/781]  eta: 0:02:03  lr: 0.000011  loss: 1.3238 (1.4436)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [420/781]  eta: 0:02:00  lr: 0.000011  loss: 1.3194 (1.4423)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.3194 (1.4423)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [440/781]  eta: 0:01:53  lr: 0.000011  loss: 1.3419 (1.4439)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.2366 (1.4390)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2296 (1.4354)  time: 0.3311  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [470/781]  eta: 0:01:43  lr: 0.000011  loss: 1.2296 (1.4319)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2540 (1.4305)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2782 (1.4292)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [500/781]  eta: 0:01:33  lr: 0.000011  loss: 1.2791 (1.4302)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2698 (1.4297)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [520/781]  eta: 0:01:26  lr: 0.000011  loss: 1.2656 (1.4287)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [530/781]  eta: 0:01:23  lr: 0.000011  loss: 1.2570 (1.4268)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2844 (1.4246)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [550/781]  eta: 0:01:16  lr: 0.000011  loss: 1.2891 (1.4221)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.2823 (1.4236)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2860 (1.4245)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [580/781]  eta: 0:01:06  lr: 0.000011  loss: 1.2860 (1.4244)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2913 (1.4230)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2474 (1.4209)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [610/781]  eta: 0:00:56  lr: 0.000011  loss: 1.2837 (1.4232)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.2638 (1.4219)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2392 (1.4201)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [640/781]  eta: 0:00:46  lr: 0.000011  loss: 1.3046 (1.4218)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2716 (1.4207)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2716 (1.4193)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [670/781]  eta: 0:00:36  lr: 0.000011  loss: 1.2643 (1.4183)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2981 (1.4209)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.3674 (1.4221)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [700/781]  eta: 0:00:26  lr: 0.000011  loss: 1.2920 (1.4221)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2861 (1.4232)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2658 (1.4207)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [730/781]  eta: 0:00:16  lr: 0.000011  loss: 1.2685 (1.4197)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2687 (1.4212)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2692 (1.4199)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [760/781]  eta: 0:00:06  lr: 0.000011  loss: 1.2372 (1.4204)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2811 (1.4195)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2946 (1.4190)  time: 0.3318  data: 0.0005  max mem: 6459\n",
            "Epoch: [77] Total time: 0:04:19 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2946 (1.4190)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32916173338890076, 'lambda_convnext_base': 0.25981029868125916, 'lambda_tf_efficientnetv2_l': 0.4110279679298401}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8118 (0.8118)  acc1: 84.3750 (84.3750)  acc5: 95.3125 (95.3125)  time: 0.8511  data: 0.8204  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8711 (0.9461)  acc1: 84.3750 (81.6288)  acc5: 95.3125 (93.8447)  time: 0.1719  data: 0.1414  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9896 (1.0131)  acc1: 79.6875 (80.6052)  acc5: 93.2292 (92.8571)  time: 0.1251  data: 0.0947  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1582 (1.0698)  acc1: 76.0417 (79.4355)  acc5: 91.6667 (92.2211)  time: 0.1275  data: 0.0970  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1982 (1.1174)  acc1: 74.4792 (78.2647)  acc5: 90.6250 (91.8572)  time: 0.1290  data: 0.0985  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1217 (1.1107)  acc1: 77.6042 (78.1863)  acc5: 92.7083 (92.1569)  time: 0.1256  data: 0.0951  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1528 (1.1203)  acc1: 75.5208 (78.0700)  acc5: 92.7083 (92.1800)  time: 0.1057  data: 0.0761  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1330 s / it)\n",
            "* Acc@1 78.070 Acc@5 92.180 loss 1.120\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.43%\n",
            "[alpha-schedule=cosine] epoch=78 distillation_alpha=0.5937\n",
            "Epoch: [78]  [  0/781]  eta: 0:14:56  lr: 0.000011  loss: 1.2288 (1.2288)  time: 1.1480  data: 0.8026  max mem: 6459\n",
            "Epoch: [78]  [ 10/781]  eta: 0:05:12  lr: 0.000011  loss: 1.2825 (1.3274)  time: 0.4058  data: 0.0733  max mem: 6459\n",
            "Epoch: [78]  [ 20/781]  eta: 0:04:41  lr: 0.000011  loss: 1.2532 (1.3447)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 30/781]  eta: 0:04:28  lr: 0.000011  loss: 1.2532 (1.3506)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 40/781]  eta: 0:04:20  lr: 0.000011  loss: 1.2743 (1.3591)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 50/781]  eta: 0:04:14  lr: 0.000011  loss: 1.2987 (1.3644)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 60/781]  eta: 0:04:08  lr: 0.000011  loss: 1.2869 (1.3905)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 70/781]  eta: 0:04:03  lr: 0.000011  loss: 1.2852 (1.3970)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 80/781]  eta: 0:03:59  lr: 0.000011  loss: 1.2692 (1.3812)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 90/781]  eta: 0:03:55  lr: 0.000011  loss: 1.3169 (1.3999)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [100/781]  eta: 0:03:51  lr: 0.000011  loss: 1.2991 (1.4000)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [110/781]  eta: 0:03:47  lr: 0.000011  loss: 1.2609 (1.4009)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [120/781]  eta: 0:03:43  lr: 0.000011  loss: 1.2674 (1.3963)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [130/781]  eta: 0:03:39  lr: 0.000011  loss: 1.2674 (1.3960)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [140/781]  eta: 0:03:36  lr: 0.000011  loss: 1.2229 (1.3886)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [150/781]  eta: 0:03:32  lr: 0.000011  loss: 1.2488 (1.3828)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [160/781]  eta: 0:03:29  lr: 0.000011  loss: 1.2836 (1.3791)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [170/781]  eta: 0:03:25  lr: 0.000011  loss: 1.2511 (1.3771)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [180/781]  eta: 0:03:22  lr: 0.000011  loss: 1.2512 (1.3722)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [190/781]  eta: 0:03:18  lr: 0.000011  loss: 1.2500 (1.3657)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [200/781]  eta: 0:03:15  lr: 0.000011  loss: 1.2634 (1.3829)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [210/781]  eta: 0:03:11  lr: 0.000011  loss: 1.3077 (1.3830)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [220/781]  eta: 0:03:08  lr: 0.000011  loss: 1.2924 (1.3831)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [230/781]  eta: 0:03:04  lr: 0.000011  loss: 1.2712 (1.3815)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [240/781]  eta: 0:03:01  lr: 0.000011  loss: 1.2477 (1.3794)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [250/781]  eta: 0:02:57  lr: 0.000011  loss: 1.2743 (1.3804)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [260/781]  eta: 0:02:54  lr: 0.000011  loss: 1.2743 (1.3824)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.2840 (1.3882)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [280/781]  eta: 0:02:47  lr: 0.000011  loss: 1.2474 (1.3865)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [290/781]  eta: 0:02:44  lr: 0.000011  loss: 1.2316 (1.3852)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [300/781]  eta: 0:02:40  lr: 0.000011  loss: 1.2734 (1.3847)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [310/781]  eta: 0:02:37  lr: 0.000011  loss: 1.2734 (1.3833)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.2607 (1.3902)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [330/781]  eta: 0:02:30  lr: 0.000011  loss: 1.2780 (1.3901)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [340/781]  eta: 0:02:27  lr: 0.000011  loss: 1.2522 (1.3894)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [350/781]  eta: 0:02:23  lr: 0.000011  loss: 1.2235 (1.3851)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [360/781]  eta: 0:02:20  lr: 0.000011  loss: 1.2689 (1.3830)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2978 (1.3862)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [380/781]  eta: 0:02:13  lr: 0.000011  loss: 1.2692 (1.3865)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [390/781]  eta: 0:02:10  lr: 0.000011  loss: 1.2435 (1.3865)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.2568 (1.3878)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [410/781]  eta: 0:02:03  lr: 0.000011  loss: 1.2915 (1.3934)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [420/781]  eta: 0:02:00  lr: 0.000011  loss: 1.2802 (1.3935)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.2504 (1.3937)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [440/781]  eta: 0:01:53  lr: 0.000011  loss: 1.2626 (1.3948)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.2611 (1.3935)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2936 (1.3928)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [470/781]  eta: 0:01:43  lr: 0.000011  loss: 1.2861 (1.3902)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2861 (1.3907)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [490/781]  eta: 0:01:36  lr: 0.000011  loss: 1.2702 (1.3923)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [500/781]  eta: 0:01:33  lr: 0.000011  loss: 1.2702 (1.3904)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2599 (1.3885)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [520/781]  eta: 0:01:26  lr: 0.000011  loss: 1.2599 (1.3884)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [530/781]  eta: 0:01:23  lr: 0.000011  loss: 1.2844 (1.3915)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2696 (1.3928)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [550/781]  eta: 0:01:16  lr: 0.000011  loss: 1.2620 (1.3934)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.2620 (1.3949)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2817 (1.3952)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [580/781]  eta: 0:01:06  lr: 0.000011  loss: 1.2692 (1.3951)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2687 (1.3941)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2687 (1.3920)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [610/781]  eta: 0:00:56  lr: 0.000011  loss: 1.2656 (1.3902)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.3020 (1.3947)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.3064 (1.3936)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [640/781]  eta: 0:00:46  lr: 0.000011  loss: 1.2802 (1.3934)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2366 (1.3938)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2763 (1.3952)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [670/781]  eta: 0:00:36  lr: 0.000011  loss: 1.3229 (1.3966)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2663 (1.3962)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2215 (1.3982)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [700/781]  eta: 0:00:26  lr: 0.000011  loss: 1.3493 (1.4005)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.3493 (1.4015)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [78]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2741 (1.4037)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [730/781]  eta: 0:00:16  lr: 0.000011  loss: 1.2488 (1.4033)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2446 (1.4049)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2979 (1.4087)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [760/781]  eta: 0:00:06  lr: 0.000011  loss: 1.2979 (1.4074)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2799 (1.4079)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2667 (1.4088)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [78] Total time: 0:04:19 (0.3329 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2667 (1.4088)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3294908404350281, 'lambda_convnext_base': 0.25973305106163025, 'lambda_tf_efficientnetv2_l': 0.4107759892940521}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7724 (0.7724)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 0.8431  data: 0.8125  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8888 (0.9407)  acc1: 83.8542 (81.9129)  acc5: 94.7917 (93.8447)  time: 0.1765  data: 0.1460  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0301 (1.0080)  acc1: 78.6458 (80.4812)  acc5: 93.7500 (92.9316)  time: 0.1279  data: 0.0975  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1462 (1.0651)  acc1: 77.0833 (79.3683)  acc5: 92.1875 (92.4731)  time: 0.1340  data: 0.1035  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1900 (1.1044)  acc1: 76.0417 (78.4680)  acc5: 91.1458 (92.0986)  time: 0.1325  data: 0.1020  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0927 (1.1025)  acc1: 75.0000 (78.1250)  acc5: 92.1875 (92.3713)  time: 0.1379  data: 0.1075  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1796 (1.1128)  acc1: 75.0000 (77.9900)  acc5: 93.2292 (92.4100)  time: 0.1217  data: 0.0921  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1411 s / it)\n",
            "* Acc@1 77.990 Acc@5 92.410 loss 1.113\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.43%\n",
            "[alpha-schedule=cosine] epoch=79 distillation_alpha=0.5956\n",
            "Epoch: [79]  [  0/781]  eta: 0:14:44  lr: 0.000011  loss: 1.2687 (1.2687)  time: 1.1328  data: 0.7936  max mem: 6459\n",
            "Epoch: [79]  [ 10/781]  eta: 0:05:12  lr: 0.000011  loss: 1.2831 (1.4916)  time: 0.4048  data: 0.0724  max mem: 6459\n",
            "Epoch: [79]  [ 20/781]  eta: 0:04:49  lr: 0.000011  loss: 1.2761 (1.4376)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 30/781]  eta: 0:04:34  lr: 0.000011  loss: 1.2723 (1.4075)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 40/781]  eta: 0:04:24  lr: 0.000011  loss: 1.3332 (1.4623)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 50/781]  eta: 0:04:17  lr: 0.000011  loss: 1.2781 (1.4645)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 60/781]  eta: 0:04:11  lr: 0.000011  loss: 1.2609 (1.4658)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 70/781]  eta: 0:04:06  lr: 0.000011  loss: 1.2718 (1.4770)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 80/781]  eta: 0:04:01  lr: 0.000011  loss: 1.2747 (1.4659)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 90/781]  eta: 0:03:56  lr: 0.000011  loss: 1.2373 (1.4484)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [100/781]  eta: 0:03:52  lr: 0.000011  loss: 1.2819 (1.4844)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [110/781]  eta: 0:03:48  lr: 0.000011  loss: 1.2819 (1.4659)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [120/781]  eta: 0:03:44  lr: 0.000011  loss: 1.2482 (1.4536)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [130/781]  eta: 0:03:40  lr: 0.000011  loss: 1.2976 (1.4547)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [140/781]  eta: 0:03:37  lr: 0.000011  loss: 1.2976 (1.4448)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [150/781]  eta: 0:03:33  lr: 0.000011  loss: 1.2938 (1.4381)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [160/781]  eta: 0:03:29  lr: 0.000011  loss: 1.2557 (1.4383)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [170/781]  eta: 0:03:26  lr: 0.000011  loss: 1.2688 (1.4456)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [180/781]  eta: 0:03:22  lr: 0.000011  loss: 1.2597 (1.4385)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [190/781]  eta: 0:03:19  lr: 0.000011  loss: 1.2517 (1.4301)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [200/781]  eta: 0:03:15  lr: 0.000011  loss: 1.2514 (1.4231)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [210/781]  eta: 0:03:12  lr: 0.000011  loss: 1.2756 (1.4191)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [220/781]  eta: 0:03:08  lr: 0.000011  loss: 1.2853 (1.4218)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [230/781]  eta: 0:03:05  lr: 0.000011  loss: 1.2683 (1.4223)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [240/781]  eta: 0:03:01  lr: 0.000011  loss: 1.2798 (1.4197)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [250/781]  eta: 0:02:58  lr: 0.000011  loss: 1.2798 (1.4137)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [260/781]  eta: 0:02:54  lr: 0.000011  loss: 1.2638 (1.4166)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.2808 (1.4210)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [280/781]  eta: 0:02:47  lr: 0.000011  loss: 1.2472 (1.4179)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [290/781]  eta: 0:02:44  lr: 0.000011  loss: 1.2643 (1.4206)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [300/781]  eta: 0:02:41  lr: 0.000011  loss: 1.2845 (1.4161)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [310/781]  eta: 0:02:37  lr: 0.000011  loss: 1.2827 (1.4185)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.2906 (1.4194)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [330/781]  eta: 0:02:30  lr: 0.000011  loss: 1.3145 (1.4235)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [340/781]  eta: 0:02:27  lr: 0.000011  loss: 1.2805 (1.4225)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [350/781]  eta: 0:02:24  lr: 0.000011  loss: 1.2728 (1.4178)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [360/781]  eta: 0:02:20  lr: 0.000011  loss: 1.2533 (1.4128)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2650 (1.4131)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [380/781]  eta: 0:02:14  lr: 0.000011  loss: 1.2762 (1.4148)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [390/781]  eta: 0:02:10  lr: 0.000011  loss: 1.2952 (1.4161)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.2680 (1.4152)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [410/781]  eta: 0:02:03  lr: 0.000011  loss: 1.2380 (1.4164)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [420/781]  eta: 0:02:00  lr: 0.000011  loss: 1.2724 (1.4150)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.2939 (1.4135)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [440/781]  eta: 0:01:53  lr: 0.000011  loss: 1.3316 (1.4118)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.3316 (1.4139)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.3743 (1.4184)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [470/781]  eta: 0:01:43  lr: 0.000011  loss: 1.3676 (1.4193)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2813 (1.4185)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2626 (1.4161)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [500/781]  eta: 0:01:33  lr: 0.000011  loss: 1.3001 (1.4157)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2604 (1.4136)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [520/781]  eta: 0:01:27  lr: 0.000011  loss: 1.2489 (1.4111)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [530/781]  eta: 0:01:23  lr: 0.000011  loss: 1.2900 (1.4090)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2894 (1.4091)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [550/781]  eta: 0:01:17  lr: 0.000011  loss: 1.2458 (1.4086)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.2521 (1.4100)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2873 (1.4093)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [580/781]  eta: 0:01:07  lr: 0.000011  loss: 1.2547 (1.4094)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2303 (1.4076)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2521 (1.4070)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [610/781]  eta: 0:00:57  lr: 0.000011  loss: 1.2799 (1.4106)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.3244 (1.4101)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2140 (1.4069)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [640/781]  eta: 0:00:46  lr: 0.000011  loss: 1.2304 (1.4069)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2519 (1.4057)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2483 (1.4069)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [670/781]  eta: 0:00:36  lr: 0.000011  loss: 1.2688 (1.4056)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2933 (1.4092)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.3488 (1.4111)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [700/781]  eta: 0:00:26  lr: 0.000011  loss: 1.3352 (1.4121)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.3267 (1.4120)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.3286 (1.4142)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [730/781]  eta: 0:00:16  lr: 0.000011  loss: 1.2701 (1.4115)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2283 (1.4122)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2804 (1.4111)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [760/781]  eta: 0:00:06  lr: 0.000011  loss: 1.2893 (1.4128)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2890 (1.4121)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2596 (1.4118)  time: 0.3322  data: 0.0005  max mem: 6459\n",
            "Epoch: [79] Total time: 0:04:20 (0.3332 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2596 (1.4118)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32883569598197937, 'lambda_convnext_base': 0.2597050964832306, 'lambda_tf_efficientnetv2_l': 0.4114593267440796}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7650 (0.7650)  acc1: 86.4583 (86.4583)  acc5: 96.3542 (96.3542)  time: 0.8174  data: 0.7856  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9121 (0.9245)  acc1: 83.8542 (82.7178)  acc5: 94.7917 (94.1761)  time: 0.1746  data: 0.1440  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0116 (1.0000)  acc1: 80.7292 (81.1012)  acc5: 93.2292 (93.0308)  time: 0.1299  data: 0.0995  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1813 (1.0625)  acc1: 76.5625 (79.7379)  acc5: 91.6667 (92.4227)  time: 0.1319  data: 0.1014  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2108 (1.1082)  acc1: 75.0000 (78.7983)  acc5: 90.1042 (91.9588)  time: 0.1190  data: 0.0885  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0772 (1.1025)  acc1: 77.6042 (78.6050)  acc5: 92.1875 (92.2488)  time: 0.1350  data: 0.1046  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1141 (1.1110)  acc1: 75.0000 (78.4800)  acc5: 92.7083 (92.2800)  time: 0.1208  data: 0.0912  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1388 s / it)\n",
            "* Acc@1 78.480 Acc@5 92.280 loss 1.111\n",
            "Accuracy of the network on the 10000 test images: 78.5%\n",
            "Max accuracy: 78.48%\n",
            "[alpha-schedule=cosine] epoch=80 distillation_alpha=0.5972\n",
            "Epoch: [80]  [  0/781]  eta: 0:13:21  lr: 0.000011  loss: 1.2499 (1.2499)  time: 1.0263  data: 0.6703  max mem: 6459\n",
            "Epoch: [80]  [ 10/781]  eta: 0:05:05  lr: 0.000011  loss: 1.2136 (1.2859)  time: 0.3956  data: 0.0612  max mem: 6459\n",
            "Epoch: [80]  [ 20/781]  eta: 0:04:37  lr: 0.000011  loss: 1.2193 (1.3026)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 30/781]  eta: 0:04:25  lr: 0.000011  loss: 1.2651 (1.3173)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 40/781]  eta: 0:04:18  lr: 0.000011  loss: 1.2851 (1.3213)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 50/781]  eta: 0:04:12  lr: 0.000011  loss: 1.2578 (1.3490)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 60/781]  eta: 0:04:07  lr: 0.000011  loss: 1.2511 (1.3418)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 70/781]  eta: 0:04:02  lr: 0.000011  loss: 1.2580 (1.3409)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 80/781]  eta: 0:03:58  lr: 0.000011  loss: 1.2748 (1.3419)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 90/781]  eta: 0:03:54  lr: 0.000011  loss: 1.2748 (1.3454)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [100/781]  eta: 0:03:50  lr: 0.000011  loss: 1.2972 (1.3504)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [110/781]  eta: 0:03:46  lr: 0.000011  loss: 1.2910 (1.3417)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [120/781]  eta: 0:03:43  lr: 0.000011  loss: 1.2343 (1.3413)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [130/781]  eta: 0:03:39  lr: 0.000011  loss: 1.2343 (1.3416)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [140/781]  eta: 0:03:35  lr: 0.000011  loss: 1.2704 (1.3431)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [150/781]  eta: 0:03:32  lr: 0.000011  loss: 1.2807 (1.3466)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [160/781]  eta: 0:03:28  lr: 0.000011  loss: 1.2807 (1.3479)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [170/781]  eta: 0:03:25  lr: 0.000011  loss: 1.2744 (1.3514)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [180/781]  eta: 0:03:21  lr: 0.000011  loss: 1.2767 (1.3522)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [190/781]  eta: 0:03:18  lr: 0.000011  loss: 1.2529 (1.3489)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [200/781]  eta: 0:03:14  lr: 0.000011  loss: 1.2529 (1.3491)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [210/781]  eta: 0:03:11  lr: 0.000011  loss: 1.2877 (1.3459)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [220/781]  eta: 0:03:07  lr: 0.000011  loss: 1.2877 (1.3526)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [230/781]  eta: 0:03:04  lr: 0.000011  loss: 1.3054 (1.3537)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [240/781]  eta: 0:03:00  lr: 0.000011  loss: 1.3039 (1.3530)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [250/781]  eta: 0:02:57  lr: 0.000011  loss: 1.2465 (1.3526)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [260/781]  eta: 0:02:54  lr: 0.000011  loss: 1.2465 (1.3534)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [270/781]  eta: 0:02:50  lr: 0.000011  loss: 1.2795 (1.3555)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [280/781]  eta: 0:02:47  lr: 0.000011  loss: 1.2713 (1.3576)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [290/781]  eta: 0:02:43  lr: 0.000011  loss: 1.2713 (1.3597)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [300/781]  eta: 0:02:40  lr: 0.000011  loss: 1.2852 (1.3619)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [310/781]  eta: 0:02:37  lr: 0.000011  loss: 1.3043 (1.3648)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [320/781]  eta: 0:02:33  lr: 0.000011  loss: 1.2701 (1.3648)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [330/781]  eta: 0:02:30  lr: 0.000011  loss: 1.2509 (1.3711)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [340/781]  eta: 0:02:27  lr: 0.000011  loss: 1.2744 (1.3724)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [350/781]  eta: 0:02:23  lr: 0.000011  loss: 1.2364 (1.3701)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [360/781]  eta: 0:02:20  lr: 0.000011  loss: 1.2732 (1.3708)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2946 (1.3686)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [380/781]  eta: 0:02:13  lr: 0.000011  loss: 1.2832 (1.3703)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [390/781]  eta: 0:02:10  lr: 0.000011  loss: 1.2999 (1.3709)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [400/781]  eta: 0:02:06  lr: 0.000011  loss: 1.3241 (1.3776)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [410/781]  eta: 0:02:03  lr: 0.000011  loss: 1.3032 (1.3756)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [420/781]  eta: 0:02:00  lr: 0.000011  loss: 1.3118 (1.3743)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [430/781]  eta: 0:01:56  lr: 0.000011  loss: 1.3064 (1.3764)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [440/781]  eta: 0:01:53  lr: 0.000011  loss: 1.2455 (1.3802)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.2455 (1.3794)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [460/781]  eta: 0:01:46  lr: 0.000011  loss: 1.2536 (1.3797)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [470/781]  eta: 0:01:43  lr: 0.000011  loss: 1.2664 (1.3825)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2850 (1.3820)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [490/781]  eta: 0:01:36  lr: 0.000011  loss: 1.2776 (1.3831)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [500/781]  eta: 0:01:33  lr: 0.000011  loss: 1.2763 (1.3819)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2655 (1.3833)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [520/781]  eta: 0:01:26  lr: 0.000011  loss: 1.2735 (1.3865)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [530/781]  eta: 0:01:23  lr: 0.000011  loss: 1.2819 (1.3890)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.3036 (1.3900)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [550/781]  eta: 0:01:16  lr: 0.000011  loss: 1.2743 (1.3891)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.2743 (1.3874)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2642 (1.3870)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [580/781]  eta: 0:01:06  lr: 0.000011  loss: 1.2330 (1.3857)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2641 (1.3846)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2888 (1.3843)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [610/781]  eta: 0:00:56  lr: 0.000011  loss: 1.2751 (1.3827)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.2379 (1.3836)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2450 (1.3832)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [640/781]  eta: 0:00:46  lr: 0.000011  loss: 1.2451 (1.3810)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2965 (1.3839)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.3246 (1.3829)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [670/781]  eta: 0:00:36  lr: 0.000011  loss: 1.2662 (1.3837)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2353 (1.3832)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2323 (1.3809)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [700/781]  eta: 0:00:26  lr: 0.000011  loss: 1.2369 (1.3796)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2857 (1.3796)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2417 (1.3800)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [730/781]  eta: 0:00:16  lr: 0.000011  loss: 1.2762 (1.3819)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2762 (1.3807)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2619 (1.3815)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [760/781]  eta: 0:00:06  lr: 0.000011  loss: 1.2504 (1.3802)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2855 (1.3819)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2899 (1.3828)  time: 0.3317  data: 0.0006  max mem: 6459\n",
            "Epoch: [80] Total time: 0:04:19 (0.3326 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2899 (1.3828)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32908207178115845, 'lambda_convnext_base': 0.2587905824184418, 'lambda_tf_efficientnetv2_l': 0.4121270775794983}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7859 (0.7859)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8377  data: 0.8071  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8483 (0.9320)  acc1: 84.3750 (82.3864)  acc5: 95.3125 (94.1288)  time: 0.1793  data: 0.1489  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0545 (0.9958)  acc1: 79.6875 (81.2252)  acc5: 93.7500 (93.0804)  time: 0.1285  data: 0.0981  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1381 (1.0584)  acc1: 77.0833 (79.9059)  acc5: 91.6667 (92.5739)  time: 0.1272  data: 0.0967  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2480 (1.1028)  acc1: 76.0417 (78.8872)  acc5: 90.6250 (92.0986)  time: 0.1135  data: 0.0831  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1237 (1.1033)  acc1: 76.5625 (78.6458)  acc5: 92.1875 (92.2794)  time: 0.1357  data: 0.1052  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1330 (1.1130)  acc1: 76.0417 (78.5300)  acc5: 93.2292 (92.3000)  time: 0.1274  data: 0.0979  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1382 s / it)\n",
            "* Acc@1 78.530 Acc@5 92.300 loss 1.113\n",
            "Accuracy of the network on the 10000 test images: 78.5%\n",
            "Max accuracy: 78.53%\n",
            "[alpha-schedule=cosine] epoch=81 distillation_alpha=0.5984\n",
            "Epoch: [81]  [  0/781]  eta: 0:14:48  lr: 0.000010  loss: 1.1863 (1.1863)  time: 1.1380  data: 0.7999  max mem: 6459\n",
            "Epoch: [81]  [ 10/781]  eta: 0:05:12  lr: 0.000010  loss: 1.2755 (1.5304)  time: 0.4050  data: 0.0730  max mem: 6459\n",
            "Epoch: [81]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2556 (1.4147)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2206 (1.3923)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2686 (1.4775)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 50/781]  eta: 0:04:13  lr: 0.000010  loss: 1.2738 (1.4537)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 60/781]  eta: 0:04:08  lr: 0.000010  loss: 1.2398 (1.4403)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 70/781]  eta: 0:04:03  lr: 0.000010  loss: 1.2406 (1.4325)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 80/781]  eta: 0:03:59  lr: 0.000010  loss: 1.3110 (1.4538)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 90/781]  eta: 0:03:55  lr: 0.000010  loss: 1.3110 (1.4545)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [100/781]  eta: 0:03:51  lr: 0.000010  loss: 1.2295 (1.4411)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [110/781]  eta: 0:03:47  lr: 0.000010  loss: 1.2380 (1.4413)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [120/781]  eta: 0:03:43  lr: 0.000010  loss: 1.2610 (1.4378)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [130/781]  eta: 0:03:39  lr: 0.000010  loss: 1.2579 (1.4271)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [140/781]  eta: 0:03:36  lr: 0.000010  loss: 1.2579 (1.4192)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [150/781]  eta: 0:03:32  lr: 0.000010  loss: 1.2714 (1.4160)  time: 0.3312  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [160/781]  eta: 0:03:28  lr: 0.000010  loss: 1.2757 (1.4175)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [170/781]  eta: 0:03:25  lr: 0.000010  loss: 1.2590 (1.4153)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [180/781]  eta: 0:03:21  lr: 0.000010  loss: 1.2542 (1.4102)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [190/781]  eta: 0:03:18  lr: 0.000010  loss: 1.3165 (1.4145)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [200/781]  eta: 0:03:14  lr: 0.000010  loss: 1.3044 (1.4185)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [210/781]  eta: 0:03:11  lr: 0.000010  loss: 1.3140 (1.4171)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [220/781]  eta: 0:03:07  lr: 0.000010  loss: 1.3140 (1.4146)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [230/781]  eta: 0:03:04  lr: 0.000010  loss: 1.2489 (1.4123)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [240/781]  eta: 0:03:01  lr: 0.000010  loss: 1.2633 (1.4135)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [250/781]  eta: 0:02:57  lr: 0.000010  loss: 1.2633 (1.4072)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [260/781]  eta: 0:02:54  lr: 0.000010  loss: 1.2560 (1.4019)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [270/781]  eta: 0:02:50  lr: 0.000010  loss: 1.2877 (1.4012)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [280/781]  eta: 0:02:47  lr: 0.000010  loss: 1.2570 (1.4052)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2461 (1.4075)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [300/781]  eta: 0:02:40  lr: 0.000010  loss: 1.2778 (1.4082)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [310/781]  eta: 0:02:37  lr: 0.000010  loss: 1.2795 (1.4097)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [320/781]  eta: 0:02:33  lr: 0.000010  loss: 1.2848 (1.4158)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [330/781]  eta: 0:02:30  lr: 0.000010  loss: 1.3180 (1.4149)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2743 (1.4152)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [350/781]  eta: 0:02:23  lr: 0.000010  loss: 1.2876 (1.4177)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [360/781]  eta: 0:02:20  lr: 0.000010  loss: 1.2963 (1.4194)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2454 (1.4154)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [380/781]  eta: 0:02:13  lr: 0.000010  loss: 1.2011 (1.4125)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [390/781]  eta: 0:02:10  lr: 0.000010  loss: 1.2218 (1.4101)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2674 (1.4138)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [410/781]  eta: 0:02:03  lr: 0.000010  loss: 1.3231 (1.4151)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2814 (1.4117)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2448 (1.4131)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [440/781]  eta: 0:01:53  lr: 0.000010  loss: 1.2448 (1.4155)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.2480 (1.4123)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [460/781]  eta: 0:01:46  lr: 0.000010  loss: 1.2442 (1.4121)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [470/781]  eta: 0:01:43  lr: 0.000010  loss: 1.2444 (1.4110)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2885 (1.4135)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [490/781]  eta: 0:01:36  lr: 0.000010  loss: 1.2267 (1.4092)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [500/781]  eta: 0:01:33  lr: 0.000010  loss: 1.2041 (1.4074)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2761 (1.4112)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [520/781]  eta: 0:01:26  lr: 0.000010  loss: 1.2415 (1.4079)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [530/781]  eta: 0:01:23  lr: 0.000010  loss: 1.2324 (1.4091)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2485 (1.4061)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [550/781]  eta: 0:01:16  lr: 0.000010  loss: 1.2976 (1.4101)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.3418 (1.4110)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.3258 (1.4123)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [580/781]  eta: 0:01:06  lr: 0.000010  loss: 1.2781 (1.4117)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2558 (1.4116)  time: 0.3426  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2659 (1.4111)  time: 0.3424  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [610/781]  eta: 0:00:56  lr: 0.000010  loss: 1.2752 (1.4135)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2046 (1.4105)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2667 (1.4094)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [640/781]  eta: 0:00:46  lr: 0.000010  loss: 1.3043 (1.4112)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2975 (1.4097)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2828 (1.4082)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [670/781]  eta: 0:00:36  lr: 0.000010  loss: 1.2778 (1.4080)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2778 (1.4062)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2804 (1.4062)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [700/781]  eta: 0:00:26  lr: 0.000010  loss: 1.2450 (1.4056)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2458 (1.4062)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2458 (1.4062)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [730/781]  eta: 0:00:16  lr: 0.000010  loss: 1.2721 (1.4072)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.3010 (1.4088)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.3267 (1.4100)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [760/781]  eta: 0:00:06  lr: 0.000010  loss: 1.3198 (1.4088)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2662 (1.4087)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2689 (1.4101)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [81] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2689 (1.4101)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3296931982040405, 'lambda_convnext_base': 0.2597440779209137, 'lambda_tf_efficientnetv2_l': 0.4105626344680786}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8456 (0.8456)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8459  data: 0.8152  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8599 (0.9490)  acc1: 83.3333 (81.4394)  acc5: 94.7917 (93.7974)  time: 0.1789  data: 0.1485  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0101 (1.0114)  acc1: 79.6875 (80.7044)  acc5: 93.7500 (92.8323)  time: 0.1334  data: 0.1029  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1589 (1.0757)  acc1: 77.6042 (79.5363)  acc5: 91.6667 (92.2547)  time: 0.1347  data: 0.1042  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2882 (1.1068)  acc1: 75.0000 (78.8491)  acc5: 90.6250 (91.9461)  time: 0.1359  data: 0.1055  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1296 (1.1059)  acc1: 76.5625 (78.5335)  acc5: 92.7083 (92.2181)  time: 0.1358  data: 0.1054  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1421 (1.1145)  acc1: 76.5625 (78.4000)  acc5: 93.7500 (92.2500)  time: 0.1141  data: 0.0846  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1409 s / it)\n",
            "* Acc@1 78.400 Acc@5 92.250 loss 1.115\n",
            "Accuracy of the network on the 10000 test images: 78.4%\n",
            "Max accuracy: 78.53%\n",
            "[alpha-schedule=cosine] epoch=82 distillation_alpha=0.5993\n",
            "Epoch: [82]  [  0/781]  eta: 0:14:45  lr: 0.000010  loss: 1.1853 (1.1853)  time: 1.1341  data: 0.7962  max mem: 6459\n",
            "Epoch: [82]  [ 10/781]  eta: 0:05:12  lr: 0.000010  loss: 1.2561 (1.3540)  time: 0.4047  data: 0.0727  max mem: 6459\n",
            "Epoch: [82]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2561 (1.3658)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2395 (1.3624)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2395 (1.3372)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 50/781]  eta: 0:04:13  lr: 0.000010  loss: 1.2909 (1.4135)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 60/781]  eta: 0:04:08  lr: 0.000010  loss: 1.2569 (1.3830)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 70/781]  eta: 0:04:03  lr: 0.000010  loss: 1.2445 (1.3646)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 80/781]  eta: 0:03:59  lr: 0.000010  loss: 1.2514 (1.3802)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 90/781]  eta: 0:03:55  lr: 0.000010  loss: 1.3102 (1.3786)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [100/781]  eta: 0:03:51  lr: 0.000010  loss: 1.3084 (1.3767)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [110/781]  eta: 0:03:47  lr: 0.000010  loss: 1.2471 (1.3718)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [120/781]  eta: 0:03:43  lr: 0.000010  loss: 1.1989 (1.3668)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [130/781]  eta: 0:03:39  lr: 0.000010  loss: 1.2117 (1.3791)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [140/781]  eta: 0:03:36  lr: 0.000010  loss: 1.2921 (1.3781)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [150/781]  eta: 0:03:32  lr: 0.000010  loss: 1.2623 (1.3895)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2877 (1.3896)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [170/781]  eta: 0:03:25  lr: 0.000010  loss: 1.2877 (1.3966)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [180/781]  eta: 0:03:21  lr: 0.000010  loss: 1.2718 (1.3988)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [190/781]  eta: 0:03:18  lr: 0.000010  loss: 1.2547 (1.3908)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [200/781]  eta: 0:03:14  lr: 0.000010  loss: 1.2634 (1.3920)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [210/781]  eta: 0:03:11  lr: 0.000010  loss: 1.2634 (1.3880)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2283 (1.3870)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [230/781]  eta: 0:03:04  lr: 0.000010  loss: 1.2672 (1.3876)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [240/781]  eta: 0:03:01  lr: 0.000010  loss: 1.2916 (1.3854)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [250/781]  eta: 0:02:57  lr: 0.000010  loss: 1.2877 (1.3905)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [260/781]  eta: 0:02:54  lr: 0.000010  loss: 1.2877 (1.3906)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [270/781]  eta: 0:02:50  lr: 0.000010  loss: 1.2790 (1.3940)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [280/781]  eta: 0:02:47  lr: 0.000010  loss: 1.2739 (1.3930)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2490 (1.3921)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [300/781]  eta: 0:02:40  lr: 0.000010  loss: 1.2162 (1.3856)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [310/781]  eta: 0:02:37  lr: 0.000010  loss: 1.2221 (1.3886)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2656 (1.3871)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [330/781]  eta: 0:02:30  lr: 0.000010  loss: 1.2339 (1.3828)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2396 (1.3799)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [350/781]  eta: 0:02:23  lr: 0.000010  loss: 1.2396 (1.3782)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [360/781]  eta: 0:02:20  lr: 0.000010  loss: 1.2279 (1.3788)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2687 (1.3790)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [380/781]  eta: 0:02:13  lr: 0.000010  loss: 1.2812 (1.3804)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [390/781]  eta: 0:02:10  lr: 0.000010  loss: 1.3044 (1.3843)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2919 (1.3879)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [410/781]  eta: 0:02:03  lr: 0.000010  loss: 1.2483 (1.3871)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2649 (1.3909)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.3155 (1.3931)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [440/781]  eta: 0:01:53  lr: 0.000010  loss: 1.2693 (1.3929)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.2019 (1.3896)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.1837 (1.3860)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [470/781]  eta: 0:01:43  lr: 0.000010  loss: 1.2297 (1.3883)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2935 (1.3894)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [490/781]  eta: 0:01:36  lr: 0.000010  loss: 1.2531 (1.3889)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [500/781]  eta: 0:01:33  lr: 0.000010  loss: 1.2531 (1.3897)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2552 (1.3878)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [520/781]  eta: 0:01:26  lr: 0.000010  loss: 1.1929 (1.3898)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [530/781]  eta: 0:01:23  lr: 0.000010  loss: 1.2406 (1.3874)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2406 (1.3878)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [550/781]  eta: 0:01:16  lr: 0.000010  loss: 1.2263 (1.3852)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2377 (1.3838)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2405 (1.3818)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [580/781]  eta: 0:01:06  lr: 0.000010  loss: 1.2428 (1.3819)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2661 (1.3805)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.3151 (1.3851)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [610/781]  eta: 0:00:56  lr: 0.000010  loss: 1.3308 (1.3875)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2719 (1.3873)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2719 (1.3877)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [640/781]  eta: 0:00:46  lr: 0.000010  loss: 1.3047 (1.3871)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2450 (1.3861)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2846 (1.3856)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [670/781]  eta: 0:00:36  lr: 0.000010  loss: 1.2900 (1.3856)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.3102 (1.3842)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2529 (1.3856)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [700/781]  eta: 0:00:26  lr: 0.000010  loss: 1.2791 (1.3872)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.3026 (1.3901)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.3026 (1.3892)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [730/781]  eta: 0:00:16  lr: 0.000010  loss: 1.2878 (1.3919)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2993 (1.3939)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.3076 (1.3938)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [760/781]  eta: 0:00:06  lr: 0.000010  loss: 1.3170 (1.3936)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.3170 (1.3930)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2672 (1.3954)  time: 0.3320  data: 0.0006  max mem: 6459\n",
            "Epoch: [82] Total time: 0:04:19 (0.3327 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2672 (1.3954)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32881325483322144, 'lambda_convnext_base': 0.25966742634773254, 'lambda_tf_efficientnetv2_l': 0.41151949763298035}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7758 (0.7758)  acc1: 83.8542 (83.8542)  acc5: 95.8333 (95.8333)  time: 0.8392  data: 0.8084  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8396 (0.9305)  acc1: 83.8542 (82.1023)  acc5: 95.3125 (94.2235)  time: 0.1749  data: 0.1444  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9637 (0.9976)  acc1: 80.2083 (80.8780)  acc5: 93.7500 (93.0556)  time: 0.1307  data: 0.1002  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1374 (1.0610)  acc1: 76.5625 (79.7379)  acc5: 91.6667 (92.3723)  time: 0.1334  data: 0.1030  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2051 (1.1019)  acc1: 76.0417 (78.8745)  acc5: 90.6250 (91.9334)  time: 0.1346  data: 0.1041  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1195 (1.0994)  acc1: 76.5625 (78.5743)  acc5: 92.1875 (92.2386)  time: 0.1376  data: 0.1071  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1235 (1.1108)  acc1: 75.5208 (78.4700)  acc5: 92.7083 (92.2600)  time: 0.1166  data: 0.0870  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1406 s / it)\n",
            "* Acc@1 78.470 Acc@5 92.260 loss 1.111\n",
            "Accuracy of the network on the 10000 test images: 78.5%\n",
            "Max accuracy: 78.53%\n",
            "[alpha-schedule=cosine] epoch=83 distillation_alpha=0.5998\n",
            "Epoch: [83]  [  0/781]  eta: 0:14:33  lr: 0.000010  loss: 1.3692 (1.3692)  time: 1.1179  data: 0.7734  max mem: 6459\n",
            "Epoch: [83]  [ 10/781]  eta: 0:05:11  lr: 0.000010  loss: 1.2214 (1.3493)  time: 0.4036  data: 0.0706  max mem: 6459\n",
            "Epoch: [83]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2097 (1.3616)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2683 (1.3493)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2697 (1.3322)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 50/781]  eta: 0:04:13  lr: 0.000010  loss: 1.2513 (1.3553)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 60/781]  eta: 0:04:08  lr: 0.000010  loss: 1.2444 (1.3708)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 70/781]  eta: 0:04:03  lr: 0.000010  loss: 1.2360 (1.3592)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 80/781]  eta: 0:03:59  lr: 0.000010  loss: 1.2280 (1.3466)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 90/781]  eta: 0:03:55  lr: 0.000010  loss: 1.2488 (1.3498)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [100/781]  eta: 0:03:51  lr: 0.000010  loss: 1.2673 (1.3782)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [110/781]  eta: 0:03:47  lr: 0.000010  loss: 1.2896 (1.3725)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [120/781]  eta: 0:03:43  lr: 0.000010  loss: 1.3081 (1.3858)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [130/781]  eta: 0:03:39  lr: 0.000010  loss: 1.2857 (1.3760)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [140/781]  eta: 0:03:36  lr: 0.000010  loss: 1.2501 (1.3774)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [150/781]  eta: 0:03:32  lr: 0.000010  loss: 1.2501 (1.3707)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2571 (1.3751)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [170/781]  eta: 0:03:25  lr: 0.000010  loss: 1.3022 (1.3857)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2590 (1.3797)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [190/781]  eta: 0:03:18  lr: 0.000010  loss: 1.2615 (1.3864)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2928 (1.3947)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [210/781]  eta: 0:03:11  lr: 0.000010  loss: 1.3239 (1.4038)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2964 (1.4060)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [230/781]  eta: 0:03:04  lr: 0.000010  loss: 1.2619 (1.4048)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [240/781]  eta: 0:03:01  lr: 0.000010  loss: 1.2059 (1.4038)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [250/781]  eta: 0:02:57  lr: 0.000010  loss: 1.2510 (1.3983)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [260/781]  eta: 0:02:54  lr: 0.000010  loss: 1.2379 (1.3942)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [270/781]  eta: 0:02:51  lr: 0.000010  loss: 1.2379 (1.3902)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [280/781]  eta: 0:02:47  lr: 0.000010  loss: 1.3120 (1.3998)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2811 (1.3948)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [300/781]  eta: 0:02:40  lr: 0.000010  loss: 1.2811 (1.3984)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [310/781]  eta: 0:02:37  lr: 0.000010  loss: 1.2852 (1.3985)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.3107 (1.3996)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [330/781]  eta: 0:02:30  lr: 0.000010  loss: 1.3107 (1.4019)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2772 (1.3986)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [350/781]  eta: 0:02:23  lr: 0.000010  loss: 1.2745 (1.4016)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [360/781]  eta: 0:02:20  lr: 0.000010  loss: 1.2572 (1.3981)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2690 (1.4048)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [380/781]  eta: 0:02:13  lr: 0.000010  loss: 1.2301 (1.4037)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [390/781]  eta: 0:02:10  lr: 0.000010  loss: 1.2527 (1.4055)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2658 (1.4073)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [410/781]  eta: 0:02:03  lr: 0.000010  loss: 1.2603 (1.4058)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2487 (1.4033)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2682 (1.4040)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [440/781]  eta: 0:01:53  lr: 0.000010  loss: 1.3173 (1.4093)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.2347 (1.4073)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2141 (1.4074)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [470/781]  eta: 0:01:43  lr: 0.000010  loss: 1.2423 (1.4049)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2600 (1.4039)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.2644 (1.4028)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [500/781]  eta: 0:01:33  lr: 0.000010  loss: 1.2371 (1.3985)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2249 (1.3966)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [520/781]  eta: 0:01:26  lr: 0.000010  loss: 1.2973 (1.3976)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [530/781]  eta: 0:01:23  lr: 0.000010  loss: 1.2894 (1.3994)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2625 (1.3994)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [550/781]  eta: 0:01:16  lr: 0.000010  loss: 1.2625 (1.4001)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2603 (1.3987)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2488 (1.3980)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [580/781]  eta: 0:01:06  lr: 0.000010  loss: 1.2727 (1.3986)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2663 (1.3990)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2663 (1.4007)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [610/781]  eta: 0:00:56  lr: 0.000010  loss: 1.2773 (1.4016)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.3193 (1.4022)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2798 (1.4017)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [640/781]  eta: 0:00:46  lr: 0.000010  loss: 1.2131 (1.4060)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2327 (1.4033)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2324 (1.4035)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [670/781]  eta: 0:00:36  lr: 0.000010  loss: 1.3043 (1.4046)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2666 (1.4042)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.3067 (1.4072)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [700/781]  eta: 0:00:26  lr: 0.000010  loss: 1.3067 (1.4079)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2791 (1.4090)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2786 (1.4086)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [730/781]  eta: 0:00:16  lr: 0.000010  loss: 1.3166 (1.4118)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2627 (1.4114)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2536 (1.4117)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [760/781]  eta: 0:00:06  lr: 0.000010  loss: 1.3011 (1.4117)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2762 (1.4117)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2650 (1.4107)  time: 0.3327  data: 0.0006  max mem: 6459\n",
            "Epoch: [83] Total time: 0:04:20 (0.3330 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2650 (1.4107)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32849860191345215, 'lambda_convnext_base': 0.2596409022808075, 'lambda_tf_efficientnetv2_l': 0.41186007857322693}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7806 (0.7806)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 0.8448  data: 0.8141  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8844 (0.9303)  acc1: 83.8542 (82.2917)  acc5: 95.3125 (94.0341)  time: 0.1728  data: 0.1423  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0136 (0.9954)  acc1: 79.6875 (81.1260)  acc5: 94.2708 (93.1796)  time: 0.1303  data: 0.0998  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1588 (1.0632)  acc1: 77.0833 (79.6539)  acc5: 91.1458 (92.4227)  time: 0.1312  data: 0.1007  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2836 (1.1014)  acc1: 75.0000 (78.7729)  acc5: 91.1458 (92.0351)  time: 0.1286  data: 0.0981  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1328 (1.1036)  acc1: 76.0417 (78.4110)  acc5: 92.1875 (92.2896)  time: 0.1309  data: 0.1004  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1924 (1.1184)  acc1: 75.0000 (78.2700)  acc5: 92.7083 (92.3100)  time: 0.1102  data: 0.0806  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1364 s / it)\n",
            "* Acc@1 78.270 Acc@5 92.310 loss 1.118\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.53%\n",
            "[alpha-schedule=cosine] epoch=84 distillation_alpha=0.6000\n",
            "Epoch: [84]  [  0/781]  eta: 0:14:14  lr: 0.000010  loss: 2.3959 (2.3959)  time: 1.0939  data: 0.7488  max mem: 6459\n",
            "Epoch: [84]  [ 10/781]  eta: 0:05:09  lr: 0.000010  loss: 1.2677 (1.4495)  time: 0.4013  data: 0.0684  max mem: 6459\n",
            "Epoch: [84]  [ 20/781]  eta: 0:04:40  lr: 0.000010  loss: 1.2524 (1.3869)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 30/781]  eta: 0:04:27  lr: 0.000010  loss: 1.2132 (1.3319)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 40/781]  eta: 0:04:19  lr: 0.000010  loss: 1.2419 (1.3240)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 50/781]  eta: 0:04:13  lr: 0.000010  loss: 1.3092 (1.3592)  time: 0.3322  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 60/781]  eta: 0:04:08  lr: 0.000010  loss: 1.3092 (1.3641)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 70/781]  eta: 0:04:03  lr: 0.000010  loss: 1.2771 (1.3793)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 80/781]  eta: 0:03:59  lr: 0.000010  loss: 1.2771 (1.4039)  time: 0.3320  data: 0.0004  max mem: 6459\n",
            "Epoch: [84]  [ 90/781]  eta: 0:03:55  lr: 0.000010  loss: 1.2747 (1.4126)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [100/781]  eta: 0:03:51  lr: 0.000010  loss: 1.2747 (1.4104)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [110/781]  eta: 0:03:47  lr: 0.000010  loss: 1.3140 (1.4149)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [120/781]  eta: 0:03:43  lr: 0.000010  loss: 1.3326 (1.4147)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [130/781]  eta: 0:03:39  lr: 0.000010  loss: 1.3326 (1.4271)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [140/781]  eta: 0:03:36  lr: 0.000010  loss: 1.2991 (1.4323)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [150/781]  eta: 0:03:32  lr: 0.000010  loss: 1.2816 (1.4376)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2722 (1.4356)  time: 0.3324  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [170/781]  eta: 0:03:25  lr: 0.000010  loss: 1.2537 (1.4298)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2311 (1.4199)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [190/781]  eta: 0:03:18  lr: 0.000010  loss: 1.2037 (1.4144)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2015 (1.4100)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [210/781]  eta: 0:03:11  lr: 0.000010  loss: 1.2437 (1.4082)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2526 (1.4072)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [230/781]  eta: 0:03:04  lr: 0.000010  loss: 1.2526 (1.4026)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [240/781]  eta: 0:03:01  lr: 0.000010  loss: 1.2849 (1.4037)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [250/781]  eta: 0:02:57  lr: 0.000010  loss: 1.2112 (1.3991)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [260/781]  eta: 0:02:54  lr: 0.000010  loss: 1.2335 (1.4051)  time: 0.3320  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [270/781]  eta: 0:02:51  lr: 0.000010  loss: 1.2348 (1.4030)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [280/781]  eta: 0:02:47  lr: 0.000010  loss: 1.2798 (1.4037)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2964 (1.4048)  time: 0.3323  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [300/781]  eta: 0:02:40  lr: 0.000010  loss: 1.2552 (1.4073)  time: 0.3321  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [310/781]  eta: 0:02:37  lr: 0.000010  loss: 1.2339 (1.4040)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2339 (1.3995)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [330/781]  eta: 0:02:30  lr: 0.000010  loss: 1.2765 (1.3965)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2767 (1.3945)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [350/781]  eta: 0:02:23  lr: 0.000010  loss: 1.2665 (1.3945)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [360/781]  eta: 0:02:20  lr: 0.000010  loss: 1.2284 (1.3951)  time: 0.3427  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2229 (1.3942)  time: 0.3428  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2518 (1.3955)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [390/781]  eta: 0:02:10  lr: 0.000010  loss: 1.2978 (1.3960)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2629 (1.3977)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [410/781]  eta: 0:02:03  lr: 0.000010  loss: 1.3007 (1.3971)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.3182 (1.3972)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2750 (1.3994)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [440/781]  eta: 0:01:53  lr: 0.000010  loss: 1.2906 (1.4007)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.3112 (1.4066)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2435 (1.4058)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [470/781]  eta: 0:01:43  lr: 0.000010  loss: 1.2291 (1.4016)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2377 (1.3985)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.2510 (1.4048)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [500/781]  eta: 0:01:33  lr: 0.000010  loss: 1.2889 (1.4038)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2880 (1.4017)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2500 (1.3988)  time: 0.3313  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [530/781]  eta: 0:01:23  lr: 0.000010  loss: 1.2530 (1.3998)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2630 (1.3991)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2466 (1.3969)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2493 (1.3971)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2785 (1.3974)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2785 (1.3984)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2390 (1.3993)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2193 (1.3968)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [610/781]  eta: 0:00:56  lr: 0.000010  loss: 1.2649 (1.4000)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2261 (1.3978)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2252 (1.3966)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [640/781]  eta: 0:00:46  lr: 0.000010  loss: 1.2410 (1.3964)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2498 (1.3943)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2581 (1.3963)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [670/781]  eta: 0:00:36  lr: 0.000010  loss: 1.2906 (1.3959)  time: 0.3319  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2900 (1.3961)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2911 (1.3959)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [700/781]  eta: 0:00:26  lr: 0.000010  loss: 1.2581 (1.3946)  time: 0.3315  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2637 (1.3962)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2554 (1.3941)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [730/781]  eta: 0:00:16  lr: 0.000010  loss: 1.2441 (1.3978)  time: 0.3314  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.3745 (1.4003)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.3128 (1.3997)  time: 0.3318  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [760/781]  eta: 0:00:06  lr: 0.000010  loss: 1.2515 (1.4007)  time: 0.3317  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2807 (1.4036)  time: 0.3316  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2917 (1.4032)  time: 0.3318  data: 0.0006  max mem: 6459\n",
            "Epoch: [84] Total time: 0:04:20 (0.3331 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2917 (1.4032)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3289836645126343, 'lambda_convnext_base': 0.2597953677177429, 'lambda_tf_efficientnetv2_l': 0.41122061014175415}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7783 (0.7783)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8666  data: 0.8359  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8276 (0.9285)  acc1: 83.3333 (82.1970)  acc5: 94.7917 (93.7974)  time: 0.1752  data: 0.1447  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0234 (1.0065)  acc1: 80.2083 (80.7044)  acc5: 93.7500 (93.0060)  time: 0.1296  data: 0.0991  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1992 (1.0665)  acc1: 76.5625 (79.6707)  acc5: 92.1875 (92.3723)  time: 0.1334  data: 0.1029  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2407 (1.1069)  acc1: 76.0417 (78.8237)  acc5: 91.1458 (92.0478)  time: 0.1177  data: 0.0872  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1156 (1.1050)  acc1: 76.0417 (78.4722)  acc5: 92.7083 (92.3407)  time: 0.1374  data: 0.1069  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1561 (1.1219)  acc1: 75.0000 (78.3400)  acc5: 92.7083 (92.3500)  time: 0.1277  data: 0.0981  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1405 s / it)\n",
            "* Acc@1 78.340 Acc@5 92.350 loss 1.122\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.53%\n",
            "Training time 6:19:37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show lines first (sanity check)\n",
        "!grep -n \"torch.load(args.resume\" /content/deit/main.py\n",
        "!grep -n \"torch.load(args.finetune\" /content/deit/main.py\n",
        "\n",
        "# Patch resume loader\n",
        "!sed -i \"s/torch.load(args.resume, map_location='cpu')/torch.load(args.resume, map_location='cpu', weights_only=False)/\" /content/deit/main.py\n",
        "\n",
        "# Patch finetune loader\n",
        "!sed -i \"s/torch.load(args.finetune, map_location='cpu')/torch.load(args.finetune, map_location='cpu', weights_only=False)/\" /content/deit/main.py"
      ],
      "metadata": {
        "id": "dojEucZ-wuv7",
        "outputId": "b8303915-6fd4-471f-8f55-c390c0f72021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "462:            checkpoint = torch.load(args.resume, map_location='cpu')\n",
            "305:            checkpoint = torch.load(args.finetune, map_location='cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "!python main.py \\\n",
        "  --model deit_tiny_patch16_224 \\\n",
        "  --data-path /content/tiny-imagenet-200 \\\n",
        "  --finetune /content/deit_runs/tiny_imagenet/best_checkpoint.pth \\\n",
        "  --epochs 15 \\\n",
        "  --batch-size 128 \\\n",
        "  --num_workers 4 \\\n",
        "  --input-size 224 \\\n",
        "  --opt adamw \\\n",
        "  --lr 2.5e-5 \\\n",
        "  --weight-decay 0.02 \\\n",
        "  --sched cosine \\\n",
        "  --warmup-epochs 0 \\\n",
        "  --smoothing 0.05 \\\n",
        "  --aa rand-m3-mstd0.5 \\\n",
        "  --reprob 0.0 \\\n",
        "  --model-ema \\\n",
        "  --model-ema-decay 0.9999 \\\n",
        "  --drop-path 0.0 \\\n",
        "  --mixup 0.0 \\\n",
        "  --cutmix 0.0 \\\n",
        "  --mixup-prob 0.0 \\\n",
        "  --distillation-type soft \\\n",
        "  --distillation-alpha 0.25 \\\n",
        "  --distillation-tau 2.0 \\\n",
        "  --hdtse-warmup-epochs 0 \\\n",
        "  --lambda-log \\\n",
        "  --output_dir /content/deit_runs/tiny_imagenet_tail20_best \\\n",
        "  --teacher-models \"swin_base_patch4_window7_224,convnext_base,tf_efficientnetv2_l\""
      ],
      "metadata": {
        "id": "OeJBYHgQw8NO",
        "outputId": "616a7e07-9437-498e-8806-b19c69be909a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "Not using distributed mode\n",
            "Namespace(batch_size=128, epochs=20, bce_loss=False, unscale_lr=False, model='deit_tiny_patch16_224', input_size=224, drop=0.0, drop_path=0.0, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.02, sched='cosine', lr=2.5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=0, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.3, aa='rand-m3-mstd0.5', smoothing=0.05, train_interpolation='bicubic', repeated_aug=True, train_mode=True, ThreeAugment=False, src=False, reprob=0.0, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety_160', teacher_path='', teacher_models='swin_base_patch4_window7_224,convnext_base,tf_efficientnetv2_l', hdtse_warmup_epochs=0, lambda_log=True, distillation_type='soft', distillation_alpha=0.1, distillation_tau=2.5, alpha_schedule='none', alpha_start=0.05, alpha_end=0.7, cosub=False, finetune='/content/deit_runs/tiny_imagenet/best_checkpoint.pth', attn_only=False, data_path='/content/tiny-imagenet-200', data_set='IMNET', inat_category='name', output_dir='/content/deit_runs/tiny_imagenet_tail20_best', device='cuda', seed=0, resume='', start_epoch=0, eval=False, eval_crop_ratio=0.875, dist_eval=False, num_workers=4, pin_mem=True, distributed=False, world_size=1, dist_url='env://')\n",
            "Creating model: deit_tiny_patch16_224\n",
            "number of params: 5717416\n",
            "/usr/local/lib/python3.12/dist-packages/timm/utils/cuda.py:40: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "✅ Multi-teacher distillation enabled. Teachers: ['swin_base_patch4_window7_224', 'convnext_base', 'tf_efficientnetv2_l']\n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Start training for 20 epochs\n",
            "/content/deit/engine.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch: [0]  [  0/781]  eta: 3:29:13  lr: 0.000006  loss: 1.6184 (1.6184)  time: 16.0735  data: 0.8633  max mem: 6384\n",
            "Epoch: [0]  [ 10/781]  eta: 0:22:39  lr: 0.000006  loss: 1.6142 (1.6088)  time: 1.7629  data: 0.0788  max mem: 6458\n",
            "Epoch: [0]  [ 20/781]  eta: 0:13:42  lr: 0.000006  loss: 1.6142 (1.6106)  time: 0.3310  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 30/781]  eta: 0:10:29  lr: 0.000006  loss: 1.5819 (1.6080)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 40/781]  eta: 0:08:49  lr: 0.000006  loss: 1.5819 (1.6070)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 50/781]  eta: 0:07:47  lr: 0.000006  loss: 1.6399 (1.6122)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 60/781]  eta: 0:07:04  lr: 0.000006  loss: 1.6117 (1.6071)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 70/781]  eta: 0:06:32  lr: 0.000006  loss: 1.5080 (1.5890)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 80/781]  eta: 0:06:07  lr: 0.000006  loss: 1.4762 (1.5776)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [ 90/781]  eta: 0:05:47  lr: 0.000006  loss: 1.5059 (1.5778)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [100/781]  eta: 0:05:31  lr: 0.000006  loss: 1.5829 (1.5835)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [110/781]  eta: 0:05:16  lr: 0.000006  loss: 1.5728 (1.5768)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [120/781]  eta: 0:05:04  lr: 0.000006  loss: 1.4823 (1.5712)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [130/781]  eta: 0:04:53  lr: 0.000006  loss: 1.4700 (1.5647)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [140/781]  eta: 0:04:43  lr: 0.000006  loss: 1.4713 (1.5577)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [150/781]  eta: 0:04:34  lr: 0.000006  loss: 1.4998 (1.5547)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [160/781]  eta: 0:04:25  lr: 0.000006  loss: 1.5208 (1.5599)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [170/781]  eta: 0:04:18  lr: 0.000006  loss: 1.5208 (1.5563)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [180/781]  eta: 0:04:10  lr: 0.000006  loss: 1.4701 (1.5513)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [190/781]  eta: 0:04:03  lr: 0.000006  loss: 1.5504 (1.5565)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [200/781]  eta: 0:03:57  lr: 0.000006  loss: 1.6109 (1.5568)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [210/781]  eta: 0:03:51  lr: 0.000006  loss: 1.5574 (1.5589)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [220/781]  eta: 0:03:45  lr: 0.000006  loss: 1.5534 (1.5591)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [230/781]  eta: 0:03:39  lr: 0.000006  loss: 1.5060 (1.5567)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [240/781]  eta: 0:03:33  lr: 0.000006  loss: 1.4919 (1.5557)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [250/781]  eta: 0:03:28  lr: 0.000006  loss: 1.5854 (1.5580)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [260/781]  eta: 0:03:23  lr: 0.000006  loss: 1.5737 (1.5578)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [270/781]  eta: 0:03:18  lr: 0.000006  loss: 1.5226 (1.5567)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [280/781]  eta: 0:03:13  lr: 0.000006  loss: 1.4918 (1.5558)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [290/781]  eta: 0:03:08  lr: 0.000006  loss: 1.4759 (1.5529)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [300/781]  eta: 0:03:03  lr: 0.000006  loss: 1.4672 (1.5501)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [310/781]  eta: 0:02:59  lr: 0.000006  loss: 1.4879 (1.5493)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [320/781]  eta: 0:02:54  lr: 0.000006  loss: 1.5387 (1.5497)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [330/781]  eta: 0:02:50  lr: 0.000006  loss: 1.5481 (1.5474)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [340/781]  eta: 0:02:45  lr: 0.000006  loss: 1.5248 (1.5475)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [350/781]  eta: 0:02:41  lr: 0.000006  loss: 1.4946 (1.5466)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [360/781]  eta: 0:02:37  lr: 0.000006  loss: 1.4946 (1.5461)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [370/781]  eta: 0:02:33  lr: 0.000006  loss: 1.4794 (1.5433)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [380/781]  eta: 0:02:28  lr: 0.000006  loss: 1.4794 (1.5423)  time: 0.3297  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [390/781]  eta: 0:02:24  lr: 0.000006  loss: 1.5489 (1.5444)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [400/781]  eta: 0:02:20  lr: 0.000006  loss: 1.5886 (1.5440)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [410/781]  eta: 0:02:16  lr: 0.000006  loss: 1.4815 (1.5419)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [420/781]  eta: 0:02:12  lr: 0.000006  loss: 1.4815 (1.5415)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [430/781]  eta: 0:02:08  lr: 0.000006  loss: 1.4728 (1.5400)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [440/781]  eta: 0:02:04  lr: 0.000006  loss: 1.4698 (1.5398)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [450/781]  eta: 0:02:00  lr: 0.000006  loss: 1.5628 (1.5410)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [460/781]  eta: 0:01:56  lr: 0.000006  loss: 1.5835 (1.5407)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [470/781]  eta: 0:01:53  lr: 0.000006  loss: 1.5985 (1.5418)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [480/781]  eta: 0:01:49  lr: 0.000006  loss: 1.5960 (1.5431)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [490/781]  eta: 0:01:45  lr: 0.000006  loss: 1.5504 (1.5422)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [500/781]  eta: 0:01:41  lr: 0.000006  loss: 1.5327 (1.5425)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [510/781]  eta: 0:01:37  lr: 0.000006  loss: 1.5327 (1.5427)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [520/781]  eta: 0:01:34  lr: 0.000006  loss: 1.5363 (1.5430)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [530/781]  eta: 0:01:30  lr: 0.000006  loss: 1.5733 (1.5433)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [540/781]  eta: 0:01:26  lr: 0.000006  loss: 1.6039 (1.5449)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [550/781]  eta: 0:01:22  lr: 0.000006  loss: 1.5675 (1.5437)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [560/781]  eta: 0:01:19  lr: 0.000006  loss: 1.5046 (1.5445)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [570/781]  eta: 0:01:15  lr: 0.000006  loss: 1.5487 (1.5438)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [580/781]  eta: 0:01:11  lr: 0.000006  loss: 1.5200 (1.5439)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [590/781]  eta: 0:01:08  lr: 0.000006  loss: 1.5561 (1.5445)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [600/781]  eta: 0:01:04  lr: 0.000006  loss: 1.5351 (1.5436)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [610/781]  eta: 0:01:00  lr: 0.000006  loss: 1.4959 (1.5432)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [620/781]  eta: 0:00:57  lr: 0.000006  loss: 1.4714 (1.5413)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [630/781]  eta: 0:00:53  lr: 0.000006  loss: 1.4267 (1.5404)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [640/781]  eta: 0:00:50  lr: 0.000006  loss: 1.5668 (1.5412)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [650/781]  eta: 0:00:46  lr: 0.000006  loss: 1.5668 (1.5410)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [660/781]  eta: 0:00:42  lr: 0.000006  loss: 1.5087 (1.5404)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [670/781]  eta: 0:00:39  lr: 0.000006  loss: 1.4919 (1.5396)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [680/781]  eta: 0:00:35  lr: 0.000006  loss: 1.4919 (1.5392)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [690/781]  eta: 0:00:32  lr: 0.000006  loss: 1.4926 (1.5384)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [700/781]  eta: 0:00:28  lr: 0.000006  loss: 1.4942 (1.5378)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [710/781]  eta: 0:00:25  lr: 0.000006  loss: 1.5104 (1.5380)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [720/781]  eta: 0:00:21  lr: 0.000006  loss: 1.4881 (1.5376)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [0]  [730/781]  eta: 0:00:17  lr: 0.000006  loss: 1.4692 (1.5367)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [740/781]  eta: 0:00:14  lr: 0.000006  loss: 1.4493 (1.5362)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [750/781]  eta: 0:00:10  lr: 0.000006  loss: 1.4463 (1.5358)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [760/781]  eta: 0:00:07  lr: 0.000006  loss: 1.5343 (1.5349)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [770/781]  eta: 0:00:03  lr: 0.000006  loss: 1.4689 (1.5339)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [0]  [780/781]  eta: 0:00:00  lr: 0.000006  loss: 1.4875 (1.5335)  time: 0.3305  data: 0.0006  max mem: 6458\n",
            "Epoch: [0] Total time: 0:04:33 (0.3505 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 1.4875 (1.5335)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "/content/deit/engine.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Test:  [ 0/53]  eta: 0:00:51  loss: 0.6716 (0.6716)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.9675  data: 0.8424  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7166 (0.8222)  acc1: 83.8542 (81.6288)  acc5: 94.7917 (93.8447)  time: 0.1672  data: 0.1260  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 0.9058 (0.8830)  acc1: 79.1667 (80.4067)  acc5: 94.2708 (93.0308)  time: 0.1070  data: 0.0754  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0383 (0.9433)  acc1: 76.0417 (79.3179)  acc5: 90.6250 (92.5067)  time: 0.1149  data: 0.0843  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1300 (0.9842)  acc1: 74.4792 (78.5188)  acc5: 90.6250 (92.0986)  time: 0.1127  data: 0.0821  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 0.9794 (0.9809)  acc1: 76.0417 (78.2680)  acc5: 92.7083 (92.4428)  time: 0.1148  data: 0.0839  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0304 (0.9924)  acc1: 76.0417 (78.1700)  acc5: 93.2292 (92.5000)  time: 0.1020  data: 0.0715  max mem: 6458\n",
            "Test: Total time: 0:00:06 (0.1236 s / it)\n",
            "* Acc@1 78.170 Acc@5 92.500 loss 0.992\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [1]  [  0/781]  eta: 0:15:33  lr: 0.000006  loss: 1.6558 (1.6558)  time: 1.1958  data: 0.8188  max mem: 6458\n",
            "Epoch: [1]  [ 10/781]  eta: 0:05:15  lr: 0.000006  loss: 1.6429 (1.6054)  time: 0.4088  data: 0.0748  max mem: 6458\n",
            "Epoch: [1]  [ 20/781]  eta: 0:04:42  lr: 0.000006  loss: 1.5765 (1.5843)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 30/781]  eta: 0:04:28  lr: 0.000006  loss: 1.5746 (1.5907)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 40/781]  eta: 0:04:20  lr: 0.000006  loss: 1.5874 (1.5832)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 50/781]  eta: 0:04:13  lr: 0.000006  loss: 1.5660 (1.5675)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 60/781]  eta: 0:04:08  lr: 0.000006  loss: 1.5669 (1.5748)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 70/781]  eta: 0:04:03  lr: 0.000006  loss: 1.5984 (1.5894)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 80/781]  eta: 0:03:59  lr: 0.000006  loss: 1.7103 (1.6052)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [ 90/781]  eta: 0:03:54  lr: 0.000006  loss: 1.6698 (1.6054)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [100/781]  eta: 0:03:50  lr: 0.000006  loss: 1.6278 (1.6117)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [110/781]  eta: 0:03:46  lr: 0.000006  loss: 1.5626 (1.6052)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [120/781]  eta: 0:03:43  lr: 0.000006  loss: 1.5288 (1.6035)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [130/781]  eta: 0:03:39  lr: 0.000006  loss: 1.5124 (1.6021)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [140/781]  eta: 0:03:35  lr: 0.000006  loss: 1.6181 (1.6013)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [150/781]  eta: 0:03:32  lr: 0.000006  loss: 1.6181 (1.5998)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [160/781]  eta: 0:03:28  lr: 0.000006  loss: 1.5369 (1.5952)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [170/781]  eta: 0:03:24  lr: 0.000006  loss: 1.5826 (1.6017)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [180/781]  eta: 0:03:21  lr: 0.000006  loss: 1.6426 (1.6029)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [190/781]  eta: 0:03:17  lr: 0.000006  loss: 1.6016 (1.6019)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [200/781]  eta: 0:03:14  lr: 0.000006  loss: 1.6063 (1.6028)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [210/781]  eta: 0:03:10  lr: 0.000006  loss: 1.6098 (1.6002)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [220/781]  eta: 0:03:07  lr: 0.000006  loss: 1.5838 (1.6019)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [230/781]  eta: 0:03:03  lr: 0.000006  loss: 1.5942 (1.6010)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [240/781]  eta: 0:03:00  lr: 0.000006  loss: 1.5907 (1.6004)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [250/781]  eta: 0:02:57  lr: 0.000006  loss: 1.5935 (1.6028)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [260/781]  eta: 0:02:53  lr: 0.000006  loss: 1.6367 (1.6017)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [270/781]  eta: 0:02:50  lr: 0.000006  loss: 1.5349 (1.6009)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [280/781]  eta: 0:02:46  lr: 0.000006  loss: 1.5349 (1.6000)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [290/781]  eta: 0:02:43  lr: 0.000006  loss: 1.5519 (1.5997)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [300/781]  eta: 0:02:40  lr: 0.000006  loss: 1.5700 (1.5987)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [310/781]  eta: 0:02:36  lr: 0.000006  loss: 1.5700 (1.5977)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [320/781]  eta: 0:02:33  lr: 0.000006  loss: 1.5750 (1.5982)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [330/781]  eta: 0:02:30  lr: 0.000006  loss: 1.5749 (1.5970)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [340/781]  eta: 0:02:26  lr: 0.000006  loss: 1.4887 (1.5958)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [350/781]  eta: 0:02:23  lr: 0.000006  loss: 1.6094 (1.5990)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [360/781]  eta: 0:02:19  lr: 0.000006  loss: 1.5640 (1.5979)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [370/781]  eta: 0:02:16  lr: 0.000006  loss: 1.5289 (1.5963)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [380/781]  eta: 0:02:13  lr: 0.000006  loss: 1.5794 (1.5979)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [390/781]  eta: 0:02:09  lr: 0.000006  loss: 1.5908 (1.5975)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [400/781]  eta: 0:02:06  lr: 0.000006  loss: 1.5994 (1.5972)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [410/781]  eta: 0:02:03  lr: 0.000006  loss: 1.5830 (1.5961)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [420/781]  eta: 0:01:59  lr: 0.000006  loss: 1.5497 (1.5965)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [430/781]  eta: 0:01:56  lr: 0.000006  loss: 1.5646 (1.5968)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [440/781]  eta: 0:01:53  lr: 0.000006  loss: 1.5826 (1.5969)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [450/781]  eta: 0:01:49  lr: 0.000006  loss: 1.5826 (1.5971)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [460/781]  eta: 0:01:46  lr: 0.000006  loss: 1.5607 (1.5966)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [470/781]  eta: 0:01:43  lr: 0.000006  loss: 1.5484 (1.5957)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [480/781]  eta: 0:01:39  lr: 0.000006  loss: 1.5499 (1.5965)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [490/781]  eta: 0:01:36  lr: 0.000006  loss: 1.5457 (1.5955)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [500/781]  eta: 0:01:33  lr: 0.000006  loss: 1.5345 (1.5953)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [510/781]  eta: 0:01:29  lr: 0.000006  loss: 1.5345 (1.5933)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [520/781]  eta: 0:01:26  lr: 0.000006  loss: 1.5351 (1.5940)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [530/781]  eta: 0:01:23  lr: 0.000006  loss: 1.5352 (1.5921)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [540/781]  eta: 0:01:19  lr: 0.000006  loss: 1.5192 (1.5929)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [550/781]  eta: 0:01:16  lr: 0.000006  loss: 1.5824 (1.5928)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [560/781]  eta: 0:01:13  lr: 0.000006  loss: 1.5668 (1.5927)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [570/781]  eta: 0:01:09  lr: 0.000006  loss: 1.5259 (1.5930)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [580/781]  eta: 0:01:06  lr: 0.000006  loss: 1.5774 (1.5923)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [590/781]  eta: 0:01:03  lr: 0.000006  loss: 1.5651 (1.5920)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [600/781]  eta: 0:01:00  lr: 0.000006  loss: 1.5580 (1.5913)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [610/781]  eta: 0:00:56  lr: 0.000006  loss: 1.5462 (1.5908)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [620/781]  eta: 0:00:53  lr: 0.000006  loss: 1.5499 (1.5910)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [630/781]  eta: 0:00:50  lr: 0.000006  loss: 1.5638 (1.5903)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [640/781]  eta: 0:00:46  lr: 0.000006  loss: 1.5337 (1.5893)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [650/781]  eta: 0:00:43  lr: 0.000006  loss: 1.5363 (1.5899)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [660/781]  eta: 0:00:40  lr: 0.000006  loss: 1.5980 (1.5895)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [670/781]  eta: 0:00:36  lr: 0.000006  loss: 1.6283 (1.5901)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [680/781]  eta: 0:00:33  lr: 0.000006  loss: 1.6233 (1.5908)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [690/781]  eta: 0:00:30  lr: 0.000006  loss: 1.5868 (1.5900)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [700/781]  eta: 0:00:26  lr: 0.000006  loss: 1.5447 (1.5893)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [710/781]  eta: 0:00:23  lr: 0.000006  loss: 1.6122 (1.5900)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [720/781]  eta: 0:00:20  lr: 0.000006  loss: 1.6483 (1.5904)  time: 0.3416  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [730/781]  eta: 0:00:16  lr: 0.000006  loss: 1.6095 (1.5906)  time: 0.3416  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [740/781]  eta: 0:00:13  lr: 0.000006  loss: 1.5750 (1.5906)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [750/781]  eta: 0:00:10  lr: 0.000006  loss: 1.5615 (1.5900)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [760/781]  eta: 0:00:06  lr: 0.000006  loss: 1.5189 (1.5895)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [770/781]  eta: 0:00:03  lr: 0.000006  loss: 1.4913 (1.5889)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [1]  [780/781]  eta: 0:00:00  lr: 0.000006  loss: 1.5024 (1.5888)  time: 0.3304  data: 0.0006  max mem: 6458\n",
            "Epoch: [1] Total time: 0:04:19 (0.3317 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 1.5024 (1.5888)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.6636 (0.6636)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8708  data: 0.8401  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7479 (0.8376)  acc1: 84.3750 (81.4394)  acc5: 94.7917 (93.9867)  time: 0.1810  data: 0.1505  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9036 (0.8950)  acc1: 78.6458 (80.3819)  acc5: 94.2708 (93.1052)  time: 0.1333  data: 0.1029  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 0.9981 (0.9497)  acc1: 76.0417 (79.3179)  acc5: 90.6250 (92.6411)  time: 0.1351  data: 0.1047  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1155 (0.9897)  acc1: 74.4792 (78.4172)  acc5: 90.6250 (92.2891)  time: 0.1366  data: 0.1062  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 0.9655 (0.9878)  acc1: 75.0000 (78.0535)  acc5: 93.2292 (92.6164)  time: 0.1362  data: 0.1057  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0276 (1.0017)  acc1: 75.0000 (77.9400)  acc5: 93.2292 (92.6600)  time: 0.1138  data: 0.0842  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1419 s / it)\n",
            "* Acc@1 77.940 Acc@5 92.660 loss 1.002\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [2]  [  0/781]  eta: 0:15:39  lr: 0.000006  loss: 1.7962 (1.7962)  time: 1.2030  data: 0.8669  max mem: 6458\n",
            "Epoch: [2]  [ 10/781]  eta: 0:05:15  lr: 0.000006  loss: 1.6976 (1.6676)  time: 0.4098  data: 0.0791  max mem: 6458\n",
            "Epoch: [2]  [ 20/781]  eta: 0:04:42  lr: 0.000006  loss: 1.7158 (1.7098)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 30/781]  eta: 0:04:29  lr: 0.000006  loss: 1.7158 (1.6863)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 40/781]  eta: 0:04:20  lr: 0.000006  loss: 1.6010 (1.6641)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 50/781]  eta: 0:04:13  lr: 0.000006  loss: 1.6146 (1.6575)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 60/781]  eta: 0:04:08  lr: 0.000006  loss: 1.6186 (1.6578)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 70/781]  eta: 0:04:03  lr: 0.000006  loss: 1.6225 (1.6584)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 80/781]  eta: 0:03:58  lr: 0.000006  loss: 1.6937 (1.6686)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [ 90/781]  eta: 0:03:54  lr: 0.000006  loss: 1.6943 (1.6702)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [100/781]  eta: 0:03:50  lr: 0.000006  loss: 1.5859 (1.6616)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [110/781]  eta: 0:03:46  lr: 0.000006  loss: 1.6364 (1.6678)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [120/781]  eta: 0:03:42  lr: 0.000006  loss: 1.7007 (1.6696)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [2]  [130/781]  eta: 0:03:39  lr: 0.000006  loss: 1.7226 (1.6744)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [140/781]  eta: 0:03:35  lr: 0.000006  loss: 1.6968 (1.6719)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [150/781]  eta: 0:03:31  lr: 0.000006  loss: 1.6050 (1.6646)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [2]  [160/781]  eta: 0:03:28  lr: 0.000006  loss: 1.6178 (1.6652)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [170/781]  eta: 0:03:24  lr: 0.000006  loss: 1.6402 (1.6660)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [180/781]  eta: 0:03:21  lr: 0.000006  loss: 1.6010 (1.6646)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [2]  [190/781]  eta: 0:03:17  lr: 0.000006  loss: 1.6010 (1.6633)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [200/781]  eta: 0:03:14  lr: 0.000006  loss: 1.6426 (1.6655)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [210/781]  eta: 0:03:10  lr: 0.000006  loss: 1.6426 (1.6641)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [220/781]  eta: 0:03:07  lr: 0.000006  loss: 1.6304 (1.6636)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [230/781]  eta: 0:03:03  lr: 0.000006  loss: 1.6245 (1.6641)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [240/781]  eta: 0:03:00  lr: 0.000006  loss: 1.6805 (1.6655)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [250/781]  eta: 0:02:57  lr: 0.000006  loss: 1.7002 (1.6669)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [260/781]  eta: 0:02:53  lr: 0.000006  loss: 1.6562 (1.6650)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [270/781]  eta: 0:02:50  lr: 0.000006  loss: 1.5953 (1.6647)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [280/781]  eta: 0:02:46  lr: 0.000006  loss: 1.6324 (1.6636)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [290/781]  eta: 0:02:43  lr: 0.000006  loss: 1.6324 (1.6629)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [300/781]  eta: 0:02:40  lr: 0.000006  loss: 1.5704 (1.6598)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [310/781]  eta: 0:02:36  lr: 0.000006  loss: 1.5704 (1.6587)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [320/781]  eta: 0:02:33  lr: 0.000006  loss: 1.6475 (1.6595)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [330/781]  eta: 0:02:30  lr: 0.000006  loss: 1.6818 (1.6623)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [340/781]  eta: 0:02:26  lr: 0.000006  loss: 1.6448 (1.6588)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [350/781]  eta: 0:02:23  lr: 0.000006  loss: 1.5989 (1.6589)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [360/781]  eta: 0:02:19  lr: 0.000006  loss: 1.6750 (1.6605)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [370/781]  eta: 0:02:16  lr: 0.000006  loss: 1.5829 (1.6583)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [380/781]  eta: 0:02:13  lr: 0.000006  loss: 1.5701 (1.6569)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [390/781]  eta: 0:02:09  lr: 0.000006  loss: 1.6194 (1.6558)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [400/781]  eta: 0:02:06  lr: 0.000006  loss: 1.6607 (1.6580)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [410/781]  eta: 0:02:03  lr: 0.000006  loss: 1.6722 (1.6587)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [420/781]  eta: 0:01:59  lr: 0.000006  loss: 1.6202 (1.6579)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [430/781]  eta: 0:01:56  lr: 0.000006  loss: 1.5793 (1.6556)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [440/781]  eta: 0:01:53  lr: 0.000006  loss: 1.5738 (1.6540)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [450/781]  eta: 0:01:49  lr: 0.000006  loss: 1.6006 (1.6537)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [460/781]  eta: 0:01:46  lr: 0.000006  loss: 1.6713 (1.6548)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [470/781]  eta: 0:01:43  lr: 0.000006  loss: 1.5934 (1.6532)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [480/781]  eta: 0:01:39  lr: 0.000006  loss: 1.5565 (1.6530)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [490/781]  eta: 0:01:36  lr: 0.000006  loss: 1.6447 (1.6541)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [500/781]  eta: 0:01:33  lr: 0.000006  loss: 1.6921 (1.6540)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [510/781]  eta: 0:01:29  lr: 0.000006  loss: 1.6466 (1.6531)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [520/781]  eta: 0:01:26  lr: 0.000006  loss: 1.6148 (1.6538)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [530/781]  eta: 0:01:23  lr: 0.000006  loss: 1.6657 (1.6542)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [540/781]  eta: 0:01:19  lr: 0.000006  loss: 1.6998 (1.6563)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [550/781]  eta: 0:01:16  lr: 0.000006  loss: 1.7479 (1.6585)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [560/781]  eta: 0:01:13  lr: 0.000006  loss: 1.6564 (1.6565)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [570/781]  eta: 0:01:09  lr: 0.000006  loss: 1.5925 (1.6565)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [580/781]  eta: 0:01:06  lr: 0.000006  loss: 1.6604 (1.6563)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [590/781]  eta: 0:01:03  lr: 0.000006  loss: 1.6952 (1.6574)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [600/781]  eta: 0:01:00  lr: 0.000006  loss: 1.7153 (1.6582)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [610/781]  eta: 0:00:56  lr: 0.000006  loss: 1.6427 (1.6565)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [620/781]  eta: 0:00:53  lr: 0.000006  loss: 1.6427 (1.6561)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [630/781]  eta: 0:00:50  lr: 0.000006  loss: 1.6521 (1.6559)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [640/781]  eta: 0:00:46  lr: 0.000006  loss: 1.6248 (1.6545)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [650/781]  eta: 0:00:43  lr: 0.000006  loss: 1.6248 (1.6541)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [660/781]  eta: 0:00:40  lr: 0.000006  loss: 1.6441 (1.6543)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [670/781]  eta: 0:00:36  lr: 0.000006  loss: 1.6707 (1.6545)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [680/781]  eta: 0:00:33  lr: 0.000006  loss: 1.6513 (1.6543)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [690/781]  eta: 0:00:30  lr: 0.000006  loss: 1.6513 (1.6560)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [700/781]  eta: 0:00:26  lr: 0.000006  loss: 1.6592 (1.6553)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [710/781]  eta: 0:00:23  lr: 0.000006  loss: 1.6300 (1.6557)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [720/781]  eta: 0:00:20  lr: 0.000006  loss: 1.6611 (1.6557)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [730/781]  eta: 0:00:16  lr: 0.000006  loss: 1.5967 (1.6559)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [740/781]  eta: 0:00:13  lr: 0.000006  loss: 1.5486 (1.6546)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [750/781]  eta: 0:00:10  lr: 0.000006  loss: 1.5645 (1.6547)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [760/781]  eta: 0:00:06  lr: 0.000006  loss: 1.7073 (1.6551)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [770/781]  eta: 0:00:03  lr: 0.000006  loss: 1.6404 (1.6548)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [2]  [780/781]  eta: 0:00:00  lr: 0.000006  loss: 1.5818 (1.6540)  time: 0.3304  data: 0.0006  max mem: 6458\n",
            "Epoch: [2] Total time: 0:04:18 (0.3314 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 1.5818 (1.6540)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7033 (0.7033)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8714  data: 0.8407  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7223 (0.8350)  acc1: 82.8125 (81.3920)  acc5: 95.3125 (93.9867)  time: 0.1752  data: 0.1448  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.8817 (0.8977)  acc1: 78.6458 (80.1587)  acc5: 93.7500 (92.9564)  time: 0.1254  data: 0.0950  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0852 (0.9534)  acc1: 76.0417 (79.0995)  acc5: 90.6250 (92.3891)  time: 0.1319  data: 0.1014  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1260 (0.9901)  acc1: 75.0000 (78.3537)  acc5: 90.6250 (91.9334)  time: 0.1274  data: 0.0969  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 0.9846 (0.9879)  acc1: 75.5208 (78.0842)  acc5: 92.7083 (92.2896)  time: 0.1365  data: 0.1061  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0117 (0.9998)  acc1: 75.0000 (77.9600)  acc5: 93.2292 (92.3400)  time: 0.1219  data: 0.0923  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1395 s / it)\n",
            "* Acc@1 77.960 Acc@5 92.340 loss 1.000\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [3]  [  0/781]  eta: 0:15:07  lr: 0.000006  loss: 1.7044 (1.7044)  time: 1.1623  data: 0.8259  max mem: 6458\n",
            "Epoch: [3]  [ 10/781]  eta: 0:05:12  lr: 0.000006  loss: 1.8422 (1.8054)  time: 0.4058  data: 0.0754  max mem: 6458\n",
            "Epoch: [3]  [ 20/781]  eta: 0:04:41  lr: 0.000006  loss: 1.7533 (1.7954)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [3]  [ 30/781]  eta: 0:04:28  lr: 0.000006  loss: 1.7281 (1.7706)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 40/781]  eta: 0:04:19  lr: 0.000006  loss: 1.7201 (1.7713)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 50/781]  eta: 0:04:13  lr: 0.000006  loss: 1.7366 (1.7634)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 60/781]  eta: 0:04:07  lr: 0.000006  loss: 1.7240 (1.7589)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 70/781]  eta: 0:04:03  lr: 0.000006  loss: 1.6837 (1.7555)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 80/781]  eta: 0:03:58  lr: 0.000006  loss: 1.7137 (1.7476)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [ 90/781]  eta: 0:03:54  lr: 0.000006  loss: 1.7265 (1.7451)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [100/781]  eta: 0:03:50  lr: 0.000006  loss: 1.7172 (1.7410)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [110/781]  eta: 0:03:46  lr: 0.000006  loss: 1.7191 (1.7437)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [120/781]  eta: 0:03:42  lr: 0.000006  loss: 1.7191 (1.7405)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [130/781]  eta: 0:03:39  lr: 0.000006  loss: 1.7388 (1.7421)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [140/781]  eta: 0:03:35  lr: 0.000006  loss: 1.7388 (1.7420)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [150/781]  eta: 0:03:31  lr: 0.000006  loss: 1.7314 (1.7407)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [3]  [160/781]  eta: 0:03:28  lr: 0.000006  loss: 1.7314 (1.7426)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [170/781]  eta: 0:03:24  lr: 0.000006  loss: 1.7421 (1.7442)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [180/781]  eta: 0:03:21  lr: 0.000006  loss: 1.7116 (1.7364)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [190/781]  eta: 0:03:17  lr: 0.000006  loss: 1.6778 (1.7347)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [200/781]  eta: 0:03:14  lr: 0.000006  loss: 1.7500 (1.7363)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [210/781]  eta: 0:03:10  lr: 0.000006  loss: 1.7452 (1.7336)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [220/781]  eta: 0:03:07  lr: 0.000006  loss: 1.7232 (1.7327)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [230/781]  eta: 0:03:03  lr: 0.000006  loss: 1.7232 (1.7332)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [240/781]  eta: 0:03:00  lr: 0.000006  loss: 1.7850 (1.7368)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [250/781]  eta: 0:02:57  lr: 0.000006  loss: 1.6986 (1.7321)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [260/781]  eta: 0:02:53  lr: 0.000006  loss: 1.7027 (1.7335)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [270/781]  eta: 0:02:50  lr: 0.000006  loss: 1.7421 (1.7314)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [280/781]  eta: 0:02:46  lr: 0.000006  loss: 1.6965 (1.7321)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [290/781]  eta: 0:02:43  lr: 0.000006  loss: 1.7031 (1.7325)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [300/781]  eta: 0:02:40  lr: 0.000006  loss: 1.7031 (1.7334)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [310/781]  eta: 0:02:36  lr: 0.000006  loss: 1.6896 (1.7325)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [320/781]  eta: 0:02:33  lr: 0.000006  loss: 1.6864 (1.7314)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [330/781]  eta: 0:02:30  lr: 0.000006  loss: 1.6960 (1.7316)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [340/781]  eta: 0:02:26  lr: 0.000006  loss: 1.7583 (1.7320)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [350/781]  eta: 0:02:23  lr: 0.000006  loss: 1.7231 (1.7311)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [360/781]  eta: 0:02:20  lr: 0.000006  loss: 1.7018 (1.7296)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [370/781]  eta: 0:02:16  lr: 0.000006  loss: 1.7047 (1.7293)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [380/781]  eta: 0:02:13  lr: 0.000006  loss: 1.7448 (1.7293)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [390/781]  eta: 0:02:09  lr: 0.000006  loss: 1.6693 (1.7283)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [400/781]  eta: 0:02:06  lr: 0.000006  loss: 1.6693 (1.7275)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [410/781]  eta: 0:02:03  lr: 0.000006  loss: 1.6962 (1.7274)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [420/781]  eta: 0:01:59  lr: 0.000006  loss: 1.7381 (1.7279)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [430/781]  eta: 0:01:56  lr: 0.000006  loss: 1.7407 (1.7282)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [440/781]  eta: 0:01:53  lr: 0.000006  loss: 1.7407 (1.7277)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [450/781]  eta: 0:01:49  lr: 0.000006  loss: 1.7072 (1.7266)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [460/781]  eta: 0:01:46  lr: 0.000006  loss: 1.7754 (1.7295)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [470/781]  eta: 0:01:43  lr: 0.000006  loss: 1.7796 (1.7297)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [480/781]  eta: 0:01:39  lr: 0.000006  loss: 1.7061 (1.7286)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [490/781]  eta: 0:01:36  lr: 0.000006  loss: 1.6824 (1.7282)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [500/781]  eta: 0:01:33  lr: 0.000006  loss: 1.6920 (1.7272)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [510/781]  eta: 0:01:29  lr: 0.000006  loss: 1.6898 (1.7264)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [520/781]  eta: 0:01:26  lr: 0.000006  loss: 1.6820 (1.7256)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [530/781]  eta: 0:01:23  lr: 0.000006  loss: 1.6820 (1.7253)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [540/781]  eta: 0:01:19  lr: 0.000006  loss: 1.7437 (1.7254)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [550/781]  eta: 0:01:16  lr: 0.000006  loss: 1.7509 (1.7255)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [560/781]  eta: 0:01:13  lr: 0.000006  loss: 1.7509 (1.7250)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [570/781]  eta: 0:01:09  lr: 0.000006  loss: 1.7078 (1.7246)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [580/781]  eta: 0:01:06  lr: 0.000006  loss: 1.7222 (1.7254)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [590/781]  eta: 0:01:03  lr: 0.000006  loss: 1.7694 (1.7257)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [600/781]  eta: 0:01:00  lr: 0.000006  loss: 1.7213 (1.7258)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [610/781]  eta: 0:00:56  lr: 0.000006  loss: 1.7347 (1.7261)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [620/781]  eta: 0:00:53  lr: 0.000006  loss: 1.7347 (1.7262)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [630/781]  eta: 0:00:50  lr: 0.000006  loss: 1.7584 (1.7271)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [640/781]  eta: 0:00:46  lr: 0.000006  loss: 1.7916 (1.7275)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [650/781]  eta: 0:00:43  lr: 0.000006  loss: 1.7916 (1.7279)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [660/781]  eta: 0:00:40  lr: 0.000006  loss: 1.7083 (1.7276)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [670/781]  eta: 0:00:36  lr: 0.000006  loss: 1.7010 (1.7279)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [680/781]  eta: 0:00:33  lr: 0.000006  loss: 1.6934 (1.7269)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [690/781]  eta: 0:00:30  lr: 0.000006  loss: 1.6885 (1.7268)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [700/781]  eta: 0:00:26  lr: 0.000006  loss: 1.6885 (1.7257)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [710/781]  eta: 0:00:23  lr: 0.000006  loss: 1.6500 (1.7252)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [720/781]  eta: 0:00:20  lr: 0.000006  loss: 1.6500 (1.7245)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [730/781]  eta: 0:00:16  lr: 0.000006  loss: 1.6787 (1.7241)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [740/781]  eta: 0:00:13  lr: 0.000006  loss: 1.6787 (1.7237)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [750/781]  eta: 0:00:10  lr: 0.000006  loss: 1.7402 (1.7241)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [760/781]  eta: 0:00:06  lr: 0.000006  loss: 1.7542 (1.7255)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [770/781]  eta: 0:00:03  lr: 0.000006  loss: 1.7427 (1.7248)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [3]  [780/781]  eta: 0:00:00  lr: 0.000006  loss: 1.7427 (1.7253)  time: 0.3302  data: 0.0006  max mem: 6458\n",
            "Epoch: [3] Total time: 0:04:18 (0.3314 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 1.7427 (1.7253)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.6638 (0.6638)  acc1: 84.3750 (84.3750)  acc5: 95.3125 (95.3125)  time: 0.8671  data: 0.8364  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7209 (0.8198)  acc1: 84.3750 (81.5341)  acc5: 94.7917 (93.8920)  time: 0.1837  data: 0.1533  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9329 (0.8926)  acc1: 78.6458 (80.2827)  acc5: 93.7500 (92.6339)  time: 0.1251  data: 0.0947  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0471 (0.9569)  acc1: 76.0417 (79.1331)  acc5: 90.1042 (92.0195)  time: 0.1164  data: 0.0859  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1486 (0.9931)  acc1: 75.0000 (78.2393)  acc5: 90.1042 (91.7429)  time: 0.1183  data: 0.0878  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0037 (0.9910)  acc1: 76.0417 (78.0433)  acc5: 92.1875 (92.0547)  time: 0.1191  data: 0.0886  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0055 (1.0057)  acc1: 75.5208 (77.9200)  acc5: 92.7083 (92.0900)  time: 0.1006  data: 0.0710  max mem: 6458\n",
            "Test: Total time: 0:00:06 (0.1294 s / it)\n",
            "* Acc@1 77.920 Acc@5 92.090 loss 1.006\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [4]  [  0/781]  eta: 0:14:29  lr: 0.000006  loss: 1.9138 (1.9138)  time: 1.1134  data: 0.7731  max mem: 6458\n",
            "Epoch: [4]  [ 10/781]  eta: 0:05:10  lr: 0.000006  loss: 1.8689 (1.8517)  time: 0.4021  data: 0.0706  max mem: 6458\n",
            "Epoch: [4]  [ 20/781]  eta: 0:04:40  lr: 0.000006  loss: 1.8274 (1.8355)  time: 0.3310  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [ 30/781]  eta: 0:04:27  lr: 0.000006  loss: 1.8258 (1.8450)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 40/781]  eta: 0:04:19  lr: 0.000006  loss: 1.8133 (1.8262)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 50/781]  eta: 0:04:12  lr: 0.000006  loss: 1.7845 (1.8258)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 60/781]  eta: 0:04:07  lr: 0.000006  loss: 1.8177 (1.8213)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 70/781]  eta: 0:04:02  lr: 0.000006  loss: 1.8177 (1.8211)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 80/781]  eta: 0:03:58  lr: 0.000006  loss: 1.7885 (1.8201)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [ 90/781]  eta: 0:03:54  lr: 0.000006  loss: 1.7754 (1.8178)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [100/781]  eta: 0:03:50  lr: 0.000006  loss: 1.8056 (1.8156)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [110/781]  eta: 0:03:46  lr: 0.000006  loss: 1.7821 (1.8120)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [120/781]  eta: 0:03:42  lr: 0.000006  loss: 1.7181 (1.8060)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [130/781]  eta: 0:03:39  lr: 0.000006  loss: 1.7181 (1.8019)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [140/781]  eta: 0:03:35  lr: 0.000006  loss: 1.7364 (1.7972)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [150/781]  eta: 0:03:31  lr: 0.000006  loss: 1.7590 (1.7985)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [160/781]  eta: 0:03:28  lr: 0.000006  loss: 1.8229 (1.8014)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [170/781]  eta: 0:03:24  lr: 0.000006  loss: 1.8148 (1.8000)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [180/781]  eta: 0:03:21  lr: 0.000006  loss: 1.7965 (1.8019)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [190/781]  eta: 0:03:17  lr: 0.000006  loss: 1.8009 (1.8035)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [200/781]  eta: 0:03:14  lr: 0.000006  loss: 1.8224 (1.8066)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [210/781]  eta: 0:03:10  lr: 0.000006  loss: 1.7716 (1.8039)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [220/781]  eta: 0:03:07  lr: 0.000006  loss: 1.7425 (1.8022)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [230/781]  eta: 0:03:04  lr: 0.000006  loss: 1.7552 (1.8007)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [240/781]  eta: 0:03:00  lr: 0.000006  loss: 1.7150 (1.7971)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [250/781]  eta: 0:02:57  lr: 0.000006  loss: 1.7175 (1.7982)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [4]  [260/781]  eta: 0:02:53  lr: 0.000006  loss: 1.7946 (1.8000)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [270/781]  eta: 0:02:50  lr: 0.000006  loss: 1.7716 (1.7995)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [280/781]  eta: 0:02:47  lr: 0.000006  loss: 1.7716 (1.8009)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [290/781]  eta: 0:02:43  lr: 0.000006  loss: 1.8273 (1.8017)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [300/781]  eta: 0:02:40  lr: 0.000006  loss: 1.7931 (1.8014)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [310/781]  eta: 0:02:36  lr: 0.000006  loss: 1.7925 (1.8020)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [320/781]  eta: 0:02:33  lr: 0.000006  loss: 1.7683 (1.8019)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [330/781]  eta: 0:02:30  lr: 0.000006  loss: 1.7794 (1.8029)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [340/781]  eta: 0:02:26  lr: 0.000006  loss: 1.8665 (1.8052)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [350/781]  eta: 0:02:23  lr: 0.000006  loss: 1.8665 (1.8063)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [360/781]  eta: 0:02:20  lr: 0.000006  loss: 1.8265 (1.8075)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [370/781]  eta: 0:02:16  lr: 0.000006  loss: 1.8536 (1.8092)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [380/781]  eta: 0:02:13  lr: 0.000006  loss: 1.8133 (1.8069)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [390/781]  eta: 0:02:10  lr: 0.000006  loss: 1.7537 (1.8074)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [400/781]  eta: 0:02:06  lr: 0.000006  loss: 1.7886 (1.8071)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [410/781]  eta: 0:02:03  lr: 0.000006  loss: 1.7228 (1.8053)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [420/781]  eta: 0:01:59  lr: 0.000006  loss: 1.7170 (1.8039)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [430/781]  eta: 0:01:56  lr: 0.000006  loss: 1.7982 (1.8036)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [440/781]  eta: 0:01:53  lr: 0.000006  loss: 1.8056 (1.8029)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [450/781]  eta: 0:01:49  lr: 0.000006  loss: 1.7690 (1.8030)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [460/781]  eta: 0:01:46  lr: 0.000006  loss: 1.7999 (1.8040)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [470/781]  eta: 0:01:43  lr: 0.000006  loss: 1.8266 (1.8047)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [480/781]  eta: 0:01:39  lr: 0.000006  loss: 1.7664 (1.8032)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [490/781]  eta: 0:01:36  lr: 0.000006  loss: 1.7664 (1.8032)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [500/781]  eta: 0:01:33  lr: 0.000006  loss: 1.7895 (1.8041)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [510/781]  eta: 0:01:29  lr: 0.000006  loss: 1.8732 (1.8042)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [520/781]  eta: 0:01:26  lr: 0.000006  loss: 1.8667 (1.8056)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [530/781]  eta: 0:01:23  lr: 0.000006  loss: 1.8090 (1.8046)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [540/781]  eta: 0:01:19  lr: 0.000006  loss: 1.7282 (1.8042)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [550/781]  eta: 0:01:16  lr: 0.000006  loss: 1.8182 (1.8050)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [560/781]  eta: 0:01:13  lr: 0.000006  loss: 1.8360 (1.8052)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [570/781]  eta: 0:01:10  lr: 0.000006  loss: 1.7379 (1.8045)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [580/781]  eta: 0:01:06  lr: 0.000006  loss: 1.7379 (1.8038)  time: 0.3415  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [590/781]  eta: 0:01:03  lr: 0.000006  loss: 1.8152 (1.8039)  time: 0.3416  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [600/781]  eta: 0:01:00  lr: 0.000006  loss: 1.7701 (1.8027)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [610/781]  eta: 0:00:56  lr: 0.000006  loss: 1.7464 (1.8021)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [620/781]  eta: 0:00:53  lr: 0.000006  loss: 1.7790 (1.8017)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [630/781]  eta: 0:00:50  lr: 0.000006  loss: 1.7836 (1.8016)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [640/781]  eta: 0:00:46  lr: 0.000006  loss: 1.7411 (1.8002)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [650/781]  eta: 0:00:43  lr: 0.000006  loss: 1.7546 (1.8002)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [660/781]  eta: 0:00:40  lr: 0.000006  loss: 1.7597 (1.7995)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [670/781]  eta: 0:00:36  lr: 0.000006  loss: 1.8018 (1.7999)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [680/781]  eta: 0:00:33  lr: 0.000006  loss: 1.8244 (1.8012)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [690/781]  eta: 0:00:30  lr: 0.000006  loss: 1.7672 (1.8006)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [700/781]  eta: 0:00:26  lr: 0.000006  loss: 1.7160 (1.8008)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [710/781]  eta: 0:00:23  lr: 0.000006  loss: 1.7663 (1.8010)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [720/781]  eta: 0:00:20  lr: 0.000006  loss: 1.7535 (1.7997)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [730/781]  eta: 0:00:16  lr: 0.000006  loss: 1.7397 (1.7999)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [740/781]  eta: 0:00:13  lr: 0.000006  loss: 1.7948 (1.8001)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [750/781]  eta: 0:00:10  lr: 0.000006  loss: 1.7825 (1.7995)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [760/781]  eta: 0:00:06  lr: 0.000006  loss: 1.7365 (1.7994)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [770/781]  eta: 0:00:03  lr: 0.000006  loss: 1.7851 (1.7999)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [4]  [780/781]  eta: 0:00:00  lr: 0.000006  loss: 1.8546 (1.8001)  time: 0.3304  data: 0.0006  max mem: 6458\n",
            "Epoch: [4] Total time: 0:04:19 (0.3318 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 1.8546 (1.8001)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.6515 (0.6515)  acc1: 83.8542 (83.8542)  acc5: 96.3542 (96.3542)  time: 0.8660  data: 0.8354  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.6707 (0.8224)  acc1: 83.8542 (81.5341)  acc5: 93.7500 (93.6553)  time: 0.1757  data: 0.1452  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.8881 (0.8904)  acc1: 81.2500 (80.4564)  acc5: 93.2292 (92.5595)  time: 0.1288  data: 0.0984  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0180 (0.9580)  acc1: 76.0417 (79.2171)  acc5: 90.1042 (91.9523)  time: 0.1357  data: 0.1052  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1612 (0.9967)  acc1: 75.5208 (78.3283)  acc5: 90.1042 (91.5523)  time: 0.1360  data: 0.1055  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 0.9942 (0.9935)  acc1: 76.5625 (78.1250)  acc5: 92.1875 (91.8811)  time: 0.1334  data: 0.1029  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0308 (1.0020)  acc1: 76.0417 (78.0300)  acc5: 93.2292 (91.9300)  time: 0.1135  data: 0.0839  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1401 s / it)\n",
            "* Acc@1 78.030 Acc@5 91.930 loss 1.002\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [5]  [  0/781]  eta: 0:14:06  lr: 0.000007  loss: 1.8768 (1.8768)  time: 1.0842  data: 0.7423  max mem: 6458\n",
            "Epoch: [5]  [ 10/781]  eta: 0:05:07  lr: 0.000007  loss: 1.8214 (1.7966)  time: 0.3989  data: 0.0678  max mem: 6458\n",
            "Epoch: [5]  [ 20/781]  eta: 0:04:38  lr: 0.000007  loss: 1.7724 (1.8083)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [5]  [ 30/781]  eta: 0:04:26  lr: 0.000007  loss: 1.8054 (1.8191)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [5]  [ 40/781]  eta: 0:04:18  lr: 0.000007  loss: 1.8400 (1.8443)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [5]  [ 50/781]  eta: 0:04:12  lr: 0.000007  loss: 1.9129 (1.8515)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [ 60/781]  eta: 0:04:06  lr: 0.000007  loss: 1.9006 (1.8566)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [ 70/781]  eta: 0:04:02  lr: 0.000007  loss: 1.8825 (1.8603)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [ 80/781]  eta: 0:03:57  lr: 0.000007  loss: 1.8159 (1.8524)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [ 90/781]  eta: 0:03:53  lr: 0.000007  loss: 1.8274 (1.8535)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [100/781]  eta: 0:03:49  lr: 0.000007  loss: 1.8979 (1.8587)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [110/781]  eta: 0:03:46  lr: 0.000007  loss: 1.8408 (1.8598)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [120/781]  eta: 0:03:42  lr: 0.000007  loss: 1.8157 (1.8552)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [130/781]  eta: 0:03:38  lr: 0.000007  loss: 1.8184 (1.8566)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [140/781]  eta: 0:03:34  lr: 0.000007  loss: 1.8715 (1.8607)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [150/781]  eta: 0:03:31  lr: 0.000007  loss: 1.8809 (1.8630)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [160/781]  eta: 0:03:27  lr: 0.000007  loss: 1.8786 (1.8597)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [170/781]  eta: 0:03:24  lr: 0.000007  loss: 1.8282 (1.8595)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [180/781]  eta: 0:03:20  lr: 0.000007  loss: 1.8154 (1.8575)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [190/781]  eta: 0:03:17  lr: 0.000007  loss: 1.7768 (1.8545)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [200/781]  eta: 0:03:13  lr: 0.000007  loss: 1.7768 (1.8523)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [210/781]  eta: 0:03:10  lr: 0.000007  loss: 1.8303 (1.8543)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [220/781]  eta: 0:03:07  lr: 0.000007  loss: 1.9114 (1.8610)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [230/781]  eta: 0:03:03  lr: 0.000007  loss: 1.8968 (1.8597)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [240/781]  eta: 0:03:00  lr: 0.000007  loss: 1.8592 (1.8619)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [250/781]  eta: 0:02:56  lr: 0.000007  loss: 1.9165 (1.8637)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [260/781]  eta: 0:02:53  lr: 0.000007  loss: 1.8980 (1.8647)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [270/781]  eta: 0:02:50  lr: 0.000007  loss: 1.8803 (1.8657)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [280/781]  eta: 0:02:46  lr: 0.000007  loss: 1.8479 (1.8644)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [290/781]  eta: 0:02:43  lr: 0.000007  loss: 1.8154 (1.8624)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [300/781]  eta: 0:02:39  lr: 0.000007  loss: 1.8362 (1.8621)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [310/781]  eta: 0:02:36  lr: 0.000007  loss: 1.8319 (1.8601)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [320/781]  eta: 0:02:33  lr: 0.000007  loss: 1.8071 (1.8611)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [330/781]  eta: 0:02:29  lr: 0.000007  loss: 1.8644 (1.8631)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [340/781]  eta: 0:02:26  lr: 0.000007  loss: 1.8603 (1.8615)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [350/781]  eta: 0:02:23  lr: 0.000007  loss: 1.8144 (1.8615)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [360/781]  eta: 0:02:19  lr: 0.000007  loss: 1.8809 (1.8627)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [370/781]  eta: 0:02:16  lr: 0.000007  loss: 1.8811 (1.8646)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [380/781]  eta: 0:02:13  lr: 0.000007  loss: 1.9127 (1.8649)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [390/781]  eta: 0:02:09  lr: 0.000007  loss: 1.8998 (1.8646)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [400/781]  eta: 0:02:06  lr: 0.000007  loss: 1.8146 (1.8627)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [410/781]  eta: 0:02:03  lr: 0.000007  loss: 1.8146 (1.8635)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [420/781]  eta: 0:01:59  lr: 0.000007  loss: 1.8929 (1.8648)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [430/781]  eta: 0:01:56  lr: 0.000007  loss: 1.8929 (1.8650)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [440/781]  eta: 0:01:53  lr: 0.000007  loss: 1.8566 (1.8667)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [450/781]  eta: 0:01:49  lr: 0.000007  loss: 1.9140 (1.8680)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [460/781]  eta: 0:01:46  lr: 0.000007  loss: 1.8775 (1.8654)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [470/781]  eta: 0:01:43  lr: 0.000007  loss: 1.7784 (1.8643)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [480/781]  eta: 0:01:39  lr: 0.000007  loss: 1.7934 (1.8637)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [490/781]  eta: 0:01:36  lr: 0.000007  loss: 1.8388 (1.8635)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [500/781]  eta: 0:01:33  lr: 0.000007  loss: 1.8388 (1.8628)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [510/781]  eta: 0:01:29  lr: 0.000007  loss: 1.8223 (1.8626)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [520/781]  eta: 0:01:26  lr: 0.000007  loss: 1.8161 (1.8617)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [530/781]  eta: 0:01:23  lr: 0.000007  loss: 1.7817 (1.8606)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [540/781]  eta: 0:01:19  lr: 0.000007  loss: 1.7956 (1.8608)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [550/781]  eta: 0:01:16  lr: 0.000007  loss: 1.9113 (1.8613)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [560/781]  eta: 0:01:13  lr: 0.000007  loss: 1.8699 (1.8606)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [570/781]  eta: 0:01:09  lr: 0.000007  loss: 1.8150 (1.8599)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [580/781]  eta: 0:01:06  lr: 0.000007  loss: 1.8222 (1.8593)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [590/781]  eta: 0:01:03  lr: 0.000007  loss: 1.8222 (1.8587)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [600/781]  eta: 0:00:59  lr: 0.000007  loss: 1.7912 (1.8588)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [610/781]  eta: 0:00:56  lr: 0.000007  loss: 1.8177 (1.8580)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [620/781]  eta: 0:00:53  lr: 0.000007  loss: 1.8297 (1.8578)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [630/781]  eta: 0:00:50  lr: 0.000007  loss: 1.8297 (1.8577)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [640/781]  eta: 0:00:46  lr: 0.000007  loss: 1.8032 (1.8574)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [650/781]  eta: 0:00:43  lr: 0.000007  loss: 1.8555 (1.8576)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [660/781]  eta: 0:00:40  lr: 0.000007  loss: 1.8544 (1.8573)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [670/781]  eta: 0:00:36  lr: 0.000007  loss: 1.8011 (1.8572)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [680/781]  eta: 0:00:33  lr: 0.000007  loss: 1.8570 (1.8577)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [690/781]  eta: 0:00:30  lr: 0.000007  loss: 1.8742 (1.8580)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [700/781]  eta: 0:00:26  lr: 0.000007  loss: 1.8322 (1.8578)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [710/781]  eta: 0:00:23  lr: 0.000007  loss: 1.7924 (1.8563)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [720/781]  eta: 0:00:20  lr: 0.000007  loss: 1.8419 (1.8574)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [730/781]  eta: 0:00:16  lr: 0.000007  loss: 1.9136 (1.8574)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [740/781]  eta: 0:00:13  lr: 0.000007  loss: 1.8393 (1.8573)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [750/781]  eta: 0:00:10  lr: 0.000007  loss: 1.8393 (1.8577)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [760/781]  eta: 0:00:06  lr: 0.000007  loss: 1.9046 (1.8582)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [770/781]  eta: 0:00:03  lr: 0.000007  loss: 1.9148 (1.8588)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [5]  [780/781]  eta: 0:00:00  lr: 0.000007  loss: 1.8603 (1.8581)  time: 0.3303  data: 0.0006  max mem: 6458\n",
            "Epoch: [5] Total time: 0:04:18 (0.3312 s / it)\n",
            "Averaged stats: lr: 0.000007  loss: 1.8603 (1.8581)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.6716 (0.6716)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8793  data: 0.8486  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7668 (0.8440)  acc1: 84.3750 (81.3447)  acc5: 94.2708 (93.5133)  time: 0.1822  data: 0.1517  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.8824 (0.9127)  acc1: 79.6875 (80.0347)  acc5: 92.7083 (92.3611)  time: 0.1342  data: 0.1037  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0659 (0.9710)  acc1: 74.4792 (78.8979)  acc5: 90.6250 (91.9019)  time: 0.1347  data: 0.1043  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1579 (1.0078)  acc1: 74.4792 (78.1123)  acc5: 89.5833 (91.5142)  time: 0.1341  data: 0.1037  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 0.9894 (1.0031)  acc1: 75.5208 (77.9003)  acc5: 92.7083 (91.8607)  time: 0.1335  data: 0.1030  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0085 (1.0108)  acc1: 75.0000 (77.7900)  acc5: 92.7083 (91.9000)  time: 0.1122  data: 0.0827  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1411 s / it)\n",
            "* Acc@1 77.790 Acc@5 91.900 loss 1.011\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [6]  [  0/781]  eta: 0:14:59  lr: 0.000007  loss: 1.8916 (1.8916)  time: 1.1515  data: 0.8154  max mem: 6458\n",
            "Epoch: [6]  [ 10/781]  eta: 0:05:12  lr: 0.000007  loss: 2.0500 (2.0215)  time: 0.4050  data: 0.0745  max mem: 6458\n",
            "Epoch: [6]  [ 20/781]  eta: 0:04:41  lr: 0.000007  loss: 1.9373 (1.9572)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 30/781]  eta: 0:04:27  lr: 0.000007  loss: 1.9323 (1.9679)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 40/781]  eta: 0:04:19  lr: 0.000007  loss: 1.9965 (1.9730)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 50/781]  eta: 0:04:13  lr: 0.000007  loss: 1.9965 (1.9788)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 60/781]  eta: 0:04:07  lr: 0.000007  loss: 1.9368 (1.9717)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 70/781]  eta: 0:04:02  lr: 0.000007  loss: 1.8906 (1.9528)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 80/781]  eta: 0:03:58  lr: 0.000007  loss: 1.8443 (1.9493)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [ 90/781]  eta: 0:03:54  lr: 0.000007  loss: 1.8911 (1.9506)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [100/781]  eta: 0:03:50  lr: 0.000007  loss: 1.9497 (1.9482)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [110/781]  eta: 0:03:46  lr: 0.000007  loss: 1.9101 (1.9454)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [120/781]  eta: 0:03:42  lr: 0.000007  loss: 1.9006 (1.9428)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [130/781]  eta: 0:03:38  lr: 0.000007  loss: 1.9697 (1.9499)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [140/781]  eta: 0:03:35  lr: 0.000007  loss: 1.9686 (1.9506)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [150/781]  eta: 0:03:31  lr: 0.000007  loss: 1.9005 (1.9484)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [160/781]  eta: 0:03:28  lr: 0.000007  loss: 1.8718 (1.9446)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [170/781]  eta: 0:03:24  lr: 0.000007  loss: 1.8841 (1.9448)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [180/781]  eta: 0:03:21  lr: 0.000007  loss: 1.9724 (1.9440)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [190/781]  eta: 0:03:17  lr: 0.000007  loss: 1.9938 (1.9448)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [200/781]  eta: 0:03:14  lr: 0.000007  loss: 1.9594 (1.9451)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [210/781]  eta: 0:03:10  lr: 0.000007  loss: 1.9902 (1.9479)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [220/781]  eta: 0:03:07  lr: 0.000007  loss: 1.9625 (1.9480)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [230/781]  eta: 0:03:03  lr: 0.000007  loss: 1.9558 (1.9485)  time: 0.3311  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [240/781]  eta: 0:03:00  lr: 0.000007  loss: 1.9627 (1.9512)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [250/781]  eta: 0:02:57  lr: 0.000007  loss: 2.0149 (1.9539)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [260/781]  eta: 0:02:53  lr: 0.000007  loss: 1.9746 (1.9542)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [270/781]  eta: 0:02:50  lr: 0.000007  loss: 1.9051 (1.9536)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [280/781]  eta: 0:02:46  lr: 0.000007  loss: 1.9761 (1.9555)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [290/781]  eta: 0:02:43  lr: 0.000007  loss: 1.9562 (1.9548)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [300/781]  eta: 0:02:40  lr: 0.000007  loss: 1.9381 (1.9559)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [310/781]  eta: 0:02:36  lr: 0.000007  loss: 1.9593 (1.9573)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [320/781]  eta: 0:02:33  lr: 0.000007  loss: 1.9198 (1.9555)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [330/781]  eta: 0:02:30  lr: 0.000007  loss: 1.9032 (1.9546)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [340/781]  eta: 0:02:26  lr: 0.000007  loss: 1.9536 (1.9554)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [350/781]  eta: 0:02:23  lr: 0.000007  loss: 1.9414 (1.9548)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [360/781]  eta: 0:02:19  lr: 0.000007  loss: 1.9375 (1.9549)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [370/781]  eta: 0:02:16  lr: 0.000007  loss: 1.9408 (1.9553)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [380/781]  eta: 0:02:13  lr: 0.000007  loss: 1.9297 (1.9544)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [390/781]  eta: 0:02:09  lr: 0.000007  loss: 1.8940 (1.9536)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [400/781]  eta: 0:02:06  lr: 0.000007  loss: 1.9073 (1.9521)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [410/781]  eta: 0:02:03  lr: 0.000007  loss: 1.9030 (1.9503)  time: 0.3310  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [420/781]  eta: 0:01:59  lr: 0.000007  loss: 1.9583 (1.9513)  time: 0.3310  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [430/781]  eta: 0:01:56  lr: 0.000007  loss: 1.9639 (1.9509)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [440/781]  eta: 0:01:53  lr: 0.000007  loss: 1.9154 (1.9509)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [450/781]  eta: 0:01:49  lr: 0.000007  loss: 1.9589 (1.9509)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [460/781]  eta: 0:01:46  lr: 0.000007  loss: 1.9815 (1.9512)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [470/781]  eta: 0:01:43  lr: 0.000007  loss: 1.9237 (1.9506)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [480/781]  eta: 0:01:39  lr: 0.000007  loss: 1.8498 (1.9503)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [490/781]  eta: 0:01:36  lr: 0.000007  loss: 1.9232 (1.9504)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [500/781]  eta: 0:01:33  lr: 0.000007  loss: 1.8981 (1.9495)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [510/781]  eta: 0:01:29  lr: 0.000007  loss: 1.8482 (1.9481)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [520/781]  eta: 0:01:26  lr: 0.000007  loss: 1.9540 (1.9496)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [530/781]  eta: 0:01:23  lr: 0.000007  loss: 1.9676 (1.9493)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [540/781]  eta: 0:01:19  lr: 0.000007  loss: 1.9664 (1.9500)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [550/781]  eta: 0:01:16  lr: 0.000007  loss: 1.9838 (1.9509)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [560/781]  eta: 0:01:13  lr: 0.000007  loss: 1.9205 (1.9496)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [570/781]  eta: 0:01:09  lr: 0.000007  loss: 1.8914 (1.9486)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [580/781]  eta: 0:01:06  lr: 0.000007  loss: 1.8948 (1.9478)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [590/781]  eta: 0:01:03  lr: 0.000007  loss: 1.9015 (1.9477)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [600/781]  eta: 0:01:00  lr: 0.000007  loss: 1.9185 (1.9480)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [610/781]  eta: 0:00:56  lr: 0.000007  loss: 1.9227 (1.9477)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [620/781]  eta: 0:00:53  lr: 0.000007  loss: 1.9643 (1.9477)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [630/781]  eta: 0:00:50  lr: 0.000007  loss: 1.9330 (1.9475)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [640/781]  eta: 0:00:46  lr: 0.000007  loss: 1.9323 (1.9479)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [650/781]  eta: 0:00:43  lr: 0.000007  loss: 1.9585 (1.9481)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [660/781]  eta: 0:00:40  lr: 0.000007  loss: 1.9585 (1.9482)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [670/781]  eta: 0:00:36  lr: 0.000007  loss: 1.9546 (1.9482)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [680/781]  eta: 0:00:33  lr: 0.000007  loss: 1.9155 (1.9468)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [690/781]  eta: 0:00:30  lr: 0.000007  loss: 1.8762 (1.9458)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [700/781]  eta: 0:00:26  lr: 0.000007  loss: 1.9150 (1.9463)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [710/781]  eta: 0:00:23  lr: 0.000007  loss: 1.9258 (1.9451)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [720/781]  eta: 0:00:20  lr: 0.000007  loss: 1.8896 (1.9451)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [730/781]  eta: 0:00:16  lr: 0.000007  loss: 1.9383 (1.9453)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [740/781]  eta: 0:00:13  lr: 0.000007  loss: 1.9140 (1.9451)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [750/781]  eta: 0:00:10  lr: 0.000007  loss: 1.9073 (1.9448)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [6]  [760/781]  eta: 0:00:06  lr: 0.000007  loss: 1.9190 (1.9450)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [770/781]  eta: 0:00:03  lr: 0.000007  loss: 1.9247 (1.9445)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [6]  [780/781]  eta: 0:00:00  lr: 0.000007  loss: 1.9060 (1.9443)  time: 0.3307  data: 0.0007  max mem: 6458\n",
            "Epoch: [6] Total time: 0:04:18 (0.3315 s / it)\n",
            "Averaged stats: lr: 0.000007  loss: 1.9060 (1.9443)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:47  loss: 0.6545 (0.6545)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.9000  data: 0.8692  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7127 (0.8364)  acc1: 84.8958 (81.9602)  acc5: 94.7917 (93.4659)  time: 0.1810  data: 0.1505  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9120 (0.9118)  acc1: 78.6458 (80.3323)  acc5: 92.7083 (92.3859)  time: 0.1304  data: 0.0999  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0514 (0.9744)  acc1: 77.0833 (79.3347)  acc5: 90.6250 (91.8851)  time: 0.1345  data: 0.1040  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1700 (1.0135)  acc1: 76.5625 (78.4045)  acc5: 90.6250 (91.4888)  time: 0.1359  data: 0.1055  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0244 (1.0084)  acc1: 77.0833 (78.0739)  acc5: 91.1458 (91.7484)  time: 0.1360  data: 0.1055  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0501 (1.0160)  acc1: 75.0000 (77.9500)  acc5: 92.1875 (91.7900)  time: 0.1149  data: 0.0853  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1416 s / it)\n",
            "* Acc@1 77.950 Acc@5 91.790 loss 1.016\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [7]  [  0/781]  eta: 0:14:20  lr: 0.000007  loss: 2.0782 (2.0782)  time: 1.1016  data: 0.7538  max mem: 6458\n",
            "Epoch: [7]  [ 10/781]  eta: 0:05:08  lr: 0.000007  loss: 1.9990 (2.0071)  time: 0.4007  data: 0.0689  max mem: 6458\n",
            "Epoch: [7]  [ 20/781]  eta: 0:04:39  lr: 0.000007  loss: 1.9806 (1.9885)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [ 30/781]  eta: 0:04:26  lr: 0.000007  loss: 1.9481 (1.9777)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [ 40/781]  eta: 0:04:18  lr: 0.000007  loss: 1.9599 (1.9854)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [ 50/781]  eta: 0:04:12  lr: 0.000007  loss: 1.9800 (1.9872)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [ 60/781]  eta: 0:04:07  lr: 0.000007  loss: 1.9615 (1.9857)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [ 70/781]  eta: 0:04:02  lr: 0.000007  loss: 2.0047 (1.9945)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [ 80/781]  eta: 0:03:58  lr: 0.000007  loss: 2.0047 (2.0014)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [ 90/781]  eta: 0:03:54  lr: 0.000007  loss: 1.9870 (2.0037)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [100/781]  eta: 0:03:50  lr: 0.000007  loss: 2.0232 (2.0041)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [110/781]  eta: 0:03:46  lr: 0.000007  loss: 1.9790 (2.0011)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [120/781]  eta: 0:03:42  lr: 0.000007  loss: 1.9876 (2.0038)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [130/781]  eta: 0:03:38  lr: 0.000007  loss: 2.0110 (2.0026)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [140/781]  eta: 0:03:35  lr: 0.000007  loss: 2.0110 (2.0076)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [150/781]  eta: 0:03:31  lr: 0.000007  loss: 2.0662 (2.0084)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [160/781]  eta: 0:03:28  lr: 0.000007  loss: 1.9588 (2.0021)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [170/781]  eta: 0:03:24  lr: 0.000007  loss: 1.9129 (1.9993)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [180/781]  eta: 0:03:21  lr: 0.000007  loss: 1.9902 (2.0020)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [190/781]  eta: 0:03:17  lr: 0.000007  loss: 2.0216 (2.0052)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [200/781]  eta: 0:03:14  lr: 0.000007  loss: 2.0183 (2.0071)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [210/781]  eta: 0:03:10  lr: 0.000007  loss: 2.0140 (2.0062)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [220/781]  eta: 0:03:07  lr: 0.000007  loss: 1.9707 (2.0047)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [230/781]  eta: 0:03:03  lr: 0.000007  loss: 1.9347 (2.0025)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [240/781]  eta: 0:03:00  lr: 0.000007  loss: 1.9079 (1.9982)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [250/781]  eta: 0:02:57  lr: 0.000007  loss: 1.9707 (1.9991)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [260/781]  eta: 0:02:53  lr: 0.000007  loss: 1.9784 (1.9999)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [270/781]  eta: 0:02:50  lr: 0.000007  loss: 2.0319 (2.0014)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [280/781]  eta: 0:02:46  lr: 0.000007  loss: 2.0366 (2.0017)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [290/781]  eta: 0:02:43  lr: 0.000007  loss: 2.0154 (2.0002)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [300/781]  eta: 0:02:40  lr: 0.000007  loss: 1.9808 (1.9999)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [310/781]  eta: 0:02:36  lr: 0.000007  loss: 1.9603 (1.9987)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [320/781]  eta: 0:02:33  lr: 0.000007  loss: 1.9473 (1.9984)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [330/781]  eta: 0:02:30  lr: 0.000007  loss: 1.9638 (1.9978)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [340/781]  eta: 0:02:26  lr: 0.000007  loss: 1.9522 (1.9959)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [350/781]  eta: 0:02:23  lr: 0.000007  loss: 1.9482 (1.9965)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [360/781]  eta: 0:02:19  lr: 0.000007  loss: 1.9956 (1.9957)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [370/781]  eta: 0:02:16  lr: 0.000007  loss: 2.0122 (1.9963)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [380/781]  eta: 0:02:13  lr: 0.000007  loss: 2.0073 (1.9957)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [390/781]  eta: 0:02:09  lr: 0.000007  loss: 1.9927 (1.9968)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [400/781]  eta: 0:02:06  lr: 0.000007  loss: 2.0589 (1.9992)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [410/781]  eta: 0:02:03  lr: 0.000007  loss: 1.9961 (1.9984)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [420/781]  eta: 0:01:59  lr: 0.000007  loss: 1.9865 (1.9987)  time: 0.3300  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [430/781]  eta: 0:01:56  lr: 0.000007  loss: 1.9966 (1.9983)  time: 0.3413  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [440/781]  eta: 0:01:53  lr: 0.000007  loss: 1.9294 (1.9976)  time: 0.3414  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [450/781]  eta: 0:01:50  lr: 0.000007  loss: 1.9691 (1.9986)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [460/781]  eta: 0:01:46  lr: 0.000007  loss: 2.0234 (1.9985)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [470/781]  eta: 0:01:43  lr: 0.000007  loss: 2.0234 (1.9993)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [480/781]  eta: 0:01:40  lr: 0.000007  loss: 2.0257 (1.9999)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [490/781]  eta: 0:01:36  lr: 0.000007  loss: 1.9790 (2.0000)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [500/781]  eta: 0:01:33  lr: 0.000007  loss: 1.9453 (1.9991)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [510/781]  eta: 0:01:30  lr: 0.000007  loss: 1.9807 (1.9998)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [520/781]  eta: 0:01:26  lr: 0.000007  loss: 1.9841 (1.9991)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [530/781]  eta: 0:01:23  lr: 0.000007  loss: 1.9841 (1.9997)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [540/781]  eta: 0:01:20  lr: 0.000007  loss: 1.9951 (1.9988)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [550/781]  eta: 0:01:16  lr: 0.000007  loss: 1.9028 (1.9984)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [560/781]  eta: 0:01:13  lr: 0.000007  loss: 1.9628 (1.9988)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [570/781]  eta: 0:01:10  lr: 0.000007  loss: 1.9296 (1.9969)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [580/781]  eta: 0:01:06  lr: 0.000007  loss: 1.9309 (1.9970)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [590/781]  eta: 0:01:03  lr: 0.000007  loss: 2.0053 (1.9976)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [600/781]  eta: 0:01:00  lr: 0.000007  loss: 2.0053 (1.9981)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [610/781]  eta: 0:00:56  lr: 0.000007  loss: 1.9987 (1.9978)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [620/781]  eta: 0:00:53  lr: 0.000007  loss: 1.9926 (1.9984)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [630/781]  eta: 0:00:50  lr: 0.000007  loss: 1.9523 (1.9989)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [640/781]  eta: 0:00:46  lr: 0.000007  loss: 1.9851 (1.9988)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [650/781]  eta: 0:00:43  lr: 0.000007  loss: 1.9347 (1.9985)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [660/781]  eta: 0:00:40  lr: 0.000007  loss: 1.9535 (1.9982)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [670/781]  eta: 0:00:36  lr: 0.000007  loss: 1.9818 (1.9992)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [680/781]  eta: 0:00:33  lr: 0.000007  loss: 1.9604 (1.9982)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [690/781]  eta: 0:00:30  lr: 0.000007  loss: 1.9785 (1.9985)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [700/781]  eta: 0:00:26  lr: 0.000007  loss: 2.0017 (1.9984)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [710/781]  eta: 0:00:23  lr: 0.000007  loss: 1.9862 (1.9981)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [720/781]  eta: 0:00:20  lr: 0.000007  loss: 1.9384 (1.9978)  time: 0.3313  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [730/781]  eta: 0:00:16  lr: 0.000007  loss: 1.9384 (1.9976)  time: 0.3314  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [740/781]  eta: 0:00:13  lr: 0.000007  loss: 1.9930 (1.9977)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [750/781]  eta: 0:00:10  lr: 0.000007  loss: 2.0137 (1.9980)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [760/781]  eta: 0:00:06  lr: 0.000007  loss: 2.0416 (1.9981)  time: 0.3309  data: 0.0004  max mem: 6458\n",
            "Epoch: [7]  [770/781]  eta: 0:00:03  lr: 0.000007  loss: 2.0085 (1.9985)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [7]  [780/781]  eta: 0:00:00  lr: 0.000007  loss: 1.9985 (1.9989)  time: 0.3308  data: 0.0006  max mem: 6458\n",
            "Epoch: [7] Total time: 0:04:19 (0.3318 s / it)\n",
            "Averaged stats: lr: 0.000007  loss: 1.9985 (1.9989)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:47  loss: 0.6970 (0.6970)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.9004  data: 0.8698  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7181 (0.8330)  acc1: 84.8958 (82.2917)  acc5: 94.2708 (93.4186)  time: 0.1806  data: 0.1501  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9273 (0.9155)  acc1: 78.6458 (80.6052)  acc5: 93.7500 (92.2619)  time: 0.1322  data: 0.1018  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1169 (0.9762)  acc1: 75.5208 (79.3347)  acc5: 89.5833 (91.6163)  time: 0.1340  data: 0.1036  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1515 (1.0147)  acc1: 75.5208 (78.2774)  acc5: 89.0625 (91.1839)  time: 0.1331  data: 0.1026  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0095 (1.0130)  acc1: 76.0417 (77.9820)  acc5: 91.1458 (91.4522)  time: 0.1302  data: 0.0997  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0565 (1.0248)  acc1: 75.5208 (77.8700)  acc5: 92.7083 (91.4900)  time: 0.1084  data: 0.0788  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1393 s / it)\n",
            "* Acc@1 77.870 Acc@5 91.490 loss 1.025\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [8]  [  0/781]  eta: 0:15:14  lr: 0.000007  loss: 2.2458 (2.2458)  time: 1.1710  data: 0.8342  max mem: 6458\n",
            "Epoch: [8]  [ 10/781]  eta: 0:05:14  lr: 0.000007  loss: 2.1176 (2.1227)  time: 0.4073  data: 0.0762  max mem: 6458\n",
            "Epoch: [8]  [ 20/781]  eta: 0:04:42  lr: 0.000007  loss: 2.0162 (2.0621)  time: 0.3312  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [ 30/781]  eta: 0:04:28  lr: 0.000007  loss: 2.0267 (2.0748)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 40/781]  eta: 0:04:20  lr: 0.000007  loss: 2.0625 (2.0694)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 50/781]  eta: 0:04:13  lr: 0.000007  loss: 2.0652 (2.0796)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 60/781]  eta: 0:04:08  lr: 0.000007  loss: 2.0296 (2.0690)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 70/781]  eta: 0:04:03  lr: 0.000007  loss: 2.0499 (2.0742)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 80/781]  eta: 0:03:59  lr: 0.000007  loss: 2.0506 (2.0707)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [ 90/781]  eta: 0:03:54  lr: 0.000007  loss: 2.0068 (2.0713)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [100/781]  eta: 0:03:50  lr: 0.000007  loss: 2.0007 (2.0659)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [110/781]  eta: 0:03:46  lr: 0.000007  loss: 2.0139 (2.0596)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [120/781]  eta: 0:03:43  lr: 0.000007  loss: 2.0327 (2.0619)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [130/781]  eta: 0:03:39  lr: 0.000007  loss: 2.0759 (2.0634)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [140/781]  eta: 0:03:35  lr: 0.000007  loss: 2.0378 (2.0573)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [150/781]  eta: 0:03:32  lr: 0.000007  loss: 2.0000 (2.0584)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [160/781]  eta: 0:03:28  lr: 0.000007  loss: 2.1036 (2.0591)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [170/781]  eta: 0:03:24  lr: 0.000007  loss: 2.0774 (2.0604)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [180/781]  eta: 0:03:21  lr: 0.000007  loss: 2.0774 (2.0618)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [190/781]  eta: 0:03:17  lr: 0.000007  loss: 2.0596 (2.0627)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [200/781]  eta: 0:03:14  lr: 0.000007  loss: 2.0539 (2.0618)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [210/781]  eta: 0:03:11  lr: 0.000007  loss: 2.0539 (2.0601)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [220/781]  eta: 0:03:07  lr: 0.000007  loss: 2.0037 (2.0573)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [230/781]  eta: 0:03:04  lr: 0.000007  loss: 2.0490 (2.0579)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [240/781]  eta: 0:03:00  lr: 0.000007  loss: 2.0694 (2.0586)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [250/781]  eta: 0:02:57  lr: 0.000007  loss: 2.0423 (2.0584)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [260/781]  eta: 0:02:53  lr: 0.000007  loss: 2.0199 (2.0586)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [8]  [270/781]  eta: 0:02:50  lr: 0.000007  loss: 2.1157 (2.0612)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [280/781]  eta: 0:02:47  lr: 0.000007  loss: 2.1294 (2.0615)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [290/781]  eta: 0:02:43  lr: 0.000007  loss: 2.0202 (2.0603)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [300/781]  eta: 0:02:40  lr: 0.000007  loss: 2.0775 (2.0615)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [310/781]  eta: 0:02:36  lr: 0.000007  loss: 2.1035 (2.0629)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [320/781]  eta: 0:02:33  lr: 0.000007  loss: 2.0817 (2.0619)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [330/781]  eta: 0:02:30  lr: 0.000007  loss: 2.0427 (2.0632)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [340/781]  eta: 0:02:26  lr: 0.000007  loss: 2.0419 (2.0610)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [350/781]  eta: 0:02:23  lr: 0.000007  loss: 1.9948 (2.0608)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [360/781]  eta: 0:02:20  lr: 0.000007  loss: 2.0606 (2.0616)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [370/781]  eta: 0:02:16  lr: 0.000007  loss: 2.1043 (2.0615)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [380/781]  eta: 0:02:13  lr: 0.000007  loss: 2.0468 (2.0607)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [390/781]  eta: 0:02:10  lr: 0.000007  loss: 2.0604 (2.0616)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [400/781]  eta: 0:02:06  lr: 0.000007  loss: 2.0493 (2.0606)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [410/781]  eta: 0:02:03  lr: 0.000007  loss: 2.0135 (2.0606)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [420/781]  eta: 0:01:59  lr: 0.000007  loss: 2.0872 (2.0617)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [430/781]  eta: 0:01:56  lr: 0.000007  loss: 2.1024 (2.0626)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [440/781]  eta: 0:01:53  lr: 0.000007  loss: 2.0323 (2.0615)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [450/781]  eta: 0:01:49  lr: 0.000007  loss: 2.0162 (2.0607)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [460/781]  eta: 0:01:46  lr: 0.000007  loss: 1.9564 (2.0592)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [470/781]  eta: 0:01:43  lr: 0.000007  loss: 2.0092 (2.0606)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [480/781]  eta: 0:01:39  lr: 0.000007  loss: 2.0890 (2.0612)  time: 0.3297  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [490/781]  eta: 0:01:36  lr: 0.000007  loss: 2.0253 (2.0602)  time: 0.3297  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [500/781]  eta: 0:01:33  lr: 0.000007  loss: 2.0079 (2.0595)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [510/781]  eta: 0:01:29  lr: 0.000007  loss: 2.0005 (2.0588)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [520/781]  eta: 0:01:26  lr: 0.000007  loss: 2.0071 (2.0579)  time: 0.3297  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [530/781]  eta: 0:01:23  lr: 0.000007  loss: 2.0196 (2.0574)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [540/781]  eta: 0:01:19  lr: 0.000007  loss: 2.0223 (2.0570)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [550/781]  eta: 0:01:16  lr: 0.000007  loss: 2.0654 (2.0581)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [560/781]  eta: 0:01:13  lr: 0.000007  loss: 2.0085 (2.0568)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [570/781]  eta: 0:01:09  lr: 0.000007  loss: 2.0085 (2.0567)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [580/781]  eta: 0:01:06  lr: 0.000007  loss: 2.0716 (2.0580)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [590/781]  eta: 0:01:03  lr: 0.000007  loss: 2.0081 (2.0566)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [600/781]  eta: 0:01:00  lr: 0.000007  loss: 1.9941 (2.0563)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [610/781]  eta: 0:00:56  lr: 0.000007  loss: 2.0224 (2.0552)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [620/781]  eta: 0:00:53  lr: 0.000007  loss: 2.0263 (2.0550)  time: 0.3297  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [630/781]  eta: 0:00:50  lr: 0.000007  loss: 2.0674 (2.0565)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [640/781]  eta: 0:00:46  lr: 0.000007  loss: 2.0867 (2.0569)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [650/781]  eta: 0:00:43  lr: 0.000007  loss: 2.0428 (2.0560)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [660/781]  eta: 0:00:40  lr: 0.000007  loss: 2.0339 (2.0562)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [670/781]  eta: 0:00:36  lr: 0.000007  loss: 2.0826 (2.0573)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [680/781]  eta: 0:00:33  lr: 0.000007  loss: 2.0695 (2.0572)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [690/781]  eta: 0:00:30  lr: 0.000007  loss: 2.0344 (2.0575)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [700/781]  eta: 0:00:26  lr: 0.000007  loss: 2.0780 (2.0579)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [710/781]  eta: 0:00:23  lr: 0.000007  loss: 2.0780 (2.0581)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [720/781]  eta: 0:00:20  lr: 0.000007  loss: 2.0554 (2.0579)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [730/781]  eta: 0:00:16  lr: 0.000007  loss: 2.0428 (2.0578)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [740/781]  eta: 0:00:13  lr: 0.000007  loss: 2.0451 (2.0581)  time: 0.3298  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [750/781]  eta: 0:00:10  lr: 0.000007  loss: 2.0451 (2.0585)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [760/781]  eta: 0:00:06  lr: 0.000007  loss: 1.9831 (2.0577)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [770/781]  eta: 0:00:03  lr: 0.000007  loss: 1.9831 (2.0565)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [8]  [780/781]  eta: 0:00:00  lr: 0.000007  loss: 2.0110 (2.0564)  time: 0.3302  data: 0.0007  max mem: 6458\n",
            "Epoch: [8] Total time: 0:04:18 (0.3314 s / it)\n",
            "Averaged stats: lr: 0.000007  loss: 2.0110 (2.0564)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:38  loss: 0.7284 (0.7284)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.7319  data: 0.7012  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7511 (0.8631)  acc1: 83.3333 (81.8182)  acc5: 93.7500 (92.7083)  time: 0.1750  data: 0.1445  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9058 (0.9309)  acc1: 79.1667 (80.4564)  acc5: 92.1875 (91.7411)  time: 0.1340  data: 0.1035  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0627 (0.9807)  acc1: 76.0417 (79.2843)  acc5: 90.6250 (91.5155)  time: 0.1359  data: 0.1055  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1057 (1.0258)  acc1: 75.0000 (78.1758)  acc5: 90.1042 (91.0188)  time: 0.1363  data: 0.1059  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0371 (1.0217)  acc1: 76.5625 (77.9208)  acc5: 91.1458 (91.2480)  time: 0.1314  data: 0.1010  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0539 (1.0324)  acc1: 75.0000 (77.8100)  acc5: 91.6667 (91.3100)  time: 0.1112  data: 0.0816  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1391 s / it)\n",
            "* Acc@1 77.810 Acc@5 91.310 loss 1.032\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [9]  [  0/781]  eta: 0:14:56  lr: 0.000008  loss: 2.0189 (2.0189)  time: 1.1473  data: 0.8067  max mem: 6458\n",
            "Epoch: [9]  [ 10/781]  eta: 0:05:12  lr: 0.000008  loss: 2.0976 (2.0654)  time: 0.4047  data: 0.0737  max mem: 6458\n",
            "Epoch: [9]  [ 20/781]  eta: 0:04:40  lr: 0.000008  loss: 2.1102 (2.1055)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [ 30/781]  eta: 0:04:27  lr: 0.000008  loss: 2.1040 (2.1099)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 40/781]  eta: 0:04:19  lr: 0.000008  loss: 2.0792 (2.0961)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 50/781]  eta: 0:04:13  lr: 0.000008  loss: 2.0813 (2.1072)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 60/781]  eta: 0:04:07  lr: 0.000008  loss: 2.1086 (2.1017)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 70/781]  eta: 0:04:02  lr: 0.000008  loss: 2.0754 (2.1007)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 80/781]  eta: 0:03:58  lr: 0.000008  loss: 2.0912 (2.1020)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [ 90/781]  eta: 0:03:54  lr: 0.000008  loss: 2.0749 (2.1021)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [100/781]  eta: 0:03:50  lr: 0.000008  loss: 2.1317 (2.1061)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [110/781]  eta: 0:03:46  lr: 0.000008  loss: 2.1684 (2.1118)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [120/781]  eta: 0:03:42  lr: 0.000008  loss: 2.1834 (2.1145)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [130/781]  eta: 0:03:39  lr: 0.000008  loss: 2.1069 (2.1142)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [140/781]  eta: 0:03:35  lr: 0.000008  loss: 2.1249 (2.1164)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [150/781]  eta: 0:03:31  lr: 0.000008  loss: 2.1395 (2.1153)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [160/781]  eta: 0:03:28  lr: 0.000008  loss: 2.0878 (2.1158)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [170/781]  eta: 0:03:24  lr: 0.000008  loss: 2.1319 (2.1181)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [180/781]  eta: 0:03:21  lr: 0.000008  loss: 2.1386 (2.1190)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [190/781]  eta: 0:03:17  lr: 0.000008  loss: 2.1358 (2.1196)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [200/781]  eta: 0:03:14  lr: 0.000008  loss: 2.1610 (2.1216)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [210/781]  eta: 0:03:10  lr: 0.000008  loss: 2.1615 (2.1233)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [220/781]  eta: 0:03:07  lr: 0.000008  loss: 2.1757 (2.1273)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [230/781]  eta: 0:03:04  lr: 0.000008  loss: 2.1190 (2.1250)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [240/781]  eta: 0:03:00  lr: 0.000008  loss: 2.1116 (2.1278)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [250/781]  eta: 0:02:57  lr: 0.000008  loss: 2.1113 (2.1257)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [260/781]  eta: 0:02:53  lr: 0.000008  loss: 2.0805 (2.1265)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [270/781]  eta: 0:02:50  lr: 0.000008  loss: 2.1111 (2.1259)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [280/781]  eta: 0:02:46  lr: 0.000008  loss: 2.1111 (2.1262)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [290/781]  eta: 0:02:43  lr: 0.000008  loss: 2.0908 (2.1253)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [300/781]  eta: 0:02:40  lr: 0.000008  loss: 2.0860 (2.1244)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [310/781]  eta: 0:02:36  lr: 0.000008  loss: 2.1433 (2.1257)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [320/781]  eta: 0:02:33  lr: 0.000008  loss: 2.1630 (2.1262)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [330/781]  eta: 0:02:30  lr: 0.000008  loss: 2.1630 (2.1259)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [340/781]  eta: 0:02:26  lr: 0.000008  loss: 2.1006 (2.1246)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [350/781]  eta: 0:02:23  lr: 0.000008  loss: 2.1126 (2.1245)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [360/781]  eta: 0:02:20  lr: 0.000008  loss: 2.1286 (2.1257)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [370/781]  eta: 0:02:16  lr: 0.000008  loss: 2.1191 (2.1259)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [380/781]  eta: 0:02:13  lr: 0.000008  loss: 2.0482 (2.1244)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [390/781]  eta: 0:02:10  lr: 0.000008  loss: 2.0630 (2.1246)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [400/781]  eta: 0:02:06  lr: 0.000008  loss: 2.1374 (2.1253)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [410/781]  eta: 0:02:03  lr: 0.000008  loss: 2.0660 (2.1229)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [420/781]  eta: 0:01:59  lr: 0.000008  loss: 2.1074 (2.1230)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [430/781]  eta: 0:01:56  lr: 0.000008  loss: 2.1287 (2.1247)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [440/781]  eta: 0:01:53  lr: 0.000008  loss: 2.1447 (2.1253)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [450/781]  eta: 0:01:49  lr: 0.000008  loss: 2.0941 (2.1241)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [460/781]  eta: 0:01:46  lr: 0.000008  loss: 2.1102 (2.1243)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [470/781]  eta: 0:01:43  lr: 0.000008  loss: 2.0666 (2.1232)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [480/781]  eta: 0:01:39  lr: 0.000008  loss: 2.0829 (2.1228)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [490/781]  eta: 0:01:36  lr: 0.000008  loss: 2.1103 (2.1219)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [500/781]  eta: 0:01:33  lr: 0.000008  loss: 2.1103 (2.1212)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [510/781]  eta: 0:01:29  lr: 0.000008  loss: 2.0794 (2.1207)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [520/781]  eta: 0:01:26  lr: 0.000008  loss: 2.1170 (2.1210)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [530/781]  eta: 0:01:23  lr: 0.000008  loss: 2.1575 (2.1216)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [540/781]  eta: 0:01:19  lr: 0.000008  loss: 2.0908 (2.1217)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [550/781]  eta: 0:01:16  lr: 0.000008  loss: 2.0659 (2.1210)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [560/781]  eta: 0:01:13  lr: 0.000008  loss: 2.1114 (2.1216)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [570/781]  eta: 0:01:10  lr: 0.000008  loss: 2.1472 (2.1222)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [580/781]  eta: 0:01:06  lr: 0.000008  loss: 2.1143 (2.1220)  time: 0.3301  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [590/781]  eta: 0:01:03  lr: 0.000008  loss: 2.0561 (2.1211)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [600/781]  eta: 0:01:00  lr: 0.000008  loss: 2.0769 (2.1208)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [610/781]  eta: 0:00:56  lr: 0.000008  loss: 2.1291 (2.1218)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [620/781]  eta: 0:00:53  lr: 0.000008  loss: 2.1391 (2.1224)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [630/781]  eta: 0:00:50  lr: 0.000008  loss: 2.1378 (2.1213)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [640/781]  eta: 0:00:46  lr: 0.000008  loss: 2.1490 (2.1221)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [650/781]  eta: 0:00:43  lr: 0.000008  loss: 2.1515 (2.1212)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [660/781]  eta: 0:00:40  lr: 0.000008  loss: 2.0336 (2.1201)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [670/781]  eta: 0:00:36  lr: 0.000008  loss: 2.0444 (2.1197)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [680/781]  eta: 0:00:33  lr: 0.000008  loss: 2.0961 (2.1198)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [690/781]  eta: 0:00:30  lr: 0.000008  loss: 2.1013 (2.1203)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [700/781]  eta: 0:00:26  lr: 0.000008  loss: 2.1494 (2.1216)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [710/781]  eta: 0:00:23  lr: 0.000008  loss: 2.1494 (2.1218)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [720/781]  eta: 0:00:20  lr: 0.000008  loss: 2.1117 (2.1215)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [730/781]  eta: 0:00:16  lr: 0.000008  loss: 2.1117 (2.1221)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [740/781]  eta: 0:00:13  lr: 0.000008  loss: 2.1440 (2.1226)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [750/781]  eta: 0:00:10  lr: 0.000008  loss: 2.1824 (2.1231)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [9]  [760/781]  eta: 0:00:06  lr: 0.000008  loss: 2.1466 (2.1228)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [770/781]  eta: 0:00:03  lr: 0.000008  loss: 2.1071 (2.1225)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [9]  [780/781]  eta: 0:00:00  lr: 0.000008  loss: 2.0926 (2.1221)  time: 0.3307  data: 0.0007  max mem: 6458\n",
            "Epoch: [9] Total time: 0:04:18 (0.3316 s / it)\n",
            "Averaged stats: lr: 0.000008  loss: 2.0926 (2.1221)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.6950 (0.6950)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8705  data: 0.8398  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7789 (0.8510)  acc1: 83.8542 (81.7235)  acc5: 94.2708 (93.0871)  time: 0.1812  data: 0.1508  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9081 (0.9133)  acc1: 78.1250 (80.5308)  acc5: 93.2292 (92.2619)  time: 0.1288  data: 0.0983  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0568 (0.9816)  acc1: 76.0417 (79.2171)  acc5: 90.1042 (91.6163)  time: 0.1317  data: 0.1012  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1761 (1.0259)  acc1: 73.4375 (78.2012)  acc5: 88.5417 (91.1331)  time: 0.1337  data: 0.1032  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0178 (1.0224)  acc1: 75.5208 (77.8697)  acc5: 91.6667 (91.3705)  time: 0.1355  data: 0.1051  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.0379 (1.0347)  acc1: 75.0000 (77.7800)  acc5: 92.7083 (91.4000)  time: 0.1173  data: 0.0877  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1402 s / it)\n",
            "* Acc@1 77.780 Acc@5 91.400 loss 1.035\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [10]  [  0/781]  eta: 0:14:08  lr: 0.000008  loss: 2.1601 (2.1601)  time: 1.0867  data: 0.7453  max mem: 6458\n",
            "Epoch: [10]  [ 10/781]  eta: 0:05:08  lr: 0.000008  loss: 2.1601 (2.1603)  time: 0.3999  data: 0.0681  max mem: 6458\n",
            "Epoch: [10]  [ 20/781]  eta: 0:04:39  lr: 0.000008  loss: 2.1600 (2.1805)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [ 30/781]  eta: 0:04:26  lr: 0.000008  loss: 2.1679 (2.1797)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 40/781]  eta: 0:04:18  lr: 0.000008  loss: 2.2144 (2.1954)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 50/781]  eta: 0:04:12  lr: 0.000008  loss: 2.0995 (2.1826)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 60/781]  eta: 0:04:07  lr: 0.000008  loss: 2.0907 (2.1781)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 70/781]  eta: 0:04:02  lr: 0.000008  loss: 2.1788 (2.1842)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 80/781]  eta: 0:03:58  lr: 0.000008  loss: 2.1551 (2.1788)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [ 90/781]  eta: 0:03:53  lr: 0.000008  loss: 2.1339 (2.1756)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [100/781]  eta: 0:03:50  lr: 0.000008  loss: 2.1753 (2.1782)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [110/781]  eta: 0:03:46  lr: 0.000008  loss: 2.1899 (2.1793)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [120/781]  eta: 0:03:42  lr: 0.000008  loss: 2.1922 (2.1801)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [130/781]  eta: 0:03:38  lr: 0.000008  loss: 2.1194 (2.1748)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [140/781]  eta: 0:03:35  lr: 0.000008  loss: 2.1045 (2.1677)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [150/781]  eta: 0:03:31  lr: 0.000008  loss: 2.1142 (2.1669)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [160/781]  eta: 0:03:28  lr: 0.000008  loss: 2.1654 (2.1667)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [170/781]  eta: 0:03:24  lr: 0.000008  loss: 2.1917 (2.1683)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [180/781]  eta: 0:03:21  lr: 0.000008  loss: 2.1968 (2.1704)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [190/781]  eta: 0:03:17  lr: 0.000008  loss: 2.1596 (2.1694)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [200/781]  eta: 0:03:14  lr: 0.000008  loss: 2.1596 (2.1690)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [210/781]  eta: 0:03:10  lr: 0.000008  loss: 2.1414 (2.1692)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [220/781]  eta: 0:03:07  lr: 0.000008  loss: 2.1527 (2.1719)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [230/781]  eta: 0:03:03  lr: 0.000008  loss: 2.2155 (2.1732)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [240/781]  eta: 0:03:00  lr: 0.000008  loss: 2.1987 (2.1748)  time: 0.3308  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [250/781]  eta: 0:02:57  lr: 0.000008  loss: 2.1841 (2.1769)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [260/781]  eta: 0:02:53  lr: 0.000008  loss: 2.1586 (2.1750)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [270/781]  eta: 0:02:50  lr: 0.000008  loss: 2.1961 (2.1771)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [280/781]  eta: 0:02:47  lr: 0.000008  loss: 2.2322 (2.1812)  time: 0.3423  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [290/781]  eta: 0:02:43  lr: 0.000008  loss: 2.1960 (2.1808)  time: 0.3426  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [300/781]  eta: 0:02:40  lr: 0.000008  loss: 2.1723 (2.1828)  time: 0.3310  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [310/781]  eta: 0:02:37  lr: 0.000008  loss: 2.1418 (2.1816)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [320/781]  eta: 0:02:33  lr: 0.000008  loss: 2.1262 (2.1817)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [330/781]  eta: 0:02:30  lr: 0.000008  loss: 2.1386 (2.1804)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [340/781]  eta: 0:02:27  lr: 0.000008  loss: 2.1574 (2.1814)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [350/781]  eta: 0:02:23  lr: 0.000008  loss: 2.2049 (2.1821)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [360/781]  eta: 0:02:20  lr: 0.000008  loss: 2.1602 (2.1817)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [370/781]  eta: 0:02:16  lr: 0.000008  loss: 2.1602 (2.1811)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [380/781]  eta: 0:02:13  lr: 0.000008  loss: 2.1302 (2.1800)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [390/781]  eta: 0:02:10  lr: 0.000008  loss: 2.1662 (2.1804)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [400/781]  eta: 0:02:06  lr: 0.000008  loss: 2.2100 (2.1823)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [410/781]  eta: 0:02:03  lr: 0.000008  loss: 2.2113 (2.1811)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [420/781]  eta: 0:02:00  lr: 0.000008  loss: 2.1822 (2.1814)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [430/781]  eta: 0:01:56  lr: 0.000008  loss: 2.1833 (2.1818)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [440/781]  eta: 0:01:53  lr: 0.000008  loss: 2.1452 (2.1793)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [450/781]  eta: 0:01:50  lr: 0.000008  loss: 2.0980 (2.1786)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [460/781]  eta: 0:01:46  lr: 0.000008  loss: 2.1074 (2.1769)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [470/781]  eta: 0:01:43  lr: 0.000008  loss: 2.1167 (2.1767)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [480/781]  eta: 0:01:40  lr: 0.000008  loss: 2.1831 (2.1768)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [490/781]  eta: 0:01:36  lr: 0.000008  loss: 2.1753 (2.1760)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [500/781]  eta: 0:01:33  lr: 0.000008  loss: 2.1263 (2.1756)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [510/781]  eta: 0:01:30  lr: 0.000008  loss: 2.1600 (2.1761)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [520/781]  eta: 0:01:26  lr: 0.000008  loss: 2.1600 (2.1762)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [530/781]  eta: 0:01:23  lr: 0.000008  loss: 2.1419 (2.1763)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [540/781]  eta: 0:01:20  lr: 0.000008  loss: 2.1391 (2.1755)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [550/781]  eta: 0:01:16  lr: 0.000008  loss: 2.1591 (2.1756)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [560/781]  eta: 0:01:13  lr: 0.000008  loss: 2.1984 (2.1773)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [570/781]  eta: 0:01:10  lr: 0.000008  loss: 2.1717 (2.1764)  time: 0.3307  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [580/781]  eta: 0:01:06  lr: 0.000008  loss: 2.1027 (2.1762)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [590/781]  eta: 0:01:03  lr: 0.000008  loss: 2.1162 (2.1753)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [600/781]  eta: 0:01:00  lr: 0.000008  loss: 2.1403 (2.1755)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [610/781]  eta: 0:00:56  lr: 0.000008  loss: 2.2085 (2.1760)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [620/781]  eta: 0:00:53  lr: 0.000008  loss: 2.1528 (2.1750)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [630/781]  eta: 0:00:50  lr: 0.000008  loss: 2.1582 (2.1749)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [640/781]  eta: 0:00:46  lr: 0.000008  loss: 2.2047 (2.1761)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [650/781]  eta: 0:00:43  lr: 0.000008  loss: 2.1711 (2.1756)  time: 0.3304  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [660/781]  eta: 0:00:40  lr: 0.000008  loss: 2.1238 (2.1752)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [670/781]  eta: 0:00:36  lr: 0.000008  loss: 2.1489 (2.1745)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [680/781]  eta: 0:00:33  lr: 0.000008  loss: 2.1658 (2.1747)  time: 0.3300  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [690/781]  eta: 0:00:30  lr: 0.000008  loss: 2.1658 (2.1744)  time: 0.3299  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [700/781]  eta: 0:00:26  lr: 0.000008  loss: 2.1615 (2.1743)  time: 0.3301  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [710/781]  eta: 0:00:23  lr: 0.000008  loss: 2.1534 (2.1730)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [720/781]  eta: 0:00:20  lr: 0.000008  loss: 2.0927 (2.1728)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [730/781]  eta: 0:00:16  lr: 0.000008  loss: 2.1528 (2.1730)  time: 0.3305  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [740/781]  eta: 0:00:13  lr: 0.000008  loss: 2.1359 (2.1722)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [750/781]  eta: 0:00:10  lr: 0.000008  loss: 2.1359 (2.1727)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [760/781]  eta: 0:00:06  lr: 0.000008  loss: 2.1776 (2.1727)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [10]  [770/781]  eta: 0:00:03  lr: 0.000008  loss: 2.1179 (2.1721)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [10]  [780/781]  eta: 0:00:00  lr: 0.000008  loss: 2.1255 (2.1717)  time: 0.3309  data: 0.0007  max mem: 6458\n",
            "Epoch: [10] Total time: 0:04:19 (0.3318 s / it)\n",
            "Averaged stats: lr: 0.000008  loss: 2.1255 (2.1717)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 1.0, 'lambda_convnext_base': 1.0, 'lambda_tf_efficientnetv2_l': 1.0}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7386 (0.7386)  acc1: 82.2917 (82.2917)  acc5: 93.7500 (93.7500)  time: 0.8784  data: 0.8478  max mem: 6458\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.7588 (0.8525)  acc1: 82.8125 (81.8182)  acc5: 93.7500 (92.8504)  time: 0.1781  data: 0.1476  max mem: 6458\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.8834 (0.9218)  acc1: 79.6875 (80.5556)  acc5: 92.1875 (91.9643)  time: 0.1292  data: 0.0988  max mem: 6458\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.0328 (0.9837)  acc1: 76.5625 (79.4187)  acc5: 90.1042 (91.3474)  time: 0.1337  data: 0.1033  max mem: 6458\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1304 (1.0320)  acc1: 75.5208 (78.3664)  acc5: 88.5417 (90.7774)  time: 0.1268  data: 0.0964  max mem: 6458\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0529 (1.0313)  acc1: 75.0000 (77.9105)  acc5: 91.6667 (90.9518)  time: 0.1356  data: 0.1051  max mem: 6458\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1145 (1.0405)  acc1: 75.0000 (77.8200)  acc5: 91.6667 (91.0000)  time: 0.1191  data: 0.0895  max mem: 6458\n",
            "Test: Total time: 0:00:07 (0.1405 s / it)\n",
            "* Acc@1 77.820 Acc@5 91.000 loss 1.040\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.17%\n",
            "Epoch: [11]  [  0/781]  eta: 0:14:50  lr: 0.000008  loss: 2.2922 (2.2922)  time: 1.1402  data: 0.7929  max mem: 6458\n",
            "Epoch: [11]  [ 10/781]  eta: 0:05:11  lr: 0.000008  loss: 2.2003 (2.2042)  time: 0.4040  data: 0.0725  max mem: 6458\n",
            "Epoch: [11]  [ 20/781]  eta: 0:04:40  lr: 0.000008  loss: 2.2164 (2.2177)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 30/781]  eta: 0:04:27  lr: 0.000008  loss: 2.2273 (2.2216)  time: 0.3303  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 40/781]  eta: 0:04:19  lr: 0.000008  loss: 2.2207 (2.2358)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 50/781]  eta: 0:04:13  lr: 0.000008  loss: 2.2249 (2.2254)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 60/781]  eta: 0:04:07  lr: 0.000008  loss: 2.2221 (2.2250)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 70/781]  eta: 0:04:03  lr: 0.000008  loss: 2.2223 (2.2278)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 80/781]  eta: 0:03:58  lr: 0.000008  loss: 2.2480 (2.2411)  time: 0.3306  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [ 90/781]  eta: 0:03:54  lr: 0.000008  loss: 2.2743 (2.2410)  time: 0.3307  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [100/781]  eta: 0:03:50  lr: 0.000008  loss: 2.2741 (2.2392)  time: 0.3308  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [110/781]  eta: 0:03:46  lr: 0.000008  loss: 2.2697 (2.2447)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [120/781]  eta: 0:03:42  lr: 0.000008  loss: 2.2544 (2.2434)  time: 0.3302  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [130/781]  eta: 0:03:39  lr: 0.000008  loss: 2.1733 (2.2388)  time: 0.3304  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [140/781]  eta: 0:03:35  lr: 0.000008  loss: 2.1336 (2.2310)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [150/781]  eta: 0:03:31  lr: 0.000008  loss: 2.1565 (2.2297)  time: 0.3303  data: 0.0003  max mem: 6458\n",
            "Epoch: [11]  [160/781]  eta: 0:03:28  lr: 0.000008  loss: 2.2159 (2.2308)  time: 0.3302  data: 0.0003  max mem: 6458\n",
            "Epoch: [11]  [170/781]  eta: 0:03:24  lr: 0.000008  loss: 2.2159 (2.2282)  time: 0.3306  data: 0.0003  max mem: 6458\n",
            "Epoch: [11]  [180/781]  eta: 0:03:21  lr: 0.000008  loss: 2.1728 (2.2286)  time: 0.3309  data: 0.0003  max mem: 6458\n",
            "Epoch: [11]  [190/781]  eta: 0:03:17  lr: 0.000008  loss: 2.1824 (2.2305)  time: 0.3305  data: 0.0004  max mem: 6458\n",
            "Epoch: [11]  [200/781]  eta: 0:03:14  lr: 0.000008  loss: 2.1933 (2.2273)  time: 0.3302  data: 0.0004  max mem: 6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 2: Base Environment — Teacher Models & Multi-Teacher Adaptations**"
      ],
      "metadata": {
        "id": "ck_VO0908kCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer 2 extends the baseline DeiT environment to support knowledge distillation from one or more teacher models. This layer is additive: it does not modify the baseline DeiT training loop unless explicitly stated.\n",
        "It includes\n",
        "1. Teacher Model Support (Single & Multiple)\n",
        "2. Teacher Registry / Configuration\n",
        "3. Multi-Teacher Fusion Mechanism (Adaptation Layer)\n",
        "4. Distillation Loss Integration"
      ],
      "metadata": {
        "id": "0ZO3MUL88nog"
      }
    }
  ]
}