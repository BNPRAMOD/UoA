{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 1: Baseline DeiT environment**"
      ],
      "metadata": {
        "id": "A814LG7i7w0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeiT’s baseline training script expects a teacher model name and distillation settings via CLI flags in main.py (e.g., --teacher-model, --teacher-path, --distillation-type).\n",
        "GitHub\n",
        "+1\n",
        "\n",
        "So the “base environment” Layer 1 must include:\n",
        "\n",
        "DeiT repo (cloned)\n",
        "\n",
        "PyTorch (Colab default) + GPU\n",
        "\n",
        "timm installed (for both student and teacher models)\n",
        "\n",
        "compatibility patches if any (because Colab uses new torch/timm)"
      ],
      "metadata": {
        "id": "yZ7gvhPl8OL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install PyTorch without pinning"
      ],
      "metadata": {
        "id": "25JXNJNx7v2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "OZgeujT4qBSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0549e437-b4cb-4585-94f3-5a6d986ef870"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "WWb1brNPqbEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uvYnPeqaBB",
        "outputId": "f73673ac-e9a6-45c5-a20a-9a4e5c6e4353"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the baseline repo (official DeiT)"
      ],
      "metadata": {
        "id": "3awWPnZtp7E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aYSAUqVmQid",
        "outputId": "9bb6c405-22ce-4ea1-896f-7a1ad4fef86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'deit'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Total 456 (delta 0), reused 0 (delta 0), pack-reused 456 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 5.73 MiB | 12.15 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n",
            "/content/deit\n",
            "1:torch==1.13.1\n",
            "2:torchvision==0.8.1\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/deit.git\n",
        "%cd /content/deit\n",
        "!grep -n \"torch\" -n requirements.txt || true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab Compatibility Fixes\n",
        "\n",
        "1. torch pin removal\n",
        "\n",
        "2. timm API changes\n",
        "\n",
        "3. kwargs popping (pretrained_cfg, cache_dir, etc.)\n",
        "\n"
      ],
      "metadata": {
        "id": "fVJsxhJv4Dwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch requirements.txt to remove torch pins"
      ],
      "metadata": {
        "id": "kHpCHaaDr1u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"requirements.txt\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "filtered = []\n",
        "removed = []\n",
        "for line in lines:\n",
        "    s = line.strip()\n",
        "    if s.startswith(\"torch==\") or s.startswith(\"torchvision==\") or s.startswith(\"torchaudio==\"):\n",
        "        removed.append(line)\n",
        "        continue\n",
        "    filtered.append(line)\n",
        "\n",
        "p.write_text(\"\\n\".join(filtered) + \"\\n\")\n",
        "print(\"✅ Removed these pinned lines:\")\n",
        "for r in removed:\n",
        "    print(\"  -\", r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3mRQRCcrLmU",
        "outputId": "12fc49eb-e730-45e6-edd5-a137e62a96ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Removed these pinned lines:\n",
            "  - torch==1.13.1\n",
            "  - torchvision==0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Pins are gone!i.e torch==1.13.1 pin was removed"
      ],
      "metadata": {
        "id": "lyODjd5lsAqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -nE \"torch|torchvision|torchaudio\" requirements.txt || echo \"✅ No torch pins remain\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7QRJmf7rg6a",
        "outputId": "1b81ba21-1243-4456-ffdd-4829afd80492"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No torch pins remain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the baseline dependencies"
      ],
      "metadata": {
        "id": "csYbu0BampB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"jedi>=0.16,<0.19\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNoLOzs5xUxa",
        "outputId": "b02024a8-1bd1-4fd1-90f1-be3d6d4f9f57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi<0.19,>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from jedi<0.19,>=0.16) (0.8.5)\n",
            "Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y timm\n",
        "!pip -q install \"jedi>=0.16,<0.19\"\n",
        "!pip -q install timm==0.6.13 submitit\n",
        "#!pip -q install timm==0.4.12 submitit\n"
      ],
      "metadata": {
        "id": "Xsc3-5Ab2Azw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "llX7-GOnsQQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import timm; print('timm:', timm.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG39iey7tfMQ",
        "outputId": "57c1a4bc-d0a8-4162-9f43-72e1b3d23c42"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timm: 0.6.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart the Session**"
      ],
      "metadata": {
        "id": "r3tle6N46b7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "needle = \"OPENAI_CLIP_MEAN\"\n",
        "if needle in txt:\n",
        "    print(\"✅ timm.data already mentions OPENAI_CLIP_MEAN; no patch needed.\")\n",
        "else:\n",
        "    patch = \"\"\"\n",
        "\n",
        "# --- Colab patch: expose CLIP normalization constants for older exports ---\n",
        "try:\n",
        "    from .constants import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD  # timm versions where defined in constants\n",
        "except Exception:\n",
        "    # Standard OpenAI CLIP normalization\n",
        "    OPENAI_CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
        "    OPENAI_CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n",
        "# --- end patch ---\n",
        "\"\"\"\n",
        "    p.write_text(txt + patch)\n",
        "    print(\"✅ Patched:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEsR06SsuQa1",
        "outputId": "f28d5930-4f17-49ce-a03c-f16e85508bfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched: /usr/local/lib/python3.12/dist-packages/timm/data/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "from models import deit_tiny_patch16_224\n",
        "m = deit_tiny_patch16_224()\n",
        "print(\"✅ DeiT model instantiated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h97jFzzrupzp",
        "outputId": "d0f12707-0f43-4b50-88b1-df9492370371"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "✅ DeiT model instantiated successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, timm\n",
        "print(torch.__version__)\n",
        "print(timm.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37b1qcS72uJs",
        "outputId": "9bed87fc-fbca-4831-cada-6c6e95c43445"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "0.6.13\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Tiny-ImageNet"
      ],
      "metadata": {
        "id": "uu-A5-G7vzTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrbd2wbQyqMV",
        "outputId": "bb14e019-03c2-40c0-deaf-8928f2efd303"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IraDkD4vavm",
        "outputId": "159a4bb9-4419-4c85-86e3-eb43587b3229",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix Tiny-ImageNet validation folder"
      ],
      "metadata": {
        "id": "qlrZWkYCvyN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python - << 'EOF'\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"/content/tiny-imagenet-200\")\n",
        "val_dir = root/\"val\"\n",
        "img_dir = val_dir/\"images\"\n",
        "ann = val_dir/\"val_annotations.txt\"\n",
        "\n",
        "with ann.open(\"r\") as f:\n",
        "    for line in f:\n",
        "        img, cls = line.strip().split(\"\\t\")[:2]\n",
        "        (val_dir/cls).mkdir(parents=True, exist_ok=True)\n",
        "        src = img_dir/img\n",
        "        dst = val_dir/cls/img\n",
        "        if src.exists():\n",
        "            shutil.move(str(src), str(dst))\n",
        "\n",
        "if img_dir.exists():\n",
        "    shutil.rmtree(img_dir)\n",
        "\n",
        "print(\"✅ Tiny-ImageNet val reorganized into class subfolders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYzGeXJwSsy",
        "outputId": "8f6fef0f-1dc5-45a1-ab90-2976fc13e9e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n",
            "✅ Tiny-ImageNet val reorganized into class subfolders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/tiny-imagenet-200/val -maxdepth 1 -type d | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bwwo30Qwi0V",
        "outputId": "45f2ee3e-51d3-47e7-ac4d-396a637debb5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tiny-imagenet-200/val\n",
            "/content/tiny-imagenet-200/val/n03854065\n",
            "/content/tiny-imagenet-200/val/n02791270\n",
            "/content/tiny-imagenet-200/val/n01698640\n",
            "/content/tiny-imagenet-200/val/n03670208\n",
            "/content/tiny-imagenet-200/val/n04067472\n",
            "/content/tiny-imagenet-200/val/n02206856\n",
            "/content/tiny-imagenet-200/val/n02129165\n",
            "/content/tiny-imagenet-200/val/n02321529\n",
            "/content/tiny-imagenet-200/val/n02415577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/tiny-imagenet-200 | head"
      ],
      "metadata": {
        "id": "0e-EkPZf6GgG",
        "outputId": "764ed5f8-c984-4703-c829-74c920922445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.6M\n",
            "drwxrwxr-x   5 root root 4.0K Feb  9  2015 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x   1 root root 4.0K Feb  9 02:00 \u001b[01;34m..\u001b[0m/\n",
            "drwxrwxr-x   3 root root 4.0K Dec 12  2014 \u001b[01;34mtest\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Dec 12  2014 \u001b[01;34mtrain\u001b[0m/\n",
            "drwxrwxr-x 202 root root 4.0K Feb  9 02:01 \u001b[01;34mval\u001b[0m/\n",
            "-rw-rw-r--   1 root root 2.0K Feb  9  2015 wnids.txt\n",
            "-rw-------   1 root root 2.6M Feb  9  2015 words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle timm incompatibilities. Although we can instantiate the model directly, the training script uses timm.create_model(), which injects metadata arguments such as pretrained_cfg and cache_dir.\n",
        "The original DeiT constructors do not support these arguments, so we remove them\n",
        "YOUR NOTEBOOK CALL\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224()          ✅ works (no kwargs)\n",
        "\n",
        "TRAINING PIPELINE\n",
        "    |\n",
        "    v\n",
        "timm.create_model()\n",
        "    |\n",
        "    v\n",
        "deit_tiny_patch16_224(**kwargs)  ❌ injects extra keys\n"
      ],
      "metadata": {
        "id": "Rtyo7rkj3vLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch /content/deit/augment.py (safe compatibility fix)"
      ],
      "metadata": {
        "id": "mWebMtbWxHi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!python - << 'PY'\n",
        "from pathlib import Path\n",
        "p = Path(\"augment.py\")\n",
        "txt = p.read_text()\n",
        "\n",
        "old = \"from timm.data.transforms import _pil_interp, RandomResizedCropAndInterpolation, ToNumpy, ToTensor\"\n",
        "if old in txt:\n",
        "    txt = txt.replace(\n",
        "        old,\n",
        "        \"from timm.data.transforms import RandomResizedCropAndInterpolation, ToNumpy, ToTensor\\n\"\n",
        "        \"try:\\n\"\n",
        "        \"    from timm.data.transforms import _pil_interp  # older timm\\n\"\n",
        "        \"except Exception:\\n\"\n",
        "        \"    _pil_interp = None  # newer timm doesn't expose this\\n\"\n",
        "    )\n",
        "    p.write_text(txt)\n",
        "    print(\"✅ Patched augment.py for timm compatibility.\")\n",
        "else:\n",
        "    print(\"ℹ️ Expected import line not found; augment.py may already be patched or different.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZwKyJqIxG2d",
        "outputId": "25a97cfe-1dd6-4573-fc98-97ee65ecaa31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "✅ Patched augment.py for timm compatibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "!rm -f multiteacher_loss.py\n",
        "!ls -l multiteacher_loss.py || echo \"✅ old file removed\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RizknqA6MBXb",
        "outputId": "cd34cda5-86f9-49bf-a4da-37c2ed804f49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "ls: cannot access 'multiteacher_loss.py': No such file or directory\n",
            "✅ old file removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deit\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "code = r'''\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Dict, List, Optional\n",
        "import json\n",
        "from pathlib import Path as _Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def normalize_lambdas(lmb: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Normalize teacher weights so they sum to 1 (supports shape (T,) or (B,T)).\n",
        "    \"\"\"\n",
        "    if lmb.dim() == 1:\n",
        "        return lmb / lmb.sum().clamp_min(eps)\n",
        "    return lmb / lmb.sum(dim=-1, keepdim=True).clamp_min(eps)\n",
        "\n",
        "\n",
        "def fuse_logits(\n",
        "    teacher_logits: Dict[str, torch.Tensor],\n",
        "    teacher_order: List[str],\n",
        "    lambdas: torch.Tensor,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Weighted sum of teacher logits.\n",
        "    teacher_logits[k]: (B,C)\n",
        "    lambdas: (B,T) or (T,)\n",
        "    returns: (B,C)\n",
        "    \"\"\"\n",
        "    logits_list = [teacher_logits[k] for k in teacher_order]\n",
        "    stacked = torch.stack(logits_list, dim=1)  # (B,T,C)\n",
        "\n",
        "    lmb = normalize_lambdas(lambdas).to(stacked.device)\n",
        "    if lmb.dim() == 1:\n",
        "        lmb = lmb.unsqueeze(0).expand(stacked.size(0), -1)  # (B,T)\n",
        "\n",
        "    return (stacked * lmb.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "def kd_soft(student_logits: torch.Tensor, teacher_logits: torch.Tensor, T: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Standard KL-based soft distillation loss with temperature scaling.\n",
        "    \"\"\"\n",
        "    p_t = F.softmax(teacher_logits / T, dim=-1)\n",
        "    log_p_s = F.log_softmax(student_logits / T, dim=-1)\n",
        "    return F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T * T)\n",
        "\n",
        "\n",
        "def kd_hard(student_logits: torch.Tensor, teacher_logits: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Hard distillation: cross-entropy against teacher argmax.\n",
        "    \"\"\"\n",
        "    return F.cross_entropy(student_logits, teacher_logits.argmax(dim=-1))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teachers\n",
        "# -----------------------------\n",
        "class FrozenTeacherEnsemble(nn.Module):\n",
        "    \"\"\"\n",
        "    Loads a list of timm pretrained teachers and freezes them.\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_names: List[str], device: torch.device):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleDict(\n",
        "            {\n",
        "                name: timm.create_model(name, pretrained=True, num_classes=1000).eval().to(device)\n",
        "                for name in teacher_names\n",
        "            }\n",
        "        )\n",
        "        for m in self.models.values():\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad_(False)\n",
        "        self.teacher_order = list(self.models.keys())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        return {k: m(x) for k, m in self.models.items()}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Teacher logits mapping: ImageNet-1k -> Tiny-ImageNet (wnid-aligned gather)\n",
        "# -----------------------------\n",
        "def build_tiny_imagenet_im1k_indices(\n",
        "    tiny_root: str,\n",
        "    class_index_json: str = \"/content/imagenet_class_index.json\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns a LongTensor of shape (200,) containing the ImageNet-1k class indices\n",
        "    corresponding to Tiny-ImageNet wnids.txt ordering.\n",
        "\n",
        "    Requires torchvision's imagenet_class_index.json (wnid->index via JSON).\n",
        "    \"\"\"\n",
        "    tiny_root_p = _Path(tiny_root)\n",
        "    wnids_path = tiny_root_p / \"wnids.txt\"\n",
        "    if not wnids_path.exists():\n",
        "        raise FileNotFoundError(f\"Could not find Tiny-ImageNet wnids.txt at: {wnids_path}\")\n",
        "\n",
        "    wnids = wnids_path.read_text().strip().splitlines()\n",
        "\n",
        "    class_index_path = _Path(class_index_json)\n",
        "    if not class_index_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing {class_index_json}. Download it before training.\\n\"\n",
        "            \"Example:\\n\"\n",
        "            \"  !wget -q https://raw.githubusercontent.com/pytorch/vision/main/torchvision/models/imagenet_class_index.json \"\n",
        "            f\"-O {class_index_json}\"\n",
        "        )\n",
        "\n",
        "    class_index = json.loads(class_index_path.read_text())\n",
        "    # class_index: {\"0\": [\"n01440764\", \"tench\"], ...}\n",
        "    wnid_to_idx = {v[0]: int(k) for k, v in class_index.items()}\n",
        "\n",
        "    indices: List[int] = []\n",
        "    missing: List[str] = []\n",
        "    for w in wnids:\n",
        "        if w in wnid_to_idx:\n",
        "            indices.append(wnid_to_idx[w])\n",
        "        else:\n",
        "            missing.append(w)\n",
        "\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            f\"{len(missing)} Tiny-ImageNet wnids were not found in ImageNet-1k mapping. \"\n",
        "            f\"First few missing: {missing[:10]}\"\n",
        "        )\n",
        "\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "\n",
        "class TeacherLogitMapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Maps ImageNet-1k teacher logits (B,1000) -> Tiny-ImageNet logits (B,200)\n",
        "    by selecting the 200 corresponding ImageNet indices (gather/index_select).\n",
        "    \"\"\"\n",
        "    def __init__(self, teacher_keys: List[str], im1k_indices: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.teacher_keys = list(teacher_keys)\n",
        "        self.register_buffer(\"im1k_indices\", im1k_indices)  # (200,)\n",
        "\n",
        "    def forward(self, teacher_logits: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        out: Dict[str, torch.Tensor] = {}\n",
        "        idx = self.im1k_indices\n",
        "        for k, v in teacher_logits.items():\n",
        "            # v: (B,1000) -> (B,200)\n",
        "            out[k] = v.index_select(dim=-1, index=idx)\n",
        "        return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# HDTSE confidence weighting\n",
        "# -----------------------------\n",
        "class HDTSEConfidence(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes per-sample teacher weights based on each teacher's confidence\n",
        "    on the (possibly soft) targets.\n",
        "    \"\"\"\n",
        "    def __init__(self, temp: float = 1.0):\n",
        "        super().__init__()\n",
        "        self.temp = float(temp)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(\n",
        "        self,\n",
        "        teacher_logits: Dict[str, torch.Tensor],\n",
        "        teacher_order: List[str],\n",
        "        targets: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        stacked = torch.stack([teacher_logits[k] for k in teacher_order], dim=1)  # (B,T,C)\n",
        "        probs = F.softmax(stacked / self.temp, dim=-1)  # (B,T,C)\n",
        "\n",
        "        # Hard labels: (B,)\n",
        "        if targets.dim() == 1:\n",
        "            idx = targets.to(dtype=torch.long, device=probs.device)\n",
        "            conf = probs.gather(-1, idx[:, None, None]).squeeze(-1)  # (B,T)\n",
        "            return normalize_lambdas(conf)\n",
        "\n",
        "        # Soft labels (mixup/cutmix): (B,C)\n",
        "        tgt = targets.to(dtype=probs.dtype, device=probs.device)\n",
        "        conf = (probs * tgt[:, None, :]).sum(dim=-1)  # (B,T)\n",
        "        return normalize_lambdas(conf)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Multi-teacher distillation loss\n",
        "# -----------------------------\n",
        "class MultiTeacherDistillationLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_criterion,\n",
        "        student_num_classes: int,\n",
        "        teacher_names: List[str],\n",
        "        distillation_type: str = \"soft\",\n",
        "        alpha: float = 0.5,\n",
        "        tau: float = 2.0,\n",
        "        device=None,\n",
        "        use_adapter: bool = True,\n",
        "        hdtse_warmup_epochs: int = 0,\n",
        "        lambda_log: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        base_criterion: supervised loss (CE or soft-target CE when mixup is enabled)\n",
        "        distillation_type: \"soft\" or \"hard\"\n",
        "        alpha: final KD weight\n",
        "        tau: KD temperature\n",
        "        use_adapter: if True, expects Tiny-ImageNet mapping via set_tiny_root() before training\n",
        "        hdtse_warmup_epochs: use uniform lambdas until this epoch (exclusive)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.base_criterion = base_criterion\n",
        "        self.distillation_type = str(distillation_type)\n",
        "        self.tau = float(tau)\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # teachers (frozen)\n",
        "        self.teachers = FrozenTeacherEnsemble(teacher_names, self.device)\n",
        "        self.teacher_order = list(self.teachers.teacher_order)\n",
        "\n",
        "        # teacher->student class mapping (ImageNet-1k -> dataset classes)\n",
        "        self.use_adapter = bool(use_adapter)\n",
        "        self.adapter: Optional[nn.Module] = None  # created by set_tiny_root()\n",
        "\n",
        "        # HDTSE teacher weighting\n",
        "        self.hdtse = HDTSEConfidence()\n",
        "\n",
        "        # epoch state\n",
        "        self.epoch: int = 0\n",
        "        self.hdtse_warmup_epochs = int(hdtse_warmup_epochs)\n",
        "\n",
        "        # alpha schedule (KD weight ramp)\n",
        "        self.alpha_final = float(alpha)\n",
        "        self.alpha_start = 0.0\n",
        "        self.alpha_ramp_epochs = 20  # default ramp duration\n",
        "\n",
        "        # lambda logging (epoch-level)\n",
        "        self.lambda_log = bool(lambda_log)\n",
        "        self._lambda_sum = torch.zeros(len(self.teacher_order), dtype=torch.float32)\n",
        "        self._lambda_count = 0\n",
        "\n",
        "    # ---- Public setters ----\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self.epoch = int(epoch)\n",
        "\n",
        "    def set_alpha_schedule(self, alpha_start: float = 0.0, alpha_ramp_epochs: int = 20):\n",
        "        self.alpha_start = float(alpha_start)\n",
        "        self.alpha_ramp_epochs = int(alpha_ramp_epochs)\n",
        "\n",
        "    def set_tiny_root(self, tiny_root: str, class_index_json: str = \"/content/imagenet_class_index.json\"):\n",
        "        \"\"\"\n",
        "        Call once (from main.py) after constructing this loss, before training starts.\n",
        "        Creates the gather-based teacher logits mapper: (B,1000)->(B,C).\n",
        "        \"\"\"\n",
        "        im1k_indices = build_tiny_imagenet_im1k_indices(tiny_root, class_index_json=class_index_json).to(self.device)\n",
        "        self.adapter = TeacherLogitMapper(self.teacher_order, im1k_indices).to(self.device)\n",
        "\n",
        "    # ---- Logging ----\n",
        "    def pop_lambda_stats(self) -> Optional[Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Returns mean λ per teacher over the epoch, then resets accumulators.\n",
        "        Call once per epoch from main.py.\n",
        "        \"\"\"\n",
        "        if self._lambda_count <= 0:\n",
        "            return None\n",
        "\n",
        "        mean_lmb = (self._lambda_sum / float(self._lambda_count)).tolist()\n",
        "        out = {f\"lambda_{name}\": float(v) for name, v in zip(self.teacher_order, mean_lmb)}\n",
        "\n",
        "        self._lambda_sum.zero_()\n",
        "        self._lambda_count = 0\n",
        "        return out\n",
        "\n",
        "    # ---- Internals ----\n",
        "    def _uniform_lambdas(self, batch_size: int, device: torch.device) -> torch.Tensor:\n",
        "        t = len(self.teacher_order)\n",
        "        return torch.full((batch_size, t), 1.0 / t, device=device, dtype=torch.float32)\n",
        "\n",
        "    def _alpha_effective(self) -> float:\n",
        "        if self.alpha_ramp_epochs <= 0:\n",
        "            return self.alpha_final\n",
        "        t = min(1.0, float(self.epoch) / float(self.alpha_ramp_epochs))\n",
        "        return self.alpha_start + t * (self.alpha_final - self.alpha_start)\n",
        "\n",
        "    # ---- Forward ----\n",
        "    def forward(self, inputs: torch.Tensor, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        inputs: images (B,3,H,W)\n",
        "        outputs: student logits (B,C)\n",
        "        targets: hard labels (B,) or soft labels (B,C) when mixup/cutmix is enabled\n",
        "        \"\"\"\n",
        "        base_loss = self.base_criterion(outputs, targets)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_logits = self.teachers(inputs)  # dict: teacher -> (B,1000)\n",
        "\n",
        "        student_C = outputs.shape[-1]\n",
        "        any_teacher = next(iter(t_logits.values()))\n",
        "        teacher_C = any_teacher.shape[-1]\n",
        "\n",
        "        if teacher_C != student_C:\n",
        "            if self.adapter is None:\n",
        "                raise RuntimeError(\n",
        "                f\"Teacher logits have {teacher_C} classes but student has {student_C}. \"\n",
        "                \"Adapter not initialized. Call criterion.set_tiny_root(args.data_path).\"\n",
        "            )\n",
        "            t_logits = self.adapter(t_logits)  # dict: teacher -> (B,student_C)\n",
        "\n",
        "        # ---- Teacher weights (λ) ----\n",
        "        if self.epoch < self.hdtse_warmup_epochs:\n",
        "            lambdas = self._uniform_lambdas(outputs.size(0), outputs.device)  # (B,T)\n",
        "        else:\n",
        "            lambdas = self.hdtse(t_logits, self.teacher_order, targets)  # (B,T)\n",
        "\n",
        "        # ---- λ logging ----\n",
        "        if self.lambda_log:\n",
        "            batch_mean = lambdas.detach().mean(dim=0).cpu()  # (T,)\n",
        "            self._lambda_sum += batch_mean * outputs.size(0)\n",
        "            self._lambda_count += outputs.size(0)\n",
        "\n",
        "        fused = fuse_logits(t_logits, self.teacher_order, lambdas)  # (B,C)\n",
        "\n",
        "        kd = kd_soft(outputs, fused, self.tau) if self.distillation_type == \"soft\" else kd_hard(outputs, fused)\n",
        "\n",
        "        alpha_eff = self._alpha_effective()\n",
        "        return (1.0 - alpha_eff) * base_loss + alpha_eff * kd\n",
        "'''\n",
        "\n",
        "path = Path(\"multiteacher_loss.py\")\n",
        "path.write_text(code)\n",
        "\n",
        "print(\"File written:\", path)\n",
        "print(\"File size (bytes):\", path.stat().st_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k4jzkzbMHD-",
        "outputId": "fd30c2d5-efaa-4082-b6fb-9dd6599bba96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deit\n",
            "File written: multiteacher_loss.py\n",
            "File size (bytes): 11996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re, py_compile\n",
        "\n",
        "MAIN = Path(\"/content/deit/main.py\")\n",
        "txt = MAIN.read_text()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Helpers (line-safe insertions to avoid indentation/newline bugs)\n",
        "# ------------------------------------------------------------\n",
        "def fix_broken_import_concatenation():\n",
        "    global txt\n",
        "    # Fix exact failure mode:\n",
        "    txt = txt.replace(\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLossfrom samplers import RASampler\",\n",
        "        \"from multiteacher_loss import MultiTeacherDistillationLoss\\nfrom samplers import RASampler\"\n",
        "    )\n",
        "\n",
        "def ensure_line_after(match_line_regex: str, new_line: str):\n",
        "    \"\"\"Insert `new_line` as a full line right AFTER the first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    if new_line.strip() in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)  # keep line endings\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            # insert after this line\n",
        "            if not new_line.endswith(\"\\n\"):\n",
        "                new_line2 = new_line + \"\\n\"\n",
        "            else:\n",
        "                new_line2 = new_line\n",
        "            lines.insert(i + 1, new_line2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert after: {match_line_regex}\")\n",
        "\n",
        "def ensure_block_after_line(match_line_regex: str, block: str):\n",
        "    \"\"\"Insert a multi-line block after first line matching regex.\"\"\"\n",
        "    global txt\n",
        "    # Heuristic: if first unique token already exists, don't re-add\n",
        "    if \"--teacher-models\" in block and \"--teacher-models\" in txt and \"--hdtse-warmup-epochs\" in txt and \"--lambda-log\" in txt:\n",
        "        return\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(match_line_regex, line):\n",
        "            if not block.endswith(\"\\n\"):\n",
        "                block2 = block + \"\\n\"\n",
        "            else:\n",
        "                block2 = block\n",
        "            lines.insert(i + 1, block2)\n",
        "            txt = \"\".join(lines)\n",
        "            return\n",
        "    raise RuntimeError(f\"Could not find line to insert block after: {match_line_regex}\")\n",
        "\n",
        "def replace_first(pattern: str, repl: str, flags=re.DOTALL):\n",
        "    global txt\n",
        "    m = re.search(pattern, txt, flags)\n",
        "    if not m:\n",
        "        return False\n",
        "    txt = txt[:m.start()] + repl + txt[m.end():]\n",
        "    return True\n",
        "\n",
        "def remove_first_line_matching(line_regex: str):\n",
        "    global txt\n",
        "    lines = txt.splitlines(True)\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.search(line_regex, line):\n",
        "            del lines[i]\n",
        "            txt = \"\".join(lines)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) Repair if prior patch created the exact SyntaxError\n",
        "# ------------------------------------------------------------\n",
        "fix_broken_import_concatenation()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Ensure MultiTeacherDistillationLoss import (safe line insertion)\n",
        "# Insert after: from losses import DistillationLoss\n",
        "# ------------------------------------------------------------\n",
        "ensure_line_after(\n",
        "    r\"^\\s*from\\s+losses\\s+import\\s+DistillationLoss\\s*$\",\n",
        "    \"from multiteacher_loss import MultiTeacherDistillationLoss\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Ensure CLI args after --teacher-path\n",
        "# ------------------------------------------------------------\n",
        "cli_block = \"\"\"\\\n",
        "    parser.add_argument('--teacher-models', type=str, default='',\n",
        "                        help='Comma-separated timm model names for multi-teacher distillation')\n",
        "    parser.add_argument('--hdtse-warmup-epochs', type=int, default=0,\n",
        "                        help='Use uniform teacher weights for first N epochs, then enable HDTSE weighting')\n",
        "    parser.add_argument('--lambda-log', action='store_true', default=False,\n",
        "                        help='Log mean λ (teacher weights) each epoch for multi-teacher distillation')\n",
        "\"\"\"\n",
        "ensure_block_after_line(r\"^\\s*parser\\.add_argument\\('--teacher-path'\", cli_block)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Allow finetune + distillation ONLY when multi-teacher is used\n",
        "# Base guard is:\n",
        "# if args.distillation_type != 'none' and args.finetune and not args.eval:\n",
        "#     raise NotImplementedError(...)\n",
        "# ------------------------------------------------------------\n",
        "replace_first(\n",
        "    r\"^\\s*if\\s+args\\.distillation_type\\s*!=\\s*'none'\\s+and\\s+args\\.finetune\\s+and\\s+not\\s+args\\.eval\\s*:\\s*\\n\\s*raise\\s+NotImplementedError\\([^\\n]*\\)\\s*$\",\n",
        "    \"    if args.distillation_type != 'none' and args.finetune and not args.eval and not getattr(args, 'teacher_models', ''):\\n\"\n",
        "    \"        raise NotImplementedError(\\\"Finetuning with distillation not yet supported (single-teacher path)\\\")\\n\",\n",
        "    flags=re.MULTILINE\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Move scheduler creation to AFTER adapter param-group add:\n",
        "# Remove early: lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "# ------------------------------------------------------------\n",
        "remove_first_line_matching(r\"^\\s*lr_scheduler,\\s*_\\s*=\\s*create_scheduler\\(\\s*args\\s*,\\s*optimizer\\s*\\)\\s*$\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Unify distillation region (multi-teacher vs single-teacher)\n",
        "# We'll replace from \"teacher_model = None\" up to \"output_dir = Path(args.output_dir)\"\n",
        "# This avoids indentation mistakes and prevents teacher_path='' crash.\n",
        "# ------------------------------------------------------------\n",
        "m_start = re.search(r\"^\\s*teacher_model\\s*=\\s*None\\s*$\", txt, flags=re.MULTILINE)\n",
        "m_end   = re.search(r\"^\\s*output_dir\\s*=\\s*Path\\(args\\.output_dir\\)\\s*$\", txt, flags=re.MULTILINE)\n",
        "if not (m_start and m_end and m_start.start() < m_end.start()):\n",
        "    raise RuntimeError(\"Could not locate distillation region anchors (teacher_model=None ... output_dir=Path(...))\")\n",
        "\n",
        "unified = \"\"\"\\\n",
        "    teacher_model = None\n",
        "\n",
        "    # -------------------------------\n",
        "    # Unified single + multi-teacher distillation\n",
        "    # -------------------------------\n",
        "    teacher_models_str = getattr(args, 'teacher_models', '').strip()\n",
        "\n",
        "    if args.distillation_type != 'none' and teacher_models_str:\n",
        "        teacher_names = [t.strip() for t in teacher_models_str.split(',') if t.strip()]\n",
        "        print(f\"✅ Multi-teacher distillation enabled. Teachers: {teacher_names}\")\n",
        "\n",
        "        criterion = MultiTeacherDistillationLoss(\n",
        "            base_criterion=criterion,\n",
        "            student_num_classes=args.nb_classes,\n",
        "            teacher_names=teacher_names,\n",
        "            distillation_type=args.distillation_type,\n",
        "            alpha=args.distillation_alpha,\n",
        "            tau=args.distillation_tau,\n",
        "            device=device,\n",
        "            use_adapter=True,\n",
        "            hdtse_warmup_epochs=getattr(args, 'hdtse_warmup_epochs', 0),\n",
        "            lambda_log=getattr(args, 'lambda_log', False),\n",
        "        )\n",
        "\n",
        "        # Initialize Tiny-ImageNet wnid -> ImageNet-1k index mapping for teacher logits\n",
        "        if hasattr(criterion, \"set_tiny_root\"):\n",
        "            criterion.set_tiny_root(args.data_path)\n",
        "\n",
        "        # Optional: alpha ramp if you add args later\n",
        "        if hasattr(criterion, \"set_alpha_schedule\") and hasattr(args, \"alpha_ramp_epochs\"):\n",
        "            criterion.set_alpha_schedule(\n",
        "                alpha_start=getattr(args, \"alpha_start\", 0.0),\n",
        "                alpha_ramp_epochs=getattr(args, \"alpha_ramp_epochs\", 20),\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        if args.distillation_type != 'none':\n",
        "            assert args.teacher_path, 'need to specify teacher-path when using single-teacher distillation'\n",
        "            print(f\"Creating teacher model: {args.teacher_model}\")\n",
        "            teacher_model = create_model(\n",
        "                args.teacher_model,\n",
        "                pretrained=False,\n",
        "                num_classes=args.nb_classes,\n",
        "                global_pool='avg',\n",
        "            )\n",
        "            if args.teacher_path.startswith('https'):\n",
        "                checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                    args.teacher_path, map_location='cpu', check_hash=True)\n",
        "            else:\n",
        "                checkpoint = torch.load(args.teacher_path, map_location='cpu')\n",
        "            teacher_model.load_state_dict(checkpoint['model'])\n",
        "            teacher_model.to(device)\n",
        "            teacher_model.eval()\n",
        "\n",
        "        criterion = DistillationLoss(\n",
        "            criterion, teacher_model, args.distillation_type, args.distillation_alpha, args.distillation_tau\n",
        "        )\n",
        "\n",
        "    # Scheduler must be created AFTER all optimizer param groups are finalized\n",
        "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
        "\"\"\"\n",
        "\n",
        "txt = txt[:m_start.start()] + unified + \"\\n    output_dir = Path(args.output_dir)\\n\" + txt[m_end.end():]\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Ensure loss call uses (samples, outputs, targets)\n",
        "# ----------------------------\n",
        "# Patch ONLY the simple 2-arg form if present.\n",
        "if \"criterion(samples, outputs, targets)\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"loss\\s*=\\s*criterion\\(\\s*outputs\\s*,\\s*targets\\s*\\)\",\n",
        "        r\"loss = criterion(samples, outputs, targets)\",\n",
        "        txt\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Insert criterion.set_epoch(epoch) before train_one_epoch\n",
        "# We add it inside the epoch loop, after sampler.set_epoch if present.\n",
        "# ------------------------------------------------------------\n",
        "if \"criterion.set_epoch(epoch)\" not in txt:\n",
        "    # If distributed block exists, insert after it\n",
        "    if re.search(r\"^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$\", txt, flags=re.MULTILINE):\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*if\\s+args\\.distributed\\s*:\\s*\\n\\s*data_loader_train\\.sampler\\.set_epoch\\(epoch\\)\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "    else:\n",
        "        # Otherwise put at top of loop\n",
        "        txt = re.sub(\n",
        "            r\"(^\\s*for\\s+epoch\\s+in\\s+range\\(args\\.start_epoch,\\s*args\\.epochs\\)\\s*:\\s*$)\",\n",
        "            r\"\\1\\n        if hasattr(criterion, 'set_epoch'):\\n            criterion.set_epoch(epoch)\",\n",
        "            txt,\n",
        "            flags=re.MULTILINE,\n",
        "            count=1\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Per-epoch λ logging after train_one_epoch call\n",
        "# ------------------------------------------------------------\n",
        "if \"print('λ means:'\" not in txt:\n",
        "    txt = re.sub(\n",
        "        r\"(train_stats\\s*=\\s*train_one_epoch\\([\\s\\S]*?\\)\\s*)\\n\",\n",
        "        r\"\\1\\n\\n\"\n",
        "        r\"        # Optional: log mean λ per teacher (multi-teacher only)\\n\"\n",
        "        r\"        if getattr(args, 'lambda_log', False) and hasattr(criterion, 'pop_lambda_stats'):\\n\"\n",
        "        r\"            lambda_means = criterion.pop_lambda_stats()\\n\"\n",
        "        r\"            if lambda_means:\\n\"\n",
        "        r\"                print('λ means:', lambda_means)\\n\",\n",
        "        txt,\n",
        "        count=1\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Write + compile check\n",
        "# ------------------------------------------------------------\n",
        "MAIN.write_text(txt)\n",
        "py_compile.compile(str(MAIN), doraise=True)\n",
        "print(\"✅ Patched main.py written and compiles:\", MAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUdJZ4F-NoE-",
        "outputId": "9ce23d55-d8a1-4792-ece8-a0e859743546"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched main.py written and compiles: /content/deit/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before constructing the model, remove those keys from kwargs"
      ],
      "metadata": {
        "id": "4sFpztpw00XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    if line.strip().startswith(\"def deit_\") and \"**kwargs\" in line:\n",
        "        out.append(\"    # Drop timm-injected kwargs not supported by DeiT\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_overlay', None)\")\n",
        "        out.append(\"    kwargs.pop('pretrained_cfg_priority', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ models.py patched to drop pretrained_cfg kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1qywwxV0RS-",
        "outputId": "555dee4a-a7e4-44c2-ce14-26af11947f5b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ models.py patched to drop pretrained_cfg kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify"
      ],
      "metadata": {
        "id": "Yh47-0Pv0-R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix: Patch /content/deit/models.py to drop pretrained_cfg=..."
      ],
      "metadata": {
        "id": "hfueTM11xy00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch models.py to also drop cache_dir (and friends)"
      ],
      "metadata": {
        "id": "OK2GsetX1ZkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/deit/models.py\")\n",
        "lines = p.read_text().splitlines()\n",
        "\n",
        "# Keys that timm may inject but DeiT constructors don't accept\n",
        "DROP_KEYS = [\n",
        "    \"cache_dir\",\n",
        "    \"hf_hub_id\",\n",
        "    \"hf_hub_filename\",\n",
        "    \"hf_hub_revision\",\n",
        "]\n",
        "\n",
        "out = []\n",
        "for line in lines:\n",
        "    out.append(line)\n",
        "    # Right after the comment line we previously inserted, add more pops once per function\n",
        "    if line.strip() == \"# Drop timm-injected kwargs not supported by DeiT\":\n",
        "        for k in DROP_KEYS:\n",
        "            out.append(f\"    kwargs.pop('{k}', None)\")\n",
        "\n",
        "p.write_text(\"\\n\".join(out) + \"\\n\")\n",
        "print(\"✅ Patched models.py to drop cache_dir/hf_hub* kwargs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0-XJmyw1aed",
        "outputId": "35a21ecd-6e9c-49d2-ec09-ea134bfa9e2f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched models.py to drop cache_dir/hf_hub* kwargs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/imagenet_class_index.json\n",
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json \\\n",
        "  -O /content/imagenet_class_index.json\n",
        "\n",
        "!python - <<'PY'\n",
        "import json\n",
        "p=\"/content/imagenet_class_index.json\"\n",
        "with open(p,\"r\",encoding=\"utf-8\") as f:\n",
        "    obj=json.load(f)\n",
        "print(\"Loaded OK. Entries:\", len(obj))\n",
        "print(\"Example 0:\", obj[\"0\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAeUxFOQMFrE",
        "outputId": "468f85f7-bcda-4ac6-9360-7387e828382a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-09 02:01:08--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.179.123, 54.231.162.224, 16.15.185.143, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.179.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/octet-stream]\n",
            "Saving to: ‘/content/imagenet_class_index.json’\n",
            "\n",
            "/content/imagenet_c 100%[===================>]  34.53K   160KB/s    in 0.2s    \n",
            "\n",
            "2026-02-09 02:01:09 (160 KB/s) - ‘/content/imagenet_class_index.json’ saved [35363/35363]\n",
            "\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "Loaded OK. Entries: 1000\n",
            "Example 0: ['n01440764', 'tench']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --pretrained \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 64 \\\n",
        "#   --num_workers 2 \\\n",
        "#   --output_dir /content/deit_runs/smoke_test\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#   --model deit_tiny_patch16_224 \\\n",
        "#   --data-path /content/tiny-imagenet-200 \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch-size 128 \\\n",
        "#   --num_workers 4 \\\n",
        "#   --input-size 224 \\\n",
        "#   --opt adamw \\\n",
        "#   --lr 5e-4 \\\n",
        "#   --weight-decay 0.05 \\\n",
        "#   --sched cosine \\\n",
        "#   --aa rand-m9-mstd0.5 \\\n",
        "#   --reprob 0.25 \\\n",
        "#   --remode pixel \\\n",
        "#   --recount 1 \\\n",
        "#   --output_dir /content/deit_runs/tiny_imagenet\n",
        "### correct one\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 3e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_5ep\n",
        "%cd /content/deit\n",
        "!python main.py \\\n",
        " --model deit_tiny_patch16_224 \\\n",
        " --data-path /content/tiny-imagenet-200 \\\n",
        " --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        " --epochs 100 \\\n",
        " --batch-size 128 \\\n",
        " --num_workers 4 \\\n",
        " --input-size 224 \\\n",
        " --opt adamw \\\n",
        " --lr 2.5e-4 \\\n",
        " --weight-decay 0.05 \\\n",
        " --sched cosine \\\n",
        " --warmup-epochs 4 \\\n",
        " --smoothing 0.1 \\\n",
        " --aa rand-m6-mstd0.5 \\\n",
        " --reprob 0.2 \\\n",
        " --model-ema \\\n",
        " --model-ema-decay 0.9999 \\\n",
        " --drop-path 0.05 \\\n",
        " --mixup 0.2 \\\n",
        " --cutmix 0.0 \\\n",
        " --mixup-prob 0.5 \\\n",
        " --distillation-type soft \\\n",
        " --distillation-alpha 0.5 \\\n",
        " --distillation-tau 3.0 \\\n",
        " --hdtse-warmup-epochs 8 \\\n",
        " --lambda-log \\\n",
        " --output_dir /content/deit_runs/tiny_imagenet \\\n",
        " --teacher-models \"swin_base_patch4_window7_224,convnext_base,tf_efficientnetv2_l\"\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --finetune https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 2.5e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.1 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.1 \\\n",
        "#  --distillation-type hard \\\n",
        "# --teacher-model regnety_160 \\\n",
        "# --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/tiny_imagenet_10ep\n",
        "# %cd /content/deit\n",
        "# !python main.py \\\n",
        "#  --model deit_tiny_distilled_patch16_224 \\\n",
        "#  --data-path /content/tiny-imagenet-200 \\\n",
        "#  --epochs 10 \\\n",
        "#  --batch-size 128 \\\n",
        "#  --num_workers 4 \\\n",
        "#  --input-size 224 \\\n",
        "#  --opt adamw \\\n",
        "#  --lr 7e-4 \\\n",
        "#  --weight-decay 0.05 \\\n",
        "#  --sched cosine \\\n",
        "#  --warmup-epochs 1 \\\n",
        "#  --smoothing 0.0 \\\n",
        "#  --aa rand-m7-mstd0.5 \\\n",
        "#  --reprob 0.1 \\\n",
        "#  --drop-path 0.0 \\\n",
        "#  --distillation-type hard \\\n",
        "#  --distillation-alpha 0.7 \\\n",
        "#  --teacher-model regnety_160 \\\n",
        "#  --teacher-path https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth \\\n",
        "#  --output_dir /content/deit_runs/deit_tiny_distilled_10ep\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TYvrcwJwlde",
        "outputId": "71526643-409e-4784-adc5-360ec13b677c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [46]  [230/781]  eta: 0:03:05  lr: 0.000040  loss: 1.4579 (1.5188)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [240/781]  eta: 0:03:02  lr: 0.000040  loss: 1.4376 (1.5191)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [250/781]  eta: 0:02:58  lr: 0.000040  loss: 1.4129 (1.5212)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [260/781]  eta: 0:02:55  lr: 0.000040  loss: 1.4691 (1.5250)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [270/781]  eta: 0:02:51  lr: 0.000040  loss: 1.4639 (1.5244)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [280/781]  eta: 0:02:48  lr: 0.000040  loss: 1.4213 (1.5212)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [290/781]  eta: 0:02:45  lr: 0.000040  loss: 1.4175 (1.5228)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [300/781]  eta: 0:02:41  lr: 0.000040  loss: 1.4603 (1.5314)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [310/781]  eta: 0:02:38  lr: 0.000040  loss: 1.4301 (1.5288)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [320/781]  eta: 0:02:34  lr: 0.000040  loss: 1.3780 (1.5261)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [330/781]  eta: 0:02:31  lr: 0.000040  loss: 1.3622 (1.5273)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [340/781]  eta: 0:02:28  lr: 0.000040  loss: 1.3689 (1.5297)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [350/781]  eta: 0:02:24  lr: 0.000040  loss: 1.3689 (1.5324)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [360/781]  eta: 0:02:21  lr: 0.000040  loss: 1.3899 (1.5412)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [370/781]  eta: 0:02:17  lr: 0.000040  loss: 1.4321 (1.5408)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [380/781]  eta: 0:02:14  lr: 0.000040  loss: 1.4691 (1.5482)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [390/781]  eta: 0:02:11  lr: 0.000040  loss: 1.4691 (1.5468)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [400/781]  eta: 0:02:07  lr: 0.000040  loss: 1.3841 (1.5465)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [410/781]  eta: 0:02:04  lr: 0.000040  loss: 1.3797 (1.5424)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [420/781]  eta: 0:02:01  lr: 0.000040  loss: 1.3987 (1.5450)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [430/781]  eta: 0:01:57  lr: 0.000040  loss: 1.4186 (1.5478)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [440/781]  eta: 0:01:54  lr: 0.000040  loss: 1.4600 (1.5500)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [450/781]  eta: 0:01:50  lr: 0.000040  loss: 1.4372 (1.5507)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [460/781]  eta: 0:01:47  lr: 0.000040  loss: 1.3902 (1.5520)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [470/781]  eta: 0:01:44  lr: 0.000040  loss: 1.3806 (1.5516)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [480/781]  eta: 0:01:40  lr: 0.000040  loss: 1.3962 (1.5528)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [490/781]  eta: 0:01:37  lr: 0.000040  loss: 1.3837 (1.5514)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [500/781]  eta: 0:01:34  lr: 0.000040  loss: 1.3941 (1.5509)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [510/781]  eta: 0:01:30  lr: 0.000040  loss: 1.4016 (1.5477)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [520/781]  eta: 0:01:27  lr: 0.000040  loss: 1.4042 (1.5468)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [530/781]  eta: 0:01:24  lr: 0.000040  loss: 1.4042 (1.5473)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [540/781]  eta: 0:01:20  lr: 0.000040  loss: 1.3989 (1.5498)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [550/781]  eta: 0:01:17  lr: 0.000040  loss: 1.4156 (1.5489)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [560/781]  eta: 0:01:13  lr: 0.000040  loss: 1.3872 (1.5488)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [570/781]  eta: 0:01:10  lr: 0.000040  loss: 1.4365 (1.5492)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [580/781]  eta: 0:01:07  lr: 0.000040  loss: 1.4301 (1.5478)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [590/781]  eta: 0:01:03  lr: 0.000040  loss: 1.3741 (1.5472)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [600/781]  eta: 0:01:00  lr: 0.000040  loss: 1.3578 (1.5457)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [610/781]  eta: 0:00:57  lr: 0.000040  loss: 1.3727 (1.5455)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [620/781]  eta: 0:00:53  lr: 0.000040  loss: 1.3933 (1.5465)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [630/781]  eta: 0:00:50  lr: 0.000040  loss: 1.4359 (1.5464)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [640/781]  eta: 0:00:47  lr: 0.000040  loss: 1.4294 (1.5454)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [650/781]  eta: 0:00:43  lr: 0.000040  loss: 1.3838 (1.5465)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [660/781]  eta: 0:00:40  lr: 0.000040  loss: 1.3879 (1.5448)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [670/781]  eta: 0:00:37  lr: 0.000040  loss: 1.4151 (1.5436)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [680/781]  eta: 0:00:33  lr: 0.000040  loss: 1.4085 (1.5440)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [690/781]  eta: 0:00:30  lr: 0.000040  loss: 1.4635 (1.5484)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [700/781]  eta: 0:00:27  lr: 0.000040  loss: 1.4981 (1.5474)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [710/781]  eta: 0:00:23  lr: 0.000040  loss: 1.3769 (1.5458)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [720/781]  eta: 0:00:20  lr: 0.000040  loss: 1.3766 (1.5448)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [730/781]  eta: 0:00:17  lr: 0.000040  loss: 1.4159 (1.5449)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [740/781]  eta: 0:00:13  lr: 0.000040  loss: 1.4500 (1.5459)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [750/781]  eta: 0:00:10  lr: 0.000040  loss: 1.4154 (1.5450)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [760/781]  eta: 0:00:07  lr: 0.000040  loss: 1.3744 (1.5459)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [770/781]  eta: 0:00:03  lr: 0.000040  loss: 1.3637 (1.5439)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [46]  [780/781]  eta: 0:00:00  lr: 0.000040  loss: 1.3708 (1.5431)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [46] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000040  loss: 1.3708 (1.5431)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3281286656856537, 'lambda_convnext_base': 0.26023930311203003, 'lambda_tf_efficientnetv2_l': 0.4116322696208954}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7729 (0.7729)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8455  data: 0.8146  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9226 (0.9552)  acc1: 82.2917 (80.8712)  acc5: 94.7917 (94.0341)  time: 0.1718  data: 0.1411  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0539 (1.0463)  acc1: 78.1250 (79.2907)  acc5: 93.7500 (92.7083)  time: 0.1210  data: 0.0903  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1920 (1.1051)  acc1: 76.0417 (78.1754)  acc5: 91.1458 (92.1539)  time: 0.1229  data: 0.0922  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2141 (1.1438)  acc1: 76.0417 (77.4898)  acc5: 91.1458 (91.7556)  time: 0.1262  data: 0.0955  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0934 (1.1446)  acc1: 76.0417 (77.2978)  acc5: 92.1875 (91.9526)  time: 0.1260  data: 0.0953  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1543 (1.1631)  acc1: 74.4792 (77.1300)  acc5: 92.7083 (91.9900)  time: 0.1103  data: 0.0805  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1312 s / it)\n",
            "* Acc@1 77.130 Acc@5 91.990 loss 1.163\n",
            "Accuracy of the network on the 10000 test images: 77.1%\n",
            "Max accuracy: 77.17%\n",
            "Epoch: [47]  [  0/781]  eta: 0:14:26  lr: 0.000040  loss: 1.7880 (1.7880)  time: 1.1099  data: 0.7525  max mem: 6459\n",
            "Epoch: [47]  [ 10/781]  eta: 0:05:11  lr: 0.000040  loss: 1.4255 (1.6189)  time: 0.4037  data: 0.0687  max mem: 6459\n",
            "Epoch: [47]  [ 20/781]  eta: 0:04:41  lr: 0.000040  loss: 1.3790 (1.5538)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 30/781]  eta: 0:04:28  lr: 0.000040  loss: 1.3768 (1.5347)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 40/781]  eta: 0:04:20  lr: 0.000040  loss: 1.3977 (1.5875)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 50/781]  eta: 0:04:14  lr: 0.000040  loss: 1.4449 (1.5642)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 60/781]  eta: 0:04:09  lr: 0.000040  loss: 1.4611 (1.5781)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 70/781]  eta: 0:04:04  lr: 0.000040  loss: 1.4477 (1.5827)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 80/781]  eta: 0:04:00  lr: 0.000040  loss: 1.3566 (1.5798)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [ 90/781]  eta: 0:03:56  lr: 0.000040  loss: 1.3194 (1.5569)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [100/781]  eta: 0:03:52  lr: 0.000040  loss: 1.3714 (1.5653)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [110/781]  eta: 0:03:48  lr: 0.000040  loss: 1.3667 (1.5527)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [120/781]  eta: 0:03:44  lr: 0.000040  loss: 1.3389 (1.5537)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [130/781]  eta: 0:03:40  lr: 0.000040  loss: 1.4093 (1.5511)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [140/781]  eta: 0:03:37  lr: 0.000040  loss: 1.3299 (1.5490)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [150/781]  eta: 0:03:33  lr: 0.000040  loss: 1.3810 (1.5458)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [160/781]  eta: 0:03:29  lr: 0.000040  loss: 1.3999 (1.5421)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [170/781]  eta: 0:03:26  lr: 0.000040  loss: 1.3999 (1.5328)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [180/781]  eta: 0:03:22  lr: 0.000040  loss: 1.3725 (1.5279)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [190/781]  eta: 0:03:19  lr: 0.000040  loss: 1.3989 (1.5253)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [200/781]  eta: 0:03:15  lr: 0.000040  loss: 1.3965 (1.5293)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [210/781]  eta: 0:03:12  lr: 0.000040  loss: 1.3902 (1.5265)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [220/781]  eta: 0:03:08  lr: 0.000040  loss: 1.3902 (1.5207)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [230/781]  eta: 0:03:05  lr: 0.000040  loss: 1.3725 (1.5140)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [240/781]  eta: 0:03:02  lr: 0.000040  loss: 1.3768 (1.5145)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [250/781]  eta: 0:02:58  lr: 0.000040  loss: 1.3805 (1.5169)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [260/781]  eta: 0:02:55  lr: 0.000040  loss: 1.4495 (1.5205)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [270/781]  eta: 0:02:51  lr: 0.000040  loss: 1.4495 (1.5213)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [280/781]  eta: 0:02:48  lr: 0.000040  loss: 1.4050 (1.5176)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [290/781]  eta: 0:02:44  lr: 0.000040  loss: 1.3885 (1.5153)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [300/781]  eta: 0:02:41  lr: 0.000040  loss: 1.4100 (1.5200)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [310/781]  eta: 0:02:38  lr: 0.000040  loss: 1.4611 (1.5207)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [320/781]  eta: 0:02:34  lr: 0.000040  loss: 1.4683 (1.5232)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [330/781]  eta: 0:02:31  lr: 0.000040  loss: 1.4151 (1.5196)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [340/781]  eta: 0:02:27  lr: 0.000040  loss: 1.3629 (1.5149)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [350/781]  eta: 0:02:24  lr: 0.000040  loss: 1.3868 (1.5173)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [360/781]  eta: 0:02:21  lr: 0.000040  loss: 1.4217 (1.5189)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [370/781]  eta: 0:02:17  lr: 0.000040  loss: 1.3602 (1.5168)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [380/781]  eta: 0:02:14  lr: 0.000040  loss: 1.3507 (1.5190)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [390/781]  eta: 0:02:11  lr: 0.000040  loss: 1.3802 (1.5192)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [400/781]  eta: 0:02:07  lr: 0.000040  loss: 1.4067 (1.5224)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [410/781]  eta: 0:02:04  lr: 0.000040  loss: 1.4023 (1.5222)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [420/781]  eta: 0:02:00  lr: 0.000040  loss: 1.3909 (1.5208)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [430/781]  eta: 0:01:57  lr: 0.000040  loss: 1.3864 (1.5206)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [440/781]  eta: 0:01:54  lr: 0.000040  loss: 1.3644 (1.5200)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [450/781]  eta: 0:01:50  lr: 0.000040  loss: 1.3644 (1.5264)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [460/781]  eta: 0:01:47  lr: 0.000040  loss: 1.4236 (1.5295)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [470/781]  eta: 0:01:44  lr: 0.000040  loss: 1.3850 (1.5266)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [480/781]  eta: 0:01:40  lr: 0.000040  loss: 1.3850 (1.5308)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [490/781]  eta: 0:01:37  lr: 0.000040  loss: 1.4798 (1.5328)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [500/781]  eta: 0:01:34  lr: 0.000040  loss: 1.3470 (1.5294)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [510/781]  eta: 0:01:30  lr: 0.000040  loss: 1.3470 (1.5297)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [520/781]  eta: 0:01:27  lr: 0.000040  loss: 1.3635 (1.5264)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [530/781]  eta: 0:01:24  lr: 0.000040  loss: 1.3686 (1.5259)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [540/781]  eta: 0:01:20  lr: 0.000040  loss: 1.4216 (1.5285)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [550/781]  eta: 0:01:17  lr: 0.000040  loss: 1.4250 (1.5269)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [560/781]  eta: 0:01:13  lr: 0.000040  loss: 1.3721 (1.5251)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [570/781]  eta: 0:01:10  lr: 0.000040  loss: 1.3897 (1.5276)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [580/781]  eta: 0:01:07  lr: 0.000040  loss: 1.4220 (1.5281)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [590/781]  eta: 0:01:03  lr: 0.000040  loss: 1.4060 (1.5263)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [600/781]  eta: 0:01:00  lr: 0.000040  loss: 1.3657 (1.5276)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [610/781]  eta: 0:00:57  lr: 0.000040  loss: 1.4259 (1.5302)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [620/781]  eta: 0:00:53  lr: 0.000040  loss: 1.4373 (1.5312)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [630/781]  eta: 0:00:50  lr: 0.000040  loss: 1.4489 (1.5324)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [640/781]  eta: 0:00:47  lr: 0.000040  loss: 1.4277 (1.5342)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [650/781]  eta: 0:00:43  lr: 0.000040  loss: 1.3930 (1.5329)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [660/781]  eta: 0:00:40  lr: 0.000040  loss: 1.3642 (1.5307)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [670/781]  eta: 0:00:37  lr: 0.000040  loss: 1.3207 (1.5318)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [680/781]  eta: 0:00:33  lr: 0.000040  loss: 1.3777 (1.5297)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [690/781]  eta: 0:00:30  lr: 0.000040  loss: 1.3986 (1.5306)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [700/781]  eta: 0:00:27  lr: 0.000040  loss: 1.4474 (1.5297)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [710/781]  eta: 0:00:23  lr: 0.000040  loss: 1.4379 (1.5313)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [720/781]  eta: 0:00:20  lr: 0.000040  loss: 1.4364 (1.5325)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [730/781]  eta: 0:00:17  lr: 0.000040  loss: 1.3855 (1.5302)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [740/781]  eta: 0:00:13  lr: 0.000040  loss: 1.3835 (1.5289)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [750/781]  eta: 0:00:10  lr: 0.000040  loss: 1.4152 (1.5320)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [760/781]  eta: 0:00:07  lr: 0.000040  loss: 1.3928 (1.5302)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [770/781]  eta: 0:00:03  lr: 0.000040  loss: 1.3896 (1.5302)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [47]  [780/781]  eta: 0:00:00  lr: 0.000040  loss: 1.4147 (1.5325)  time: 0.3335  data: 0.0005  max mem: 6459\n",
            "Epoch: [47] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000040  loss: 1.4147 (1.5325)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32879573106765747, 'lambda_convnext_base': 0.25995081663131714, 'lambda_tf_efficientnetv2_l': 0.4112530052661896}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7449 (0.7449)  acc1: 85.4167 (85.4167)  acc5: 95.3125 (95.3125)  time: 0.8446  data: 0.8136  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9467 (0.9584)  acc1: 83.3333 (80.9659)  acc5: 95.3125 (94.4129)  time: 0.1756  data: 0.1449  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0368 (1.0469)  acc1: 79.1667 (79.1171)  acc5: 94.2708 (93.2788)  time: 0.1271  data: 0.0965  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2184 (1.1026)  acc1: 75.0000 (78.1082)  acc5: 91.1458 (92.6075)  time: 0.1254  data: 0.0947  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2494 (1.1519)  acc1: 75.0000 (77.2485)  acc5: 90.6250 (91.8826)  time: 0.1234  data: 0.0927  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1416 (1.1472)  acc1: 75.0000 (77.1446)  acc5: 90.6250 (92.0445)  time: 0.1242  data: 0.0936  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1767 (1.1535)  acc1: 73.9583 (77.0700)  acc5: 92.1875 (92.0900)  time: 0.1055  data: 0.0758  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1323 s / it)\n",
            "* Acc@1 77.070 Acc@5 92.090 loss 1.154\n",
            "Accuracy of the network on the 10000 test images: 77.1%\n",
            "Max accuracy: 77.17%\n",
            "Epoch: [48]  [  0/781]  eta: 0:14:30  lr: 0.000039  loss: 1.3324 (1.3324)  time: 1.1140  data: 0.7593  max mem: 6459\n",
            "Epoch: [48]  [ 10/781]  eta: 0:05:11  lr: 0.000039  loss: 1.4132 (1.5328)  time: 0.4041  data: 0.0693  max mem: 6459\n",
            "Epoch: [48]  [ 20/781]  eta: 0:04:41  lr: 0.000039  loss: 1.3835 (1.4725)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 30/781]  eta: 0:04:29  lr: 0.000039  loss: 1.3797 (1.4623)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 40/781]  eta: 0:04:21  lr: 0.000039  loss: 1.3654 (1.4340)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 50/781]  eta: 0:04:14  lr: 0.000039  loss: 1.3695 (1.4496)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 60/781]  eta: 0:04:09  lr: 0.000039  loss: 1.3784 (1.4768)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 70/781]  eta: 0:04:04  lr: 0.000039  loss: 1.3687 (1.4579)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 80/781]  eta: 0:04:00  lr: 0.000039  loss: 1.3352 (1.4822)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [ 90/781]  eta: 0:03:56  lr: 0.000039  loss: 1.3824 (1.5086)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [100/781]  eta: 0:03:52  lr: 0.000039  loss: 1.3824 (1.5041)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [110/781]  eta: 0:03:48  lr: 0.000039  loss: 1.3446 (1.5083)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [120/781]  eta: 0:03:44  lr: 0.000039  loss: 1.4074 (1.5029)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [130/781]  eta: 0:03:40  lr: 0.000039  loss: 1.3807 (1.5065)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [140/781]  eta: 0:03:37  lr: 0.000039  loss: 1.3513 (1.5028)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [150/781]  eta: 0:03:33  lr: 0.000039  loss: 1.3698 (1.5116)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [160/781]  eta: 0:03:29  lr: 0.000039  loss: 1.3698 (1.5182)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [170/781]  eta: 0:03:26  lr: 0.000039  loss: 1.3556 (1.5154)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [180/781]  eta: 0:03:22  lr: 0.000039  loss: 1.3813 (1.5187)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [190/781]  eta: 0:03:19  lr: 0.000039  loss: 1.4275 (1.5243)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [200/781]  eta: 0:03:15  lr: 0.000039  loss: 1.3581 (1.5151)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [210/781]  eta: 0:03:12  lr: 0.000039  loss: 1.3581 (1.5160)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [220/781]  eta: 0:03:08  lr: 0.000039  loss: 1.4169 (1.5186)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [230/781]  eta: 0:03:05  lr: 0.000039  loss: 1.3782 (1.5101)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [240/781]  eta: 0:03:01  lr: 0.000039  loss: 1.3471 (1.5105)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [250/781]  eta: 0:02:58  lr: 0.000039  loss: 1.3927 (1.5061)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [260/781]  eta: 0:02:55  lr: 0.000039  loss: 1.4110 (1.5166)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [270/781]  eta: 0:02:51  lr: 0.000039  loss: 1.4344 (1.5223)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [280/781]  eta: 0:02:48  lr: 0.000039  loss: 1.3745 (1.5220)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [290/781]  eta: 0:02:44  lr: 0.000039  loss: 1.3522 (1.5197)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [300/781]  eta: 0:02:41  lr: 0.000039  loss: 1.3522 (1.5186)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [310/781]  eta: 0:02:38  lr: 0.000039  loss: 1.3417 (1.5155)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [320/781]  eta: 0:02:34  lr: 0.000039  loss: 1.3513 (1.5115)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [330/781]  eta: 0:02:31  lr: 0.000039  loss: 1.3737 (1.5162)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [340/781]  eta: 0:02:27  lr: 0.000039  loss: 1.3856 (1.5152)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [350/781]  eta: 0:02:24  lr: 0.000039  loss: 1.3969 (1.5204)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [360/781]  eta: 0:02:21  lr: 0.000039  loss: 1.4488 (1.5242)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [370/781]  eta: 0:02:17  lr: 0.000039  loss: 1.4031 (1.5199)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [380/781]  eta: 0:02:14  lr: 0.000039  loss: 1.3768 (1.5191)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [390/781]  eta: 0:02:11  lr: 0.000039  loss: 1.3718 (1.5159)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [400/781]  eta: 0:02:07  lr: 0.000039  loss: 1.3785 (1.5161)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [410/781]  eta: 0:02:04  lr: 0.000039  loss: 1.3443 (1.5114)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [420/781]  eta: 0:02:00  lr: 0.000039  loss: 1.3667 (1.5090)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [430/781]  eta: 0:01:57  lr: 0.000039  loss: 1.3830 (1.5055)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [440/781]  eta: 0:01:54  lr: 0.000039  loss: 1.3554 (1.5057)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [450/781]  eta: 0:01:50  lr: 0.000039  loss: 1.3698 (1.5036)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [460/781]  eta: 0:01:47  lr: 0.000039  loss: 1.3862 (1.5064)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [470/781]  eta: 0:01:44  lr: 0.000039  loss: 1.4066 (1.5042)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [480/781]  eta: 0:01:40  lr: 0.000039  loss: 1.3863 (1.5011)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [490/781]  eta: 0:01:37  lr: 0.000039  loss: 1.3570 (1.5055)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [500/781]  eta: 0:01:34  lr: 0.000039  loss: 1.4138 (1.5046)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [510/781]  eta: 0:01:30  lr: 0.000039  loss: 1.4098 (1.5065)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [520/781]  eta: 0:01:27  lr: 0.000039  loss: 1.4068 (1.5066)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [530/781]  eta: 0:01:23  lr: 0.000039  loss: 1.3505 (1.5047)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [540/781]  eta: 0:01:20  lr: 0.000039  loss: 1.4074 (1.5062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [550/781]  eta: 0:01:17  lr: 0.000039  loss: 1.5071 (1.5104)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [560/781]  eta: 0:01:13  lr: 0.000039  loss: 1.4835 (1.5101)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [570/781]  eta: 0:01:10  lr: 0.000039  loss: 1.3932 (1.5093)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [580/781]  eta: 0:01:07  lr: 0.000039  loss: 1.3663 (1.5105)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [590/781]  eta: 0:01:03  lr: 0.000039  loss: 1.3455 (1.5101)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [600/781]  eta: 0:01:00  lr: 0.000039  loss: 1.3455 (1.5076)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [610/781]  eta: 0:00:57  lr: 0.000039  loss: 1.3657 (1.5062)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [620/781]  eta: 0:00:53  lr: 0.000039  loss: 1.3994 (1.5072)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [630/781]  eta: 0:00:50  lr: 0.000039  loss: 1.4549 (1.5116)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [640/781]  eta: 0:00:47  lr: 0.000039  loss: 1.4282 (1.5117)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [650/781]  eta: 0:00:43  lr: 0.000039  loss: 1.4282 (1.5140)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [660/781]  eta: 0:00:40  lr: 0.000039  loss: 1.4584 (1.5147)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [670/781]  eta: 0:00:37  lr: 0.000039  loss: 1.3858 (1.5140)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [680/781]  eta: 0:00:33  lr: 0.000039  loss: 1.3617 (1.5132)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [690/781]  eta: 0:00:30  lr: 0.000039  loss: 1.4268 (1.5149)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [700/781]  eta: 0:00:27  lr: 0.000039  loss: 1.4433 (1.5148)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [710/781]  eta: 0:00:23  lr: 0.000039  loss: 1.3967 (1.5154)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [720/781]  eta: 0:00:20  lr: 0.000039  loss: 1.3627 (1.5130)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [730/781]  eta: 0:00:17  lr: 0.000039  loss: 1.3650 (1.5118)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [740/781]  eta: 0:00:13  lr: 0.000039  loss: 1.3698 (1.5126)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [750/781]  eta: 0:00:10  lr: 0.000039  loss: 1.3742 (1.5124)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [760/781]  eta: 0:00:07  lr: 0.000039  loss: 1.3954 (1.5118)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [770/781]  eta: 0:00:03  lr: 0.000039  loss: 1.4239 (1.5123)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [48]  [780/781]  eta: 0:00:00  lr: 0.000039  loss: 1.4506 (1.5143)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [48] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000039  loss: 1.4506 (1.5143)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3286956250667572, 'lambda_convnext_base': 0.25993579626083374, 'lambda_tf_efficientnetv2_l': 0.41136863827705383}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8304 (0.8304)  acc1: 83.3333 (83.3333)  acc5: 94.2708 (94.2708)  time: 0.8492  data: 0.8183  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9425 (0.9730)  acc1: 82.2917 (80.9186)  acc5: 95.3125 (94.1761)  time: 0.1737  data: 0.1430  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0029 (1.0482)  acc1: 79.6875 (79.5635)  acc5: 93.2292 (92.9315)  time: 0.1234  data: 0.0928  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1883 (1.1073)  acc1: 73.9583 (78.2930)  acc5: 90.6250 (92.3219)  time: 0.1203  data: 0.0896  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2596 (1.1537)  acc1: 73.9583 (77.4517)  acc5: 90.6250 (91.8953)  time: 0.1181  data: 0.0874  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1729 (1.1609)  acc1: 75.5208 (77.1038)  acc5: 91.6667 (92.0854)  time: 0.1209  data: 0.0902  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1731 (1.1719)  acc1: 75.0000 (76.9200)  acc5: 92.7083 (92.1100)  time: 0.1009  data: 0.0711  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1287 s / it)\n",
            "* Acc@1 76.920 Acc@5 92.110 loss 1.172\n",
            "Accuracy of the network on the 10000 test images: 76.9%\n",
            "Max accuracy: 77.17%\n",
            "Epoch: [49]  [  0/781]  eta: 0:13:59  lr: 0.000038  loss: 1.3301 (1.3301)  time: 1.0747  data: 0.7308  max mem: 6459\n",
            "Epoch: [49]  [ 10/781]  eta: 0:05:08  lr: 0.000038  loss: 1.3298 (1.4836)  time: 0.4007  data: 0.0667  max mem: 6459\n",
            "Epoch: [49]  [ 20/781]  eta: 0:04:40  lr: 0.000038  loss: 1.3316 (1.4281)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 30/781]  eta: 0:04:28  lr: 0.000038  loss: 1.3433 (1.4172)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 40/781]  eta: 0:04:20  lr: 0.000038  loss: 1.3562 (1.4180)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 50/781]  eta: 0:04:14  lr: 0.000038  loss: 1.4088 (1.4548)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 60/781]  eta: 0:04:09  lr: 0.000038  loss: 1.4325 (1.4547)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 70/781]  eta: 0:04:04  lr: 0.000038  loss: 1.3424 (1.4526)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 80/781]  eta: 0:04:00  lr: 0.000038  loss: 1.4455 (1.4803)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [ 90/781]  eta: 0:03:56  lr: 0.000038  loss: 1.5444 (1.4952)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [100/781]  eta: 0:03:52  lr: 0.000038  loss: 1.4147 (1.4874)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [110/781]  eta: 0:03:48  lr: 0.000038  loss: 1.3497 (1.4738)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [120/781]  eta: 0:03:44  lr: 0.000038  loss: 1.3497 (1.4766)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [130/781]  eta: 0:03:40  lr: 0.000038  loss: 1.3998 (1.4734)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [140/781]  eta: 0:03:37  lr: 0.000038  loss: 1.3769 (1.4699)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [150/781]  eta: 0:03:33  lr: 0.000038  loss: 1.3555 (1.4707)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [160/781]  eta: 0:03:29  lr: 0.000038  loss: 1.4055 (1.4817)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [170/781]  eta: 0:03:26  lr: 0.000038  loss: 1.3930 (1.4772)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [180/781]  eta: 0:03:22  lr: 0.000038  loss: 1.3930 (1.4851)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [190/781]  eta: 0:03:19  lr: 0.000038  loss: 1.3933 (1.4801)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [200/781]  eta: 0:03:15  lr: 0.000038  loss: 1.3865 (1.4838)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [210/781]  eta: 0:03:12  lr: 0.000038  loss: 1.3452 (1.4847)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [220/781]  eta: 0:03:09  lr: 0.000038  loss: 1.4278 (1.4956)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [230/781]  eta: 0:03:05  lr: 0.000038  loss: 1.4688 (1.4926)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [240/781]  eta: 0:03:02  lr: 0.000038  loss: 1.3514 (1.4913)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [250/781]  eta: 0:02:58  lr: 0.000038  loss: 1.3317 (1.4852)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [260/781]  eta: 0:02:55  lr: 0.000038  loss: 1.3317 (1.4908)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [270/781]  eta: 0:02:51  lr: 0.000038  loss: 1.3825 (1.4955)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [280/781]  eta: 0:02:48  lr: 0.000038  loss: 1.3931 (1.4934)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [290/781]  eta: 0:02:45  lr: 0.000038  loss: 1.4553 (1.4971)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [300/781]  eta: 0:02:41  lr: 0.000038  loss: 1.4536 (1.5019)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [310/781]  eta: 0:02:38  lr: 0.000038  loss: 1.4040 (1.5015)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [320/781]  eta: 0:02:34  lr: 0.000038  loss: 1.4199 (1.4989)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [330/781]  eta: 0:02:31  lr: 0.000038  loss: 1.4200 (1.4960)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [340/781]  eta: 0:02:28  lr: 0.000038  loss: 1.3349 (1.4920)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [350/781]  eta: 0:02:24  lr: 0.000038  loss: 1.3686 (1.4907)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [360/781]  eta: 0:02:21  lr: 0.000038  loss: 1.3668 (1.4892)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [370/781]  eta: 0:02:17  lr: 0.000038  loss: 1.3462 (1.4929)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [380/781]  eta: 0:02:14  lr: 0.000038  loss: 1.3438 (1.4910)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [390/781]  eta: 0:02:11  lr: 0.000038  loss: 1.3224 (1.4880)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [400/781]  eta: 0:02:07  lr: 0.000038  loss: 1.3439 (1.4888)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [410/781]  eta: 0:02:04  lr: 0.000038  loss: 1.3540 (1.4903)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [420/781]  eta: 0:02:01  lr: 0.000038  loss: 1.3645 (1.4901)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [430/781]  eta: 0:01:57  lr: 0.000038  loss: 1.3656 (1.4900)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [440/781]  eta: 0:01:54  lr: 0.000038  loss: 1.3783 (1.4914)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [450/781]  eta: 0:01:50  lr: 0.000038  loss: 1.3805 (1.4924)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [460/781]  eta: 0:01:47  lr: 0.000038  loss: 1.3893 (1.4967)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [470/781]  eta: 0:01:44  lr: 0.000038  loss: 1.4212 (1.4973)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [480/781]  eta: 0:01:40  lr: 0.000038  loss: 1.3920 (1.4947)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [490/781]  eta: 0:01:37  lr: 0.000038  loss: 1.3804 (1.4934)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [500/781]  eta: 0:01:34  lr: 0.000038  loss: 1.3912 (1.4940)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [510/781]  eta: 0:01:30  lr: 0.000038  loss: 1.3573 (1.4913)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [520/781]  eta: 0:01:27  lr: 0.000038  loss: 1.3367 (1.4892)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [530/781]  eta: 0:01:24  lr: 0.000038  loss: 1.3941 (1.4939)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [540/781]  eta: 0:01:20  lr: 0.000038  loss: 1.4250 (1.4937)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [550/781]  eta: 0:01:17  lr: 0.000038  loss: 1.3923 (1.4907)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [560/781]  eta: 0:01:13  lr: 0.000038  loss: 1.3348 (1.4887)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [570/781]  eta: 0:01:10  lr: 0.000038  loss: 1.3523 (1.4896)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [580/781]  eta: 0:01:07  lr: 0.000038  loss: 1.4015 (1.4917)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [590/781]  eta: 0:01:03  lr: 0.000038  loss: 1.4462 (1.4946)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [600/781]  eta: 0:01:00  lr: 0.000038  loss: 1.3586 (1.4954)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [610/781]  eta: 0:00:57  lr: 0.000038  loss: 1.3353 (1.4952)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [620/781]  eta: 0:00:53  lr: 0.000038  loss: 1.3814 (1.4971)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [630/781]  eta: 0:00:50  lr: 0.000038  loss: 1.3790 (1.4946)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [640/781]  eta: 0:00:47  lr: 0.000038  loss: 1.3952 (1.4933)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [650/781]  eta: 0:00:43  lr: 0.000038  loss: 1.4088 (1.4912)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [660/781]  eta: 0:00:40  lr: 0.000038  loss: 1.3571 (1.4900)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [670/781]  eta: 0:00:37  lr: 0.000038  loss: 1.3571 (1.4912)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [680/781]  eta: 0:00:33  lr: 0.000038  loss: 1.3743 (1.4895)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [690/781]  eta: 0:00:30  lr: 0.000038  loss: 1.3835 (1.4877)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [700/781]  eta: 0:00:27  lr: 0.000038  loss: 1.3717 (1.4879)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [710/781]  eta: 0:00:23  lr: 0.000038  loss: 1.3424 (1.4871)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [720/781]  eta: 0:00:20  lr: 0.000038  loss: 1.4055 (1.4875)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [730/781]  eta: 0:00:17  lr: 0.000038  loss: 1.4059 (1.4865)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [740/781]  eta: 0:00:13  lr: 0.000038  loss: 1.3774 (1.4855)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [750/781]  eta: 0:00:10  lr: 0.000038  loss: 1.4392 (1.4871)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [760/781]  eta: 0:00:07  lr: 0.000038  loss: 1.4549 (1.4859)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [770/781]  eta: 0:00:03  lr: 0.000038  loss: 1.3713 (1.4866)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [49]  [780/781]  eta: 0:00:00  lr: 0.000038  loss: 1.4168 (1.4866)  time: 0.3339  data: 0.0005  max mem: 6459\n",
            "Epoch: [49] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000038  loss: 1.4168 (1.4866)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3299887180328369, 'lambda_convnext_base': 0.25997263193130493, 'lambda_tf_efficientnetv2_l': 0.41003891825675964}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8295 (0.8295)  acc1: 85.4167 (85.4167)  acc5: 95.3125 (95.3125)  time: 0.8418  data: 0.8110  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9600 (0.9525)  acc1: 81.7708 (81.2974)  acc5: 95.3125 (94.1288)  time: 0.1705  data: 0.1398  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9608 (1.0122)  acc1: 79.1667 (80.2331)  acc5: 94.2708 (93.1796)  time: 0.1217  data: 0.0911  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1587 (1.0873)  acc1: 77.0833 (78.6626)  acc5: 91.6667 (92.5235)  time: 0.1219  data: 0.0913  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3087 (1.1348)  acc1: 75.5208 (77.7058)  acc5: 91.1458 (91.9970)  time: 0.1220  data: 0.0914  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1410 (1.1376)  acc1: 77.6042 (77.3795)  acc5: 91.6667 (92.1773)  time: 0.1226  data: 0.0920  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2012 (1.1482)  acc1: 75.0000 (77.2600)  acc5: 91.6667 (92.2200)  time: 0.1035  data: 0.0738  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1293 s / it)\n",
            "* Acc@1 77.260 Acc@5 92.220 loss 1.148\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.26%\n",
            "Epoch: [50]  [  0/781]  eta: 0:14:23  lr: 0.000037  loss: 1.3459 (1.3459)  time: 1.1050  data: 0.7632  max mem: 6459\n",
            "Epoch: [50]  [ 10/781]  eta: 0:05:10  lr: 0.000037  loss: 1.3459 (1.3465)  time: 0.4033  data: 0.0696  max mem: 6459\n",
            "Epoch: [50]  [ 20/781]  eta: 0:04:41  lr: 0.000037  loss: 1.3546 (1.3722)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 30/781]  eta: 0:04:28  lr: 0.000037  loss: 1.3705 (1.3932)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 40/781]  eta: 0:04:20  lr: 0.000037  loss: 1.3705 (1.4098)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 50/781]  eta: 0:04:14  lr: 0.000037  loss: 1.3221 (1.4185)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 60/781]  eta: 0:04:09  lr: 0.000037  loss: 1.3691 (1.4815)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 70/781]  eta: 0:04:04  lr: 0.000037  loss: 1.3726 (1.4946)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 80/781]  eta: 0:04:00  lr: 0.000037  loss: 1.3462 (1.4848)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [ 90/781]  eta: 0:03:56  lr: 0.000037  loss: 1.3471 (1.4842)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [100/781]  eta: 0:03:52  lr: 0.000037  loss: 1.3471 (1.4800)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [110/781]  eta: 0:03:48  lr: 0.000037  loss: 1.3479 (1.4759)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [120/781]  eta: 0:03:44  lr: 0.000037  loss: 1.3482 (1.4779)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [130/781]  eta: 0:03:40  lr: 0.000037  loss: 1.3759 (1.4787)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [140/781]  eta: 0:03:37  lr: 0.000037  loss: 1.3938 (1.4826)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [150/781]  eta: 0:03:33  lr: 0.000037  loss: 1.4063 (1.5022)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [160/781]  eta: 0:03:29  lr: 0.000037  loss: 1.4339 (1.5111)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [170/781]  eta: 0:03:26  lr: 0.000037  loss: 1.3941 (1.5085)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [180/781]  eta: 0:03:22  lr: 0.000037  loss: 1.3905 (1.5121)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [190/781]  eta: 0:03:19  lr: 0.000037  loss: 1.4427 (1.5212)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [200/781]  eta: 0:03:15  lr: 0.000037  loss: 1.3788 (1.5172)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [210/781]  eta: 0:03:12  lr: 0.000037  loss: 1.3337 (1.5148)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [220/781]  eta: 0:03:08  lr: 0.000037  loss: 1.3485 (1.5132)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [230/781]  eta: 0:03:05  lr: 0.000037  loss: 1.3604 (1.5123)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [240/781]  eta: 0:03:02  lr: 0.000037  loss: 1.3533 (1.5070)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [250/781]  eta: 0:02:58  lr: 0.000037  loss: 1.3394 (1.5063)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [260/781]  eta: 0:02:55  lr: 0.000037  loss: 1.3422 (1.5012)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [270/781]  eta: 0:02:51  lr: 0.000037  loss: 1.3422 (1.5040)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [280/781]  eta: 0:02:48  lr: 0.000037  loss: 1.3552 (1.5061)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [290/781]  eta: 0:02:44  lr: 0.000037  loss: 1.3851 (1.5082)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [300/781]  eta: 0:02:41  lr: 0.000037  loss: 1.4176 (1.5201)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [310/781]  eta: 0:02:38  lr: 0.000037  loss: 1.4318 (1.5248)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [320/781]  eta: 0:02:34  lr: 0.000037  loss: 1.3704 (1.5262)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [330/781]  eta: 0:02:31  lr: 0.000037  loss: 1.3289 (1.5231)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [340/781]  eta: 0:02:27  lr: 0.000037  loss: 1.3355 (1.5207)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [350/781]  eta: 0:02:24  lr: 0.000037  loss: 1.3355 (1.5219)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [360/781]  eta: 0:02:21  lr: 0.000037  loss: 1.3589 (1.5234)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [370/781]  eta: 0:02:17  lr: 0.000037  loss: 1.3736 (1.5235)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [380/781]  eta: 0:02:14  lr: 0.000037  loss: 1.3612 (1.5226)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [390/781]  eta: 0:02:11  lr: 0.000037  loss: 1.3498 (1.5226)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [400/781]  eta: 0:02:07  lr: 0.000037  loss: 1.4643 (1.5261)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [410/781]  eta: 0:02:04  lr: 0.000037  loss: 1.4834 (1.5292)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [420/781]  eta: 0:02:00  lr: 0.000037  loss: 1.4484 (1.5287)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [430/781]  eta: 0:01:57  lr: 0.000037  loss: 1.4484 (1.5338)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [440/781]  eta: 0:01:54  lr: 0.000037  loss: 1.4115 (1.5333)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [450/781]  eta: 0:01:50  lr: 0.000037  loss: 1.3892 (1.5311)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [460/781]  eta: 0:01:47  lr: 0.000037  loss: 1.3301 (1.5279)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [470/781]  eta: 0:01:44  lr: 0.000037  loss: 1.3621 (1.5283)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [480/781]  eta: 0:01:40  lr: 0.000037  loss: 1.3674 (1.5285)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [490/781]  eta: 0:01:37  lr: 0.000037  loss: 1.3455 (1.5252)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [500/781]  eta: 0:01:34  lr: 0.000037  loss: 1.3627 (1.5228)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [510/781]  eta: 0:01:30  lr: 0.000037  loss: 1.3870 (1.5268)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [520/781]  eta: 0:01:27  lr: 0.000037  loss: 1.3762 (1.5280)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [530/781]  eta: 0:01:24  lr: 0.000037  loss: 1.3583 (1.5287)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [540/781]  eta: 0:01:20  lr: 0.000037  loss: 1.3153 (1.5252)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [550/781]  eta: 0:01:17  lr: 0.000037  loss: 1.3097 (1.5220)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [560/781]  eta: 0:01:14  lr: 0.000037  loss: 1.3382 (1.5204)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [570/781]  eta: 0:01:10  lr: 0.000037  loss: 1.3751 (1.5220)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [580/781]  eta: 0:01:07  lr: 0.000037  loss: 1.4308 (1.5222)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [590/781]  eta: 0:01:03  lr: 0.000037  loss: 1.4207 (1.5209)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [600/781]  eta: 0:01:00  lr: 0.000037  loss: 1.4666 (1.5242)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [610/781]  eta: 0:00:57  lr: 0.000037  loss: 1.4913 (1.5250)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [620/781]  eta: 0:00:53  lr: 0.000037  loss: 1.3673 (1.5246)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [630/781]  eta: 0:00:50  lr: 0.000037  loss: 1.3413 (1.5223)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [640/781]  eta: 0:00:47  lr: 0.000037  loss: 1.3804 (1.5215)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [650/781]  eta: 0:00:43  lr: 0.000037  loss: 1.3847 (1.5200)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [660/781]  eta: 0:00:40  lr: 0.000037  loss: 1.3995 (1.5198)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [670/781]  eta: 0:00:37  lr: 0.000037  loss: 1.4245 (1.5242)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [680/781]  eta: 0:00:33  lr: 0.000037  loss: 1.4344 (1.5236)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [690/781]  eta: 0:00:30  lr: 0.000037  loss: 1.3641 (1.5207)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [700/781]  eta: 0:00:27  lr: 0.000037  loss: 1.3583 (1.5203)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [710/781]  eta: 0:00:23  lr: 0.000037  loss: 1.3895 (1.5184)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [720/781]  eta: 0:00:20  lr: 0.000037  loss: 1.3994 (1.5179)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [730/781]  eta: 0:00:17  lr: 0.000037  loss: 1.3994 (1.5162)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [740/781]  eta: 0:00:13  lr: 0.000037  loss: 1.3985 (1.5149)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [750/781]  eta: 0:00:10  lr: 0.000037  loss: 1.3569 (1.5135)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [760/781]  eta: 0:00:07  lr: 0.000037  loss: 1.3717 (1.5142)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [770/781]  eta: 0:00:03  lr: 0.000037  loss: 1.3717 (1.5131)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [50]  [780/781]  eta: 0:00:00  lr: 0.000037  loss: 1.3689 (1.5123)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [50] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000037  loss: 1.3689 (1.5123)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3279373347759247, 'lambda_convnext_base': 0.25968798995018005, 'lambda_tf_efficientnetv2_l': 0.41237449645996094}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7985 (0.7985)  acc1: 82.8125 (82.8125)  acc5: 94.2708 (94.2708)  time: 0.8213  data: 0.7904  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8666 (0.9587)  acc1: 82.8125 (81.0133)  acc5: 94.7917 (93.9867)  time: 0.1721  data: 0.1414  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0078 (1.0224)  acc1: 81.7708 (80.1339)  acc5: 93.2292 (92.8571)  time: 0.1264  data: 0.0957  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1931 (1.0915)  acc1: 77.0833 (78.8811)  acc5: 90.6250 (92.0867)  time: 0.1278  data: 0.0972  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2806 (1.1329)  acc1: 76.5625 (78.1885)  acc5: 90.1042 (91.6540)  time: 0.1298  data: 0.0991  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1821 (1.1392)  acc1: 76.0417 (77.6246)  acc5: 91.6667 (91.8607)  time: 0.1307  data: 0.1000  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1821 (1.1511)  acc1: 73.9583 (77.4400)  acc5: 92.1875 (91.9000)  time: 0.1101  data: 0.0804  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1350 s / it)\n",
            "* Acc@1 77.440 Acc@5 91.900 loss 1.151\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.44%\n",
            "Epoch: [51]  [  0/781]  eta: 0:14:25  lr: 0.000036  loss: 1.3427 (1.3427)  time: 1.1087  data: 0.7584  max mem: 6459\n",
            "Epoch: [51]  [ 10/781]  eta: 0:05:11  lr: 0.000036  loss: 1.3300 (1.4815)  time: 0.4040  data: 0.0692  max mem: 6459\n",
            "Epoch: [51]  [ 20/781]  eta: 0:04:41  lr: 0.000036  loss: 1.3437 (1.5109)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 30/781]  eta: 0:04:29  lr: 0.000036  loss: 1.3770 (1.5189)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 40/781]  eta: 0:04:21  lr: 0.000036  loss: 1.3742 (1.5222)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 50/781]  eta: 0:04:14  lr: 0.000036  loss: 1.3423 (1.5138)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 60/781]  eta: 0:04:09  lr: 0.000036  loss: 1.3889 (1.5597)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 70/781]  eta: 0:04:04  lr: 0.000036  loss: 1.3845 (1.5416)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 80/781]  eta: 0:04:00  lr: 0.000036  loss: 1.3553 (1.5309)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [ 90/781]  eta: 0:03:56  lr: 0.000036  loss: 1.3788 (1.5382)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [100/781]  eta: 0:03:52  lr: 0.000036  loss: 1.3782 (1.5424)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [110/781]  eta: 0:03:48  lr: 0.000036  loss: 1.3687 (1.5449)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [120/781]  eta: 0:03:44  lr: 0.000036  loss: 1.3529 (1.5371)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [130/781]  eta: 0:03:41  lr: 0.000036  loss: 1.3430 (1.5285)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [140/781]  eta: 0:03:37  lr: 0.000036  loss: 1.3454 (1.5170)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [150/781]  eta: 0:03:33  lr: 0.000036  loss: 1.3862 (1.5211)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [160/781]  eta: 0:03:30  lr: 0.000036  loss: 1.3842 (1.5157)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [170/781]  eta: 0:03:26  lr: 0.000036  loss: 1.3679 (1.5181)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [180/781]  eta: 0:03:23  lr: 0.000036  loss: 1.3623 (1.5135)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [190/781]  eta: 0:03:19  lr: 0.000036  loss: 1.3493 (1.5190)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [200/781]  eta: 0:03:16  lr: 0.000036  loss: 1.3244 (1.5209)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [210/781]  eta: 0:03:12  lr: 0.000036  loss: 1.3774 (1.5219)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [220/781]  eta: 0:03:09  lr: 0.000036  loss: 1.3802 (1.5265)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [230/781]  eta: 0:03:05  lr: 0.000036  loss: 1.4018 (1.5269)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [240/781]  eta: 0:03:02  lr: 0.000036  loss: 1.3451 (1.5211)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [250/781]  eta: 0:02:58  lr: 0.000036  loss: 1.3244 (1.5170)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [260/781]  eta: 0:02:55  lr: 0.000036  loss: 1.3244 (1.5198)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [270/781]  eta: 0:02:51  lr: 0.000036  loss: 1.4136 (1.5255)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [280/781]  eta: 0:02:48  lr: 0.000036  loss: 1.4046 (1.5287)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [290/781]  eta: 0:02:45  lr: 0.000036  loss: 1.5867 (1.5435)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [300/781]  eta: 0:02:41  lr: 0.000036  loss: 1.5556 (1.5395)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [310/781]  eta: 0:02:38  lr: 0.000036  loss: 1.3876 (1.5432)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [320/781]  eta: 0:02:34  lr: 0.000036  loss: 1.4616 (1.5440)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [330/781]  eta: 0:02:31  lr: 0.000036  loss: 1.3847 (1.5449)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [340/781]  eta: 0:02:28  lr: 0.000036  loss: 1.4222 (1.5426)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [350/781]  eta: 0:02:24  lr: 0.000036  loss: 1.3535 (1.5408)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [360/781]  eta: 0:02:21  lr: 0.000036  loss: 1.3410 (1.5355)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [370/781]  eta: 0:02:17  lr: 0.000036  loss: 1.3202 (1.5302)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [380/781]  eta: 0:02:14  lr: 0.000036  loss: 1.3192 (1.5280)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [390/781]  eta: 0:02:11  lr: 0.000036  loss: 1.3590 (1.5260)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [400/781]  eta: 0:02:07  lr: 0.000036  loss: 1.3667 (1.5287)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [410/781]  eta: 0:02:04  lr: 0.000036  loss: 1.4051 (1.5271)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [420/781]  eta: 0:02:01  lr: 0.000036  loss: 1.3888 (1.5239)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [430/781]  eta: 0:01:57  lr: 0.000036  loss: 1.3390 (1.5200)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [440/781]  eta: 0:01:54  lr: 0.000036  loss: 1.4005 (1.5260)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [450/781]  eta: 0:01:50  lr: 0.000036  loss: 1.3797 (1.5222)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [460/781]  eta: 0:01:47  lr: 0.000036  loss: 1.3721 (1.5260)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [470/781]  eta: 0:01:44  lr: 0.000036  loss: 1.3789 (1.5272)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [480/781]  eta: 0:01:40  lr: 0.000036  loss: 1.3446 (1.5233)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [490/781]  eta: 0:01:37  lr: 0.000036  loss: 1.3612 (1.5265)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [500/781]  eta: 0:01:34  lr: 0.000036  loss: 1.4311 (1.5251)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [510/781]  eta: 0:01:30  lr: 0.000036  loss: 1.4029 (1.5240)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [520/781]  eta: 0:01:27  lr: 0.000036  loss: 1.3664 (1.5210)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [530/781]  eta: 0:01:24  lr: 0.000036  loss: 1.3664 (1.5202)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [540/781]  eta: 0:01:20  lr: 0.000036  loss: 1.3807 (1.5220)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [550/781]  eta: 0:01:17  lr: 0.000036  loss: 1.3762 (1.5224)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [560/781]  eta: 0:01:13  lr: 0.000036  loss: 1.3607 (1.5238)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [570/781]  eta: 0:01:10  lr: 0.000036  loss: 1.3664 (1.5220)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [580/781]  eta: 0:01:07  lr: 0.000036  loss: 1.3745 (1.5229)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [590/781]  eta: 0:01:03  lr: 0.000036  loss: 1.3830 (1.5225)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [600/781]  eta: 0:01:00  lr: 0.000036  loss: 1.3340 (1.5211)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [610/781]  eta: 0:00:57  lr: 0.000036  loss: 1.3056 (1.5199)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [620/781]  eta: 0:00:53  lr: 0.000036  loss: 1.3956 (1.5199)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [630/781]  eta: 0:00:50  lr: 0.000036  loss: 1.3711 (1.5195)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [640/781]  eta: 0:00:47  lr: 0.000036  loss: 1.4124 (1.5184)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [650/781]  eta: 0:00:43  lr: 0.000036  loss: 1.4277 (1.5183)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [660/781]  eta: 0:00:40  lr: 0.000036  loss: 1.4312 (1.5178)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [670/781]  eta: 0:00:37  lr: 0.000036  loss: 1.4312 (1.5166)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [680/781]  eta: 0:00:33  lr: 0.000036  loss: 1.3825 (1.5145)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [690/781]  eta: 0:00:30  lr: 0.000036  loss: 1.3629 (1.5164)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [700/781]  eta: 0:00:27  lr: 0.000036  loss: 1.3697 (1.5168)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [710/781]  eta: 0:00:23  lr: 0.000036  loss: 1.3697 (1.5156)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [720/781]  eta: 0:00:20  lr: 0.000036  loss: 1.3414 (1.5167)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [730/781]  eta: 0:00:17  lr: 0.000036  loss: 1.3638 (1.5149)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [740/781]  eta: 0:00:13  lr: 0.000036  loss: 1.3864 (1.5160)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [750/781]  eta: 0:00:10  lr: 0.000036  loss: 1.3740 (1.5143)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [760/781]  eta: 0:00:07  lr: 0.000036  loss: 1.3762 (1.5139)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [770/781]  eta: 0:00:03  lr: 0.000036  loss: 1.3798 (1.5140)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [51]  [780/781]  eta: 0:00:00  lr: 0.000036  loss: 1.3798 (1.5144)  time: 0.3334  data: 0.0005  max mem: 6459\n",
            "Epoch: [51] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000036  loss: 1.3798 (1.5144)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32840484380722046, 'lambda_convnext_base': 0.2604108452796936, 'lambda_tf_efficientnetv2_l': 0.4111843407154083}\n",
            "Test:  [ 0/53]  eta: 0:00:41  loss: 0.7716 (0.7716)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.7871  data: 0.7561  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:06  loss: 1.0168 (0.9840)  acc1: 83.3333 (81.0606)  acc5: 94.7917 (94.1761)  time: 0.1618  data: 0.1310  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0168 (1.0394)  acc1: 79.1667 (80.0099)  acc5: 93.7500 (93.1548)  time: 0.1093  data: 0.0786  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:02  loss: 1.1927 (1.0976)  acc1: 76.5625 (78.8474)  acc5: 90.6250 (92.4563)  time: 0.1119  data: 0.0812  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2907 (1.1362)  acc1: 75.0000 (78.1631)  acc5: 90.1042 (91.9461)  time: 0.1192  data: 0.0884  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1071 (1.1384)  acc1: 76.0417 (77.7778)  acc5: 91.1458 (92.0139)  time: 0.1160  data: 0.0853  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1775 (1.1463)  acc1: 76.0417 (77.6700)  acc5: 91.1458 (92.0600)  time: 0.1018  data: 0.0720  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1214 s / it)\n",
            "* Acc@1 77.670 Acc@5 92.060 loss 1.146\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [52]  [  0/781]  eta: 0:13:56  lr: 0.000035  loss: 1.3065 (1.3065)  time: 1.0711  data: 0.7245  max mem: 6459\n",
            "Epoch: [52]  [ 10/781]  eta: 0:05:08  lr: 0.000035  loss: 1.3813 (1.4447)  time: 0.4001  data: 0.0661  max mem: 6459\n",
            "Epoch: [52]  [ 20/781]  eta: 0:04:40  lr: 0.000035  loss: 1.3122 (1.4448)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 30/781]  eta: 0:04:28  lr: 0.000035  loss: 1.3556 (1.5160)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 40/781]  eta: 0:04:20  lr: 0.000035  loss: 1.3666 (1.4741)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 50/781]  eta: 0:04:14  lr: 0.000035  loss: 1.3770 (1.5204)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 60/781]  eta: 0:04:09  lr: 0.000035  loss: 1.3861 (1.5056)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 70/781]  eta: 0:04:04  lr: 0.000035  loss: 1.3317 (1.4813)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 80/781]  eta: 0:04:00  lr: 0.000035  loss: 1.3504 (1.4661)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [ 90/781]  eta: 0:03:55  lr: 0.000035  loss: 1.3572 (1.4630)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [100/781]  eta: 0:03:51  lr: 0.000035  loss: 1.3538 (1.4638)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [110/781]  eta: 0:03:48  lr: 0.000035  loss: 1.3506 (1.4529)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [120/781]  eta: 0:03:44  lr: 0.000035  loss: 1.3401 (1.4469)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [130/781]  eta: 0:03:40  lr: 0.000035  loss: 1.3399 (1.4473)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [140/781]  eta: 0:03:36  lr: 0.000035  loss: 1.3399 (1.4430)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [150/781]  eta: 0:03:33  lr: 0.000035  loss: 1.3718 (1.4389)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [160/781]  eta: 0:03:29  lr: 0.000035  loss: 1.3354 (1.4530)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [170/781]  eta: 0:03:26  lr: 0.000035  loss: 1.3564 (1.4606)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [180/781]  eta: 0:03:22  lr: 0.000035  loss: 1.3599 (1.4567)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [190/781]  eta: 0:03:19  lr: 0.000035  loss: 1.3328 (1.4595)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [200/781]  eta: 0:03:15  lr: 0.000035  loss: 1.3153 (1.4566)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [210/781]  eta: 0:03:12  lr: 0.000035  loss: 1.3379 (1.4544)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [220/781]  eta: 0:03:08  lr: 0.000035  loss: 1.3981 (1.4576)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [230/781]  eta: 0:03:05  lr: 0.000035  loss: 1.3949 (1.4670)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [240/781]  eta: 0:03:01  lr: 0.000035  loss: 1.3640 (1.4682)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [250/781]  eta: 0:02:58  lr: 0.000035  loss: 1.4035 (1.4835)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [260/781]  eta: 0:02:55  lr: 0.000035  loss: 1.4106 (1.4846)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [270/781]  eta: 0:02:51  lr: 0.000035  loss: 1.3724 (1.4797)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [280/781]  eta: 0:02:48  lr: 0.000035  loss: 1.3762 (1.4916)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [290/781]  eta: 0:02:44  lr: 0.000035  loss: 1.4002 (1.4934)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [300/781]  eta: 0:02:41  lr: 0.000035  loss: 1.3851 (1.4941)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [310/781]  eta: 0:02:38  lr: 0.000035  loss: 1.4219 (1.4993)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [320/781]  eta: 0:02:34  lr: 0.000035  loss: 1.4444 (1.5005)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [330/781]  eta: 0:02:31  lr: 0.000035  loss: 1.3801 (1.5014)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [340/781]  eta: 0:02:27  lr: 0.000035  loss: 1.3801 (1.5055)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [350/781]  eta: 0:02:24  lr: 0.000035  loss: 1.3616 (1.5034)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [360/781]  eta: 0:02:21  lr: 0.000035  loss: 1.3589 (1.5045)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [370/781]  eta: 0:02:17  lr: 0.000035  loss: 1.4008 (1.5045)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [380/781]  eta: 0:02:14  lr: 0.000035  loss: 1.3850 (1.5087)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [390/781]  eta: 0:02:11  lr: 0.000035  loss: 1.3536 (1.5115)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [400/781]  eta: 0:02:07  lr: 0.000035  loss: 1.3541 (1.5078)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [410/781]  eta: 0:02:04  lr: 0.000035  loss: 1.3718 (1.5096)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [420/781]  eta: 0:02:00  lr: 0.000035  loss: 1.3736 (1.5065)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [430/781]  eta: 0:01:57  lr: 0.000035  loss: 1.3736 (1.5060)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [440/781]  eta: 0:01:54  lr: 0.000035  loss: 1.3838 (1.5026)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [450/781]  eta: 0:01:50  lr: 0.000035  loss: 1.3605 (1.4996)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [460/781]  eta: 0:01:47  lr: 0.000035  loss: 1.3460 (1.4981)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [470/781]  eta: 0:01:44  lr: 0.000035  loss: 1.3371 (1.4971)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [480/781]  eta: 0:01:40  lr: 0.000035  loss: 1.3360 (1.4993)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [490/781]  eta: 0:01:37  lr: 0.000035  loss: 1.3709 (1.4982)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [500/781]  eta: 0:01:34  lr: 0.000035  loss: 1.3753 (1.4994)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [510/781]  eta: 0:01:30  lr: 0.000035  loss: 1.3622 (1.4985)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [520/781]  eta: 0:01:27  lr: 0.000035  loss: 1.3566 (1.4972)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [530/781]  eta: 0:01:23  lr: 0.000035  loss: 1.3543 (1.4988)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [540/781]  eta: 0:01:20  lr: 0.000035  loss: 1.4029 (1.4985)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [550/781]  eta: 0:01:17  lr: 0.000035  loss: 1.4894 (1.5013)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [560/781]  eta: 0:01:13  lr: 0.000035  loss: 1.3912 (1.4986)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [570/781]  eta: 0:01:10  lr: 0.000035  loss: 1.3268 (1.4957)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [580/781]  eta: 0:01:07  lr: 0.000035  loss: 1.3251 (1.4949)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [590/781]  eta: 0:01:03  lr: 0.000035  loss: 1.3893 (1.4955)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [600/781]  eta: 0:01:00  lr: 0.000035  loss: 1.3812 (1.4958)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [610/781]  eta: 0:00:57  lr: 0.000035  loss: 1.3424 (1.4952)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [620/781]  eta: 0:00:53  lr: 0.000035  loss: 1.3871 (1.4952)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [630/781]  eta: 0:00:50  lr: 0.000035  loss: 1.4036 (1.4971)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [640/781]  eta: 0:00:47  lr: 0.000035  loss: 1.3768 (1.5001)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [650/781]  eta: 0:00:43  lr: 0.000035  loss: 1.4000 (1.4996)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [660/781]  eta: 0:00:40  lr: 0.000035  loss: 1.4000 (1.5036)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [670/781]  eta: 0:00:37  lr: 0.000035  loss: 1.4000 (1.5056)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [680/781]  eta: 0:00:33  lr: 0.000035  loss: 1.3968 (1.5063)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [690/781]  eta: 0:00:30  lr: 0.000035  loss: 1.3637 (1.5058)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [700/781]  eta: 0:00:27  lr: 0.000035  loss: 1.4024 (1.5069)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [710/781]  eta: 0:00:23  lr: 0.000035  loss: 1.3797 (1.5083)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [720/781]  eta: 0:00:20  lr: 0.000035  loss: 1.3097 (1.5062)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [730/781]  eta: 0:00:17  lr: 0.000035  loss: 1.3901 (1.5074)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [740/781]  eta: 0:00:13  lr: 0.000035  loss: 1.3901 (1.5061)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [750/781]  eta: 0:00:10  lr: 0.000035  loss: 1.3686 (1.5062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [760/781]  eta: 0:00:07  lr: 0.000035  loss: 1.3838 (1.5053)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [770/781]  eta: 0:00:03  lr: 0.000035  loss: 1.4032 (1.5065)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [52]  [780/781]  eta: 0:00:00  lr: 0.000035  loss: 1.4206 (1.5059)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [52] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000035  loss: 1.4206 (1.5059)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32851269841194153, 'lambda_convnext_base': 0.260545939207077, 'lambda_tf_efficientnetv2_l': 0.4109412133693695}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7126 (0.7126)  acc1: 85.4167 (85.4167)  acc5: 95.3125 (95.3125)  time: 0.8512  data: 0.8204  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8695 (0.9689)  acc1: 83.3333 (81.2500)  acc5: 94.7917 (93.6553)  time: 0.1677  data: 0.1370  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0835 (1.0636)  acc1: 79.1667 (79.5387)  acc5: 92.7083 (92.6835)  time: 0.1250  data: 0.0943  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1753 (1.1058)  acc1: 77.6042 (78.6458)  acc5: 91.6667 (92.2379)  time: 0.1311  data: 0.1004  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1965 (1.1547)  acc1: 74.4792 (77.7820)  acc5: 90.6250 (91.7048)  time: 0.1267  data: 0.0960  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1965 (1.1541)  acc1: 73.9583 (77.4510)  acc5: 91.6667 (91.9730)  time: 0.1234  data: 0.0927  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2072 (1.1676)  acc1: 73.9583 (77.3600)  acc5: 91.6667 (92.0100)  time: 0.1041  data: 0.0744  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1325 s / it)\n",
            "* Acc@1 77.360 Acc@5 92.010 loss 1.168\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [53]  [  0/781]  eta: 0:14:43  lr: 0.000035  loss: 1.3162 (1.3162)  time: 1.1310  data: 0.7830  max mem: 6459\n",
            "Epoch: [53]  [ 10/781]  eta: 0:05:13  lr: 0.000035  loss: 1.3902 (1.5244)  time: 0.4063  data: 0.0714  max mem: 6459\n",
            "Epoch: [53]  [ 20/781]  eta: 0:04:42  lr: 0.000035  loss: 1.3862 (1.4455)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 30/781]  eta: 0:04:29  lr: 0.000035  loss: 1.3830 (1.4503)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 40/781]  eta: 0:04:21  lr: 0.000035  loss: 1.4210 (1.5405)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 50/781]  eta: 0:04:15  lr: 0.000035  loss: 1.4210 (1.5281)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 60/781]  eta: 0:04:09  lr: 0.000035  loss: 1.3575 (1.5153)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 70/781]  eta: 0:04:05  lr: 0.000035  loss: 1.3481 (1.5039)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 80/781]  eta: 0:04:00  lr: 0.000035  loss: 1.3284 (1.4917)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [ 90/781]  eta: 0:03:56  lr: 0.000035  loss: 1.3406 (1.4981)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [100/781]  eta: 0:03:52  lr: 0.000035  loss: 1.3658 (1.4885)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [110/781]  eta: 0:03:48  lr: 0.000035  loss: 1.3429 (1.4818)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [120/781]  eta: 0:03:44  lr: 0.000035  loss: 1.3380 (1.4690)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [130/781]  eta: 0:03:41  lr: 0.000035  loss: 1.3429 (1.4700)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [140/781]  eta: 0:03:37  lr: 0.000035  loss: 1.3917 (1.4655)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [150/781]  eta: 0:03:33  lr: 0.000035  loss: 1.4140 (1.4767)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [160/781]  eta: 0:03:30  lr: 0.000035  loss: 1.4468 (1.4912)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [170/781]  eta: 0:03:26  lr: 0.000035  loss: 1.4423 (1.5089)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [180/781]  eta: 0:03:22  lr: 0.000035  loss: 1.4429 (1.5150)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [190/781]  eta: 0:03:19  lr: 0.000035  loss: 1.4412 (1.5153)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [200/781]  eta: 0:03:15  lr: 0.000035  loss: 1.4191 (1.5118)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [210/781]  eta: 0:03:12  lr: 0.000035  loss: 1.4163 (1.5133)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [220/781]  eta: 0:03:09  lr: 0.000035  loss: 1.4022 (1.5189)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [230/781]  eta: 0:03:05  lr: 0.000035  loss: 1.3823 (1.5120)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [240/781]  eta: 0:03:02  lr: 0.000035  loss: 1.4047 (1.5156)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [250/781]  eta: 0:02:58  lr: 0.000035  loss: 1.4413 (1.5195)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [260/781]  eta: 0:02:55  lr: 0.000035  loss: 1.4212 (1.5166)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [270/781]  eta: 0:02:51  lr: 0.000035  loss: 1.4065 (1.5244)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [280/781]  eta: 0:02:48  lr: 0.000035  loss: 1.4065 (1.5270)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [290/781]  eta: 0:02:45  lr: 0.000035  loss: 1.4393 (1.5323)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [300/781]  eta: 0:02:41  lr: 0.000035  loss: 1.4072 (1.5276)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [310/781]  eta: 0:02:38  lr: 0.000035  loss: 1.4072 (1.5279)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [320/781]  eta: 0:02:34  lr: 0.000035  loss: 1.4305 (1.5226)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [330/781]  eta: 0:02:31  lr: 0.000035  loss: 1.3651 (1.5191)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [340/781]  eta: 0:02:28  lr: 0.000035  loss: 1.3708 (1.5161)  time: 0.3432  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [350/781]  eta: 0:02:24  lr: 0.000035  loss: 1.3970 (1.5151)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [360/781]  eta: 0:02:21  lr: 0.000035  loss: 1.4050 (1.5218)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [370/781]  eta: 0:02:18  lr: 0.000035  loss: 1.4316 (1.5261)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [380/781]  eta: 0:02:14  lr: 0.000035  loss: 1.3678 (1.5247)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [390/781]  eta: 0:02:11  lr: 0.000035  loss: 1.3678 (1.5221)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [400/781]  eta: 0:02:07  lr: 0.000035  loss: 1.3838 (1.5215)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [410/781]  eta: 0:02:04  lr: 0.000035  loss: 1.3838 (1.5188)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [420/781]  eta: 0:02:01  lr: 0.000035  loss: 1.3403 (1.5168)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [430/781]  eta: 0:01:57  lr: 0.000035  loss: 1.3769 (1.5155)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [440/781]  eta: 0:01:54  lr: 0.000035  loss: 1.3848 (1.5179)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [450/781]  eta: 0:01:51  lr: 0.000035  loss: 1.3691 (1.5185)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [460/781]  eta: 0:01:47  lr: 0.000035  loss: 1.3361 (1.5157)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [470/781]  eta: 0:01:44  lr: 0.000035  loss: 1.3128 (1.5114)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [480/781]  eta: 0:01:40  lr: 0.000035  loss: 1.3555 (1.5137)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [490/781]  eta: 0:01:37  lr: 0.000035  loss: 1.3769 (1.5105)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [500/781]  eta: 0:01:34  lr: 0.000035  loss: 1.3650 (1.5101)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [510/781]  eta: 0:01:30  lr: 0.000035  loss: 1.3750 (1.5140)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [520/781]  eta: 0:01:27  lr: 0.000035  loss: 1.3556 (1.5148)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [530/781]  eta: 0:01:24  lr: 0.000035  loss: 1.3544 (1.5155)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [540/781]  eta: 0:01:20  lr: 0.000035  loss: 1.4002 (1.5192)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [550/781]  eta: 0:01:17  lr: 0.000035  loss: 1.4225 (1.5189)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [560/781]  eta: 0:01:14  lr: 0.000035  loss: 1.3823 (1.5171)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [570/781]  eta: 0:01:10  lr: 0.000035  loss: 1.3917 (1.5152)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [580/781]  eta: 0:01:07  lr: 0.000035  loss: 1.3944 (1.5178)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [590/781]  eta: 0:01:03  lr: 0.000035  loss: 1.3926 (1.5183)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [600/781]  eta: 0:01:00  lr: 0.000035  loss: 1.3684 (1.5177)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [610/781]  eta: 0:00:57  lr: 0.000035  loss: 1.3438 (1.5146)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [620/781]  eta: 0:00:53  lr: 0.000035  loss: 1.3428 (1.5153)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [630/781]  eta: 0:00:50  lr: 0.000035  loss: 1.3742 (1.5141)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [640/781]  eta: 0:00:47  lr: 0.000035  loss: 1.3566 (1.5133)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [650/781]  eta: 0:00:43  lr: 0.000035  loss: 1.3642 (1.5157)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [660/781]  eta: 0:00:40  lr: 0.000035  loss: 1.4125 (1.5161)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [670/781]  eta: 0:00:37  lr: 0.000035  loss: 1.3520 (1.5169)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [680/781]  eta: 0:00:33  lr: 0.000035  loss: 1.3520 (1.5160)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [690/781]  eta: 0:00:30  lr: 0.000035  loss: 1.3623 (1.5145)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [700/781]  eta: 0:00:27  lr: 0.000035  loss: 1.3658 (1.5151)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [710/781]  eta: 0:00:23  lr: 0.000035  loss: 1.3394 (1.5127)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [720/781]  eta: 0:00:20  lr: 0.000035  loss: 1.3377 (1.5108)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [730/781]  eta: 0:00:17  lr: 0.000035  loss: 1.3716 (1.5089)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [740/781]  eta: 0:00:13  lr: 0.000035  loss: 1.3469 (1.5071)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [750/781]  eta: 0:00:10  lr: 0.000035  loss: 1.3667 (1.5085)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [760/781]  eta: 0:00:07  lr: 0.000035  loss: 1.3657 (1.5090)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [770/781]  eta: 0:00:03  lr: 0.000035  loss: 1.3657 (1.5110)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [53]  [780/781]  eta: 0:00:00  lr: 0.000035  loss: 1.3316 (1.5083)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [53] Total time: 0:04:21 (0.3348 s / it)\n",
            "Averaged stats: lr: 0.000035  loss: 1.3316 (1.5083)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3286922574043274, 'lambda_convnext_base': 0.2602235972881317, 'lambda_tf_efficientnetv2_l': 0.4110840857028961}\n",
            "Test:  [ 0/53]  eta: 0:00:48  loss: 0.7588 (0.7588)  acc1: 82.2917 (82.2917)  acc5: 95.8333 (95.8333)  time: 0.9135  data: 0.8826  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8595 (0.9520)  acc1: 82.2917 (81.0606)  acc5: 94.7917 (93.6080)  time: 0.1755  data: 0.1448  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0026 (1.0224)  acc1: 80.2083 (79.8859)  acc5: 92.7083 (92.7083)  time: 0.1183  data: 0.0876  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1088 (1.0700)  acc1: 76.5625 (78.8979)  acc5: 92.1875 (92.3051)  time: 0.1223  data: 0.0917  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1611 (1.1266)  acc1: 75.5208 (78.0488)  acc5: 91.1458 (91.7429)  time: 0.1236  data: 0.0930  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0994 (1.1257)  acc1: 78.6458 (77.8799)  acc5: 91.1458 (91.8505)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1027 (1.1412)  acc1: 75.5208 (77.6600)  acc5: 91.1458 (91.8800)  time: 0.1057  data: 0.0760  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1307 s / it)\n",
            "* Acc@1 77.660 Acc@5 91.880 loss 1.141\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [54]  [  0/781]  eta: 0:14:47  lr: 0.000034  loss: 2.2915 (2.2915)  time: 1.1367  data: 0.7854  max mem: 6459\n",
            "Epoch: [54]  [ 10/781]  eta: 0:05:13  lr: 0.000034  loss: 1.3611 (1.6328)  time: 0.4062  data: 0.0717  max mem: 6459\n",
            "Epoch: [54]  [ 20/781]  eta: 0:04:42  lr: 0.000034  loss: 1.3320 (1.4894)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 30/781]  eta: 0:04:29  lr: 0.000034  loss: 1.3404 (1.4634)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 40/781]  eta: 0:04:21  lr: 0.000034  loss: 1.3927 (1.5176)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 50/781]  eta: 0:04:15  lr: 0.000034  loss: 1.3690 (1.4777)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 60/781]  eta: 0:04:09  lr: 0.000034  loss: 1.3141 (1.4830)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 70/781]  eta: 0:04:04  lr: 0.000034  loss: 1.3735 (1.4810)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 80/781]  eta: 0:04:00  lr: 0.000034  loss: 1.3403 (1.4644)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [ 90/781]  eta: 0:03:56  lr: 0.000034  loss: 1.3572 (1.4760)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [100/781]  eta: 0:03:52  lr: 0.000034  loss: 1.3549 (1.4668)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [110/781]  eta: 0:03:48  lr: 0.000034  loss: 1.3542 (1.4744)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [120/781]  eta: 0:03:44  lr: 0.000034  loss: 1.3542 (1.4736)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [130/781]  eta: 0:03:40  lr: 0.000034  loss: 1.3520 (1.4647)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [140/781]  eta: 0:03:37  lr: 0.000034  loss: 1.3425 (1.4596)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [150/781]  eta: 0:03:33  lr: 0.000034  loss: 1.3535 (1.4617)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [160/781]  eta: 0:03:30  lr: 0.000034  loss: 1.3600 (1.4550)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [170/781]  eta: 0:03:26  lr: 0.000034  loss: 1.3635 (1.4548)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [180/781]  eta: 0:03:22  lr: 0.000034  loss: 1.3372 (1.4479)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [190/781]  eta: 0:03:19  lr: 0.000034  loss: 1.3080 (1.4416)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [200/781]  eta: 0:03:15  lr: 0.000034  loss: 1.3683 (1.4585)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [210/781]  eta: 0:03:12  lr: 0.000034  loss: 1.4534 (1.4592)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [220/781]  eta: 0:03:08  lr: 0.000034  loss: 1.3585 (1.4599)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [230/781]  eta: 0:03:05  lr: 0.000034  loss: 1.3653 (1.4594)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [240/781]  eta: 0:03:02  lr: 0.000034  loss: 1.3448 (1.4574)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [250/781]  eta: 0:02:58  lr: 0.000034  loss: 1.3448 (1.4605)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [260/781]  eta: 0:02:55  lr: 0.000034  loss: 1.3760 (1.4612)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [270/781]  eta: 0:02:51  lr: 0.000034  loss: 1.3731 (1.4627)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [280/781]  eta: 0:02:48  lr: 0.000034  loss: 1.3864 (1.4657)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [290/781]  eta: 0:02:44  lr: 0.000034  loss: 1.3974 (1.4686)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [300/781]  eta: 0:02:41  lr: 0.000034  loss: 1.3882 (1.4750)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [310/781]  eta: 0:02:38  lr: 0.000034  loss: 1.3744 (1.4751)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [320/781]  eta: 0:02:34  lr: 0.000034  loss: 1.3738 (1.4763)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [330/781]  eta: 0:02:31  lr: 0.000034  loss: 1.4088 (1.4762)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [340/781]  eta: 0:02:27  lr: 0.000034  loss: 1.4052 (1.4738)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [350/781]  eta: 0:02:24  lr: 0.000034  loss: 1.3594 (1.4770)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [360/781]  eta: 0:02:21  lr: 0.000034  loss: 1.3483 (1.4741)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [370/781]  eta: 0:02:17  lr: 0.000034  loss: 1.3483 (1.4788)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [380/781]  eta: 0:02:14  lr: 0.000034  loss: 1.3631 (1.4805)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [390/781]  eta: 0:02:11  lr: 0.000034  loss: 1.3606 (1.4859)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [400/781]  eta: 0:02:07  lr: 0.000034  loss: 1.4348 (1.4890)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [410/781]  eta: 0:02:04  lr: 0.000034  loss: 1.3864 (1.4888)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [420/781]  eta: 0:02:00  lr: 0.000034  loss: 1.3622 (1.4872)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [430/781]  eta: 0:01:57  lr: 0.000034  loss: 1.3622 (1.4874)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [440/781]  eta: 0:01:54  lr: 0.000034  loss: 1.4278 (1.4902)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [450/781]  eta: 0:01:50  lr: 0.000034  loss: 1.4142 (1.4899)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [460/781]  eta: 0:01:47  lr: 0.000034  loss: 1.4009 (1.4920)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [470/781]  eta: 0:01:44  lr: 0.000034  loss: 1.3826 (1.4929)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [480/781]  eta: 0:01:40  lr: 0.000034  loss: 1.3826 (1.4942)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [490/781]  eta: 0:01:37  lr: 0.000034  loss: 1.3488 (1.4909)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [500/781]  eta: 0:01:34  lr: 0.000034  loss: 1.3780 (1.4939)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [510/781]  eta: 0:01:30  lr: 0.000034  loss: 1.4025 (1.4945)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [520/781]  eta: 0:01:27  lr: 0.000034  loss: 1.3886 (1.4923)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [530/781]  eta: 0:01:24  lr: 0.000034  loss: 1.4113 (1.4975)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [540/781]  eta: 0:01:20  lr: 0.000034  loss: 1.4267 (1.4975)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [550/781]  eta: 0:01:17  lr: 0.000034  loss: 1.4136 (1.4988)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [560/781]  eta: 0:01:13  lr: 0.000034  loss: 1.3895 (1.4991)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [570/781]  eta: 0:01:10  lr: 0.000034  loss: 1.3612 (1.4991)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [580/781]  eta: 0:01:07  lr: 0.000034  loss: 1.3820 (1.4990)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [590/781]  eta: 0:01:03  lr: 0.000034  loss: 1.4041 (1.5001)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [600/781]  eta: 0:01:00  lr: 0.000034  loss: 1.3847 (1.4998)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [610/781]  eta: 0:00:57  lr: 0.000034  loss: 1.3838 (1.5016)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [620/781]  eta: 0:00:53  lr: 0.000034  loss: 1.3737 (1.4994)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [630/781]  eta: 0:00:50  lr: 0.000034  loss: 1.3392 (1.4984)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [640/781]  eta: 0:00:47  lr: 0.000034  loss: 1.3354 (1.4976)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [650/781]  eta: 0:00:43  lr: 0.000034  loss: 1.3354 (1.4969)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [660/781]  eta: 0:00:40  lr: 0.000034  loss: 1.3312 (1.4949)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [670/781]  eta: 0:00:37  lr: 0.000034  loss: 1.3314 (1.4957)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [680/781]  eta: 0:00:33  lr: 0.000034  loss: 1.3831 (1.4959)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [690/781]  eta: 0:00:30  lr: 0.000034  loss: 1.3751 (1.4955)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [700/781]  eta: 0:00:27  lr: 0.000034  loss: 1.3777 (1.4958)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [710/781]  eta: 0:00:23  lr: 0.000034  loss: 1.3548 (1.4966)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [720/781]  eta: 0:00:20  lr: 0.000034  loss: 1.3416 (1.4975)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [730/781]  eta: 0:00:17  lr: 0.000034  loss: 1.3667 (1.4976)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [740/781]  eta: 0:00:13  lr: 0.000034  loss: 1.3667 (1.4990)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [750/781]  eta: 0:00:10  lr: 0.000034  loss: 1.3307 (1.4967)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [760/781]  eta: 0:00:07  lr: 0.000034  loss: 1.3261 (1.4949)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [770/781]  eta: 0:00:03  lr: 0.000034  loss: 1.3527 (1.4949)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [54]  [780/781]  eta: 0:00:00  lr: 0.000034  loss: 1.3885 (1.4973)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [54] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000034  loss: 1.3885 (1.4973)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3284681439399719, 'lambda_convnext_base': 0.2598760426044464, 'lambda_tf_efficientnetv2_l': 0.4116557538509369}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8483 (0.8483)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8473  data: 0.8165  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8911 (0.9793)  acc1: 83.3333 (81.2027)  acc5: 95.3125 (93.7027)  time: 0.1717  data: 0.1410  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0289 (1.0463)  acc1: 78.6458 (79.8115)  acc5: 93.2292 (92.7083)  time: 0.1226  data: 0.0920  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2153 (1.1092)  acc1: 75.5208 (78.6962)  acc5: 90.6250 (92.0699)  time: 0.1231  data: 0.0925  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2684 (1.1511)  acc1: 74.4792 (77.9599)  acc5: 90.1042 (91.5904)  time: 0.1222  data: 0.0915  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1056 (1.1480)  acc1: 77.6042 (77.6961)  acc5: 91.6667 (91.8403)  time: 0.1205  data: 0.0899  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1249 (1.1572)  acc1: 75.5208 (77.5000)  acc5: 91.6667 (91.8800)  time: 0.1012  data: 0.0715  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1294 s / it)\n",
            "* Acc@1 77.500 Acc@5 91.880 loss 1.157\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [55]  [  0/781]  eta: 0:14:28  lr: 0.000033  loss: 1.2804 (1.2804)  time: 1.1117  data: 0.7624  max mem: 6459\n",
            "Epoch: [55]  [ 10/781]  eta: 0:05:11  lr: 0.000033  loss: 1.3781 (1.5831)  time: 0.4043  data: 0.0696  max mem: 6459\n",
            "Epoch: [55]  [ 20/781]  eta: 0:04:41  lr: 0.000033  loss: 1.3781 (1.6131)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 30/781]  eta: 0:04:29  lr: 0.000033  loss: 1.3766 (1.5519)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 40/781]  eta: 0:04:21  lr: 0.000033  loss: 1.3638 (1.5154)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 50/781]  eta: 0:04:14  lr: 0.000033  loss: 1.3458 (1.4963)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 60/781]  eta: 0:04:09  lr: 0.000033  loss: 1.3458 (1.4903)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 70/781]  eta: 0:04:04  lr: 0.000033  loss: 1.3251 (1.4824)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 80/781]  eta: 0:04:00  lr: 0.000033  loss: 1.3251 (1.4652)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [ 90/781]  eta: 0:03:56  lr: 0.000033  loss: 1.3204 (1.4638)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [100/781]  eta: 0:03:52  lr: 0.000033  loss: 1.3539 (1.4582)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [110/781]  eta: 0:03:48  lr: 0.000033  loss: 1.4075 (1.4714)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [120/781]  eta: 0:03:44  lr: 0.000033  loss: 1.3706 (1.4768)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [130/781]  eta: 0:03:40  lr: 0.000033  loss: 1.3510 (1.4703)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [140/781]  eta: 0:03:37  lr: 0.000033  loss: 1.3413 (1.4688)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [150/781]  eta: 0:03:33  lr: 0.000033  loss: 1.3231 (1.4632)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [160/781]  eta: 0:03:30  lr: 0.000033  loss: 1.2777 (1.4514)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [170/781]  eta: 0:03:26  lr: 0.000033  loss: 1.3001 (1.4529)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [180/781]  eta: 0:03:23  lr: 0.000033  loss: 1.3734 (1.4559)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [190/781]  eta: 0:03:19  lr: 0.000033  loss: 1.3937 (1.4581)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [200/781]  eta: 0:03:15  lr: 0.000033  loss: 1.3603 (1.4634)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [210/781]  eta: 0:03:12  lr: 0.000033  loss: 1.4051 (1.4736)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [220/781]  eta: 0:03:09  lr: 0.000033  loss: 1.3815 (1.4727)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [230/781]  eta: 0:03:05  lr: 0.000033  loss: 1.3695 (1.4789)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [240/781]  eta: 0:03:02  lr: 0.000033  loss: 1.3971 (1.4752)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [250/781]  eta: 0:02:58  lr: 0.000033  loss: 1.3691 (1.4747)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [260/781]  eta: 0:02:55  lr: 0.000033  loss: 1.3688 (1.4725)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [270/781]  eta: 0:02:51  lr: 0.000033  loss: 1.3544 (1.4726)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [280/781]  eta: 0:02:48  lr: 0.000033  loss: 1.3312 (1.4685)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [290/781]  eta: 0:02:44  lr: 0.000033  loss: 1.3594 (1.4701)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [300/781]  eta: 0:02:41  lr: 0.000033  loss: 1.3767 (1.4666)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [310/781]  eta: 0:02:38  lr: 0.000033  loss: 1.3171 (1.4614)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [320/781]  eta: 0:02:34  lr: 0.000033  loss: 1.2877 (1.4616)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [330/781]  eta: 0:02:31  lr: 0.000033  loss: 1.3520 (1.4625)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [340/781]  eta: 0:02:27  lr: 0.000033  loss: 1.4082 (1.4748)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [350/781]  eta: 0:02:24  lr: 0.000033  loss: 1.3859 (1.4708)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [360/781]  eta: 0:02:21  lr: 0.000033  loss: 1.3464 (1.4691)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [370/781]  eta: 0:02:17  lr: 0.000033  loss: 1.3907 (1.4686)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [380/781]  eta: 0:02:14  lr: 0.000033  loss: 1.3853 (1.4688)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [390/781]  eta: 0:02:11  lr: 0.000033  loss: 1.3706 (1.4686)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [400/781]  eta: 0:02:07  lr: 0.000033  loss: 1.3489 (1.4678)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [410/781]  eta: 0:02:04  lr: 0.000033  loss: 1.3299 (1.4641)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [420/781]  eta: 0:02:00  lr: 0.000033  loss: 1.3224 (1.4625)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [430/781]  eta: 0:01:57  lr: 0.000033  loss: 1.3788 (1.4632)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [440/781]  eta: 0:01:54  lr: 0.000033  loss: 1.3788 (1.4644)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [450/781]  eta: 0:01:50  lr: 0.000033  loss: 1.3282 (1.4619)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [460/781]  eta: 0:01:47  lr: 0.000033  loss: 1.3308 (1.4591)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [470/781]  eta: 0:01:44  lr: 0.000033  loss: 1.3498 (1.4601)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [480/781]  eta: 0:01:40  lr: 0.000033  loss: 1.3491 (1.4583)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [490/781]  eta: 0:01:37  lr: 0.000033  loss: 1.4010 (1.4608)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [500/781]  eta: 0:01:34  lr: 0.000033  loss: 1.4010 (1.4612)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [510/781]  eta: 0:01:30  lr: 0.000033  loss: 1.3835 (1.4611)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [520/781]  eta: 0:01:27  lr: 0.000033  loss: 1.2946 (1.4604)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [530/781]  eta: 0:01:24  lr: 0.000033  loss: 1.3690 (1.4596)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [540/781]  eta: 0:01:20  lr: 0.000033  loss: 1.4118 (1.4647)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [550/781]  eta: 0:01:17  lr: 0.000033  loss: 1.3980 (1.4638)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [560/781]  eta: 0:01:13  lr: 0.000033  loss: 1.3527 (1.4646)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [570/781]  eta: 0:01:10  lr: 0.000033  loss: 1.3564 (1.4624)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [580/781]  eta: 0:01:07  lr: 0.000033  loss: 1.3340 (1.4620)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [590/781]  eta: 0:01:03  lr: 0.000033  loss: 1.3317 (1.4632)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [600/781]  eta: 0:01:00  lr: 0.000033  loss: 1.3229 (1.4618)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [610/781]  eta: 0:00:57  lr: 0.000033  loss: 1.3289 (1.4634)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [620/781]  eta: 0:00:53  lr: 0.000033  loss: 1.4323 (1.4659)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [630/781]  eta: 0:00:50  lr: 0.000033  loss: 1.3626 (1.4667)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [640/781]  eta: 0:00:47  lr: 0.000033  loss: 1.3374 (1.4654)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [650/781]  eta: 0:00:43  lr: 0.000033  loss: 1.3556 (1.4632)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [660/781]  eta: 0:00:40  lr: 0.000033  loss: 1.3317 (1.4626)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [670/781]  eta: 0:00:37  lr: 0.000033  loss: 1.3647 (1.4627)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [680/781]  eta: 0:00:33  lr: 0.000033  loss: 1.3580 (1.4615)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [690/781]  eta: 0:00:30  lr: 0.000033  loss: 1.3518 (1.4640)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [700/781]  eta: 0:00:27  lr: 0.000033  loss: 1.3257 (1.4624)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [710/781]  eta: 0:00:23  lr: 0.000033  loss: 1.2875 (1.4633)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [720/781]  eta: 0:00:20  lr: 0.000033  loss: 1.3290 (1.4639)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [730/781]  eta: 0:00:17  lr: 0.000033  loss: 1.3537 (1.4647)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [740/781]  eta: 0:00:13  lr: 0.000033  loss: 1.3552 (1.4658)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [750/781]  eta: 0:00:10  lr: 0.000033  loss: 1.3847 (1.4658)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [760/781]  eta: 0:00:07  lr: 0.000033  loss: 1.3940 (1.4650)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [770/781]  eta: 0:00:03  lr: 0.000033  loss: 1.2940 (1.4648)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [55]  [780/781]  eta: 0:00:00  lr: 0.000033  loss: 1.3412 (1.4648)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [55] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000033  loss: 1.3412 (1.4648)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32966870069503784, 'lambda_convnext_base': 0.25955137610435486, 'lambda_tf_efficientnetv2_l': 0.41078001260757446}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7794 (0.7794)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8226  data: 0.7917  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8665 (0.9636)  acc1: 82.8125 (81.3920)  acc5: 94.7917 (93.8920)  time: 0.1766  data: 0.1459  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9845 (1.0345)  acc1: 79.6875 (79.9603)  acc5: 93.2292 (92.8323)  time: 0.1321  data: 0.1014  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2136 (1.0993)  acc1: 76.0417 (78.8306)  acc5: 90.6250 (92.0195)  time: 0.1319  data: 0.1012  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2620 (1.1475)  acc1: 75.5208 (77.7058)  acc5: 89.5833 (91.6286)  time: 0.1333  data: 0.1026  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1388 (1.1411)  acc1: 75.0000 (77.4510)  acc5: 92.1875 (91.9935)  time: 0.1351  data: 0.1044  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1647 (1.1526)  acc1: 73.9583 (77.3100)  acc5: 92.7083 (92.0300)  time: 0.1135  data: 0.0838  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1391 s / it)\n",
            "* Acc@1 77.310 Acc@5 92.030 loss 1.153\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [56]  [  0/781]  eta: 0:14:44  lr: 0.000032  loss: 2.5194 (2.5194)  time: 1.1322  data: 0.7835  max mem: 6459\n",
            "Epoch: [56]  [ 10/781]  eta: 0:05:13  lr: 0.000032  loss: 1.3487 (1.4791)  time: 0.4061  data: 0.0715  max mem: 6459\n",
            "Epoch: [56]  [ 20/781]  eta: 0:04:42  lr: 0.000032  loss: 1.3274 (1.4123)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 30/781]  eta: 0:04:29  lr: 0.000032  loss: 1.3393 (1.4215)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 40/781]  eta: 0:04:21  lr: 0.000032  loss: 1.3378 (1.4010)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 50/781]  eta: 0:04:15  lr: 0.000032  loss: 1.3172 (1.4074)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 60/781]  eta: 0:04:09  lr: 0.000032  loss: 1.3476 (1.4239)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 70/781]  eta: 0:04:04  lr: 0.000032  loss: 1.3793 (1.4471)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 80/781]  eta: 0:04:02  lr: 0.000032  loss: 1.4291 (1.4690)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [ 90/781]  eta: 0:03:57  lr: 0.000032  loss: 1.4291 (1.4664)  time: 0.3435  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [100/781]  eta: 0:03:53  lr: 0.000032  loss: 1.3839 (1.4688)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [110/781]  eta: 0:03:49  lr: 0.000032  loss: 1.3930 (1.4744)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [120/781]  eta: 0:03:45  lr: 0.000032  loss: 1.3788 (1.4655)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [130/781]  eta: 0:03:41  lr: 0.000032  loss: 1.3567 (1.4610)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [140/781]  eta: 0:03:38  lr: 0.000032  loss: 1.3253 (1.4581)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [150/781]  eta: 0:03:34  lr: 0.000032  loss: 1.3174 (1.4616)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [160/781]  eta: 0:03:30  lr: 0.000032  loss: 1.3240 (1.4577)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [170/781]  eta: 0:03:27  lr: 0.000032  loss: 1.3477 (1.4520)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [180/781]  eta: 0:03:23  lr: 0.000032  loss: 1.2797 (1.4435)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [190/781]  eta: 0:03:20  lr: 0.000032  loss: 1.2998 (1.4413)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [200/781]  eta: 0:03:16  lr: 0.000032  loss: 1.3224 (1.4383)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [210/781]  eta: 0:03:13  lr: 0.000032  loss: 1.3645 (1.4441)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [220/781]  eta: 0:03:09  lr: 0.000032  loss: 1.3759 (1.4415)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [230/781]  eta: 0:03:06  lr: 0.000032  loss: 1.3465 (1.4387)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [240/781]  eta: 0:03:02  lr: 0.000032  loss: 1.3077 (1.4335)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [250/781]  eta: 0:02:59  lr: 0.000032  loss: 1.3077 (1.4336)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [260/781]  eta: 0:02:55  lr: 0.000032  loss: 1.3694 (1.4359)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [270/781]  eta: 0:02:52  lr: 0.000032  loss: 1.3494 (1.4349)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [280/781]  eta: 0:02:48  lr: 0.000032  loss: 1.3045 (1.4342)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [290/781]  eta: 0:02:45  lr: 0.000032  loss: 1.3764 (1.4387)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [300/781]  eta: 0:02:41  lr: 0.000032  loss: 1.4098 (1.4392)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [310/781]  eta: 0:02:38  lr: 0.000032  loss: 1.3630 (1.4468)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [320/781]  eta: 0:02:35  lr: 0.000032  loss: 1.3770 (1.4474)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [330/781]  eta: 0:02:31  lr: 0.000032  loss: 1.3770 (1.4531)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [340/781]  eta: 0:02:28  lr: 0.000032  loss: 1.3480 (1.4497)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [350/781]  eta: 0:02:24  lr: 0.000032  loss: 1.3415 (1.4512)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [360/781]  eta: 0:02:21  lr: 0.000032  loss: 1.3446 (1.4540)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [370/781]  eta: 0:02:18  lr: 0.000032  loss: 1.3096 (1.4535)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [380/781]  eta: 0:02:14  lr: 0.000032  loss: 1.3255 (1.4529)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [390/781]  eta: 0:02:11  lr: 0.000032  loss: 1.3651 (1.4524)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [400/781]  eta: 0:02:07  lr: 0.000032  loss: 1.3875 (1.4546)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [410/781]  eta: 0:02:04  lr: 0.000032  loss: 1.4173 (1.4574)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [420/781]  eta: 0:02:01  lr: 0.000032  loss: 1.3931 (1.4550)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [430/781]  eta: 0:01:57  lr: 0.000032  loss: 1.3858 (1.4548)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [440/781]  eta: 0:01:54  lr: 0.000032  loss: 1.3683 (1.4535)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [450/781]  eta: 0:01:51  lr: 0.000032  loss: 1.3553 (1.4522)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [460/781]  eta: 0:01:47  lr: 0.000032  loss: 1.3553 (1.4517)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [470/781]  eta: 0:01:44  lr: 0.000032  loss: 1.3587 (1.4545)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [480/781]  eta: 0:01:40  lr: 0.000032  loss: 1.3427 (1.4533)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [490/781]  eta: 0:01:37  lr: 0.000032  loss: 1.3527 (1.4559)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [500/781]  eta: 0:01:34  lr: 0.000032  loss: 1.3413 (1.4544)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [510/781]  eta: 0:01:30  lr: 0.000032  loss: 1.3413 (1.4562)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [520/781]  eta: 0:01:27  lr: 0.000032  loss: 1.3550 (1.4586)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [530/781]  eta: 0:01:24  lr: 0.000032  loss: 1.3104 (1.4579)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [540/781]  eta: 0:01:20  lr: 0.000032  loss: 1.3104 (1.4570)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [550/781]  eta: 0:01:17  lr: 0.000032  loss: 1.3286 (1.4548)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [560/781]  eta: 0:01:14  lr: 0.000032  loss: 1.3627 (1.4595)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [570/781]  eta: 0:01:10  lr: 0.000032  loss: 1.3932 (1.4610)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [580/781]  eta: 0:01:07  lr: 0.000032  loss: 1.3739 (1.4625)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [590/781]  eta: 0:01:04  lr: 0.000032  loss: 1.3497 (1.4632)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [600/781]  eta: 0:01:00  lr: 0.000032  loss: 1.3485 (1.4659)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [610/781]  eta: 0:00:57  lr: 0.000032  loss: 1.4022 (1.4674)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [620/781]  eta: 0:00:53  lr: 0.000032  loss: 1.3939 (1.4665)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [630/781]  eta: 0:00:50  lr: 0.000032  loss: 1.3698 (1.4683)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [640/781]  eta: 0:00:47  lr: 0.000032  loss: 1.3723 (1.4687)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [650/781]  eta: 0:00:43  lr: 0.000032  loss: 1.3676 (1.4692)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [660/781]  eta: 0:00:40  lr: 0.000032  loss: 1.3670 (1.4681)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [670/781]  eta: 0:00:37  lr: 0.000032  loss: 1.3651 (1.4681)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [680/781]  eta: 0:00:33  lr: 0.000032  loss: 1.3655 (1.4704)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [690/781]  eta: 0:00:30  lr: 0.000032  loss: 1.3942 (1.4717)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [700/781]  eta: 0:00:27  lr: 0.000032  loss: 1.3553 (1.4746)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [710/781]  eta: 0:00:23  lr: 0.000032  loss: 1.3488 (1.4746)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [720/781]  eta: 0:00:20  lr: 0.000032  loss: 1.3570 (1.4764)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [730/781]  eta: 0:00:17  lr: 0.000032  loss: 1.3657 (1.4782)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [740/781]  eta: 0:00:13  lr: 0.000032  loss: 1.3657 (1.4790)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [750/781]  eta: 0:00:10  lr: 0.000032  loss: 1.3587 (1.4775)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [760/781]  eta: 0:00:07  lr: 0.000032  loss: 1.3979 (1.4815)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [770/781]  eta: 0:00:03  lr: 0.000032  loss: 1.4377 (1.4816)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [56]  [780/781]  eta: 0:00:00  lr: 0.000032  loss: 1.4011 (1.4834)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [56] Total time: 0:04:21 (0.3348 s / it)\n",
            "Averaged stats: lr: 0.000032  loss: 1.4011 (1.4834)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3284308910369873, 'lambda_convnext_base': 0.2596530616283417, 'lambda_tf_efficientnetv2_l': 0.4119161367416382}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7274 (0.7274)  acc1: 86.4583 (86.4583)  acc5: 96.3542 (96.3542)  time: 0.8260  data: 0.7951  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9128 (0.9670)  acc1: 84.3750 (81.2974)  acc5: 94.2708 (94.0814)  time: 0.1778  data: 0.1471  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0142 (1.0465)  acc1: 80.7292 (79.5387)  acc5: 93.7500 (92.9564)  time: 0.1318  data: 0.1011  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1683 (1.0998)  acc1: 77.0833 (78.6626)  acc5: 90.6250 (92.2043)  time: 0.1305  data: 0.0998  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2534 (1.1406)  acc1: 77.0833 (77.8455)  acc5: 89.5833 (91.7302)  time: 0.1350  data: 0.1043  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1413 (1.1453)  acc1: 77.0833 (77.3489)  acc5: 91.6667 (91.9322)  time: 0.1339  data: 0.1032  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2004 (1.1577)  acc1: 75.0000 (77.1900)  acc5: 92.1875 (91.9600)  time: 0.1125  data: 0.0828  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1384 s / it)\n",
            "* Acc@1 77.190 Acc@5 91.960 loss 1.158\n",
            "Accuracy of the network on the 10000 test images: 77.2%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [57]  [  0/781]  eta: 0:14:30  lr: 0.000031  loss: 1.3142 (1.3142)  time: 1.1147  data: 0.7702  max mem: 6459\n",
            "Epoch: [57]  [ 10/781]  eta: 0:05:11  lr: 0.000031  loss: 1.3250 (1.3737)  time: 0.4044  data: 0.0703  max mem: 6459\n",
            "Epoch: [57]  [ 20/781]  eta: 0:04:41  lr: 0.000031  loss: 1.3464 (1.5002)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 30/781]  eta: 0:04:29  lr: 0.000031  loss: 1.3442 (1.4657)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 40/781]  eta: 0:04:21  lr: 0.000031  loss: 1.3442 (1.4812)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 50/781]  eta: 0:04:14  lr: 0.000031  loss: 1.3522 (1.4518)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 60/781]  eta: 0:04:09  lr: 0.000031  loss: 1.3758 (1.4919)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 70/781]  eta: 0:04:04  lr: 0.000031  loss: 1.3758 (1.4872)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 80/781]  eta: 0:04:00  lr: 0.000031  loss: 1.3164 (1.4654)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [ 90/781]  eta: 0:03:56  lr: 0.000031  loss: 1.3164 (1.4748)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [100/781]  eta: 0:03:52  lr: 0.000031  loss: 1.3272 (1.4698)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [110/781]  eta: 0:03:48  lr: 0.000031  loss: 1.3284 (1.4665)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [120/781]  eta: 0:03:44  lr: 0.000031  loss: 1.3654 (1.4620)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [130/781]  eta: 0:03:40  lr: 0.000031  loss: 1.3395 (1.4605)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [140/781]  eta: 0:03:37  lr: 0.000031  loss: 1.3467 (1.4607)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [150/781]  eta: 0:03:33  lr: 0.000031  loss: 1.3891 (1.4708)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [160/781]  eta: 0:03:30  lr: 0.000031  loss: 1.3425 (1.4694)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [170/781]  eta: 0:03:26  lr: 0.000031  loss: 1.3275 (1.4607)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [180/781]  eta: 0:03:22  lr: 0.000031  loss: 1.3106 (1.4723)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [190/781]  eta: 0:03:19  lr: 0.000031  loss: 1.3181 (1.4715)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [200/781]  eta: 0:03:15  lr: 0.000031  loss: 1.3497 (1.4741)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [210/781]  eta: 0:03:12  lr: 0.000031  loss: 1.4205 (1.4825)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [220/781]  eta: 0:03:08  lr: 0.000031  loss: 1.4067 (1.4815)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [230/781]  eta: 0:03:05  lr: 0.000031  loss: 1.3422 (1.4837)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [240/781]  eta: 0:03:02  lr: 0.000031  loss: 1.3371 (1.4842)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [250/781]  eta: 0:02:58  lr: 0.000031  loss: 1.3353 (1.4870)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [260/781]  eta: 0:02:55  lr: 0.000031  loss: 1.4060 (1.4880)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [270/781]  eta: 0:02:51  lr: 0.000031  loss: 1.4060 (1.4898)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [280/781]  eta: 0:02:48  lr: 0.000031  loss: 1.3533 (1.4868)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [290/781]  eta: 0:02:44  lr: 0.000031  loss: 1.3490 (1.4867)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [300/781]  eta: 0:02:41  lr: 0.000031  loss: 1.2864 (1.4839)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [310/781]  eta: 0:02:38  lr: 0.000031  loss: 1.2847 (1.4806)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [320/781]  eta: 0:02:34  lr: 0.000031  loss: 1.3102 (1.4801)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [330/781]  eta: 0:02:31  lr: 0.000031  loss: 1.2728 (1.4738)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [340/781]  eta: 0:02:27  lr: 0.000031  loss: 1.2710 (1.4684)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [350/781]  eta: 0:02:24  lr: 0.000031  loss: 1.3309 (1.4689)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [360/781]  eta: 0:02:21  lr: 0.000031  loss: 1.3949 (1.4742)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [370/781]  eta: 0:02:17  lr: 0.000031  loss: 1.3949 (1.4732)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [380/781]  eta: 0:02:14  lr: 0.000031  loss: 1.3175 (1.4736)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [390/781]  eta: 0:02:11  lr: 0.000031  loss: 1.3153 (1.4723)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [400/781]  eta: 0:02:07  lr: 0.000031  loss: 1.3542 (1.4729)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [410/781]  eta: 0:02:04  lr: 0.000031  loss: 1.3553 (1.4723)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [420/781]  eta: 0:02:00  lr: 0.000031  loss: 1.3678 (1.4747)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [430/781]  eta: 0:01:57  lr: 0.000031  loss: 1.3713 (1.4726)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [440/781]  eta: 0:01:54  lr: 0.000031  loss: 1.3400 (1.4695)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [450/781]  eta: 0:01:50  lr: 0.000031  loss: 1.3035 (1.4685)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [460/781]  eta: 0:01:47  lr: 0.000031  loss: 1.3787 (1.4698)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [470/781]  eta: 0:01:44  lr: 0.000031  loss: 1.3328 (1.4715)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [480/781]  eta: 0:01:40  lr: 0.000031  loss: 1.3328 (1.4728)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [490/781]  eta: 0:01:37  lr: 0.000031  loss: 1.4019 (1.4740)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [500/781]  eta: 0:01:34  lr: 0.000031  loss: 1.4044 (1.4758)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [510/781]  eta: 0:01:30  lr: 0.000031  loss: 1.3645 (1.4774)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [520/781]  eta: 0:01:27  lr: 0.000031  loss: 1.3329 (1.4755)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [530/781]  eta: 0:01:24  lr: 0.000031  loss: 1.3604 (1.4768)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [540/781]  eta: 0:01:20  lr: 0.000031  loss: 1.3955 (1.4792)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [550/781]  eta: 0:01:17  lr: 0.000031  loss: 1.3855 (1.4802)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [560/781]  eta: 0:01:13  lr: 0.000031  loss: 1.3515 (1.4795)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [570/781]  eta: 0:01:10  lr: 0.000031  loss: 1.3597 (1.4796)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [580/781]  eta: 0:01:07  lr: 0.000031  loss: 1.3597 (1.4780)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [590/781]  eta: 0:01:03  lr: 0.000031  loss: 1.3018 (1.4782)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [600/781]  eta: 0:01:00  lr: 0.000031  loss: 1.3389 (1.4764)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [610/781]  eta: 0:00:57  lr: 0.000031  loss: 1.3305 (1.4759)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [620/781]  eta: 0:00:53  lr: 0.000031  loss: 1.3727 (1.4787)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [630/781]  eta: 0:00:50  lr: 0.000031  loss: 1.3698 (1.4772)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [640/781]  eta: 0:00:47  lr: 0.000031  loss: 1.3219 (1.4774)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [650/781]  eta: 0:00:43  lr: 0.000031  loss: 1.3753 (1.4759)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [660/781]  eta: 0:00:40  lr: 0.000031  loss: 1.3726 (1.4758)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [670/781]  eta: 0:00:37  lr: 0.000031  loss: 1.3285 (1.4762)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [680/781]  eta: 0:00:33  lr: 0.000031  loss: 1.3188 (1.4752)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [690/781]  eta: 0:00:30  lr: 0.000031  loss: 1.3558 (1.4760)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [700/781]  eta: 0:00:27  lr: 0.000031  loss: 1.4038 (1.4751)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [710/781]  eta: 0:00:23  lr: 0.000031  loss: 1.3565 (1.4731)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [720/781]  eta: 0:00:20  lr: 0.000031  loss: 1.3275 (1.4726)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [730/781]  eta: 0:00:17  lr: 0.000031  loss: 1.3458 (1.4729)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [740/781]  eta: 0:00:13  lr: 0.000031  loss: 1.4012 (1.4751)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [750/781]  eta: 0:00:10  lr: 0.000031  loss: 1.3951 (1.4763)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [760/781]  eta: 0:00:07  lr: 0.000031  loss: 1.3710 (1.4776)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [770/781]  eta: 0:00:03  lr: 0.000031  loss: 1.3571 (1.4807)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [57]  [780/781]  eta: 0:00:00  lr: 0.000031  loss: 1.3719 (1.4831)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [57] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000031  loss: 1.3719 (1.4831)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3288958966732025, 'lambda_convnext_base': 0.25911596417427063, 'lambda_tf_efficientnetv2_l': 0.4119878113269806}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7949 (0.7949)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8289  data: 0.7980  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9142 (0.9801)  acc1: 82.8125 (81.1553)  acc5: 94.2708 (93.1818)  time: 0.1780  data: 0.1473  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9478 (1.0475)  acc1: 79.6875 (79.2163)  acc5: 92.7083 (92.5099)  time: 0.1297  data: 0.0990  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2027 (1.1130)  acc1: 74.4792 (78.1586)  acc5: 90.1042 (91.9523)  time: 0.1302  data: 0.0994  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2495 (1.1569)  acc1: 74.4792 (77.4771)  acc5: 90.1042 (91.4126)  time: 0.1297  data: 0.0990  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1419 (1.1502)  acc1: 76.5625 (77.4612)  acc5: 91.1458 (91.6462)  time: 0.1336  data: 0.1029  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1491 (1.1560)  acc1: 75.5208 (77.3800)  acc5: 91.6667 (91.7000)  time: 0.1156  data: 0.0859  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1382 s / it)\n",
            "* Acc@1 77.380 Acc@5 91.700 loss 1.156\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [58]  [  0/781]  eta: 0:14:10  lr: 0.000031  loss: 1.2103 (1.2103)  time: 1.0896  data: 0.7222  max mem: 6459\n",
            "Epoch: [58]  [ 10/781]  eta: 0:05:09  lr: 0.000031  loss: 1.3635 (1.5791)  time: 0.4020  data: 0.0659  max mem: 6459\n",
            "Epoch: [58]  [ 20/781]  eta: 0:04:41  lr: 0.000031  loss: 1.3635 (1.5902)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 30/781]  eta: 0:04:28  lr: 0.000031  loss: 1.3607 (1.5579)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 40/781]  eta: 0:04:20  lr: 0.000031  loss: 1.3295 (1.5293)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 50/781]  eta: 0:04:14  lr: 0.000031  loss: 1.2942 (1.5129)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 60/781]  eta: 0:04:09  lr: 0.000031  loss: 1.3179 (1.5033)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 70/781]  eta: 0:04:04  lr: 0.000031  loss: 1.3103 (1.4892)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 80/781]  eta: 0:04:00  lr: 0.000031  loss: 1.3107 (1.4801)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [ 90/781]  eta: 0:03:55  lr: 0.000031  loss: 1.3455 (1.4853)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [100/781]  eta: 0:03:51  lr: 0.000031  loss: 1.3759 (1.4914)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [110/781]  eta: 0:03:48  lr: 0.000031  loss: 1.3759 (1.4908)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [120/781]  eta: 0:03:44  lr: 0.000031  loss: 1.3525 (1.4801)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [130/781]  eta: 0:03:40  lr: 0.000031  loss: 1.3372 (1.4887)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [140/781]  eta: 0:03:36  lr: 0.000031  loss: 1.3547 (1.4884)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [150/781]  eta: 0:03:33  lr: 0.000031  loss: 1.3161 (1.4829)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [160/781]  eta: 0:03:29  lr: 0.000031  loss: 1.3197 (1.4792)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [170/781]  eta: 0:03:26  lr: 0.000031  loss: 1.3301 (1.4847)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [180/781]  eta: 0:03:22  lr: 0.000031  loss: 1.3332 (1.4883)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [190/781]  eta: 0:03:19  lr: 0.000031  loss: 1.3735 (1.4862)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [200/781]  eta: 0:03:15  lr: 0.000031  loss: 1.3740 (1.4885)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [210/781]  eta: 0:03:12  lr: 0.000031  loss: 1.3791 (1.4846)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [220/781]  eta: 0:03:08  lr: 0.000031  loss: 1.3389 (1.4864)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [230/781]  eta: 0:03:05  lr: 0.000031  loss: 1.3180 (1.4847)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [240/781]  eta: 0:03:01  lr: 0.000031  loss: 1.3178 (1.4841)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [250/781]  eta: 0:02:58  lr: 0.000031  loss: 1.3583 (1.4860)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [260/781]  eta: 0:02:55  lr: 0.000031  loss: 1.3959 (1.4960)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [270/781]  eta: 0:02:51  lr: 0.000031  loss: 1.4149 (1.4961)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [280/781]  eta: 0:02:48  lr: 0.000031  loss: 1.4149 (1.4975)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [290/781]  eta: 0:02:44  lr: 0.000031  loss: 1.3392 (1.4940)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [300/781]  eta: 0:02:41  lr: 0.000031  loss: 1.3560 (1.5005)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [310/781]  eta: 0:02:38  lr: 0.000031  loss: 1.3590 (1.5005)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [320/781]  eta: 0:02:34  lr: 0.000031  loss: 1.3528 (1.4998)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [330/781]  eta: 0:02:31  lr: 0.000031  loss: 1.3841 (1.5034)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [340/781]  eta: 0:02:27  lr: 0.000031  loss: 1.3549 (1.4991)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [350/781]  eta: 0:02:24  lr: 0.000031  loss: 1.3580 (1.4957)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [360/781]  eta: 0:02:21  lr: 0.000031  loss: 1.3341 (1.4896)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [370/781]  eta: 0:02:17  lr: 0.000031  loss: 1.2931 (1.4861)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [380/781]  eta: 0:02:14  lr: 0.000031  loss: 1.3133 (1.4856)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [390/781]  eta: 0:02:11  lr: 0.000031  loss: 1.3133 (1.4847)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [400/781]  eta: 0:02:07  lr: 0.000031  loss: 1.3489 (1.4830)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [410/781]  eta: 0:02:04  lr: 0.000031  loss: 1.3575 (1.4803)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [420/781]  eta: 0:02:00  lr: 0.000031  loss: 1.3804 (1.4925)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [430/781]  eta: 0:01:57  lr: 0.000031  loss: 1.3320 (1.4901)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [440/781]  eta: 0:01:54  lr: 0.000031  loss: 1.3320 (1.4877)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [450/781]  eta: 0:01:50  lr: 0.000031  loss: 1.3433 (1.4942)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [460/781]  eta: 0:01:47  lr: 0.000031  loss: 1.3848 (1.4958)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [470/781]  eta: 0:01:44  lr: 0.000031  loss: 1.3513 (1.4948)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [480/781]  eta: 0:01:40  lr: 0.000031  loss: 1.3513 (1.4952)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [490/781]  eta: 0:01:37  lr: 0.000031  loss: 1.3873 (1.4932)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [500/781]  eta: 0:01:34  lr: 0.000031  loss: 1.3873 (1.4947)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [510/781]  eta: 0:01:30  lr: 0.000031  loss: 1.3822 (1.4959)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [520/781]  eta: 0:01:27  lr: 0.000031  loss: 1.3568 (1.4979)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [530/781]  eta: 0:01:23  lr: 0.000031  loss: 1.4114 (1.4999)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [540/781]  eta: 0:01:20  lr: 0.000031  loss: 1.3772 (1.4972)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [550/781]  eta: 0:01:17  lr: 0.000031  loss: 1.3267 (1.4948)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [560/781]  eta: 0:01:13  lr: 0.000031  loss: 1.3345 (1.4922)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [570/781]  eta: 0:01:10  lr: 0.000031  loss: 1.3424 (1.4957)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [580/781]  eta: 0:01:07  lr: 0.000031  loss: 1.4075 (1.4954)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [590/781]  eta: 0:01:03  lr: 0.000031  loss: 1.4352 (1.4970)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [600/781]  eta: 0:01:00  lr: 0.000031  loss: 1.3888 (1.4958)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [610/781]  eta: 0:00:57  lr: 0.000031  loss: 1.3173 (1.4933)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [620/781]  eta: 0:00:53  lr: 0.000031  loss: 1.3099 (1.4910)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [630/781]  eta: 0:00:50  lr: 0.000031  loss: 1.3294 (1.4903)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [640/781]  eta: 0:00:47  lr: 0.000031  loss: 1.3636 (1.4906)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [650/781]  eta: 0:00:43  lr: 0.000031  loss: 1.3636 (1.4912)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [660/781]  eta: 0:00:40  lr: 0.000031  loss: 1.3720 (1.4925)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [670/781]  eta: 0:00:37  lr: 0.000031  loss: 1.3713 (1.4941)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [680/781]  eta: 0:00:33  lr: 0.000031  loss: 1.3710 (1.4932)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [690/781]  eta: 0:00:30  lr: 0.000031  loss: 1.3717 (1.4958)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [700/781]  eta: 0:00:27  lr: 0.000031  loss: 1.3740 (1.4960)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [710/781]  eta: 0:00:23  lr: 0.000031  loss: 1.3223 (1.4952)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [720/781]  eta: 0:00:20  lr: 0.000031  loss: 1.3299 (1.4936)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [730/781]  eta: 0:00:17  lr: 0.000031  loss: 1.3751 (1.4983)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [740/781]  eta: 0:00:13  lr: 0.000031  loss: 1.4396 (1.4998)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [750/781]  eta: 0:00:10  lr: 0.000031  loss: 1.3465 (1.4978)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [760/781]  eta: 0:00:07  lr: 0.000031  loss: 1.3213 (1.4977)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [770/781]  eta: 0:00:03  lr: 0.000031  loss: 1.3805 (1.4977)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [58]  [780/781]  eta: 0:00:00  lr: 0.000031  loss: 1.3879 (1.4985)  time: 0.3330  data: 0.0006  max mem: 6459\n",
            "Epoch: [58] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000031  loss: 1.3879 (1.4985)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32880929112434387, 'lambda_convnext_base': 0.26001185178756714, 'lambda_tf_efficientnetv2_l': 0.411178857088089}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8263 (0.8263)  acc1: 83.8542 (83.8542)  acc5: 94.7917 (94.7917)  time: 0.8577  data: 0.8268  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0225 (0.9696)  acc1: 81.2500 (81.2027)  acc5: 94.2708 (93.7027)  time: 0.1720  data: 0.1413  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0486 (1.0429)  acc1: 78.6458 (79.5387)  acc5: 93.2292 (92.8323)  time: 0.1194  data: 0.0888  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1389 (1.1011)  acc1: 75.5208 (78.6458)  acc5: 91.6667 (92.2715)  time: 0.1214  data: 0.0907  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2569 (1.1454)  acc1: 75.5208 (77.8328)  acc5: 90.6250 (91.7302)  time: 0.1235  data: 0.0928  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1170 (1.1455)  acc1: 76.5625 (77.5531)  acc5: 92.1875 (91.9118)  time: 0.1226  data: 0.0919  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1607 (1.1541)  acc1: 75.5208 (77.4100)  acc5: 92.7083 (91.9400)  time: 0.1037  data: 0.0740  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1294 s / it)\n",
            "* Acc@1 77.410 Acc@5 91.940 loss 1.154\n",
            "Accuracy of the network on the 10000 test images: 77.4%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [59]  [  0/781]  eta: 0:14:37  lr: 0.000030  loss: 1.3679 (1.3679)  time: 1.1229  data: 0.7845  max mem: 6459\n",
            "Epoch: [59]  [ 10/781]  eta: 0:05:12  lr: 0.000030  loss: 1.3521 (1.4209)  time: 0.4051  data: 0.0716  max mem: 6459\n",
            "Epoch: [59]  [ 20/781]  eta: 0:04:42  lr: 0.000030  loss: 1.3521 (1.4463)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 30/781]  eta: 0:04:29  lr: 0.000030  loss: 1.3661 (1.4982)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 40/781]  eta: 0:04:21  lr: 0.000030  loss: 1.3597 (1.4958)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 50/781]  eta: 0:04:15  lr: 0.000030  loss: 1.3351 (1.5126)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 60/781]  eta: 0:04:09  lr: 0.000030  loss: 1.3025 (1.4848)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 70/781]  eta: 0:04:04  lr: 0.000030  loss: 1.3025 (1.4661)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 80/781]  eta: 0:04:00  lr: 0.000030  loss: 1.3763 (1.4636)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [ 90/781]  eta: 0:03:56  lr: 0.000030  loss: 1.3403 (1.4498)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [100/781]  eta: 0:03:52  lr: 0.000030  loss: 1.3403 (1.4672)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [110/781]  eta: 0:03:48  lr: 0.000030  loss: 1.3524 (1.4623)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [120/781]  eta: 0:03:44  lr: 0.000030  loss: 1.3464 (1.4630)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [130/781]  eta: 0:03:40  lr: 0.000030  loss: 1.3330 (1.4542)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [140/781]  eta: 0:03:37  lr: 0.000030  loss: 1.3212 (1.4462)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [150/781]  eta: 0:03:33  lr: 0.000030  loss: 1.3357 (1.4407)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [160/781]  eta: 0:03:29  lr: 0.000030  loss: 1.3590 (1.4418)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [170/781]  eta: 0:03:26  lr: 0.000030  loss: 1.3629 (1.4454)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [180/781]  eta: 0:03:22  lr: 0.000030  loss: 1.3623 (1.4420)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [190/781]  eta: 0:03:19  lr: 0.000030  loss: 1.3114 (1.4385)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [200/781]  eta: 0:03:15  lr: 0.000030  loss: 1.3114 (1.4437)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [210/781]  eta: 0:03:12  lr: 0.000030  loss: 1.3634 (1.4426)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [220/781]  eta: 0:03:08  lr: 0.000030  loss: 1.3272 (1.4395)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [230/781]  eta: 0:03:05  lr: 0.000030  loss: 1.3297 (1.4404)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [240/781]  eta: 0:03:01  lr: 0.000030  loss: 1.3405 (1.4376)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [250/781]  eta: 0:02:58  lr: 0.000030  loss: 1.3405 (1.4380)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [260/781]  eta: 0:02:55  lr: 0.000030  loss: 1.3444 (1.4375)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [270/781]  eta: 0:02:51  lr: 0.000030  loss: 1.3741 (1.4547)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [280/781]  eta: 0:02:48  lr: 0.000030  loss: 1.3542 (1.4500)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [290/781]  eta: 0:02:44  lr: 0.000030  loss: 1.3164 (1.4483)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [300/781]  eta: 0:02:41  lr: 0.000030  loss: 1.3387 (1.4535)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [310/781]  eta: 0:02:38  lr: 0.000030  loss: 1.3743 (1.4564)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [320/781]  eta: 0:02:34  lr: 0.000030  loss: 1.3789 (1.4576)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [330/781]  eta: 0:02:31  lr: 0.000030  loss: 1.3186 (1.4588)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [340/781]  eta: 0:02:27  lr: 0.000030  loss: 1.3237 (1.4611)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [350/781]  eta: 0:02:24  lr: 0.000030  loss: 1.3473 (1.4643)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [360/781]  eta: 0:02:21  lr: 0.000030  loss: 1.3473 (1.4618)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [370/781]  eta: 0:02:17  lr: 0.000030  loss: 1.3437 (1.4630)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [380/781]  eta: 0:02:14  lr: 0.000030  loss: 1.3121 (1.4621)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [390/781]  eta: 0:02:11  lr: 0.000030  loss: 1.3227 (1.4636)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [400/781]  eta: 0:02:07  lr: 0.000030  loss: 1.3521 (1.4630)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [410/781]  eta: 0:02:04  lr: 0.000030  loss: 1.3521 (1.4607)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [420/781]  eta: 0:02:00  lr: 0.000030  loss: 1.3603 (1.4585)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [430/781]  eta: 0:01:57  lr: 0.000030  loss: 1.3462 (1.4577)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [440/781]  eta: 0:01:54  lr: 0.000030  loss: 1.3219 (1.4592)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [450/781]  eta: 0:01:50  lr: 0.000030  loss: 1.3745 (1.4660)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [460/781]  eta: 0:01:47  lr: 0.000030  loss: 1.3545 (1.4651)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [470/781]  eta: 0:01:44  lr: 0.000030  loss: 1.3040 (1.4676)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [480/781]  eta: 0:01:40  lr: 0.000030  loss: 1.3713 (1.4703)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [490/781]  eta: 0:01:37  lr: 0.000030  loss: 1.3639 (1.4701)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [500/781]  eta: 0:01:34  lr: 0.000030  loss: 1.3566 (1.4700)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [510/781]  eta: 0:01:30  lr: 0.000030  loss: 1.3605 (1.4719)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [520/781]  eta: 0:01:27  lr: 0.000030  loss: 1.3640 (1.4741)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [530/781]  eta: 0:01:24  lr: 0.000030  loss: 1.3379 (1.4717)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [540/781]  eta: 0:01:20  lr: 0.000030  loss: 1.3081 (1.4735)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [550/781]  eta: 0:01:17  lr: 0.000030  loss: 1.3575 (1.4722)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [560/781]  eta: 0:01:13  lr: 0.000030  loss: 1.3236 (1.4737)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [570/781]  eta: 0:01:10  lr: 0.000030  loss: 1.3400 (1.4734)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [580/781]  eta: 0:01:07  lr: 0.000030  loss: 1.3548 (1.4760)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [590/781]  eta: 0:01:03  lr: 0.000030  loss: 1.4073 (1.4764)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [600/781]  eta: 0:01:00  lr: 0.000030  loss: 1.3139 (1.4738)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [610/781]  eta: 0:00:57  lr: 0.000030  loss: 1.3253 (1.4744)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [620/781]  eta: 0:00:53  lr: 0.000030  loss: 1.3555 (1.4722)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [630/781]  eta: 0:00:50  lr: 0.000030  loss: 1.3241 (1.4698)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [640/781]  eta: 0:00:47  lr: 0.000030  loss: 1.3617 (1.4713)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [650/781]  eta: 0:00:43  lr: 0.000030  loss: 1.3107 (1.4687)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [660/781]  eta: 0:00:40  lr: 0.000030  loss: 1.2877 (1.4680)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [670/781]  eta: 0:00:37  lr: 0.000030  loss: 1.3037 (1.4699)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [680/781]  eta: 0:00:33  lr: 0.000030  loss: 1.3590 (1.4742)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [690/781]  eta: 0:00:30  lr: 0.000030  loss: 1.3424 (1.4730)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [700/781]  eta: 0:00:27  lr: 0.000030  loss: 1.3409 (1.4716)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [710/781]  eta: 0:00:23  lr: 0.000030  loss: 1.3227 (1.4693)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [720/781]  eta: 0:00:20  lr: 0.000030  loss: 1.3267 (1.4701)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [730/781]  eta: 0:00:17  lr: 0.000030  loss: 1.3314 (1.4691)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [740/781]  eta: 0:00:13  lr: 0.000030  loss: 1.3410 (1.4697)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [750/781]  eta: 0:00:10  lr: 0.000030  loss: 1.3637 (1.4682)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [760/781]  eta: 0:00:07  lr: 0.000030  loss: 1.3122 (1.4663)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [770/781]  eta: 0:00:03  lr: 0.000030  loss: 1.3518 (1.4671)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [59]  [780/781]  eta: 0:00:00  lr: 0.000030  loss: 1.4060 (1.4684)  time: 0.3333  data: 0.0006  max mem: 6459\n",
            "Epoch: [59] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000030  loss: 1.4060 (1.4684)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3291318714618683, 'lambda_convnext_base': 0.2588692605495453, 'lambda_tf_efficientnetv2_l': 0.4119986891746521}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7673 (0.7673)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8287  data: 0.7979  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9570 (0.9926)  acc1: 82.8125 (81.2027)  acc5: 94.2708 (93.4659)  time: 0.1736  data: 0.1429  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0059 (1.0453)  acc1: 78.6458 (79.8859)  acc5: 93.2292 (92.8323)  time: 0.1244  data: 0.0937  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2676 (1.1116)  acc1: 76.5625 (78.8474)  acc5: 90.6250 (92.2547)  time: 0.1164  data: 0.0857  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2813 (1.1570)  acc1: 75.0000 (77.7566)  acc5: 90.1042 (91.7556)  time: 0.1074  data: 0.0768  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1107 (1.1499)  acc1: 75.0000 (77.4101)  acc5: 91.6667 (92.0037)  time: 0.1091  data: 0.0784  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1561 (1.1637)  acc1: 74.4792 (77.3100)  acc5: 91.6667 (92.0200)  time: 0.0945  data: 0.0648  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1230 s / it)\n",
            "* Acc@1 77.310 Acc@5 92.020 loss 1.164\n",
            "Accuracy of the network on the 10000 test images: 77.3%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [60]  [  0/781]  eta: 0:15:06  lr: 0.000029  loss: 1.3835 (1.3835)  time: 1.1613  data: 0.8180  max mem: 6459\n",
            "Epoch: [60]  [ 10/781]  eta: 0:05:14  lr: 0.000029  loss: 1.3219 (1.3164)  time: 0.4085  data: 0.0746  max mem: 6459\n",
            "Epoch: [60]  [ 20/781]  eta: 0:04:43  lr: 0.000029  loss: 1.3006 (1.3665)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 30/781]  eta: 0:04:30  lr: 0.000029  loss: 1.2972 (1.3692)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 40/781]  eta: 0:04:21  lr: 0.000029  loss: 1.2983 (1.4114)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 50/781]  eta: 0:04:15  lr: 0.000029  loss: 1.3238 (1.4060)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 60/781]  eta: 0:04:09  lr: 0.000029  loss: 1.2904 (1.3864)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 70/781]  eta: 0:04:05  lr: 0.000029  loss: 1.2898 (1.3861)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 80/781]  eta: 0:04:00  lr: 0.000029  loss: 1.3290 (1.4212)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [ 90/781]  eta: 0:03:56  lr: 0.000029  loss: 1.3447 (1.4193)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [100/781]  eta: 0:03:52  lr: 0.000029  loss: 1.3559 (1.4127)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [110/781]  eta: 0:03:48  lr: 0.000029  loss: 1.3316 (1.4134)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [120/781]  eta: 0:03:44  lr: 0.000029  loss: 1.2927 (1.4101)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [130/781]  eta: 0:03:40  lr: 0.000029  loss: 1.3219 (1.4167)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [140/781]  eta: 0:03:37  lr: 0.000029  loss: 1.3539 (1.4150)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [150/781]  eta: 0:03:33  lr: 0.000029  loss: 1.3633 (1.4223)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [160/781]  eta: 0:03:30  lr: 0.000029  loss: 1.3108 (1.4167)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [170/781]  eta: 0:03:26  lr: 0.000029  loss: 1.3013 (1.4161)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [180/781]  eta: 0:03:22  lr: 0.000029  loss: 1.3278 (1.4179)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [190/781]  eta: 0:03:19  lr: 0.000029  loss: 1.3234 (1.4198)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [200/781]  eta: 0:03:15  lr: 0.000029  loss: 1.3458 (1.4158)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [210/781]  eta: 0:03:12  lr: 0.000029  loss: 1.3148 (1.4146)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [220/781]  eta: 0:03:09  lr: 0.000029  loss: 1.3107 (1.4103)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [230/781]  eta: 0:03:05  lr: 0.000029  loss: 1.3131 (1.4084)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [240/781]  eta: 0:03:02  lr: 0.000029  loss: 1.3201 (1.4091)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [250/781]  eta: 0:02:58  lr: 0.000029  loss: 1.3201 (1.4072)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [260/781]  eta: 0:02:55  lr: 0.000029  loss: 1.3152 (1.4033)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [270/781]  eta: 0:02:51  lr: 0.000029  loss: 1.3168 (1.4117)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [280/781]  eta: 0:02:48  lr: 0.000029  loss: 1.3724 (1.4195)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [290/781]  eta: 0:02:45  lr: 0.000029  loss: 1.3479 (1.4157)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [300/781]  eta: 0:02:41  lr: 0.000029  loss: 1.2798 (1.4155)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [310/781]  eta: 0:02:38  lr: 0.000029  loss: 1.2723 (1.4111)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [320/781]  eta: 0:02:34  lr: 0.000029  loss: 1.3222 (1.4115)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [330/781]  eta: 0:02:31  lr: 0.000029  loss: 1.3435 (1.4105)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [340/781]  eta: 0:02:28  lr: 0.000029  loss: 1.3214 (1.4105)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [350/781]  eta: 0:02:24  lr: 0.000029  loss: 1.3124 (1.4155)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [360/781]  eta: 0:02:21  lr: 0.000029  loss: 1.3199 (1.4160)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [370/781]  eta: 0:02:17  lr: 0.000029  loss: 1.3211 (1.4220)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [380/781]  eta: 0:02:14  lr: 0.000029  loss: 1.3797 (1.4235)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [390/781]  eta: 0:02:11  lr: 0.000029  loss: 1.3797 (1.4322)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [400/781]  eta: 0:02:07  lr: 0.000029  loss: 1.4583 (1.4354)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [410/781]  eta: 0:02:04  lr: 0.000029  loss: 1.3976 (1.4414)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [420/781]  eta: 0:02:01  lr: 0.000029  loss: 1.3620 (1.4402)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [430/781]  eta: 0:01:57  lr: 0.000029  loss: 1.3374 (1.4392)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [440/781]  eta: 0:01:54  lr: 0.000029  loss: 1.3383 (1.4435)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [450/781]  eta: 0:01:50  lr: 0.000029  loss: 1.3663 (1.4446)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [460/781]  eta: 0:01:47  lr: 0.000029  loss: 1.3235 (1.4464)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [470/781]  eta: 0:01:44  lr: 0.000029  loss: 1.3182 (1.4443)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [480/781]  eta: 0:01:40  lr: 0.000029  loss: 1.3549 (1.4432)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [490/781]  eta: 0:01:37  lr: 0.000029  loss: 1.3800 (1.4488)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [500/781]  eta: 0:01:34  lr: 0.000029  loss: 1.3985 (1.4488)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [510/781]  eta: 0:01:30  lr: 0.000029  loss: 1.3632 (1.4477)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [520/781]  eta: 0:01:27  lr: 0.000029  loss: 1.3539 (1.4479)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [530/781]  eta: 0:01:24  lr: 0.000029  loss: 1.3279 (1.4478)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [540/781]  eta: 0:01:20  lr: 0.000029  loss: 1.3279 (1.4479)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [550/781]  eta: 0:01:17  lr: 0.000029  loss: 1.3272 (1.4491)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [560/781]  eta: 0:01:13  lr: 0.000029  loss: 1.2877 (1.4485)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [570/781]  eta: 0:01:10  lr: 0.000029  loss: 1.3408 (1.4506)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [580/781]  eta: 0:01:07  lr: 0.000029  loss: 1.3641 (1.4513)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [590/781]  eta: 0:01:03  lr: 0.000029  loss: 1.3828 (1.4573)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [600/781]  eta: 0:01:00  lr: 0.000029  loss: 1.3717 (1.4597)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [610/781]  eta: 0:00:57  lr: 0.000029  loss: 1.3481 (1.4585)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [620/781]  eta: 0:00:53  lr: 0.000029  loss: 1.3197 (1.4580)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [630/781]  eta: 0:00:50  lr: 0.000029  loss: 1.3289 (1.4603)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [640/781]  eta: 0:00:47  lr: 0.000029  loss: 1.3919 (1.4628)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [650/781]  eta: 0:00:43  lr: 0.000029  loss: 1.3919 (1.4627)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [660/781]  eta: 0:00:40  lr: 0.000029  loss: 1.3786 (1.4628)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [670/781]  eta: 0:00:37  lr: 0.000029  loss: 1.3786 (1.4645)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [680/781]  eta: 0:00:33  lr: 0.000029  loss: 1.3703 (1.4634)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [690/781]  eta: 0:00:30  lr: 0.000029  loss: 1.3252 (1.4612)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [700/781]  eta: 0:00:27  lr: 0.000029  loss: 1.3128 (1.4614)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [710/781]  eta: 0:00:23  lr: 0.000029  loss: 1.3073 (1.4609)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [720/781]  eta: 0:00:20  lr: 0.000029  loss: 1.3311 (1.4613)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [730/781]  eta: 0:00:17  lr: 0.000029  loss: 1.3710 (1.4619)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [740/781]  eta: 0:00:13  lr: 0.000029  loss: 1.3749 (1.4607)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [750/781]  eta: 0:00:10  lr: 0.000029  loss: 1.3749 (1.4610)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [760/781]  eta: 0:00:07  lr: 0.000029  loss: 1.4059 (1.4626)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [770/781]  eta: 0:00:03  lr: 0.000029  loss: 1.3669 (1.4635)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [60]  [780/781]  eta: 0:00:00  lr: 0.000029  loss: 1.3473 (1.4646)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [60] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000029  loss: 1.3473 (1.4646)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3286304771900177, 'lambda_convnext_base': 0.2592187225818634, 'lambda_tf_efficientnetv2_l': 0.41215065121650696}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8512 (0.8512)  acc1: 83.8542 (83.8542)  acc5: 93.2292 (93.2292)  time: 0.8272  data: 0.7962  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9674 (0.9748)  acc1: 83.8542 (81.1080)  acc5: 93.7500 (93.5606)  time: 0.1730  data: 0.1423  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9932 (1.0729)  acc1: 79.6875 (79.5139)  acc5: 93.2292 (92.4107)  time: 0.1301  data: 0.0994  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1907 (1.1182)  acc1: 76.5625 (78.8979)  acc5: 91.1458 (91.8851)  time: 0.1331  data: 0.1025  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2970 (1.1570)  acc1: 76.5625 (77.8582)  acc5: 90.6250 (91.4507)  time: 0.1325  data: 0.1018  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1332 (1.1568)  acc1: 76.0417 (77.5531)  acc5: 91.6667 (91.7382)  time: 0.1365  data: 0.1058  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1701 (1.1681)  acc1: 75.5208 (77.4500)  acc5: 92.7083 (91.7800)  time: 0.1176  data: 0.0879  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1392 s / it)\n",
            "* Acc@1 77.450 Acc@5 91.780 loss 1.168\n",
            "Accuracy of the network on the 10000 test images: 77.5%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [61]  [  0/781]  eta: 0:14:40  lr: 0.000028  loss: 1.3320 (1.3320)  time: 1.1277  data: 0.7901  max mem: 6459\n",
            "Epoch: [61]  [ 10/781]  eta: 0:05:12  lr: 0.000028  loss: 1.3206 (1.4783)  time: 0.4057  data: 0.0721  max mem: 6459\n",
            "Epoch: [61]  [ 20/781]  eta: 0:04:42  lr: 0.000028  loss: 1.3206 (1.4562)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 30/781]  eta: 0:04:29  lr: 0.000028  loss: 1.3517 (1.4499)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 40/781]  eta: 0:04:21  lr: 0.000028  loss: 1.3428 (1.4466)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 50/781]  eta: 0:04:14  lr: 0.000028  loss: 1.3459 (1.4790)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 60/781]  eta: 0:04:09  lr: 0.000028  loss: 1.3125 (1.4560)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 70/781]  eta: 0:04:04  lr: 0.000028  loss: 1.2818 (1.4658)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 80/781]  eta: 0:04:00  lr: 0.000028  loss: 1.3167 (1.4677)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [ 90/781]  eta: 0:03:56  lr: 0.000028  loss: 1.3264 (1.4686)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [100/781]  eta: 0:03:52  lr: 0.000028  loss: 1.3421 (1.4667)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [110/781]  eta: 0:03:48  lr: 0.000028  loss: 1.3841 (1.4721)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [120/781]  eta: 0:03:44  lr: 0.000028  loss: 1.3722 (1.4837)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [130/781]  eta: 0:03:40  lr: 0.000028  loss: 1.3215 (1.4753)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [140/781]  eta: 0:03:37  lr: 0.000028  loss: 1.3682 (1.4784)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [150/781]  eta: 0:03:33  lr: 0.000028  loss: 1.3642 (1.4666)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [160/781]  eta: 0:03:30  lr: 0.000028  loss: 1.3757 (1.4790)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [170/781]  eta: 0:03:26  lr: 0.000028  loss: 1.3752 (1.4772)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [180/781]  eta: 0:03:22  lr: 0.000028  loss: 1.3473 (1.4808)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [190/781]  eta: 0:03:19  lr: 0.000028  loss: 1.3237 (1.4714)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [200/781]  eta: 0:03:15  lr: 0.000028  loss: 1.3053 (1.4786)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [210/781]  eta: 0:03:12  lr: 0.000028  loss: 1.3475 (1.4764)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [220/781]  eta: 0:03:08  lr: 0.000028  loss: 1.3475 (1.4798)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [230/781]  eta: 0:03:05  lr: 0.000028  loss: 1.3675 (1.4756)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [240/781]  eta: 0:03:02  lr: 0.000028  loss: 1.3608 (1.4776)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [250/781]  eta: 0:02:58  lr: 0.000028  loss: 1.3735 (1.4767)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [260/781]  eta: 0:02:55  lr: 0.000028  loss: 1.3020 (1.4782)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [270/781]  eta: 0:02:51  lr: 0.000028  loss: 1.3389 (1.4740)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [280/781]  eta: 0:02:48  lr: 0.000028  loss: 1.3186 (1.4681)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [290/781]  eta: 0:02:44  lr: 0.000028  loss: 1.3258 (1.4702)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [300/781]  eta: 0:02:41  lr: 0.000028  loss: 1.3538 (1.4737)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [310/781]  eta: 0:02:38  lr: 0.000028  loss: 1.3365 (1.4707)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [320/781]  eta: 0:02:34  lr: 0.000028  loss: 1.3594 (1.4718)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [330/781]  eta: 0:02:31  lr: 0.000028  loss: 1.3594 (1.4702)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [340/781]  eta: 0:02:27  lr: 0.000028  loss: 1.2980 (1.4700)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [350/781]  eta: 0:02:24  lr: 0.000028  loss: 1.3622 (1.4706)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [360/781]  eta: 0:02:21  lr: 0.000028  loss: 1.3606 (1.4750)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [370/781]  eta: 0:02:17  lr: 0.000028  loss: 1.3596 (1.4760)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [380/781]  eta: 0:02:14  lr: 0.000028  loss: 1.3196 (1.4765)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [390/781]  eta: 0:02:11  lr: 0.000028  loss: 1.3019 (1.4719)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [400/781]  eta: 0:02:07  lr: 0.000028  loss: 1.2643 (1.4681)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [410/781]  eta: 0:02:04  lr: 0.000028  loss: 1.3086 (1.4655)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [420/781]  eta: 0:02:00  lr: 0.000028  loss: 1.3086 (1.4623)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [430/781]  eta: 0:01:57  lr: 0.000028  loss: 1.3321 (1.4620)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [440/781]  eta: 0:01:54  lr: 0.000028  loss: 1.3490 (1.4608)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [450/781]  eta: 0:01:50  lr: 0.000028  loss: 1.3475 (1.4618)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [460/781]  eta: 0:01:47  lr: 0.000028  loss: 1.3783 (1.4638)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [470/781]  eta: 0:01:44  lr: 0.000028  loss: 1.3412 (1.4617)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [480/781]  eta: 0:01:40  lr: 0.000028  loss: 1.2674 (1.4579)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [490/781]  eta: 0:01:37  lr: 0.000028  loss: 1.2727 (1.4597)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [500/781]  eta: 0:01:34  lr: 0.000028  loss: 1.3585 (1.4605)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [510/781]  eta: 0:01:30  lr: 0.000028  loss: 1.3237 (1.4621)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [520/781]  eta: 0:01:27  lr: 0.000028  loss: 1.3520 (1.4649)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [530/781]  eta: 0:01:24  lr: 0.000028  loss: 1.5297 (1.4718)  time: 0.3441  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [540/781]  eta: 0:01:20  lr: 0.000028  loss: 1.3983 (1.4716)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [550/781]  eta: 0:01:17  lr: 0.000028  loss: 1.3294 (1.4705)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [560/781]  eta: 0:01:14  lr: 0.000028  loss: 1.3433 (1.4724)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [570/781]  eta: 0:01:10  lr: 0.000028  loss: 1.3512 (1.4724)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [580/781]  eta: 0:01:07  lr: 0.000028  loss: 1.3510 (1.4732)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [590/781]  eta: 0:01:03  lr: 0.000028  loss: 1.3660 (1.4721)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [600/781]  eta: 0:01:00  lr: 0.000028  loss: 1.3660 (1.4750)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [610/781]  eta: 0:00:57  lr: 0.000028  loss: 1.4023 (1.4758)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [620/781]  eta: 0:00:53  lr: 0.000028  loss: 1.3676 (1.4750)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [630/781]  eta: 0:00:50  lr: 0.000028  loss: 1.3730 (1.4781)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [640/781]  eta: 0:00:47  lr: 0.000028  loss: 1.3641 (1.4790)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [650/781]  eta: 0:00:43  lr: 0.000028  loss: 1.3555 (1.4808)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [660/781]  eta: 0:00:40  lr: 0.000028  loss: 1.3085 (1.4789)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [670/781]  eta: 0:00:37  lr: 0.000028  loss: 1.3107 (1.4824)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [680/781]  eta: 0:00:33  lr: 0.000028  loss: 1.3343 (1.4825)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [690/781]  eta: 0:00:30  lr: 0.000028  loss: 1.3194 (1.4815)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [700/781]  eta: 0:00:27  lr: 0.000028  loss: 1.3142 (1.4796)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [710/781]  eta: 0:00:23  lr: 0.000028  loss: 1.3210 (1.4830)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [720/781]  eta: 0:00:20  lr: 0.000028  loss: 1.3355 (1.4833)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [730/781]  eta: 0:00:17  lr: 0.000028  loss: 1.3310 (1.4809)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [740/781]  eta: 0:00:13  lr: 0.000028  loss: 1.3532 (1.4818)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [750/781]  eta: 0:00:10  lr: 0.000028  loss: 1.3901 (1.4843)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [760/781]  eta: 0:00:07  lr: 0.000028  loss: 1.4575 (1.4871)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [770/781]  eta: 0:00:03  lr: 0.000028  loss: 1.3508 (1.4864)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [61]  [780/781]  eta: 0:00:00  lr: 0.000028  loss: 1.3220 (1.4870)  time: 0.3332  data: 0.0006  max mem: 6459\n",
            "Epoch: [61] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000028  loss: 1.3220 (1.4870)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32815995812416077, 'lambda_convnext_base': 0.2599794566631317, 'lambda_tf_efficientnetv2_l': 0.4118601977825165}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8467 (0.8467)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8205  data: 0.7897  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9555 (0.9992)  acc1: 83.3333 (80.4924)  acc5: 94.7917 (94.1761)  time: 0.1770  data: 0.1463  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9940 (1.0511)  acc1: 79.6875 (79.4891)  acc5: 93.7500 (92.9812)  time: 0.1342  data: 0.1035  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2138 (1.1132)  acc1: 75.5208 (78.1754)  acc5: 92.1875 (92.3051)  time: 0.1330  data: 0.1023  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2637 (1.1518)  acc1: 74.4792 (77.4390)  acc5: 90.6250 (91.8572)  time: 0.1292  data: 0.0985  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1272 (1.1419)  acc1: 75.5208 (77.3795)  acc5: 92.1875 (92.0650)  time: 0.1331  data: 0.1024  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1829 (1.1591)  acc1: 75.0000 (77.2300)  acc5: 92.1875 (92.1000)  time: 0.1123  data: 0.0826  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1389 s / it)\n",
            "* Acc@1 77.230 Acc@5 92.100 loss 1.159\n",
            "Accuracy of the network on the 10000 test images: 77.2%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [62]  [  0/781]  eta: 0:13:36  lr: 0.000027  loss: 1.2215 (1.2215)  time: 1.0449  data: 0.7020  max mem: 6459\n",
            "Epoch: [62]  [ 10/781]  eta: 0:05:06  lr: 0.000027  loss: 1.3663 (1.3823)  time: 0.3980  data: 0.0641  max mem: 6459\n",
            "Epoch: [62]  [ 20/781]  eta: 0:04:39  lr: 0.000027  loss: 1.3346 (1.3695)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 30/781]  eta: 0:04:27  lr: 0.000027  loss: 1.2749 (1.3730)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 40/781]  eta: 0:04:19  lr: 0.000027  loss: 1.3208 (1.4049)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 50/781]  eta: 0:04:13  lr: 0.000027  loss: 1.3826 (1.4764)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 60/781]  eta: 0:04:08  lr: 0.000027  loss: 1.3045 (1.4730)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 70/781]  eta: 0:04:04  lr: 0.000027  loss: 1.3168 (1.4832)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 80/781]  eta: 0:03:59  lr: 0.000027  loss: 1.3347 (1.4778)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [ 90/781]  eta: 0:03:55  lr: 0.000027  loss: 1.3470 (1.5025)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [100/781]  eta: 0:03:51  lr: 0.000027  loss: 1.3901 (1.5026)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [110/781]  eta: 0:03:47  lr: 0.000027  loss: 1.3717 (1.4999)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [120/781]  eta: 0:03:44  lr: 0.000027  loss: 1.3634 (1.5087)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [130/781]  eta: 0:03:40  lr: 0.000027  loss: 1.3459 (1.5060)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [140/781]  eta: 0:03:36  lr: 0.000027  loss: 1.3244 (1.5011)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [150/781]  eta: 0:03:33  lr: 0.000027  loss: 1.3195 (1.4992)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [160/781]  eta: 0:03:29  lr: 0.000027  loss: 1.3622 (1.5095)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [170/781]  eta: 0:03:26  lr: 0.000027  loss: 1.3407 (1.5086)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [180/781]  eta: 0:03:22  lr: 0.000027  loss: 1.2999 (1.4964)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [190/781]  eta: 0:03:19  lr: 0.000027  loss: 1.2938 (1.4911)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [200/781]  eta: 0:03:15  lr: 0.000027  loss: 1.3313 (1.4895)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [210/781]  eta: 0:03:12  lr: 0.000027  loss: 1.3285 (1.4885)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [220/781]  eta: 0:03:08  lr: 0.000027  loss: 1.3184 (1.4810)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [230/781]  eta: 0:03:05  lr: 0.000027  loss: 1.3184 (1.4797)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [240/781]  eta: 0:03:01  lr: 0.000027  loss: 1.3692 (1.4755)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [250/781]  eta: 0:02:58  lr: 0.000027  loss: 1.3251 (1.4678)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [260/781]  eta: 0:02:55  lr: 0.000027  loss: 1.2789 (1.4685)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [270/781]  eta: 0:02:51  lr: 0.000027  loss: 1.2831 (1.4676)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [280/781]  eta: 0:02:48  lr: 0.000027  loss: 1.3560 (1.4687)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [290/781]  eta: 0:02:44  lr: 0.000027  loss: 1.3295 (1.4676)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [300/781]  eta: 0:02:41  lr: 0.000027  loss: 1.3264 (1.4646)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [310/781]  eta: 0:02:38  lr: 0.000027  loss: 1.3479 (1.4639)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [320/781]  eta: 0:02:34  lr: 0.000027  loss: 1.3479 (1.4592)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [330/781]  eta: 0:02:31  lr: 0.000027  loss: 1.3583 (1.4609)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [340/781]  eta: 0:02:27  lr: 0.000027  loss: 1.3520 (1.4593)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [350/781]  eta: 0:02:24  lr: 0.000027  loss: 1.3529 (1.4674)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [360/781]  eta: 0:02:21  lr: 0.000027  loss: 1.3538 (1.4683)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [370/781]  eta: 0:02:17  lr: 0.000027  loss: 1.3545 (1.4676)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [380/781]  eta: 0:02:14  lr: 0.000027  loss: 1.3685 (1.4652)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [390/781]  eta: 0:02:10  lr: 0.000027  loss: 1.3677 (1.4716)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [400/781]  eta: 0:02:07  lr: 0.000027  loss: 1.3601 (1.4682)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [410/781]  eta: 0:02:04  lr: 0.000027  loss: 1.3660 (1.4694)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [420/781]  eta: 0:02:00  lr: 0.000027  loss: 1.3097 (1.4651)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [430/781]  eta: 0:01:57  lr: 0.000027  loss: 1.3185 (1.4700)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [440/781]  eta: 0:01:54  lr: 0.000027  loss: 1.3728 (1.4679)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [450/781]  eta: 0:01:50  lr: 0.000027  loss: 1.3473 (1.4652)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [460/781]  eta: 0:01:47  lr: 0.000027  loss: 1.3097 (1.4615)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [470/781]  eta: 0:01:44  lr: 0.000027  loss: 1.3278 (1.4619)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [480/781]  eta: 0:01:40  lr: 0.000027  loss: 1.3967 (1.4660)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [490/781]  eta: 0:01:37  lr: 0.000027  loss: 1.4218 (1.4693)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [500/781]  eta: 0:01:34  lr: 0.000027  loss: 1.3207 (1.4699)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [510/781]  eta: 0:01:30  lr: 0.000027  loss: 1.3161 (1.4719)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [520/781]  eta: 0:01:27  lr: 0.000027  loss: 1.3564 (1.4723)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [530/781]  eta: 0:01:23  lr: 0.000027  loss: 1.3786 (1.4758)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [540/781]  eta: 0:01:20  lr: 0.000027  loss: 1.3747 (1.4750)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [550/781]  eta: 0:01:17  lr: 0.000027  loss: 1.3477 (1.4726)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [560/781]  eta: 0:01:13  lr: 0.000027  loss: 1.3082 (1.4704)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [570/781]  eta: 0:01:10  lr: 0.000027  loss: 1.2886 (1.4680)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [580/781]  eta: 0:01:07  lr: 0.000027  loss: 1.2880 (1.4653)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [590/781]  eta: 0:01:03  lr: 0.000027  loss: 1.3283 (1.4685)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [600/781]  eta: 0:01:00  lr: 0.000027  loss: 1.3312 (1.4662)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [610/781]  eta: 0:00:57  lr: 0.000027  loss: 1.3301 (1.4643)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [620/781]  eta: 0:00:53  lr: 0.000027  loss: 1.3358 (1.4621)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [630/781]  eta: 0:00:50  lr: 0.000027  loss: 1.3358 (1.4618)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [640/781]  eta: 0:00:47  lr: 0.000027  loss: 1.3375 (1.4623)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [650/781]  eta: 0:00:43  lr: 0.000027  loss: 1.3591 (1.4630)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [660/781]  eta: 0:00:40  lr: 0.000027  loss: 1.3660 (1.4632)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [670/781]  eta: 0:00:37  lr: 0.000027  loss: 1.3618 (1.4631)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [680/781]  eta: 0:00:33  lr: 0.000027  loss: 1.3179 (1.4633)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [690/781]  eta: 0:00:30  lr: 0.000027  loss: 1.3423 (1.4632)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [700/781]  eta: 0:00:27  lr: 0.000027  loss: 1.3288 (1.4617)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [710/781]  eta: 0:00:23  lr: 0.000027  loss: 1.3288 (1.4603)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [720/781]  eta: 0:00:20  lr: 0.000027  loss: 1.3370 (1.4588)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [730/781]  eta: 0:00:17  lr: 0.000027  loss: 1.3133 (1.4586)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [740/781]  eta: 0:00:13  lr: 0.000027  loss: 1.3133 (1.4568)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [750/781]  eta: 0:00:10  lr: 0.000027  loss: 1.3476 (1.4620)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [760/781]  eta: 0:00:07  lr: 0.000027  loss: 1.3752 (1.4643)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [770/781]  eta: 0:00:03  lr: 0.000027  loss: 1.3088 (1.4637)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [62]  [780/781]  eta: 0:00:00  lr: 0.000027  loss: 1.2920 (1.4626)  time: 0.3335  data: 0.0005  max mem: 6459\n",
            "Epoch: [62] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000027  loss: 1.2920 (1.4626)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3291589319705963, 'lambda_convnext_base': 0.2599503993988037, 'lambda_tf_efficientnetv2_l': 0.41089069843292236}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8055 (0.8055)  acc1: 82.8125 (82.8125)  acc5: 93.7500 (93.7500)  time: 0.8470  data: 0.8161  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9144 (0.9675)  acc1: 82.2917 (81.1553)  acc5: 94.2708 (93.7500)  time: 0.1716  data: 0.1409  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0041 (1.0347)  acc1: 79.6875 (80.0099)  acc5: 93.7500 (92.9067)  time: 0.1221  data: 0.0915  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1717 (1.0932)  acc1: 76.0417 (78.8642)  acc5: 91.6667 (92.3387)  time: 0.1221  data: 0.0915  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.1810 (1.1393)  acc1: 76.0417 (77.8074)  acc5: 90.6250 (91.7429)  time: 0.1229  data: 0.0923  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1615 (1.1367)  acc1: 77.6042 (77.7267)  acc5: 91.1458 (91.9118)  time: 0.1228  data: 0.0922  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1804 (1.1441)  acc1: 76.0417 (77.6100)  acc5: 92.1875 (91.9600)  time: 0.1033  data: 0.0736  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1297 s / it)\n",
            "* Acc@1 77.610 Acc@5 91.960 loss 1.144\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [63]  [  0/781]  eta: 0:14:44  lr: 0.000027  loss: 2.4900 (2.4900)  time: 1.1328  data: 0.7870  max mem: 6459\n",
            "Epoch: [63]  [ 10/781]  eta: 0:05:13  lr: 0.000027  loss: 1.3154 (1.5624)  time: 0.4066  data: 0.0718  max mem: 6459\n",
            "Epoch: [63]  [ 20/781]  eta: 0:04:43  lr: 0.000027  loss: 1.3151 (1.4586)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 30/781]  eta: 0:04:30  lr: 0.000027  loss: 1.2971 (1.4280)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 40/781]  eta: 0:04:21  lr: 0.000027  loss: 1.3463 (1.4393)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 50/781]  eta: 0:04:15  lr: 0.000027  loss: 1.3463 (1.4321)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 60/781]  eta: 0:04:09  lr: 0.000027  loss: 1.3171 (1.4149)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 70/781]  eta: 0:04:05  lr: 0.000027  loss: 1.3054 (1.4149)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 80/781]  eta: 0:04:00  lr: 0.000027  loss: 1.3581 (1.4220)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [ 90/781]  eta: 0:03:56  lr: 0.000027  loss: 1.3530 (1.4260)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [100/781]  eta: 0:03:52  lr: 0.000027  loss: 1.3373 (1.4366)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [110/781]  eta: 0:03:48  lr: 0.000027  loss: 1.3063 (1.4236)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [120/781]  eta: 0:03:44  lr: 0.000027  loss: 1.3163 (1.4378)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [130/781]  eta: 0:03:40  lr: 0.000027  loss: 1.3572 (1.4305)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [140/781]  eta: 0:03:37  lr: 0.000027  loss: 1.3384 (1.4298)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [150/781]  eta: 0:03:33  lr: 0.000027  loss: 1.3048 (1.4315)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [160/781]  eta: 0:03:30  lr: 0.000027  loss: 1.2838 (1.4322)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [170/781]  eta: 0:03:26  lr: 0.000027  loss: 1.2836 (1.4380)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [180/781]  eta: 0:03:23  lr: 0.000027  loss: 1.3527 (1.4440)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [190/781]  eta: 0:03:19  lr: 0.000027  loss: 1.3306 (1.4373)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [200/781]  eta: 0:03:16  lr: 0.000027  loss: 1.3309 (1.4375)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [210/781]  eta: 0:03:12  lr: 0.000027  loss: 1.3292 (1.4307)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [220/781]  eta: 0:03:09  lr: 0.000027  loss: 1.3224 (1.4312)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [230/781]  eta: 0:03:05  lr: 0.000027  loss: 1.3236 (1.4342)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [240/781]  eta: 0:03:02  lr: 0.000027  loss: 1.3822 (1.4370)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [250/781]  eta: 0:02:58  lr: 0.000027  loss: 1.3162 (1.4364)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [260/781]  eta: 0:02:55  lr: 0.000027  loss: 1.3610 (1.4368)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [270/781]  eta: 0:02:51  lr: 0.000027  loss: 1.3805 (1.4401)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [280/781]  eta: 0:02:48  lr: 0.000027  loss: 1.3311 (1.4394)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [290/781]  eta: 0:02:45  lr: 0.000027  loss: 1.2996 (1.4426)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [300/781]  eta: 0:02:41  lr: 0.000027  loss: 1.3704 (1.4414)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [310/781]  eta: 0:02:38  lr: 0.000027  loss: 1.3553 (1.4472)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [320/781]  eta: 0:02:34  lr: 0.000027  loss: 1.3460 (1.4461)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [330/781]  eta: 0:02:31  lr: 0.000027  loss: 1.3274 (1.4469)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [340/781]  eta: 0:02:28  lr: 0.000027  loss: 1.3187 (1.4502)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [350/781]  eta: 0:02:24  lr: 0.000027  loss: 1.3098 (1.4464)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [360/781]  eta: 0:02:21  lr: 0.000027  loss: 1.3133 (1.4478)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [370/781]  eta: 0:02:17  lr: 0.000027  loss: 1.3133 (1.4480)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [380/781]  eta: 0:02:14  lr: 0.000027  loss: 1.3207 (1.4482)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [390/781]  eta: 0:02:11  lr: 0.000027  loss: 1.3207 (1.4451)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [400/781]  eta: 0:02:07  lr: 0.000027  loss: 1.2787 (1.4411)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [410/781]  eta: 0:02:04  lr: 0.000027  loss: 1.3101 (1.4399)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [420/781]  eta: 0:02:01  lr: 0.000027  loss: 1.3576 (1.4375)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [430/781]  eta: 0:01:57  lr: 0.000027  loss: 1.3197 (1.4354)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [440/781]  eta: 0:01:54  lr: 0.000027  loss: 1.3057 (1.4319)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [450/781]  eta: 0:01:50  lr: 0.000027  loss: 1.3057 (1.4305)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [460/781]  eta: 0:01:47  lr: 0.000027  loss: 1.3445 (1.4288)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [470/781]  eta: 0:01:44  lr: 0.000027  loss: 1.3311 (1.4283)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [480/781]  eta: 0:01:40  lr: 0.000027  loss: 1.2925 (1.4287)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [490/781]  eta: 0:01:37  lr: 0.000027  loss: 1.3088 (1.4263)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [500/781]  eta: 0:01:34  lr: 0.000027  loss: 1.3139 (1.4247)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [510/781]  eta: 0:01:30  lr: 0.000027  loss: 1.3196 (1.4245)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [520/781]  eta: 0:01:27  lr: 0.000027  loss: 1.3517 (1.4288)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [530/781]  eta: 0:01:24  lr: 0.000027  loss: 1.3517 (1.4271)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [540/781]  eta: 0:01:20  lr: 0.000027  loss: 1.2988 (1.4249)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [550/781]  eta: 0:01:17  lr: 0.000027  loss: 1.2988 (1.4225)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [560/781]  eta: 0:01:14  lr: 0.000027  loss: 1.3095 (1.4207)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [570/781]  eta: 0:01:10  lr: 0.000027  loss: 1.3670 (1.4221)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [580/781]  eta: 0:01:07  lr: 0.000027  loss: 1.3670 (1.4235)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [590/781]  eta: 0:01:03  lr: 0.000027  loss: 1.3357 (1.4241)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [600/781]  eta: 0:01:00  lr: 0.000027  loss: 1.3225 (1.4229)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [610/781]  eta: 0:00:57  lr: 0.000027  loss: 1.3404 (1.4289)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [620/781]  eta: 0:00:53  lr: 0.000027  loss: 1.3922 (1.4309)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [630/781]  eta: 0:00:50  lr: 0.000027  loss: 1.3175 (1.4290)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [640/781]  eta: 0:00:47  lr: 0.000027  loss: 1.2958 (1.4322)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [650/781]  eta: 0:00:43  lr: 0.000027  loss: 1.3100 (1.4306)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [660/781]  eta: 0:00:40  lr: 0.000027  loss: 1.3167 (1.4310)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [670/781]  eta: 0:00:37  lr: 0.000027  loss: 1.3337 (1.4306)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [680/781]  eta: 0:00:33  lr: 0.000027  loss: 1.3337 (1.4314)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [690/781]  eta: 0:00:30  lr: 0.000027  loss: 1.3640 (1.4336)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [700/781]  eta: 0:00:27  lr: 0.000027  loss: 1.3638 (1.4334)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [710/781]  eta: 0:00:23  lr: 0.000027  loss: 1.3950 (1.4336)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [720/781]  eta: 0:00:20  lr: 0.000027  loss: 1.3950 (1.4361)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [730/781]  eta: 0:00:17  lr: 0.000027  loss: 1.3176 (1.4370)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [740/781]  eta: 0:00:13  lr: 0.000027  loss: 1.3176 (1.4375)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [750/781]  eta: 0:00:10  lr: 0.000027  loss: 1.3352 (1.4386)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [760/781]  eta: 0:00:07  lr: 0.000027  loss: 1.3250 (1.4372)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [770/781]  eta: 0:00:03  lr: 0.000027  loss: 1.3232 (1.4369)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [63]  [780/781]  eta: 0:00:00  lr: 0.000027  loss: 1.3341 (1.4389)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [63] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000027  loss: 1.3341 (1.4389)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3292103409767151, 'lambda_convnext_base': 0.2592996656894684, 'lambda_tf_efficientnetv2_l': 0.4114900827407837}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8298 (0.8298)  acc1: 81.7708 (81.7708)  acc5: 95.3125 (95.3125)  time: 0.8441  data: 0.8133  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0284 (0.9691)  acc1: 81.7708 (81.1080)  acc5: 94.2708 (93.5133)  time: 0.1683  data: 0.1377  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0284 (1.0346)  acc1: 81.2500 (79.6379)  acc5: 93.7500 (92.7083)  time: 0.1183  data: 0.0876  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1857 (1.0889)  acc1: 76.5625 (78.8474)  acc5: 91.6667 (92.2211)  time: 0.1214  data: 0.0907  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2198 (1.1339)  acc1: 75.0000 (77.8201)  acc5: 90.6250 (91.8318)  time: 0.1234  data: 0.0927  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1585 (1.1297)  acc1: 76.0417 (77.6859)  acc5: 91.6667 (92.0650)  time: 0.1219  data: 0.0912  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1740 (1.1418)  acc1: 75.5208 (77.5600)  acc5: 91.6667 (92.0700)  time: 0.1029  data: 0.0733  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1284 s / it)\n",
            "* Acc@1 77.560 Acc@5 92.070 loss 1.142\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [64]  [  0/781]  eta: 0:14:49  lr: 0.000026  loss: 1.4569 (1.4569)  time: 1.1383  data: 0.7954  max mem: 6459\n",
            "Epoch: [64]  [ 10/781]  eta: 0:05:13  lr: 0.000026  loss: 1.3365 (1.4349)  time: 0.4068  data: 0.0726  max mem: 6459\n",
            "Epoch: [64]  [ 20/781]  eta: 0:04:43  lr: 0.000026  loss: 1.3196 (1.3797)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 30/781]  eta: 0:04:29  lr: 0.000026  loss: 1.3330 (1.4501)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 40/781]  eta: 0:04:21  lr: 0.000026  loss: 1.3330 (1.4134)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 50/781]  eta: 0:04:15  lr: 0.000026  loss: 1.3043 (1.4100)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 60/781]  eta: 0:04:09  lr: 0.000026  loss: 1.3114 (1.4612)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 70/781]  eta: 0:04:05  lr: 0.000026  loss: 1.3474 (1.4663)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 80/781]  eta: 0:04:00  lr: 0.000026  loss: 1.3457 (1.4796)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [ 90/781]  eta: 0:03:56  lr: 0.000026  loss: 1.3811 (1.5107)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [100/781]  eta: 0:03:52  lr: 0.000026  loss: 1.3831 (1.5157)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [110/781]  eta: 0:03:48  lr: 0.000026  loss: 1.3541 (1.5107)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [120/781]  eta: 0:03:44  lr: 0.000026  loss: 1.2926 (1.4973)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [130/781]  eta: 0:03:40  lr: 0.000026  loss: 1.2926 (1.4860)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [140/781]  eta: 0:03:37  lr: 0.000026  loss: 1.3111 (1.4973)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [150/781]  eta: 0:03:33  lr: 0.000026  loss: 1.3337 (1.4902)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [160/781]  eta: 0:03:30  lr: 0.000026  loss: 1.2864 (1.4838)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [170/781]  eta: 0:03:26  lr: 0.000026  loss: 1.2864 (1.4761)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [180/781]  eta: 0:03:23  lr: 0.000026  loss: 1.3105 (1.4741)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [190/781]  eta: 0:03:19  lr: 0.000026  loss: 1.3472 (1.4799)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [200/781]  eta: 0:03:15  lr: 0.000026  loss: 1.2945 (1.4731)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [210/781]  eta: 0:03:12  lr: 0.000026  loss: 1.2867 (1.4719)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [220/781]  eta: 0:03:09  lr: 0.000026  loss: 1.2598 (1.4644)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [230/781]  eta: 0:03:05  lr: 0.000026  loss: 1.2808 (1.4620)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [240/781]  eta: 0:03:02  lr: 0.000026  loss: 1.3363 (1.4627)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [250/781]  eta: 0:02:58  lr: 0.000026  loss: 1.3453 (1.4634)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [260/781]  eta: 0:02:55  lr: 0.000026  loss: 1.3009 (1.4607)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [270/781]  eta: 0:02:51  lr: 0.000026  loss: 1.2975 (1.4589)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [280/781]  eta: 0:02:48  lr: 0.000026  loss: 1.2972 (1.4537)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [290/781]  eta: 0:02:44  lr: 0.000026  loss: 1.2967 (1.4538)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [300/781]  eta: 0:02:41  lr: 0.000026  loss: 1.3313 (1.4550)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [310/781]  eta: 0:02:38  lr: 0.000026  loss: 1.3756 (1.4571)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [320/781]  eta: 0:02:34  lr: 0.000026  loss: 1.3126 (1.4564)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [330/781]  eta: 0:02:31  lr: 0.000026  loss: 1.2986 (1.4541)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [340/781]  eta: 0:02:28  lr: 0.000026  loss: 1.2921 (1.4513)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [350/781]  eta: 0:02:24  lr: 0.000026  loss: 1.2895 (1.4501)  time: 0.3425  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [360/781]  eta: 0:02:21  lr: 0.000026  loss: 1.3162 (1.4512)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [370/781]  eta: 0:02:18  lr: 0.000026  loss: 1.3534 (1.4500)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [380/781]  eta: 0:02:14  lr: 0.000026  loss: 1.3376 (1.4516)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [390/781]  eta: 0:02:11  lr: 0.000026  loss: 1.3468 (1.4532)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [400/781]  eta: 0:02:07  lr: 0.000026  loss: 1.3753 (1.4571)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [410/781]  eta: 0:02:04  lr: 0.000026  loss: 1.4079 (1.4602)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [420/781]  eta: 0:02:01  lr: 0.000026  loss: 1.3694 (1.4619)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [430/781]  eta: 0:01:57  lr: 0.000026  loss: 1.3694 (1.4651)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [440/781]  eta: 0:01:54  lr: 0.000026  loss: 1.3729 (1.4656)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [450/781]  eta: 0:01:51  lr: 0.000026  loss: 1.3180 (1.4633)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [460/781]  eta: 0:01:47  lr: 0.000026  loss: 1.3329 (1.4625)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [470/781]  eta: 0:01:44  lr: 0.000026  loss: 1.3417 (1.4651)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [480/781]  eta: 0:01:40  lr: 0.000026  loss: 1.3438 (1.4637)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [490/781]  eta: 0:01:37  lr: 0.000026  loss: 1.4061 (1.4701)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [500/781]  eta: 0:01:34  lr: 0.000026  loss: 1.3674 (1.4719)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [510/781]  eta: 0:01:30  lr: 0.000026  loss: 1.3349 (1.4724)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [520/781]  eta: 0:01:27  lr: 0.000026  loss: 1.3400 (1.4746)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [530/781]  eta: 0:01:24  lr: 0.000026  loss: 1.3292 (1.4715)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [540/781]  eta: 0:01:20  lr: 0.000026  loss: 1.3007 (1.4746)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [550/781]  eta: 0:01:17  lr: 0.000026  loss: 1.3130 (1.4725)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [560/781]  eta: 0:01:14  lr: 0.000026  loss: 1.3419 (1.4703)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [570/781]  eta: 0:01:10  lr: 0.000026  loss: 1.3462 (1.4700)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [580/781]  eta: 0:01:07  lr: 0.000026  loss: 1.3465 (1.4709)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [590/781]  eta: 0:01:03  lr: 0.000026  loss: 1.3553 (1.4707)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [600/781]  eta: 0:01:00  lr: 0.000026  loss: 1.3083 (1.4681)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [610/781]  eta: 0:00:57  lr: 0.000026  loss: 1.2867 (1.4657)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [620/781]  eta: 0:00:53  lr: 0.000026  loss: 1.3027 (1.4636)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [630/781]  eta: 0:00:50  lr: 0.000026  loss: 1.3377 (1.4687)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [640/781]  eta: 0:00:47  lr: 0.000026  loss: 1.5220 (1.4735)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [650/781]  eta: 0:00:43  lr: 0.000026  loss: 1.4001 (1.4735)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [660/781]  eta: 0:00:40  lr: 0.000026  loss: 1.3578 (1.4718)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [670/781]  eta: 0:00:37  lr: 0.000026  loss: 1.3145 (1.4713)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [680/781]  eta: 0:00:33  lr: 0.000026  loss: 1.3554 (1.4737)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [690/781]  eta: 0:00:30  lr: 0.000026  loss: 1.3513 (1.4713)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [700/781]  eta: 0:00:27  lr: 0.000026  loss: 1.2869 (1.4698)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [710/781]  eta: 0:00:23  lr: 0.000026  loss: 1.3034 (1.4697)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [720/781]  eta: 0:00:20  lr: 0.000026  loss: 1.3161 (1.4719)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [730/781]  eta: 0:00:17  lr: 0.000026  loss: 1.3767 (1.4743)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [740/781]  eta: 0:00:13  lr: 0.000026  loss: 1.3439 (1.4722)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [750/781]  eta: 0:00:10  lr: 0.000026  loss: 1.3332 (1.4715)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [760/781]  eta: 0:00:07  lr: 0.000026  loss: 1.3332 (1.4713)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [770/781]  eta: 0:00:03  lr: 0.000026  loss: 1.3349 (1.4713)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [64]  [780/781]  eta: 0:00:00  lr: 0.000026  loss: 1.3046 (1.4707)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [64] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000026  loss: 1.3046 (1.4707)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32836562395095825, 'lambda_convnext_base': 0.25973808765411377, 'lambda_tf_efficientnetv2_l': 0.411896288394928}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8187 (0.8187)  acc1: 81.7708 (81.7708)  acc5: 95.3125 (95.3125)  time: 0.8498  data: 0.8189  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9848 (0.9970)  acc1: 81.7708 (81.2974)  acc5: 94.2708 (93.4659)  time: 0.1705  data: 0.1399  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0492 (1.0368)  acc1: 78.1250 (80.2579)  acc5: 93.7500 (92.9564)  time: 0.1215  data: 0.0908  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1372 (1.0906)  acc1: 76.0417 (79.0155)  acc5: 91.6667 (92.4731)  time: 0.1221  data: 0.0914  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2345 (1.1435)  acc1: 75.5208 (77.9599)  acc5: 90.6250 (91.8953)  time: 0.1236  data: 0.0929  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1326 (1.1417)  acc1: 75.5208 (77.6961)  acc5: 92.1875 (92.0343)  time: 0.1240  data: 0.0933  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1936 (1.1516)  acc1: 75.5208 (77.6100)  acc5: 92.7083 (92.0800)  time: 0.1043  data: 0.0746  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1299 s / it)\n",
            "* Acc@1 77.610 Acc@5 92.080 loss 1.152\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [65]  [  0/781]  eta: 0:14:26  lr: 0.000025  loss: 1.2445 (1.2445)  time: 1.1095  data: 0.7711  max mem: 6459\n",
            "Epoch: [65]  [ 10/781]  eta: 0:05:11  lr: 0.000025  loss: 1.3556 (1.5462)  time: 0.4036  data: 0.0704  max mem: 6459\n",
            "Epoch: [65]  [ 20/781]  eta: 0:04:41  lr: 0.000025  loss: 1.3292 (1.4855)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 30/781]  eta: 0:04:29  lr: 0.000025  loss: 1.3052 (1.4860)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 40/781]  eta: 0:04:21  lr: 0.000025  loss: 1.2991 (1.4717)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 50/781]  eta: 0:04:14  lr: 0.000025  loss: 1.3214 (1.4412)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 60/781]  eta: 0:04:09  lr: 0.000025  loss: 1.3575 (1.4599)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 70/781]  eta: 0:04:04  lr: 0.000025  loss: 1.2933 (1.4490)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 80/781]  eta: 0:04:00  lr: 0.000025  loss: 1.2933 (1.4321)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [ 90/781]  eta: 0:03:56  lr: 0.000025  loss: 1.3222 (1.4414)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [100/781]  eta: 0:03:52  lr: 0.000025  loss: 1.3266 (1.4558)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [110/781]  eta: 0:03:48  lr: 0.000025  loss: 1.3047 (1.4522)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [120/781]  eta: 0:03:44  lr: 0.000025  loss: 1.2958 (1.4551)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [130/781]  eta: 0:03:40  lr: 0.000025  loss: 1.3402 (1.4528)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [140/781]  eta: 0:03:37  lr: 0.000025  loss: 1.3443 (1.4587)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [150/781]  eta: 0:03:33  lr: 0.000025  loss: 1.3302 (1.4487)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [160/781]  eta: 0:03:29  lr: 0.000025  loss: 1.2947 (1.4609)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [170/781]  eta: 0:03:26  lr: 0.000025  loss: 1.2866 (1.4578)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [180/781]  eta: 0:03:22  lr: 0.000025  loss: 1.3133 (1.4555)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [190/781]  eta: 0:03:19  lr: 0.000025  loss: 1.3194 (1.4523)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [200/781]  eta: 0:03:15  lr: 0.000025  loss: 1.3008 (1.4518)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [210/781]  eta: 0:03:12  lr: 0.000025  loss: 1.3053 (1.4514)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [220/781]  eta: 0:03:08  lr: 0.000025  loss: 1.2757 (1.4496)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [230/781]  eta: 0:03:05  lr: 0.000025  loss: 1.2714 (1.4481)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [240/781]  eta: 0:03:02  lr: 0.000025  loss: 1.2684 (1.4422)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [250/781]  eta: 0:02:58  lr: 0.000025  loss: 1.2660 (1.4354)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [260/781]  eta: 0:02:55  lr: 0.000025  loss: 1.3347 (1.4401)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [270/781]  eta: 0:02:51  lr: 0.000025  loss: 1.3868 (1.4448)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [280/781]  eta: 0:02:48  lr: 0.000025  loss: 1.3457 (1.4464)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [290/781]  eta: 0:02:44  lr: 0.000025  loss: 1.3120 (1.4453)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [300/781]  eta: 0:02:41  lr: 0.000025  loss: 1.3520 (1.4444)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [310/781]  eta: 0:02:38  lr: 0.000025  loss: 1.3354 (1.4491)  time: 0.3346  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [320/781]  eta: 0:02:34  lr: 0.000025  loss: 1.3469 (1.4504)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [330/781]  eta: 0:02:31  lr: 0.000025  loss: 1.3788 (1.4523)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [340/781]  eta: 0:02:28  lr: 0.000025  loss: 1.3495 (1.4489)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [350/781]  eta: 0:02:24  lr: 0.000025  loss: 1.3146 (1.4469)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [360/781]  eta: 0:02:21  lr: 0.000025  loss: 1.2921 (1.4460)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [370/781]  eta: 0:02:17  lr: 0.000025  loss: 1.3169 (1.4449)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [380/781]  eta: 0:02:14  lr: 0.000025  loss: 1.3245 (1.4453)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [390/781]  eta: 0:02:11  lr: 0.000025  loss: 1.3571 (1.4471)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [400/781]  eta: 0:02:07  lr: 0.000025  loss: 1.3326 (1.4483)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [410/781]  eta: 0:02:04  lr: 0.000025  loss: 1.3821 (1.4527)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [420/781]  eta: 0:02:01  lr: 0.000025  loss: 1.3821 (1.4549)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [430/781]  eta: 0:01:57  lr: 0.000025  loss: 1.3010 (1.4510)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [440/781]  eta: 0:01:54  lr: 0.000025  loss: 1.2892 (1.4471)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [450/781]  eta: 0:01:50  lr: 0.000025  loss: 1.3048 (1.4486)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [460/781]  eta: 0:01:47  lr: 0.000025  loss: 1.3651 (1.4514)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [470/781]  eta: 0:01:44  lr: 0.000025  loss: 1.3349 (1.4502)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [480/781]  eta: 0:01:40  lr: 0.000025  loss: 1.3459 (1.4525)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [490/781]  eta: 0:01:37  lr: 0.000025  loss: 1.4016 (1.4578)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [500/781]  eta: 0:01:34  lr: 0.000025  loss: 1.4027 (1.4587)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [510/781]  eta: 0:01:30  lr: 0.000025  loss: 1.3235 (1.4584)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [520/781]  eta: 0:01:27  lr: 0.000025  loss: 1.2967 (1.4597)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [530/781]  eta: 0:01:24  lr: 0.000025  loss: 1.3707 (1.4604)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [540/781]  eta: 0:01:20  lr: 0.000025  loss: 1.3199 (1.4578)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [550/781]  eta: 0:01:17  lr: 0.000025  loss: 1.3057 (1.4556)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [560/781]  eta: 0:01:14  lr: 0.000025  loss: 1.3320 (1.4557)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [570/781]  eta: 0:01:10  lr: 0.000025  loss: 1.3461 (1.4575)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [580/781]  eta: 0:01:07  lr: 0.000025  loss: 1.3147 (1.4553)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [590/781]  eta: 0:01:03  lr: 0.000025  loss: 1.3597 (1.4538)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [600/781]  eta: 0:01:00  lr: 0.000025  loss: 1.3620 (1.4567)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [610/781]  eta: 0:00:57  lr: 0.000025  loss: 1.3477 (1.4567)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [620/781]  eta: 0:00:53  lr: 0.000025  loss: 1.3240 (1.4541)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [630/781]  eta: 0:00:50  lr: 0.000025  loss: 1.3385 (1.4548)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [640/781]  eta: 0:00:47  lr: 0.000025  loss: 1.3359 (1.4529)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [650/781]  eta: 0:00:43  lr: 0.000025  loss: 1.3359 (1.4518)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [660/781]  eta: 0:00:40  lr: 0.000025  loss: 1.3613 (1.4526)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [670/781]  eta: 0:00:37  lr: 0.000025  loss: 1.3166 (1.4513)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [680/781]  eta: 0:00:33  lr: 0.000025  loss: 1.3407 (1.4509)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [690/781]  eta: 0:00:30  lr: 0.000025  loss: 1.4058 (1.4546)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [700/781]  eta: 0:00:27  lr: 0.000025  loss: 1.4120 (1.4563)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [710/781]  eta: 0:00:23  lr: 0.000025  loss: 1.3035 (1.4547)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [720/781]  eta: 0:00:20  lr: 0.000025  loss: 1.3035 (1.4548)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [730/781]  eta: 0:00:17  lr: 0.000025  loss: 1.3091 (1.4548)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [740/781]  eta: 0:00:13  lr: 0.000025  loss: 1.2999 (1.4557)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [750/781]  eta: 0:00:10  lr: 0.000025  loss: 1.2956 (1.4536)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [760/781]  eta: 0:00:07  lr: 0.000025  loss: 1.3452 (1.4576)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [770/781]  eta: 0:00:03  lr: 0.000025  loss: 1.3895 (1.4581)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [65]  [780/781]  eta: 0:00:00  lr: 0.000025  loss: 1.3649 (1.4597)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [65] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000025  loss: 1.3649 (1.4597)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290930688381195, 'lambda_convnext_base': 0.25951358675956726, 'lambda_tf_efficientnetv2_l': 0.4113931357860565}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8115 (0.8115)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 0.8531  data: 0.8222  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9789 (0.9939)  acc1: 83.3333 (81.4394)  acc5: 94.2708 (93.7974)  time: 0.1681  data: 0.1374  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0530 (1.0514)  acc1: 78.1250 (79.8859)  acc5: 93.7500 (92.9067)  time: 0.1191  data: 0.0884  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1513 (1.0977)  acc1: 76.5625 (79.0827)  acc5: 91.6667 (92.3387)  time: 0.1298  data: 0.0991  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2518 (1.1446)  acc1: 76.5625 (78.0615)  acc5: 91.1458 (91.8699)  time: 0.1334  data: 0.1027  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0967 (1.1421)  acc1: 74.4792 (77.6757)  acc5: 92.7083 (92.1364)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2191 (1.1505)  acc1: 74.4792 (77.5800)  acc5: 92.7083 (92.1800)  time: 0.1058  data: 0.0761  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1329 s / it)\n",
            "* Acc@1 77.580 Acc@5 92.180 loss 1.150\n",
            "Accuracy of the network on the 10000 test images: 77.6%\n",
            "Max accuracy: 77.67%\n",
            "Epoch: [66]  [  0/781]  eta: 0:14:45  lr: 0.000024  loss: 1.6335 (1.6335)  time: 1.1334  data: 0.7862  max mem: 6459\n",
            "Epoch: [66]  [ 10/781]  eta: 0:05:13  lr: 0.000024  loss: 1.2817 (1.3464)  time: 0.4061  data: 0.0717  max mem: 6459\n",
            "Epoch: [66]  [ 20/781]  eta: 0:04:42  lr: 0.000024  loss: 1.2918 (1.3868)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 30/781]  eta: 0:04:29  lr: 0.000024  loss: 1.3089 (1.4281)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 40/781]  eta: 0:04:21  lr: 0.000024  loss: 1.3080 (1.4067)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 50/781]  eta: 0:04:15  lr: 0.000024  loss: 1.3080 (1.3952)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 60/781]  eta: 0:04:09  lr: 0.000024  loss: 1.2951 (1.3888)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 70/781]  eta: 0:04:05  lr: 0.000024  loss: 1.2951 (1.3902)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 80/781]  eta: 0:04:00  lr: 0.000024  loss: 1.3166 (1.4003)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [ 90/781]  eta: 0:03:56  lr: 0.000024  loss: 1.2519 (1.3972)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [100/781]  eta: 0:03:52  lr: 0.000024  loss: 1.2467 (1.4074)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [110/781]  eta: 0:03:48  lr: 0.000024  loss: 1.3371 (1.4425)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [120/781]  eta: 0:03:44  lr: 0.000024  loss: 1.3193 (1.4373)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [130/781]  eta: 0:03:41  lr: 0.000024  loss: 1.2914 (1.4317)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [140/781]  eta: 0:03:37  lr: 0.000024  loss: 1.2986 (1.4353)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [150/781]  eta: 0:03:33  lr: 0.000024  loss: 1.3032 (1.4448)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [160/781]  eta: 0:03:30  lr: 0.000024  loss: 1.3237 (1.4476)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [170/781]  eta: 0:03:26  lr: 0.000024  loss: 1.3259 (1.4470)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [180/781]  eta: 0:03:22  lr: 0.000024  loss: 1.3255 (1.4414)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [190/781]  eta: 0:03:19  lr: 0.000024  loss: 1.3109 (1.4419)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [200/781]  eta: 0:03:15  lr: 0.000024  loss: 1.2836 (1.4346)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [210/781]  eta: 0:03:12  lr: 0.000024  loss: 1.2890 (1.4328)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [220/781]  eta: 0:03:09  lr: 0.000024  loss: 1.2901 (1.4256)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [230/781]  eta: 0:03:05  lr: 0.000024  loss: 1.2901 (1.4210)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [240/781]  eta: 0:03:02  lr: 0.000024  loss: 1.3427 (1.4211)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [250/781]  eta: 0:02:58  lr: 0.000024  loss: 1.3340 (1.4244)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [260/781]  eta: 0:02:55  lr: 0.000024  loss: 1.3390 (1.4262)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [270/781]  eta: 0:02:51  lr: 0.000024  loss: 1.3296 (1.4254)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [280/781]  eta: 0:02:48  lr: 0.000024  loss: 1.3296 (1.4292)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [290/781]  eta: 0:02:44  lr: 0.000024  loss: 1.3414 (1.4256)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [300/781]  eta: 0:02:41  lr: 0.000024  loss: 1.3337 (1.4248)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [310/781]  eta: 0:02:38  lr: 0.000024  loss: 1.3337 (1.4272)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [320/781]  eta: 0:02:34  lr: 0.000024  loss: 1.2969 (1.4246)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [330/781]  eta: 0:02:31  lr: 0.000024  loss: 1.2740 (1.4203)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [340/781]  eta: 0:02:28  lr: 0.000024  loss: 1.2865 (1.4237)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [350/781]  eta: 0:02:24  lr: 0.000024  loss: 1.3259 (1.4230)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [360/781]  eta: 0:02:21  lr: 0.000024  loss: 1.3319 (1.4234)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [370/781]  eta: 0:02:17  lr: 0.000024  loss: 1.2860 (1.4213)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [380/781]  eta: 0:02:14  lr: 0.000024  loss: 1.2860 (1.4215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [390/781]  eta: 0:02:11  lr: 0.000024  loss: 1.3290 (1.4226)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [400/781]  eta: 0:02:07  lr: 0.000024  loss: 1.3324 (1.4196)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [410/781]  eta: 0:02:04  lr: 0.000024  loss: 1.2944 (1.4172)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [420/781]  eta: 0:02:01  lr: 0.000024  loss: 1.3622 (1.4220)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [430/781]  eta: 0:01:57  lr: 0.000024  loss: 1.3742 (1.4237)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [440/781]  eta: 0:01:54  lr: 0.000024  loss: 1.3038 (1.4232)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [450/781]  eta: 0:01:50  lr: 0.000024  loss: 1.2675 (1.4216)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [460/781]  eta: 0:01:47  lr: 0.000024  loss: 1.2605 (1.4186)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [470/781]  eta: 0:01:44  lr: 0.000024  loss: 1.2532 (1.4165)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [480/781]  eta: 0:01:40  lr: 0.000024  loss: 1.2815 (1.4152)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [490/781]  eta: 0:01:37  lr: 0.000024  loss: 1.2967 (1.4163)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [500/781]  eta: 0:01:34  lr: 0.000024  loss: 1.3432 (1.4215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [510/781]  eta: 0:01:30  lr: 0.000024  loss: 1.3440 (1.4208)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [520/781]  eta: 0:01:27  lr: 0.000024  loss: 1.3302 (1.4250)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [530/781]  eta: 0:01:24  lr: 0.000024  loss: 1.3213 (1.4250)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [540/781]  eta: 0:01:20  lr: 0.000024  loss: 1.3295 (1.4256)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [550/781]  eta: 0:01:17  lr: 0.000024  loss: 1.3427 (1.4289)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [560/781]  eta: 0:01:13  lr: 0.000024  loss: 1.3427 (1.4292)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [570/781]  eta: 0:01:10  lr: 0.000024  loss: 1.3031 (1.4270)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [580/781]  eta: 0:01:07  lr: 0.000024  loss: 1.3209 (1.4305)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [590/781]  eta: 0:01:03  lr: 0.000024  loss: 1.3228 (1.4302)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [600/781]  eta: 0:01:00  lr: 0.000024  loss: 1.3335 (1.4312)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [610/781]  eta: 0:00:57  lr: 0.000024  loss: 1.3577 (1.4313)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [620/781]  eta: 0:00:53  lr: 0.000024  loss: 1.3019 (1.4315)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [630/781]  eta: 0:00:50  lr: 0.000024  loss: 1.3287 (1.4306)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [640/781]  eta: 0:00:47  lr: 0.000024  loss: 1.3401 (1.4323)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [650/781]  eta: 0:00:43  lr: 0.000024  loss: 1.3134 (1.4333)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [660/781]  eta: 0:00:40  lr: 0.000024  loss: 1.2965 (1.4345)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [670/781]  eta: 0:00:37  lr: 0.000024  loss: 1.3239 (1.4336)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [680/781]  eta: 0:00:33  lr: 0.000024  loss: 1.3096 (1.4323)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [690/781]  eta: 0:00:30  lr: 0.000024  loss: 1.3256 (1.4324)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [700/781]  eta: 0:00:27  lr: 0.000024  loss: 1.3639 (1.4326)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [710/781]  eta: 0:00:23  lr: 0.000024  loss: 1.3201 (1.4331)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [720/781]  eta: 0:00:20  lr: 0.000024  loss: 1.2659 (1.4305)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [730/781]  eta: 0:00:17  lr: 0.000024  loss: 1.3276 (1.4333)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [740/781]  eta: 0:00:13  lr: 0.000024  loss: 1.3598 (1.4334)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [750/781]  eta: 0:00:10  lr: 0.000024  loss: 1.2964 (1.4318)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [760/781]  eta: 0:00:07  lr: 0.000024  loss: 1.3232 (1.4320)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [770/781]  eta: 0:00:03  lr: 0.000024  loss: 1.3447 (1.4351)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [66]  [780/781]  eta: 0:00:00  lr: 0.000024  loss: 1.3235 (1.4366)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [66] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000024  loss: 1.3235 (1.4366)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32899031043052673, 'lambda_convnext_base': 0.25938865542411804, 'lambda_tf_efficientnetv2_l': 0.4116211235523224}\n",
            "Test:  [ 0/53]  eta: 0:00:46  loss: 0.7624 (0.7624)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8691  data: 0.8382  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9394 (0.9831)  acc1: 82.8125 (80.4924)  acc5: 94.7917 (94.0341)  time: 0.1690  data: 0.1383  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0574 (1.0587)  acc1: 78.6458 (79.4891)  acc5: 93.2292 (92.8571)  time: 0.1173  data: 0.0866  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1569 (1.1057)  acc1: 77.0833 (78.7634)  acc5: 91.6667 (92.3387)  time: 0.1222  data: 0.0913  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2272 (1.1429)  acc1: 76.0417 (78.0615)  acc5: 91.6667 (92.0859)  time: 0.1248  data: 0.0939  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1028 (1.1383)  acc1: 76.0417 (77.8391)  acc5: 92.7083 (92.3101)  time: 0.1222  data: 0.0915  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1231 (1.1513)  acc1: 75.5208 (77.7500)  acc5: 93.2292 (92.3400)  time: 0.1032  data: 0.0735  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1289 s / it)\n",
            "* Acc@1 77.750 Acc@5 92.340 loss 1.151\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.75%\n",
            "Epoch: [67]  [  0/781]  eta: 0:14:31  lr: 0.000024  loss: 1.2675 (1.2675)  time: 1.1161  data: 0.7778  max mem: 6459\n",
            "Epoch: [67]  [ 10/781]  eta: 0:05:11  lr: 0.000024  loss: 1.3856 (1.4385)  time: 0.4045  data: 0.0710  max mem: 6459\n",
            "Epoch: [67]  [ 20/781]  eta: 0:04:41  lr: 0.000024  loss: 1.3319 (1.4083)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 30/781]  eta: 0:04:29  lr: 0.000024  loss: 1.2847 (1.3922)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 40/781]  eta: 0:04:20  lr: 0.000024  loss: 1.2866 (1.4266)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 50/781]  eta: 0:04:14  lr: 0.000024  loss: 1.2840 (1.4195)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 60/781]  eta: 0:04:09  lr: 0.000024  loss: 1.2973 (1.4301)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 70/781]  eta: 0:04:04  lr: 0.000024  loss: 1.3242 (1.4610)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 80/781]  eta: 0:04:00  lr: 0.000024  loss: 1.3357 (1.4609)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [ 90/781]  eta: 0:03:56  lr: 0.000024  loss: 1.3261 (1.4654)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [100/781]  eta: 0:03:52  lr: 0.000024  loss: 1.2722 (1.4500)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [110/781]  eta: 0:03:48  lr: 0.000024  loss: 1.2946 (1.4468)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [120/781]  eta: 0:03:44  lr: 0.000024  loss: 1.2747 (1.4473)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [130/781]  eta: 0:03:40  lr: 0.000024  loss: 1.2910 (1.4564)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [140/781]  eta: 0:03:37  lr: 0.000024  loss: 1.2931 (1.4439)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [150/781]  eta: 0:03:33  lr: 0.000024  loss: 1.3535 (1.4614)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [160/781]  eta: 0:03:30  lr: 0.000024  loss: 1.3245 (1.4600)  time: 0.3436  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [170/781]  eta: 0:03:27  lr: 0.000024  loss: 1.3032 (1.4640)  time: 0.3440  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [180/781]  eta: 0:03:23  lr: 0.000024  loss: 1.3316 (1.4642)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [190/781]  eta: 0:03:20  lr: 0.000024  loss: 1.3410 (1.4651)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [200/781]  eta: 0:03:16  lr: 0.000024  loss: 1.3050 (1.4588)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [210/781]  eta: 0:03:12  lr: 0.000024  loss: 1.2926 (1.4534)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [220/781]  eta: 0:03:09  lr: 0.000024  loss: 1.3331 (1.4580)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [230/781]  eta: 0:03:05  lr: 0.000024  loss: 1.3624 (1.4605)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [240/781]  eta: 0:03:02  lr: 0.000024  loss: 1.2953 (1.4561)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [250/781]  eta: 0:02:59  lr: 0.000024  loss: 1.2687 (1.4535)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [260/781]  eta: 0:02:55  lr: 0.000024  loss: 1.2722 (1.4479)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [270/781]  eta: 0:02:52  lr: 0.000024  loss: 1.3008 (1.4515)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [280/781]  eta: 0:02:48  lr: 0.000024  loss: 1.2738 (1.4529)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [290/781]  eta: 0:02:45  lr: 0.000024  loss: 1.2745 (1.4496)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [300/781]  eta: 0:02:41  lr: 0.000024  loss: 1.3196 (1.4550)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [310/781]  eta: 0:02:38  lr: 0.000024  loss: 1.3222 (1.4538)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [320/781]  eta: 0:02:35  lr: 0.000024  loss: 1.3059 (1.4524)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [330/781]  eta: 0:02:31  lr: 0.000024  loss: 1.2991 (1.4525)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [340/781]  eta: 0:02:28  lr: 0.000024  loss: 1.3040 (1.4548)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [350/781]  eta: 0:02:24  lr: 0.000024  loss: 1.3465 (1.4542)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [360/781]  eta: 0:02:21  lr: 0.000024  loss: 1.3750 (1.4578)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [370/781]  eta: 0:02:18  lr: 0.000024  loss: 1.3729 (1.4553)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [380/781]  eta: 0:02:14  lr: 0.000024  loss: 1.3635 (1.4586)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [390/781]  eta: 0:02:11  lr: 0.000024  loss: 1.3319 (1.4614)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [400/781]  eta: 0:02:07  lr: 0.000024  loss: 1.2946 (1.4618)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [410/781]  eta: 0:02:04  lr: 0.000024  loss: 1.3003 (1.4627)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [420/781]  eta: 0:02:01  lr: 0.000024  loss: 1.2908 (1.4603)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [430/781]  eta: 0:01:57  lr: 0.000024  loss: 1.2797 (1.4581)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [440/781]  eta: 0:01:54  lr: 0.000024  loss: 1.3084 (1.4605)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [450/781]  eta: 0:01:51  lr: 0.000024  loss: 1.3405 (1.4652)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [460/781]  eta: 0:01:47  lr: 0.000024  loss: 1.3437 (1.4695)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [470/781]  eta: 0:01:44  lr: 0.000024  loss: 1.3072 (1.4679)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [480/781]  eta: 0:01:40  lr: 0.000024  loss: 1.2801 (1.4663)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [490/781]  eta: 0:01:37  lr: 0.000024  loss: 1.2873 (1.4637)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [500/781]  eta: 0:01:34  lr: 0.000024  loss: 1.2840 (1.4638)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [510/781]  eta: 0:01:30  lr: 0.000024  loss: 1.2642 (1.4630)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [520/781]  eta: 0:01:27  lr: 0.000024  loss: 1.2686 (1.4629)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [530/781]  eta: 0:01:24  lr: 0.000024  loss: 1.2977 (1.4607)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [540/781]  eta: 0:01:20  lr: 0.000024  loss: 1.3455 (1.4604)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [550/781]  eta: 0:01:17  lr: 0.000024  loss: 1.3294 (1.4591)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [560/781]  eta: 0:01:14  lr: 0.000024  loss: 1.2861 (1.4561)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [570/781]  eta: 0:01:10  lr: 0.000024  loss: 1.2792 (1.4552)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [580/781]  eta: 0:01:07  lr: 0.000024  loss: 1.2601 (1.4539)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [590/781]  eta: 0:01:03  lr: 0.000024  loss: 1.3042 (1.4543)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [600/781]  eta: 0:01:00  lr: 0.000024  loss: 1.3348 (1.4544)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [610/781]  eta: 0:00:57  lr: 0.000024  loss: 1.3880 (1.4592)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [620/781]  eta: 0:00:53  lr: 0.000024  loss: 1.3957 (1.4604)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [630/781]  eta: 0:00:50  lr: 0.000024  loss: 1.3838 (1.4633)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [640/781]  eta: 0:00:47  lr: 0.000024  loss: 1.3782 (1.4632)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [650/781]  eta: 0:00:43  lr: 0.000024  loss: 1.3466 (1.4643)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [660/781]  eta: 0:00:40  lr: 0.000024  loss: 1.2877 (1.4616)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [670/781]  eta: 0:00:37  lr: 0.000024  loss: 1.3216 (1.4613)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [680/781]  eta: 0:00:33  lr: 0.000024  loss: 1.3478 (1.4595)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [690/781]  eta: 0:00:30  lr: 0.000024  loss: 1.2891 (1.4579)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [700/781]  eta: 0:00:27  lr: 0.000024  loss: 1.2793 (1.4554)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [710/781]  eta: 0:00:23  lr: 0.000024  loss: 1.3024 (1.4568)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [720/781]  eta: 0:00:20  lr: 0.000024  loss: 1.2905 (1.4566)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [730/781]  eta: 0:00:17  lr: 0.000024  loss: 1.2973 (1.4549)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [740/781]  eta: 0:00:13  lr: 0.000024  loss: 1.3195 (1.4530)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [750/781]  eta: 0:00:10  lr: 0.000024  loss: 1.2975 (1.4513)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [760/781]  eta: 0:00:07  lr: 0.000024  loss: 1.2688 (1.4496)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [770/781]  eta: 0:00:03  lr: 0.000024  loss: 1.3020 (1.4477)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [67]  [780/781]  eta: 0:00:00  lr: 0.000024  loss: 1.3287 (1.4472)  time: 0.3331  data: 0.0006  max mem: 6459\n",
            "Epoch: [67] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000024  loss: 1.3287 (1.4472)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290823698043823, 'lambda_convnext_base': 0.25969523191452026, 'lambda_tf_efficientnetv2_l': 0.41122257709503174}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8503 (0.8503)  acc1: 82.2917 (82.2917)  acc5: 93.7500 (93.7500)  time: 0.8399  data: 0.8090  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 1.0245 (0.9959)  acc1: 82.2917 (80.4924)  acc5: 94.2708 (93.4659)  time: 0.1656  data: 0.1344  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0245 (1.0325)  acc1: 80.2083 (80.0099)  acc5: 93.2292 (92.7827)  time: 0.1213  data: 0.0903  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1335 (1.0899)  acc1: 77.0833 (78.9819)  acc5: 91.1458 (92.1875)  time: 0.1241  data: 0.0933  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2144 (1.1396)  acc1: 75.5208 (77.9218)  acc5: 90.6250 (91.7302)  time: 0.1222  data: 0.0915  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1435 (1.1394)  acc1: 76.0417 (77.7165)  acc5: 91.6667 (91.9424)  time: 0.1254  data: 0.0947  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1890 (1.1487)  acc1: 75.0000 (77.6600)  acc5: 92.1875 (91.9700)  time: 0.1065  data: 0.0768  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1303 s / it)\n",
            "* Acc@1 77.660 Acc@5 91.970 loss 1.149\n",
            "Accuracy of the network on the 10000 test images: 77.7%\n",
            "Max accuracy: 77.75%\n",
            "Epoch: [68]  [  0/781]  eta: 0:14:07  lr: 0.000023  loss: 1.2020 (1.2020)  time: 1.0851  data: 0.7379  max mem: 6459\n",
            "Epoch: [68]  [ 10/781]  eta: 0:05:09  lr: 0.000023  loss: 1.2970 (1.3346)  time: 0.4019  data: 0.0674  max mem: 6459\n",
            "Epoch: [68]  [ 20/781]  eta: 0:04:41  lr: 0.000023  loss: 1.2981 (1.3201)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 30/781]  eta: 0:04:28  lr: 0.000023  loss: 1.3025 (1.3497)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 40/781]  eta: 0:04:20  lr: 0.000023  loss: 1.3053 (1.3459)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 50/781]  eta: 0:04:14  lr: 0.000023  loss: 1.3065 (1.3712)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 60/781]  eta: 0:04:09  lr: 0.000023  loss: 1.3252 (1.3766)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 70/781]  eta: 0:04:04  lr: 0.000023  loss: 1.3031 (1.3839)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 80/781]  eta: 0:04:00  lr: 0.000023  loss: 1.3020 (1.3895)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [ 90/781]  eta: 0:03:56  lr: 0.000023  loss: 1.3260 (1.4050)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [100/781]  eta: 0:03:52  lr: 0.000023  loss: 1.3260 (1.4151)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [110/781]  eta: 0:03:48  lr: 0.000023  loss: 1.3451 (1.4135)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [120/781]  eta: 0:03:44  lr: 0.000023  loss: 1.3234 (1.4115)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [130/781]  eta: 0:03:40  lr: 0.000023  loss: 1.3108 (1.4112)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [140/781]  eta: 0:03:37  lr: 0.000023  loss: 1.2969 (1.4101)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [150/781]  eta: 0:03:33  lr: 0.000023  loss: 1.3191 (1.4039)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [160/781]  eta: 0:03:30  lr: 0.000023  loss: 1.3191 (1.4209)  time: 0.3347  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [170/781]  eta: 0:03:26  lr: 0.000023  loss: 1.2952 (1.4152)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [180/781]  eta: 0:03:22  lr: 0.000023  loss: 1.2945 (1.4106)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [190/781]  eta: 0:03:19  lr: 0.000023  loss: 1.3142 (1.4104)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [200/781]  eta: 0:03:15  lr: 0.000023  loss: 1.3421 (1.4165)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [210/781]  eta: 0:03:12  lr: 0.000023  loss: 1.3421 (1.4192)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [220/781]  eta: 0:03:09  lr: 0.000023  loss: 1.4016 (1.4319)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [230/781]  eta: 0:03:05  lr: 0.000023  loss: 1.3841 (1.4340)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [240/781]  eta: 0:03:02  lr: 0.000023  loss: 1.3079 (1.4274)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [250/781]  eta: 0:02:58  lr: 0.000023  loss: 1.2948 (1.4235)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [260/781]  eta: 0:02:55  lr: 0.000023  loss: 1.2948 (1.4230)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [270/781]  eta: 0:02:51  lr: 0.000023  loss: 1.3431 (1.4249)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [280/781]  eta: 0:02:48  lr: 0.000023  loss: 1.3539 (1.4251)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [290/781]  eta: 0:02:44  lr: 0.000023  loss: 1.2894 (1.4203)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [300/781]  eta: 0:02:41  lr: 0.000023  loss: 1.3082 (1.4193)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [310/781]  eta: 0:02:38  lr: 0.000023  loss: 1.3190 (1.4229)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [320/781]  eta: 0:02:34  lr: 0.000023  loss: 1.3135 (1.4231)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [330/781]  eta: 0:02:31  lr: 0.000023  loss: 1.3048 (1.4225)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [340/781]  eta: 0:02:28  lr: 0.000023  loss: 1.2592 (1.4180)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [350/781]  eta: 0:02:24  lr: 0.000023  loss: 1.2615 (1.4164)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [360/781]  eta: 0:02:21  lr: 0.000023  loss: 1.2615 (1.4167)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [370/781]  eta: 0:02:17  lr: 0.000023  loss: 1.2516 (1.4142)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [380/781]  eta: 0:02:14  lr: 0.000023  loss: 1.2632 (1.4117)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [390/781]  eta: 0:02:11  lr: 0.000023  loss: 1.3268 (1.4114)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [400/781]  eta: 0:02:07  lr: 0.000023  loss: 1.3334 (1.4124)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [410/781]  eta: 0:02:04  lr: 0.000023  loss: 1.2684 (1.4083)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [420/781]  eta: 0:02:01  lr: 0.000023  loss: 1.2414 (1.4054)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [430/781]  eta: 0:01:57  lr: 0.000023  loss: 1.3158 (1.4111)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [440/781]  eta: 0:01:54  lr: 0.000023  loss: 1.3636 (1.4136)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [450/781]  eta: 0:01:50  lr: 0.000023  loss: 1.3334 (1.4157)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [460/781]  eta: 0:01:47  lr: 0.000023  loss: 1.3418 (1.4173)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [470/781]  eta: 0:01:44  lr: 0.000023  loss: 1.3452 (1.4179)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [480/781]  eta: 0:01:40  lr: 0.000023  loss: 1.2828 (1.4150)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [490/781]  eta: 0:01:37  lr: 0.000023  loss: 1.2722 (1.4167)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [500/781]  eta: 0:01:34  lr: 0.000023  loss: 1.3283 (1.4203)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [510/781]  eta: 0:01:30  lr: 0.000023  loss: 1.3331 (1.4211)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [520/781]  eta: 0:01:27  lr: 0.000023  loss: 1.3304 (1.4230)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [530/781]  eta: 0:01:24  lr: 0.000023  loss: 1.3475 (1.4239)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [540/781]  eta: 0:01:20  lr: 0.000023  loss: 1.3806 (1.4237)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [550/781]  eta: 0:01:17  lr: 0.000023  loss: 1.3098 (1.4223)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [560/781]  eta: 0:01:13  lr: 0.000023  loss: 1.2550 (1.4212)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [570/781]  eta: 0:01:10  lr: 0.000023  loss: 1.3098 (1.4246)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [580/781]  eta: 0:01:07  lr: 0.000023  loss: 1.3451 (1.4236)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [590/781]  eta: 0:01:03  lr: 0.000023  loss: 1.3203 (1.4248)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [600/781]  eta: 0:01:00  lr: 0.000023  loss: 1.3028 (1.4233)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [610/781]  eta: 0:00:57  lr: 0.000023  loss: 1.3283 (1.4240)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [620/781]  eta: 0:00:53  lr: 0.000023  loss: 1.2793 (1.4220)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [630/781]  eta: 0:00:50  lr: 0.000023  loss: 1.2660 (1.4246)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [640/781]  eta: 0:00:47  lr: 0.000023  loss: 1.3247 (1.4250)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [650/781]  eta: 0:00:43  lr: 0.000023  loss: 1.3247 (1.4260)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [660/781]  eta: 0:00:40  lr: 0.000023  loss: 1.3210 (1.4258)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [670/781]  eta: 0:00:37  lr: 0.000023  loss: 1.3595 (1.4303)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [680/781]  eta: 0:00:33  lr: 0.000023  loss: 1.4193 (1.4310)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [690/781]  eta: 0:00:30  lr: 0.000023  loss: 1.2845 (1.4293)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [700/781]  eta: 0:00:27  lr: 0.000023  loss: 1.3119 (1.4309)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [710/781]  eta: 0:00:23  lr: 0.000023  loss: 1.3362 (1.4307)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [720/781]  eta: 0:00:20  lr: 0.000023  loss: 1.3260 (1.4331)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [730/781]  eta: 0:00:17  lr: 0.000023  loss: 1.3242 (1.4315)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [740/781]  eta: 0:00:13  lr: 0.000023  loss: 1.3254 (1.4343)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [750/781]  eta: 0:00:10  lr: 0.000023  loss: 1.4249 (1.4373)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [760/781]  eta: 0:00:07  lr: 0.000023  loss: 1.3274 (1.4360)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [770/781]  eta: 0:00:03  lr: 0.000023  loss: 1.2888 (1.4346)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [68]  [780/781]  eta: 0:00:00  lr: 0.000023  loss: 1.3131 (1.4352)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [68] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000023  loss: 1.3131 (1.4352)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3280598521232605, 'lambda_convnext_base': 0.25917699933052063, 'lambda_tf_efficientnetv2_l': 0.412762850522995}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8194 (0.8194)  acc1: 82.8125 (82.8125)  acc5: 93.2292 (93.2292)  time: 0.8451  data: 0.8142  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9349 (0.9612)  acc1: 82.8125 (81.6288)  acc5: 93.7500 (93.3712)  time: 0.1675  data: 0.1368  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0534 (1.0281)  acc1: 76.5625 (80.2083)  acc5: 93.7500 (92.7331)  time: 0.1223  data: 0.0916  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1530 (1.0802)  acc1: 75.5208 (79.1667)  acc5: 91.1458 (92.3051)  time: 0.1248  data: 0.0941  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2453 (1.1261)  acc1: 75.5208 (78.2266)  acc5: 91.1458 (91.8572)  time: 0.1219  data: 0.0912  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1453 (1.1265)  acc1: 76.0417 (77.8595)  acc5: 92.1875 (92.1160)  time: 0.1249  data: 0.0942  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1679 (1.1407)  acc1: 76.0417 (77.7500)  acc5: 92.7083 (92.1400)  time: 0.1059  data: 0.0761  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1306 s / it)\n",
            "* Acc@1 77.750 Acc@5 92.140 loss 1.141\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.75%\n",
            "Epoch: [69]  [  0/781]  eta: 0:14:43  lr: 0.000022  loss: 1.2141 (1.2141)  time: 1.1315  data: 0.7934  max mem: 6459\n",
            "Epoch: [69]  [ 10/781]  eta: 0:05:13  lr: 0.000022  loss: 1.2736 (1.4026)  time: 0.4061  data: 0.0724  max mem: 6459\n",
            "Epoch: [69]  [ 20/781]  eta: 0:04:42  lr: 0.000022  loss: 1.2979 (1.4345)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 30/781]  eta: 0:04:29  lr: 0.000022  loss: 1.2979 (1.4063)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 40/781]  eta: 0:04:21  lr: 0.000022  loss: 1.2711 (1.4146)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 50/781]  eta: 0:04:15  lr: 0.000022  loss: 1.2466 (1.3819)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 60/781]  eta: 0:04:09  lr: 0.000022  loss: 1.2466 (1.3791)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 70/781]  eta: 0:04:04  lr: 0.000022  loss: 1.2973 (1.3852)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 80/781]  eta: 0:04:00  lr: 0.000022  loss: 1.3236 (1.3859)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [ 90/781]  eta: 0:03:56  lr: 0.000022  loss: 1.2922 (1.3824)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [100/781]  eta: 0:03:52  lr: 0.000022  loss: 1.3186 (1.3965)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [110/781]  eta: 0:03:48  lr: 0.000022  loss: 1.3334 (1.3889)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [120/781]  eta: 0:03:44  lr: 0.000022  loss: 1.2837 (1.4075)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [130/781]  eta: 0:03:40  lr: 0.000022  loss: 1.2753 (1.4132)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [140/781]  eta: 0:03:37  lr: 0.000022  loss: 1.2991 (1.4129)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [150/781]  eta: 0:03:33  lr: 0.000022  loss: 1.3130 (1.4063)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [160/781]  eta: 0:03:30  lr: 0.000022  loss: 1.3234 (1.4072)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [170/781]  eta: 0:03:26  lr: 0.000022  loss: 1.3234 (1.4172)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [180/781]  eta: 0:03:22  lr: 0.000022  loss: 1.2611 (1.4137)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [190/781]  eta: 0:03:19  lr: 0.000022  loss: 1.2526 (1.4116)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [200/781]  eta: 0:03:15  lr: 0.000022  loss: 1.2573 (1.4098)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [210/781]  eta: 0:03:12  lr: 0.000022  loss: 1.2633 (1.4087)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [220/781]  eta: 0:03:09  lr: 0.000022  loss: 1.2696 (1.4128)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [230/781]  eta: 0:03:05  lr: 0.000022  loss: 1.3186 (1.4236)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [240/781]  eta: 0:03:02  lr: 0.000022  loss: 1.3186 (1.4219)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [250/781]  eta: 0:02:58  lr: 0.000022  loss: 1.2688 (1.4218)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [260/781]  eta: 0:02:55  lr: 0.000022  loss: 1.2904 (1.4267)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [270/781]  eta: 0:02:51  lr: 0.000022  loss: 1.3310 (1.4239)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [280/781]  eta: 0:02:48  lr: 0.000022  loss: 1.2742 (1.4194)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [290/781]  eta: 0:02:45  lr: 0.000022  loss: 1.2689 (1.4222)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [300/781]  eta: 0:02:41  lr: 0.000022  loss: 1.2848 (1.4246)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [310/781]  eta: 0:02:38  lr: 0.000022  loss: 1.3231 (1.4302)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [320/781]  eta: 0:02:34  lr: 0.000022  loss: 1.3718 (1.4331)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [330/781]  eta: 0:02:31  lr: 0.000022  loss: 1.3718 (1.4302)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [340/781]  eta: 0:02:28  lr: 0.000022  loss: 1.3347 (1.4370)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [350/781]  eta: 0:02:24  lr: 0.000022  loss: 1.3062 (1.4352)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [360/781]  eta: 0:02:21  lr: 0.000022  loss: 1.2987 (1.4399)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [370/781]  eta: 0:02:17  lr: 0.000022  loss: 1.3448 (1.4406)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [380/781]  eta: 0:02:14  lr: 0.000022  loss: 1.3100 (1.4374)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [390/781]  eta: 0:02:11  lr: 0.000022  loss: 1.3261 (1.4391)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [400/781]  eta: 0:02:07  lr: 0.000022  loss: 1.3687 (1.4405)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [410/781]  eta: 0:02:04  lr: 0.000022  loss: 1.3972 (1.4493)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [420/781]  eta: 0:02:01  lr: 0.000022  loss: 1.4421 (1.4526)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [430/781]  eta: 0:01:57  lr: 0.000022  loss: 1.3180 (1.4551)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [440/781]  eta: 0:01:54  lr: 0.000022  loss: 1.3218 (1.4580)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [450/781]  eta: 0:01:50  lr: 0.000022  loss: 1.2863 (1.4545)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [460/781]  eta: 0:01:47  lr: 0.000022  loss: 1.2607 (1.4505)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [470/781]  eta: 0:01:44  lr: 0.000022  loss: 1.2502 (1.4509)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [480/781]  eta: 0:01:40  lr: 0.000022  loss: 1.2923 (1.4502)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [490/781]  eta: 0:01:37  lr: 0.000022  loss: 1.3032 (1.4486)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [500/781]  eta: 0:01:34  lr: 0.000022  loss: 1.3203 (1.4529)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [510/781]  eta: 0:01:30  lr: 0.000022  loss: 1.2986 (1.4501)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [520/781]  eta: 0:01:27  lr: 0.000022  loss: 1.3011 (1.4532)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [530/781]  eta: 0:01:24  lr: 0.000022  loss: 1.3181 (1.4525)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [540/781]  eta: 0:01:20  lr: 0.000022  loss: 1.3077 (1.4525)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [550/781]  eta: 0:01:17  lr: 0.000022  loss: 1.3051 (1.4534)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [560/781]  eta: 0:01:14  lr: 0.000022  loss: 1.3291 (1.4541)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [570/781]  eta: 0:01:10  lr: 0.000022  loss: 1.2917 (1.4535)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [580/781]  eta: 0:01:07  lr: 0.000022  loss: 1.2700 (1.4511)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [590/781]  eta: 0:01:03  lr: 0.000022  loss: 1.2700 (1.4497)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [600/781]  eta: 0:01:00  lr: 0.000022  loss: 1.3607 (1.4512)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [610/781]  eta: 0:00:57  lr: 0.000022  loss: 1.3653 (1.4500)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [620/781]  eta: 0:00:53  lr: 0.000022  loss: 1.3718 (1.4530)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [630/781]  eta: 0:00:50  lr: 0.000022  loss: 1.3649 (1.4543)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [640/781]  eta: 0:00:47  lr: 0.000022  loss: 1.3210 (1.4525)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [650/781]  eta: 0:00:43  lr: 0.000022  loss: 1.3694 (1.4538)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [660/781]  eta: 0:00:40  lr: 0.000022  loss: 1.3744 (1.4541)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [670/781]  eta: 0:00:37  lr: 0.000022  loss: 1.2959 (1.4546)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [680/781]  eta: 0:00:33  lr: 0.000022  loss: 1.2640 (1.4521)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [690/781]  eta: 0:00:30  lr: 0.000022  loss: 1.2715 (1.4547)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [700/781]  eta: 0:00:27  lr: 0.000022  loss: 1.3348 (1.4546)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [710/781]  eta: 0:00:23  lr: 0.000022  loss: 1.3718 (1.4572)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [720/781]  eta: 0:00:20  lr: 0.000022  loss: 1.3984 (1.4580)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [730/781]  eta: 0:00:17  lr: 0.000022  loss: 1.3389 (1.4572)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [740/781]  eta: 0:00:13  lr: 0.000022  loss: 1.3474 (1.4593)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [750/781]  eta: 0:00:10  lr: 0.000022  loss: 1.3416 (1.4577)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [760/781]  eta: 0:00:07  lr: 0.000022  loss: 1.3416 (1.4591)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [770/781]  eta: 0:00:03  lr: 0.000022  loss: 1.3404 (1.4585)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [69]  [780/781]  eta: 0:00:00  lr: 0.000022  loss: 1.3186 (1.4596)  time: 0.3338  data: 0.0005  max mem: 6459\n",
            "Epoch: [69] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000022  loss: 1.3186 (1.4596)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32900309562683105, 'lambda_convnext_base': 0.2595585584640503, 'lambda_tf_efficientnetv2_l': 0.41143783926963806}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8234 (0.8234)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8450  data: 0.8141  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9414 (0.9716)  acc1: 82.2917 (81.0606)  acc5: 94.7917 (93.7027)  time: 0.1720  data: 0.1413  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9949 (1.0405)  acc1: 79.1667 (80.0347)  acc5: 93.7500 (92.8075)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1996 (1.1027)  acc1: 76.0417 (79.0491)  acc5: 91.1458 (92.1875)  time: 0.1247  data: 0.0941  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3379 (1.1412)  acc1: 74.4792 (78.3283)  acc5: 90.6250 (91.7302)  time: 0.1264  data: 0.0957  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0955 (1.1376)  acc1: 76.5625 (78.0127)  acc5: 92.1875 (92.0547)  time: 0.1250  data: 0.0943  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1863 (1.1484)  acc1: 75.0000 (77.9100)  acc5: 92.7083 (92.0900)  time: 0.1053  data: 0.0756  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1317 s / it)\n",
            "* Acc@1 77.910 Acc@5 92.090 loss 1.148\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.91%\n",
            "Epoch: [70]  [  0/781]  eta: 0:14:48  lr: 0.000021  loss: 1.2905 (1.2905)  time: 1.1376  data: 0.7959  max mem: 6459\n",
            "Epoch: [70]  [ 10/781]  eta: 0:05:13  lr: 0.000021  loss: 1.2997 (1.4463)  time: 0.4068  data: 0.0726  max mem: 6459\n",
            "Epoch: [70]  [ 20/781]  eta: 0:04:42  lr: 0.000021  loss: 1.3203 (1.4486)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 30/781]  eta: 0:04:30  lr: 0.000021  loss: 1.3399 (1.4891)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 40/781]  eta: 0:04:21  lr: 0.000021  loss: 1.3328 (1.4708)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 50/781]  eta: 0:04:15  lr: 0.000021  loss: 1.3052 (1.4392)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 60/781]  eta: 0:04:09  lr: 0.000021  loss: 1.2587 (1.4337)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 70/781]  eta: 0:04:05  lr: 0.000021  loss: 1.2628 (1.4278)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 80/781]  eta: 0:04:00  lr: 0.000021  loss: 1.2580 (1.4270)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [ 90/781]  eta: 0:03:56  lr: 0.000021  loss: 1.3024 (1.4199)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [100/781]  eta: 0:03:52  lr: 0.000021  loss: 1.2974 (1.4123)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [110/781]  eta: 0:03:48  lr: 0.000021  loss: 1.3033 (1.4088)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [120/781]  eta: 0:03:44  lr: 0.000021  loss: 1.3210 (1.4086)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [130/781]  eta: 0:03:41  lr: 0.000021  loss: 1.3210 (1.4161)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [140/781]  eta: 0:03:37  lr: 0.000021  loss: 1.2785 (1.4127)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [150/781]  eta: 0:03:33  lr: 0.000021  loss: 1.2962 (1.4285)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [160/781]  eta: 0:03:30  lr: 0.000021  loss: 1.3080 (1.4190)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [170/781]  eta: 0:03:26  lr: 0.000021  loss: 1.2776 (1.4123)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [180/781]  eta: 0:03:23  lr: 0.000021  loss: 1.2641 (1.4055)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [190/781]  eta: 0:03:19  lr: 0.000021  loss: 1.2951 (1.4122)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [200/781]  eta: 0:03:16  lr: 0.000021  loss: 1.3068 (1.4172)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [210/781]  eta: 0:03:12  lr: 0.000021  loss: 1.3165 (1.4158)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [220/781]  eta: 0:03:09  lr: 0.000021  loss: 1.3261 (1.4152)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [230/781]  eta: 0:03:05  lr: 0.000021  loss: 1.3144 (1.4151)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [240/781]  eta: 0:03:02  lr: 0.000021  loss: 1.3150 (1.4158)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [250/781]  eta: 0:02:58  lr: 0.000021  loss: 1.3427 (1.4174)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [260/781]  eta: 0:02:55  lr: 0.000021  loss: 1.2723 (1.4138)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [270/781]  eta: 0:02:51  lr: 0.000021  loss: 1.3168 (1.4217)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [280/781]  eta: 0:02:48  lr: 0.000021  loss: 1.3239 (1.4242)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [290/781]  eta: 0:02:45  lr: 0.000021  loss: 1.3132 (1.4290)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [300/781]  eta: 0:02:41  lr: 0.000021  loss: 1.3143 (1.4332)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [310/781]  eta: 0:02:38  lr: 0.000021  loss: 1.3401 (1.4325)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [320/781]  eta: 0:02:34  lr: 0.000021  loss: 1.3457 (1.4298)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [330/781]  eta: 0:02:31  lr: 0.000021  loss: 1.3910 (1.4368)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [340/781]  eta: 0:02:28  lr: 0.000021  loss: 1.3910 (1.4389)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [350/781]  eta: 0:02:24  lr: 0.000021  loss: 1.3721 (1.4429)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [360/781]  eta: 0:02:21  lr: 0.000021  loss: 1.3213 (1.4453)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [370/781]  eta: 0:02:17  lr: 0.000021  loss: 1.3132 (1.4429)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [380/781]  eta: 0:02:14  lr: 0.000021  loss: 1.3226 (1.4399)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [390/781]  eta: 0:02:11  lr: 0.000021  loss: 1.3330 (1.4415)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [400/781]  eta: 0:02:07  lr: 0.000021  loss: 1.3517 (1.4447)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [410/781]  eta: 0:02:04  lr: 0.000021  loss: 1.3057 (1.4404)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [420/781]  eta: 0:02:01  lr: 0.000021  loss: 1.2706 (1.4372)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [430/781]  eta: 0:01:57  lr: 0.000021  loss: 1.3172 (1.4408)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [440/781]  eta: 0:01:54  lr: 0.000021  loss: 1.3417 (1.4390)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [450/781]  eta: 0:01:51  lr: 0.000021  loss: 1.2943 (1.4392)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [460/781]  eta: 0:01:47  lr: 0.000021  loss: 1.2342 (1.4340)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [470/781]  eta: 0:01:44  lr: 0.000021  loss: 1.2029 (1.4338)  time: 0.3352  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [480/781]  eta: 0:01:40  lr: 0.000021  loss: 1.2696 (1.4350)  time: 0.3354  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [490/781]  eta: 0:01:37  lr: 0.000021  loss: 1.3314 (1.4351)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [500/781]  eta: 0:01:34  lr: 0.000021  loss: 1.3331 (1.4350)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [510/781]  eta: 0:01:30  lr: 0.000021  loss: 1.3255 (1.4366)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [520/781]  eta: 0:01:27  lr: 0.000021  loss: 1.3020 (1.4343)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [530/781]  eta: 0:01:24  lr: 0.000021  loss: 1.2825 (1.4332)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [540/781]  eta: 0:01:20  lr: 0.000021  loss: 1.3275 (1.4359)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [550/781]  eta: 0:01:17  lr: 0.000021  loss: 1.2972 (1.4336)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [560/781]  eta: 0:01:14  lr: 0.000021  loss: 1.2938 (1.4341)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [570/781]  eta: 0:01:10  lr: 0.000021  loss: 1.2966 (1.4345)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [580/781]  eta: 0:01:07  lr: 0.000021  loss: 1.2939 (1.4323)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [590/781]  eta: 0:01:04  lr: 0.000021  loss: 1.2939 (1.4335)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [600/781]  eta: 0:01:00  lr: 0.000021  loss: 1.2734 (1.4339)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [610/781]  eta: 0:00:57  lr: 0.000021  loss: 1.2738 (1.4319)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [620/781]  eta: 0:00:53  lr: 0.000021  loss: 1.3535 (1.4345)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [630/781]  eta: 0:00:50  lr: 0.000021  loss: 1.3425 (1.4335)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [640/781]  eta: 0:00:47  lr: 0.000021  loss: 1.3176 (1.4313)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [650/781]  eta: 0:00:43  lr: 0.000021  loss: 1.3086 (1.4320)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [660/781]  eta: 0:00:40  lr: 0.000021  loss: 1.3415 (1.4314)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [670/781]  eta: 0:00:37  lr: 0.000021  loss: 1.3026 (1.4332)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [680/781]  eta: 0:00:33  lr: 0.000021  loss: 1.3224 (1.4338)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [690/781]  eta: 0:00:30  lr: 0.000021  loss: 1.3161 (1.4320)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [700/781]  eta: 0:00:27  lr: 0.000021  loss: 1.2772 (1.4302)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [710/781]  eta: 0:00:23  lr: 0.000021  loss: 1.2726 (1.4290)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [720/781]  eta: 0:00:20  lr: 0.000021  loss: 1.2554 (1.4282)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [730/781]  eta: 0:00:17  lr: 0.000021  loss: 1.2450 (1.4277)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [740/781]  eta: 0:00:13  lr: 0.000021  loss: 1.2963 (1.4315)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [750/781]  eta: 0:00:10  lr: 0.000021  loss: 1.3070 (1.4295)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [760/781]  eta: 0:00:07  lr: 0.000021  loss: 1.3070 (1.4291)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [770/781]  eta: 0:00:03  lr: 0.000021  loss: 1.3176 (1.4319)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [70]  [780/781]  eta: 0:00:00  lr: 0.000021  loss: 1.3311 (1.4309)  time: 0.3337  data: 0.0006  max mem: 6459\n",
            "Epoch: [70] Total time: 0:04:21 (0.3349 s / it)\n",
            "Averaged stats: lr: 0.000021  loss: 1.3311 (1.4309)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3287598192691803, 'lambda_convnext_base': 0.2596709132194519, 'lambda_tf_efficientnetv2_l': 0.41156911849975586}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8364 (0.8364)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8489  data: 0.8180  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9382 (0.9727)  acc1: 83.8542 (81.4394)  acc5: 94.7917 (93.7027)  time: 0.1780  data: 0.1473  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0415 (1.0294)  acc1: 77.6042 (80.0595)  acc5: 93.2292 (92.6587)  time: 0.1210  data: 0.0904  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1743 (1.0917)  acc1: 76.0417 (79.0827)  acc5: 92.1875 (92.1035)  time: 0.1200  data: 0.0893  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2627 (1.1365)  acc1: 75.0000 (78.2901)  acc5: 91.1458 (91.6667)  time: 0.1204  data: 0.0897  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0929 (1.1362)  acc1: 77.6042 (77.9412)  acc5: 91.6667 (91.9526)  time: 0.1235  data: 0.0928  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1082 (1.1499)  acc1: 75.0000 (77.8500)  acc5: 91.6667 (91.9700)  time: 0.1080  data: 0.0783  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1306 s / it)\n",
            "* Acc@1 77.850 Acc@5 91.970 loss 1.150\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.91%\n",
            "Epoch: [71]  [  0/781]  eta: 0:13:52  lr: 0.000021  loss: 2.3418 (2.3418)  time: 1.0665  data: 0.7224  max mem: 6459\n",
            "Epoch: [71]  [ 10/781]  eta: 0:05:08  lr: 0.000021  loss: 1.2752 (1.3990)  time: 0.4007  data: 0.0660  max mem: 6459\n",
            "Epoch: [71]  [ 20/781]  eta: 0:04:40  lr: 0.000021  loss: 1.2785 (1.4131)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 30/781]  eta: 0:04:28  lr: 0.000021  loss: 1.2785 (1.4248)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 40/781]  eta: 0:04:20  lr: 0.000021  loss: 1.2541 (1.4346)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 50/781]  eta: 0:04:14  lr: 0.000021  loss: 1.2765 (1.4474)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 60/781]  eta: 0:04:09  lr: 0.000021  loss: 1.3029 (1.4281)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 70/781]  eta: 0:04:04  lr: 0.000021  loss: 1.3074 (1.4345)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 80/781]  eta: 0:04:00  lr: 0.000021  loss: 1.3063 (1.4349)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [ 90/781]  eta: 0:03:56  lr: 0.000021  loss: 1.3516 (1.4663)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [100/781]  eta: 0:03:52  lr: 0.000021  loss: 1.3516 (1.4656)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [110/781]  eta: 0:03:48  lr: 0.000021  loss: 1.2544 (1.4492)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [120/781]  eta: 0:03:44  lr: 0.000021  loss: 1.3124 (1.4552)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [130/781]  eta: 0:03:40  lr: 0.000021  loss: 1.3845 (1.4583)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [140/781]  eta: 0:03:37  lr: 0.000021  loss: 1.3281 (1.4631)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [150/781]  eta: 0:03:33  lr: 0.000021  loss: 1.3028 (1.4563)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [160/781]  eta: 0:03:29  lr: 0.000021  loss: 1.3046 (1.4595)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [170/781]  eta: 0:03:26  lr: 0.000021  loss: 1.3257 (1.4536)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [180/781]  eta: 0:03:22  lr: 0.000021  loss: 1.3182 (1.4480)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [190/781]  eta: 0:03:19  lr: 0.000021  loss: 1.3154 (1.4437)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [200/781]  eta: 0:03:15  lr: 0.000021  loss: 1.3154 (1.4444)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [210/781]  eta: 0:03:12  lr: 0.000021  loss: 1.3036 (1.4383)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [220/781]  eta: 0:03:08  lr: 0.000021  loss: 1.3036 (1.4423)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [230/781]  eta: 0:03:05  lr: 0.000021  loss: 1.3255 (1.4421)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [240/781]  eta: 0:03:02  lr: 0.000021  loss: 1.2868 (1.4414)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [250/781]  eta: 0:02:58  lr: 0.000021  loss: 1.2868 (1.4364)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [260/781]  eta: 0:02:55  lr: 0.000021  loss: 1.2424 (1.4325)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [270/781]  eta: 0:02:51  lr: 0.000021  loss: 1.2289 (1.4307)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [280/781]  eta: 0:02:48  lr: 0.000021  loss: 1.2799 (1.4331)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [290/781]  eta: 0:02:44  lr: 0.000021  loss: 1.3364 (1.4329)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [300/781]  eta: 0:02:41  lr: 0.000021  loss: 1.3364 (1.4393)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [310/781]  eta: 0:02:38  lr: 0.000021  loss: 1.3802 (1.4443)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [320/781]  eta: 0:02:34  lr: 0.000021  loss: 1.3626 (1.4429)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [330/781]  eta: 0:02:31  lr: 0.000021  loss: 1.3004 (1.4457)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [340/781]  eta: 0:02:27  lr: 0.000021  loss: 1.3359 (1.4425)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [350/781]  eta: 0:02:24  lr: 0.000021  loss: 1.2789 (1.4374)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [360/781]  eta: 0:02:21  lr: 0.000021  loss: 1.2673 (1.4380)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [370/781]  eta: 0:02:17  lr: 0.000021  loss: 1.3404 (1.4351)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [380/781]  eta: 0:02:14  lr: 0.000021  loss: 1.3281 (1.4373)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [390/781]  eta: 0:02:11  lr: 0.000021  loss: 1.3109 (1.4365)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [400/781]  eta: 0:02:07  lr: 0.000021  loss: 1.2869 (1.4358)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [410/781]  eta: 0:02:04  lr: 0.000021  loss: 1.2813 (1.4370)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [420/781]  eta: 0:02:00  lr: 0.000021  loss: 1.3076 (1.4385)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [430/781]  eta: 0:01:57  lr: 0.000021  loss: 1.2914 (1.4351)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [440/781]  eta: 0:01:54  lr: 0.000021  loss: 1.3019 (1.4354)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [450/781]  eta: 0:01:50  lr: 0.000021  loss: 1.3133 (1.4338)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [460/781]  eta: 0:01:47  lr: 0.000021  loss: 1.3266 (1.4335)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [470/781]  eta: 0:01:44  lr: 0.000021  loss: 1.3129 (1.4306)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [480/781]  eta: 0:01:40  lr: 0.000021  loss: 1.2797 (1.4303)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [490/781]  eta: 0:01:37  lr: 0.000021  loss: 1.2927 (1.4303)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [500/781]  eta: 0:01:34  lr: 0.000021  loss: 1.3067 (1.4325)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [510/781]  eta: 0:01:30  lr: 0.000021  loss: 1.3518 (1.4341)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [520/781]  eta: 0:01:27  lr: 0.000021  loss: 1.3521 (1.4338)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [530/781]  eta: 0:01:24  lr: 0.000021  loss: 1.3277 (1.4345)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [540/781]  eta: 0:01:20  lr: 0.000021  loss: 1.3277 (1.4371)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [550/781]  eta: 0:01:17  lr: 0.000021  loss: 1.3376 (1.4353)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [560/781]  eta: 0:01:13  lr: 0.000021  loss: 1.2978 (1.4358)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [570/781]  eta: 0:01:10  lr: 0.000021  loss: 1.2929 (1.4367)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [580/781]  eta: 0:01:07  lr: 0.000021  loss: 1.3190 (1.4369)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [590/781]  eta: 0:01:03  lr: 0.000021  loss: 1.2953 (1.4362)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [600/781]  eta: 0:01:00  lr: 0.000021  loss: 1.2831 (1.4357)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [610/781]  eta: 0:00:57  lr: 0.000021  loss: 1.3134 (1.4341)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [620/781]  eta: 0:00:53  lr: 0.000021  loss: 1.3286 (1.4335)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [630/781]  eta: 0:00:50  lr: 0.000021  loss: 1.3312 (1.4349)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [640/781]  eta: 0:00:47  lr: 0.000021  loss: 1.3665 (1.4371)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [650/781]  eta: 0:00:43  lr: 0.000021  loss: 1.3137 (1.4386)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [660/781]  eta: 0:00:40  lr: 0.000021  loss: 1.2949 (1.4378)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [670/781]  eta: 0:00:37  lr: 0.000021  loss: 1.3138 (1.4385)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [680/781]  eta: 0:00:33  lr: 0.000021  loss: 1.3212 (1.4377)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [690/781]  eta: 0:00:30  lr: 0.000021  loss: 1.3212 (1.4375)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [700/781]  eta: 0:00:27  lr: 0.000021  loss: 1.3171 (1.4386)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [710/781]  eta: 0:00:23  lr: 0.000021  loss: 1.3171 (1.4395)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [720/781]  eta: 0:00:20  lr: 0.000021  loss: 1.2941 (1.4406)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [730/781]  eta: 0:00:17  lr: 0.000021  loss: 1.2966 (1.4398)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [740/781]  eta: 0:00:13  lr: 0.000021  loss: 1.3310 (1.4385)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [750/781]  eta: 0:00:10  lr: 0.000021  loss: 1.3202 (1.4367)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [760/781]  eta: 0:00:07  lr: 0.000021  loss: 1.2948 (1.4358)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [770/781]  eta: 0:00:03  lr: 0.000021  loss: 1.3008 (1.4388)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [71]  [780/781]  eta: 0:00:00  lr: 0.000021  loss: 1.3008 (1.4382)  time: 0.3337  data: 0.0005  max mem: 6459\n",
            "Epoch: [71] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000021  loss: 1.3008 (1.4382)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3286791741847992, 'lambda_convnext_base': 0.25954341888427734, 'lambda_tf_efficientnetv2_l': 0.4117778241634369}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8062 (0.8062)  acc1: 82.8125 (82.8125)  acc5: 95.3125 (95.3125)  time: 0.8620  data: 0.8312  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9003 (0.9637)  acc1: 82.8125 (81.5341)  acc5: 95.3125 (93.7500)  time: 0.1722  data: 0.1416  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9831 (1.0318)  acc1: 80.2083 (80.4812)  acc5: 93.2292 (92.8075)  time: 0.1220  data: 0.0914  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2307 (1.0901)  acc1: 75.5208 (79.3683)  acc5: 91.6667 (92.2043)  time: 0.1223  data: 0.0917  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2348 (1.1434)  acc1: 75.5208 (78.2266)  acc5: 90.6250 (91.6794)  time: 0.1218  data: 0.0912  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1318 (1.1393)  acc1: 75.5208 (77.9003)  acc5: 92.1875 (92.0139)  time: 0.1206  data: 0.0899  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1481 (1.1479)  acc1: 75.5208 (77.8100)  acc5: 92.1875 (92.0400)  time: 0.1006  data: 0.0708  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1291 s / it)\n",
            "* Acc@1 77.810 Acc@5 92.040 loss 1.148\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 77.91%\n",
            "Epoch: [72]  [  0/781]  eta: 0:14:34  lr: 0.000020  loss: 1.1612 (1.1612)  time: 1.1198  data: 0.7793  max mem: 6459\n",
            "Epoch: [72]  [ 10/781]  eta: 0:05:12  lr: 0.000020  loss: 1.3516 (1.5331)  time: 0.4057  data: 0.0712  max mem: 6459\n",
            "Epoch: [72]  [ 20/781]  eta: 0:04:42  lr: 0.000020  loss: 1.3516 (1.5640)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 30/781]  eta: 0:04:29  lr: 0.000020  loss: 1.3932 (1.6428)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 40/781]  eta: 0:04:21  lr: 0.000020  loss: 1.3237 (1.5569)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 50/781]  eta: 0:04:15  lr: 0.000020  loss: 1.3237 (1.5286)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 60/781]  eta: 0:04:09  lr: 0.000020  loss: 1.3341 (1.5103)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 70/781]  eta: 0:04:05  lr: 0.000020  loss: 1.2802 (1.5160)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 80/781]  eta: 0:04:00  lr: 0.000020  loss: 1.3171 (1.5212)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [ 90/781]  eta: 0:03:56  lr: 0.000020  loss: 1.3334 (1.5361)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [100/781]  eta: 0:03:52  lr: 0.000020  loss: 1.3537 (1.5460)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [110/781]  eta: 0:03:48  lr: 0.000020  loss: 1.3044 (1.5304)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [120/781]  eta: 0:03:44  lr: 0.000020  loss: 1.2910 (1.5158)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [130/781]  eta: 0:03:40  lr: 0.000020  loss: 1.2661 (1.5043)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [140/781]  eta: 0:03:37  lr: 0.000020  loss: 1.2723 (1.5009)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [150/781]  eta: 0:03:33  lr: 0.000020  loss: 1.3002 (1.5078)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [160/781]  eta: 0:03:30  lr: 0.000020  loss: 1.3101 (1.5111)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [170/781]  eta: 0:03:26  lr: 0.000020  loss: 1.3043 (1.5088)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [180/781]  eta: 0:03:23  lr: 0.000020  loss: 1.2992 (1.5031)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [190/781]  eta: 0:03:19  lr: 0.000020  loss: 1.2694 (1.4939)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [200/781]  eta: 0:03:16  lr: 0.000020  loss: 1.2594 (1.4885)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [210/781]  eta: 0:03:12  lr: 0.000020  loss: 1.3053 (1.4842)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [220/781]  eta: 0:03:09  lr: 0.000020  loss: 1.3146 (1.4755)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [230/781]  eta: 0:03:05  lr: 0.000020  loss: 1.2901 (1.4700)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [240/781]  eta: 0:03:02  lr: 0.000020  loss: 1.2385 (1.4645)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [250/781]  eta: 0:02:58  lr: 0.000020  loss: 1.2631 (1.4570)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [260/781]  eta: 0:02:55  lr: 0.000020  loss: 1.3084 (1.4573)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [270/781]  eta: 0:02:51  lr: 0.000020  loss: 1.2917 (1.4537)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [280/781]  eta: 0:02:48  lr: 0.000020  loss: 1.3135 (1.4600)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [290/781]  eta: 0:02:45  lr: 0.000020  loss: 1.2814 (1.4596)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [300/781]  eta: 0:02:41  lr: 0.000020  loss: 1.2742 (1.4581)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [310/781]  eta: 0:02:38  lr: 0.000020  loss: 1.2863 (1.4530)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [320/781]  eta: 0:02:34  lr: 0.000020  loss: 1.2893 (1.4494)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [330/781]  eta: 0:02:31  lr: 0.000020  loss: 1.3044 (1.4501)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [340/781]  eta: 0:02:28  lr: 0.000020  loss: 1.3175 (1.4562)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [350/781]  eta: 0:02:24  lr: 0.000020  loss: 1.3671 (1.4619)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [360/781]  eta: 0:02:21  lr: 0.000020  loss: 1.3150 (1.4590)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [370/781]  eta: 0:02:18  lr: 0.000020  loss: 1.3458 (1.4616)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [380/781]  eta: 0:02:14  lr: 0.000020  loss: 1.3793 (1.4650)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [390/781]  eta: 0:02:11  lr: 0.000020  loss: 1.3134 (1.4605)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.2872 (1.4577)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [410/781]  eta: 0:02:04  lr: 0.000020  loss: 1.2866 (1.4544)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [420/781]  eta: 0:02:01  lr: 0.000020  loss: 1.3063 (1.4555)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.3063 (1.4567)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [440/781]  eta: 0:01:54  lr: 0.000020  loss: 1.3210 (1.4560)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [450/781]  eta: 0:01:51  lr: 0.000020  loss: 1.3401 (1.4593)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.3261 (1.4563)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [470/781]  eta: 0:01:44  lr: 0.000020  loss: 1.3338 (1.4578)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.3182 (1.4566)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.2890 (1.4578)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [500/781]  eta: 0:01:34  lr: 0.000020  loss: 1.3133 (1.4557)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.3133 (1.4542)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [520/781]  eta: 0:01:27  lr: 0.000020  loss: 1.3152 (1.4533)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [530/781]  eta: 0:01:24  lr: 0.000020  loss: 1.3252 (1.4517)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.3260 (1.4506)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [550/781]  eta: 0:01:17  lr: 0.000020  loss: 1.3333 (1.4491)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [560/781]  eta: 0:01:14  lr: 0.000020  loss: 1.3333 (1.4515)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.3266 (1.4520)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [580/781]  eta: 0:01:07  lr: 0.000020  loss: 1.3266 (1.4511)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.3706 (1.4531)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.3367 (1.4513)  time: 0.3442  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [610/781]  eta: 0:00:57  lr: 0.000020  loss: 1.3074 (1.4500)  time: 0.3440  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.3575 (1.4490)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.3599 (1.4478)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [640/781]  eta: 0:00:47  lr: 0.000020  loss: 1.2957 (1.4453)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.2933 (1.4445)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.3005 (1.4445)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [670/781]  eta: 0:00:37  lr: 0.000020  loss: 1.3005 (1.4426)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.2958 (1.4411)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3539 (1.4429)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [700/781]  eta: 0:00:27  lr: 0.000020  loss: 1.3489 (1.4426)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.3489 (1.4463)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.3615 (1.4476)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [730/781]  eta: 0:00:17  lr: 0.000020  loss: 1.3240 (1.4475)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.2915 (1.4462)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.3224 (1.4491)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [760/781]  eta: 0:00:07  lr: 0.000020  loss: 1.3224 (1.4506)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.3267 (1.4498)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [72]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.3414 (1.4506)  time: 0.3337  data: 0.0005  max mem: 6459\n",
            "Epoch: [72] Total time: 0:04:21 (0.3351 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.3414 (1.4506)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32858341932296753, 'lambda_convnext_base': 0.259758323431015, 'lambda_tf_efficientnetv2_l': 0.41165852546691895}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8238 (0.8238)  acc1: 83.3333 (83.3333)  acc5: 94.2708 (94.2708)  time: 0.8462  data: 0.8154  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9501 (0.9780)  acc1: 83.3333 (81.6761)  acc5: 94.2708 (93.4186)  time: 0.1678  data: 0.1371  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 0.9776 (1.0406)  acc1: 81.2500 (80.4067)  acc5: 92.7083 (92.3115)  time: 0.1159  data: 0.0852  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1481 (1.0863)  acc1: 77.0833 (79.6875)  acc5: 91.6667 (92.1371)  time: 0.1208  data: 0.0902  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2148 (1.1394)  acc1: 76.5625 (78.3791)  acc5: 91.1458 (91.6921)  time: 0.1217  data: 0.0910  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1463 (1.1418)  acc1: 77.0833 (78.0229)  acc5: 91.6667 (91.8811)  time: 0.1263  data: 0.0956  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1481 (1.1553)  acc1: 75.0000 (77.9400)  acc5: 91.6667 (91.9200)  time: 0.1108  data: 0.0811  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1298 s / it)\n",
            "* Acc@1 77.940 Acc@5 91.920 loss 1.155\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.94%\n",
            "Epoch: [73]  [  0/781]  eta: 0:14:31  lr: 0.000020  loss: 1.3702 (1.3702)  time: 1.1153  data: 0.7769  max mem: 6459\n",
            "Epoch: [73]  [ 10/781]  eta: 0:05:12  lr: 0.000020  loss: 1.3702 (1.5969)  time: 0.4048  data: 0.0709  max mem: 6459\n",
            "Epoch: [73]  [ 20/781]  eta: 0:04:42  lr: 0.000020  loss: 1.3293 (1.5173)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 30/781]  eta: 0:04:29  lr: 0.000020  loss: 1.3293 (1.5210)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 40/781]  eta: 0:04:21  lr: 0.000020  loss: 1.2989 (1.4702)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 50/781]  eta: 0:04:14  lr: 0.000020  loss: 1.2777 (1.4454)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 60/781]  eta: 0:04:09  lr: 0.000020  loss: 1.2666 (1.4453)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 70/781]  eta: 0:04:04  lr: 0.000020  loss: 1.3145 (1.4658)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 80/781]  eta: 0:04:00  lr: 0.000020  loss: 1.3209 (1.4719)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [ 90/781]  eta: 0:03:56  lr: 0.000020  loss: 1.2506 (1.4650)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [100/781]  eta: 0:03:52  lr: 0.000020  loss: 1.3014 (1.4491)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [110/781]  eta: 0:03:48  lr: 0.000020  loss: 1.3184 (1.4587)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [120/781]  eta: 0:03:44  lr: 0.000020  loss: 1.3096 (1.4553)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [130/781]  eta: 0:03:40  lr: 0.000020  loss: 1.2802 (1.4414)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [140/781]  eta: 0:03:37  lr: 0.000020  loss: 1.2562 (1.4455)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [150/781]  eta: 0:03:33  lr: 0.000020  loss: 1.3067 (1.4457)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [160/781]  eta: 0:03:30  lr: 0.000020  loss: 1.3217 (1.4463)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [170/781]  eta: 0:03:26  lr: 0.000020  loss: 1.3217 (1.4405)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [180/781]  eta: 0:03:22  lr: 0.000020  loss: 1.2946 (1.4340)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [190/781]  eta: 0:03:19  lr: 0.000020  loss: 1.2546 (1.4274)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [200/781]  eta: 0:03:15  lr: 0.000020  loss: 1.2546 (1.4211)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [210/781]  eta: 0:03:12  lr: 0.000020  loss: 1.2781 (1.4215)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [220/781]  eta: 0:03:08  lr: 0.000020  loss: 1.3220 (1.4184)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [230/781]  eta: 0:03:05  lr: 0.000020  loss: 1.2905 (1.4165)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [240/781]  eta: 0:03:02  lr: 0.000020  loss: 1.2905 (1.4169)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [250/781]  eta: 0:02:58  lr: 0.000020  loss: 1.3024 (1.4249)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [260/781]  eta: 0:02:55  lr: 0.000020  loss: 1.3875 (1.4296)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [270/781]  eta: 0:02:51  lr: 0.000020  loss: 1.3555 (1.4286)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [280/781]  eta: 0:02:48  lr: 0.000020  loss: 1.2913 (1.4329)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [290/781]  eta: 0:02:44  lr: 0.000020  loss: 1.2941 (1.4286)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [300/781]  eta: 0:02:41  lr: 0.000020  loss: 1.2941 (1.4285)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [310/781]  eta: 0:02:38  lr: 0.000020  loss: 1.2686 (1.4295)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [320/781]  eta: 0:02:34  lr: 0.000020  loss: 1.2571 (1.4259)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [330/781]  eta: 0:02:31  lr: 0.000020  loss: 1.3152 (1.4281)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [340/781]  eta: 0:02:27  lr: 0.000020  loss: 1.3558 (1.4285)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [350/781]  eta: 0:02:24  lr: 0.000020  loss: 1.3337 (1.4271)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [360/781]  eta: 0:02:21  lr: 0.000020  loss: 1.3034 (1.4283)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [370/781]  eta: 0:02:17  lr: 0.000020  loss: 1.3325 (1.4265)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [380/781]  eta: 0:02:14  lr: 0.000020  loss: 1.2962 (1.4293)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [390/781]  eta: 0:02:11  lr: 0.000020  loss: 1.3127 (1.4276)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [400/781]  eta: 0:02:07  lr: 0.000020  loss: 1.2959 (1.4268)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [410/781]  eta: 0:02:04  lr: 0.000020  loss: 1.2959 (1.4279)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [420/781]  eta: 0:02:00  lr: 0.000020  loss: 1.2780 (1.4248)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [430/781]  eta: 0:01:57  lr: 0.000020  loss: 1.3137 (1.4278)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [440/781]  eta: 0:01:54  lr: 0.000020  loss: 1.3998 (1.4307)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [450/781]  eta: 0:01:50  lr: 0.000020  loss: 1.3294 (1.4306)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [460/781]  eta: 0:01:47  lr: 0.000020  loss: 1.2956 (1.4321)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [470/781]  eta: 0:01:44  lr: 0.000020  loss: 1.2956 (1.4299)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [480/781]  eta: 0:01:40  lr: 0.000020  loss: 1.3071 (1.4321)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [490/781]  eta: 0:01:37  lr: 0.000020  loss: 1.3222 (1.4357)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [500/781]  eta: 0:01:34  lr: 0.000020  loss: 1.3130 (1.4333)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [510/781]  eta: 0:01:30  lr: 0.000020  loss: 1.2866 (1.4347)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [520/781]  eta: 0:01:27  lr: 0.000020  loss: 1.2767 (1.4317)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [530/781]  eta: 0:01:24  lr: 0.000020  loss: 1.2650 (1.4317)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [540/781]  eta: 0:01:20  lr: 0.000020  loss: 1.3054 (1.4305)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [550/781]  eta: 0:01:17  lr: 0.000020  loss: 1.2567 (1.4298)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [560/781]  eta: 0:01:13  lr: 0.000020  loss: 1.3140 (1.4308)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [570/781]  eta: 0:01:10  lr: 0.000020  loss: 1.2607 (1.4306)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [580/781]  eta: 0:01:07  lr: 0.000020  loss: 1.2566 (1.4278)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [590/781]  eta: 0:01:03  lr: 0.000020  loss: 1.2557 (1.4275)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [600/781]  eta: 0:01:00  lr: 0.000020  loss: 1.2534 (1.4252)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [610/781]  eta: 0:00:57  lr: 0.000020  loss: 1.2992 (1.4266)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [620/781]  eta: 0:00:53  lr: 0.000020  loss: 1.3236 (1.4268)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [630/781]  eta: 0:00:50  lr: 0.000020  loss: 1.3155 (1.4258)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [640/781]  eta: 0:00:47  lr: 0.000020  loss: 1.3157 (1.4250)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [650/781]  eta: 0:00:43  lr: 0.000020  loss: 1.3044 (1.4231)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [660/781]  eta: 0:00:40  lr: 0.000020  loss: 1.3044 (1.4214)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [670/781]  eta: 0:00:37  lr: 0.000020  loss: 1.3176 (1.4240)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [680/781]  eta: 0:00:33  lr: 0.000020  loss: 1.3271 (1.4274)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [690/781]  eta: 0:00:30  lr: 0.000020  loss: 1.3373 (1.4287)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [700/781]  eta: 0:00:27  lr: 0.000020  loss: 1.2759 (1.4278)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [710/781]  eta: 0:00:23  lr: 0.000020  loss: 1.3015 (1.4310)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [720/781]  eta: 0:00:20  lr: 0.000020  loss: 1.3307 (1.4318)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [730/781]  eta: 0:00:17  lr: 0.000020  loss: 1.2978 (1.4325)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [740/781]  eta: 0:00:13  lr: 0.000020  loss: 1.2875 (1.4318)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [750/781]  eta: 0:00:10  lr: 0.000020  loss: 1.2875 (1.4306)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [760/781]  eta: 0:00:07  lr: 0.000020  loss: 1.3037 (1.4307)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [770/781]  eta: 0:00:03  lr: 0.000020  loss: 1.3225 (1.4313)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [73]  [780/781]  eta: 0:00:00  lr: 0.000020  loss: 1.2556 (1.4288)  time: 0.3350  data: 0.0007  max mem: 6459\n",
            "Epoch: [73] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000020  loss: 1.2556 (1.4288)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32975295186042786, 'lambda_convnext_base': 0.2592761814594269, 'lambda_tf_efficientnetv2_l': 0.4109710454940796}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.7473 (0.7473)  acc1: 85.4167 (85.4167)  acc5: 96.3542 (96.3542)  time: 0.8336  data: 0.8027  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9938 (0.9427)  acc1: 81.7708 (82.2917)  acc5: 94.7917 (94.2708)  time: 0.1768  data: 0.1461  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9938 (1.0300)  acc1: 80.7292 (80.2579)  acc5: 93.2292 (92.9067)  time: 0.1286  data: 0.0978  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1958 (1.0861)  acc1: 76.0417 (79.3515)  acc5: 91.1458 (92.3387)  time: 0.1289  data: 0.0982  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2690 (1.1322)  acc1: 75.5208 (78.4553)  acc5: 90.1042 (91.8699)  time: 0.1272  data: 0.0965  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1373 (1.1322)  acc1: 78.1250 (78.0739)  acc5: 92.1875 (92.1160)  time: 0.1237  data: 0.0930  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1839 (1.1429)  acc1: 75.0000 (77.9400)  acc5: 92.1875 (92.1300)  time: 0.1040  data: 0.0743  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1337 s / it)\n",
            "* Acc@1 77.940 Acc@5 92.130 loss 1.143\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.94%\n",
            "Epoch: [74]  [  0/781]  eta: 0:14:38  lr: 0.000019  loss: 1.2815 (1.2815)  time: 1.1253  data: 0.7753  max mem: 6459\n",
            "Epoch: [74]  [ 10/781]  eta: 0:05:12  lr: 0.000019  loss: 1.2907 (1.4986)  time: 0.4051  data: 0.0708  max mem: 6459\n",
            "Epoch: [74]  [ 20/781]  eta: 0:04:42  lr: 0.000019  loss: 1.3036 (1.4784)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 30/781]  eta: 0:04:29  lr: 0.000019  loss: 1.3087 (1.4872)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 40/781]  eta: 0:04:21  lr: 0.000019  loss: 1.2855 (1.4540)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 50/781]  eta: 0:04:14  lr: 0.000019  loss: 1.2570 (1.4353)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 60/781]  eta: 0:04:09  lr: 0.000019  loss: 1.3408 (1.4351)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 70/781]  eta: 0:04:04  lr: 0.000019  loss: 1.3159 (1.4150)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 80/781]  eta: 0:04:00  lr: 0.000019  loss: 1.2945 (1.4115)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [ 90/781]  eta: 0:03:56  lr: 0.000019  loss: 1.2634 (1.4129)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [100/781]  eta: 0:03:52  lr: 0.000019  loss: 1.2634 (1.3989)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [110/781]  eta: 0:03:48  lr: 0.000019  loss: 1.2898 (1.4017)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [120/781]  eta: 0:03:44  lr: 0.000019  loss: 1.3412 (1.3990)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [130/781]  eta: 0:03:41  lr: 0.000019  loss: 1.3383 (1.4039)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [140/781]  eta: 0:03:37  lr: 0.000019  loss: 1.3058 (1.4066)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [150/781]  eta: 0:03:33  lr: 0.000019  loss: 1.3011 (1.3998)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [160/781]  eta: 0:03:30  lr: 0.000019  loss: 1.2700 (1.3959)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [170/781]  eta: 0:03:26  lr: 0.000019  loss: 1.2939 (1.4016)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [180/781]  eta: 0:03:22  lr: 0.000019  loss: 1.3358 (1.4044)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [190/781]  eta: 0:03:19  lr: 0.000019  loss: 1.3384 (1.4113)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [200/781]  eta: 0:03:15  lr: 0.000019  loss: 1.3170 (1.4151)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [210/781]  eta: 0:03:12  lr: 0.000019  loss: 1.2718 (1.4139)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [220/781]  eta: 0:03:09  lr: 0.000019  loss: 1.2562 (1.4123)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [230/781]  eta: 0:03:05  lr: 0.000019  loss: 1.2544 (1.4097)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [240/781]  eta: 0:03:02  lr: 0.000019  loss: 1.2544 (1.4045)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [250/781]  eta: 0:02:58  lr: 0.000019  loss: 1.3014 (1.4131)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [260/781]  eta: 0:02:55  lr: 0.000019  loss: 1.3900 (1.4103)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [270/781]  eta: 0:02:51  lr: 0.000019  loss: 1.3313 (1.4108)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [280/781]  eta: 0:02:48  lr: 0.000019  loss: 1.2843 (1.4072)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [290/781]  eta: 0:02:44  lr: 0.000019  loss: 1.2564 (1.4058)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [300/781]  eta: 0:02:41  lr: 0.000019  loss: 1.2314 (1.4045)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [310/781]  eta: 0:02:38  lr: 0.000019  loss: 1.2806 (1.4086)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [320/781]  eta: 0:02:34  lr: 0.000019  loss: 1.2400 (1.4029)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [330/781]  eta: 0:02:31  lr: 0.000019  loss: 1.2643 (1.4046)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [340/781]  eta: 0:02:28  lr: 0.000019  loss: 1.2860 (1.4053)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [350/781]  eta: 0:02:24  lr: 0.000019  loss: 1.3286 (1.4069)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [360/781]  eta: 0:02:21  lr: 0.000019  loss: 1.2889 (1.4037)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [370/781]  eta: 0:02:17  lr: 0.000019  loss: 1.2889 (1.4024)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [380/781]  eta: 0:02:14  lr: 0.000019  loss: 1.2898 (1.4010)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [390/781]  eta: 0:02:11  lr: 0.000019  loss: 1.2701 (1.4004)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [400/781]  eta: 0:02:07  lr: 0.000019  loss: 1.2755 (1.4025)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [410/781]  eta: 0:02:04  lr: 0.000019  loss: 1.2785 (1.4009)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [420/781]  eta: 0:02:01  lr: 0.000019  loss: 1.2674 (1.3978)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [430/781]  eta: 0:01:57  lr: 0.000019  loss: 1.2706 (1.3958)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [440/781]  eta: 0:01:54  lr: 0.000019  loss: 1.3089 (1.3977)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [450/781]  eta: 0:01:50  lr: 0.000019  loss: 1.3148 (1.3979)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [460/781]  eta: 0:01:47  lr: 0.000019  loss: 1.3009 (1.4002)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [470/781]  eta: 0:01:44  lr: 0.000019  loss: 1.3362 (1.4005)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [480/781]  eta: 0:01:40  lr: 0.000019  loss: 1.2698 (1.3980)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [490/781]  eta: 0:01:37  lr: 0.000019  loss: 1.2628 (1.3992)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [500/781]  eta: 0:01:34  lr: 0.000019  loss: 1.2638 (1.3986)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [510/781]  eta: 0:01:30  lr: 0.000019  loss: 1.3141 (1.4035)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [520/781]  eta: 0:01:27  lr: 0.000019  loss: 1.3315 (1.4028)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [530/781]  eta: 0:01:24  lr: 0.000019  loss: 1.2701 (1.4006)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [540/781]  eta: 0:01:20  lr: 0.000019  loss: 1.2701 (1.3985)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [550/781]  eta: 0:01:17  lr: 0.000019  loss: 1.2983 (1.4016)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [560/781]  eta: 0:01:13  lr: 0.000019  loss: 1.3298 (1.4029)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [570/781]  eta: 0:01:10  lr: 0.000019  loss: 1.3080 (1.4025)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [580/781]  eta: 0:01:07  lr: 0.000019  loss: 1.2676 (1.4018)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [590/781]  eta: 0:01:03  lr: 0.000019  loss: 1.2676 (1.4010)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [600/781]  eta: 0:01:00  lr: 0.000019  loss: 1.2617 (1.4004)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [610/781]  eta: 0:00:57  lr: 0.000019  loss: 1.2842 (1.4002)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [620/781]  eta: 0:00:53  lr: 0.000019  loss: 1.2783 (1.3998)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [630/781]  eta: 0:00:50  lr: 0.000019  loss: 1.2783 (1.3998)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [640/781]  eta: 0:00:47  lr: 0.000019  loss: 1.3354 (1.4021)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [650/781]  eta: 0:00:43  lr: 0.000019  loss: 1.2594 (1.3996)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [660/781]  eta: 0:00:40  lr: 0.000019  loss: 1.2594 (1.3999)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [670/781]  eta: 0:00:37  lr: 0.000019  loss: 1.3489 (1.4007)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [680/781]  eta: 0:00:33  lr: 0.000019  loss: 1.4014 (1.4031)  time: 0.3346  data: 0.0004  max mem: 6459\n",
            "Epoch: [74]  [690/781]  eta: 0:00:30  lr: 0.000019  loss: 1.2981 (1.4011)  time: 0.3345  data: 0.0004  max mem: 6459\n",
            "Epoch: [74]  [700/781]  eta: 0:00:27  lr: 0.000019  loss: 1.2536 (1.4033)  time: 0.3346  data: 0.0004  max mem: 6459\n",
            "Epoch: [74]  [710/781]  eta: 0:00:23  lr: 0.000019  loss: 1.2417 (1.4027)  time: 0.3347  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [720/781]  eta: 0:00:20  lr: 0.000019  loss: 1.2822 (1.4026)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [730/781]  eta: 0:00:17  lr: 0.000019  loss: 1.2935 (1.4042)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [740/781]  eta: 0:00:13  lr: 0.000019  loss: 1.3038 (1.4058)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [750/781]  eta: 0:00:10  lr: 0.000019  loss: 1.3189 (1.4063)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [760/781]  eta: 0:00:07  lr: 0.000019  loss: 1.3356 (1.4058)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [770/781]  eta: 0:00:03  lr: 0.000019  loss: 1.3382 (1.4066)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [74]  [780/781]  eta: 0:00:00  lr: 0.000019  loss: 1.3129 (1.4059)  time: 0.3334  data: 0.0005  max mem: 6459\n",
            "Epoch: [74] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000019  loss: 1.3129 (1.4059)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3285386562347412, 'lambda_convnext_base': 0.25914883613586426, 'lambda_tf_efficientnetv2_l': 0.4123122990131378}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8528 (0.8528)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8498  data: 0.8188  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9386 (0.9731)  acc1: 82.8125 (81.6288)  acc5: 94.2708 (93.7500)  time: 0.1707  data: 0.1400  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0165 (1.0346)  acc1: 77.0833 (80.3323)  acc5: 93.2292 (92.6587)  time: 0.1202  data: 0.0895  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2259 (1.1040)  acc1: 75.0000 (78.9651)  acc5: 90.6250 (91.9355)  time: 0.1259  data: 0.0952  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2792 (1.1497)  acc1: 74.4792 (78.0869)  acc5: 90.1042 (91.5015)  time: 0.1267  data: 0.0960  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1709 (1.1425)  acc1: 77.6042 (77.9820)  acc5: 91.6667 (91.8199)  time: 0.1218  data: 0.0912  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1878 (1.1528)  acc1: 77.0833 (77.8700)  acc5: 92.1875 (91.8600)  time: 0.1032  data: 0.0735  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1307 s / it)\n",
            "* Acc@1 77.870 Acc@5 91.860 loss 1.153\n",
            "Accuracy of the network on the 10000 test images: 77.9%\n",
            "Max accuracy: 77.94%\n",
            "Epoch: [75]  [  0/781]  eta: 0:14:35  lr: 0.000018  loss: 1.3534 (1.3534)  time: 1.1205  data: 0.7820  max mem: 6459\n",
            "Epoch: [75]  [ 10/781]  eta: 0:05:12  lr: 0.000018  loss: 1.3607 (1.4970)  time: 0.4054  data: 0.0714  max mem: 6459\n",
            "Epoch: [75]  [ 20/781]  eta: 0:04:42  lr: 0.000018  loss: 1.2807 (1.4433)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 30/781]  eta: 0:04:29  lr: 0.000018  loss: 1.2807 (1.4802)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 40/781]  eta: 0:04:21  lr: 0.000018  loss: 1.2736 (1.4259)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 50/781]  eta: 0:04:15  lr: 0.000018  loss: 1.2602 (1.4326)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 60/781]  eta: 0:04:09  lr: 0.000018  loss: 1.2681 (1.4597)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 70/781]  eta: 0:04:05  lr: 0.000018  loss: 1.2625 (1.4578)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 80/781]  eta: 0:04:00  lr: 0.000018  loss: 1.2407 (1.4305)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [ 90/781]  eta: 0:03:56  lr: 0.000018  loss: 1.2407 (1.4362)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [100/781]  eta: 0:03:52  lr: 0.000018  loss: 1.3344 (1.4539)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [110/781]  eta: 0:03:48  lr: 0.000018  loss: 1.3341 (1.4517)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [120/781]  eta: 0:03:44  lr: 0.000018  loss: 1.3251 (1.4478)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [130/781]  eta: 0:03:41  lr: 0.000018  loss: 1.3329 (1.4578)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [140/781]  eta: 0:03:37  lr: 0.000018  loss: 1.3293 (1.4473)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [150/781]  eta: 0:03:33  lr: 0.000018  loss: 1.3293 (1.4596)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [160/781]  eta: 0:03:30  lr: 0.000018  loss: 1.5545 (1.4844)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [170/781]  eta: 0:03:26  lr: 0.000018  loss: 1.4384 (1.4831)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [180/781]  eta: 0:03:23  lr: 0.000018  loss: 1.2980 (1.4725)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [190/781]  eta: 0:03:19  lr: 0.000018  loss: 1.2910 (1.4691)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [200/781]  eta: 0:03:16  lr: 0.000018  loss: 1.2796 (1.4677)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [210/781]  eta: 0:03:12  lr: 0.000018  loss: 1.3290 (1.4673)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [220/781]  eta: 0:03:09  lr: 0.000018  loss: 1.3025 (1.4692)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [230/781]  eta: 0:03:05  lr: 0.000018  loss: 1.2593 (1.4644)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [240/781]  eta: 0:03:02  lr: 0.000018  loss: 1.2547 (1.4685)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [250/781]  eta: 0:02:58  lr: 0.000018  loss: 1.3303 (1.4760)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [260/781]  eta: 0:02:55  lr: 0.000018  loss: 1.3371 (1.4774)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.2808 (1.4698)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [280/781]  eta: 0:02:48  lr: 0.000018  loss: 1.2680 (1.4684)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [290/781]  eta: 0:02:45  lr: 0.000018  loss: 1.3032 (1.4703)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [300/781]  eta: 0:02:41  lr: 0.000018  loss: 1.3420 (1.4691)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [310/781]  eta: 0:02:38  lr: 0.000018  loss: 1.2821 (1.4642)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.3023 (1.4635)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [330/781]  eta: 0:02:31  lr: 0.000018  loss: 1.3133 (1.4610)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [340/781]  eta: 0:02:28  lr: 0.000018  loss: 1.3245 (1.4587)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [350/781]  eta: 0:02:24  lr: 0.000018  loss: 1.2750 (1.4532)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [360/781]  eta: 0:02:21  lr: 0.000018  loss: 1.2750 (1.4591)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [370/781]  eta: 0:02:18  lr: 0.000018  loss: 1.3408 (1.4581)  time: 0.3438  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [380/781]  eta: 0:02:14  lr: 0.000018  loss: 1.3431 (1.4616)  time: 0.3437  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [390/781]  eta: 0:02:11  lr: 0.000018  loss: 1.3258 (1.4601)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [400/781]  eta: 0:02:08  lr: 0.000018  loss: 1.2818 (1.4641)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [410/781]  eta: 0:02:04  lr: 0.000018  loss: 1.2824 (1.4608)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [420/781]  eta: 0:02:01  lr: 0.000018  loss: 1.2824 (1.4565)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.2943 (1.4555)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [440/781]  eta: 0:01:54  lr: 0.000018  loss: 1.3098 (1.4545)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [450/781]  eta: 0:01:51  lr: 0.000018  loss: 1.2755 (1.4549)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.3079 (1.4546)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [470/781]  eta: 0:01:44  lr: 0.000018  loss: 1.3005 (1.4528)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [480/781]  eta: 0:01:41  lr: 0.000018  loss: 1.2530 (1.4507)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.2504 (1.4485)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [500/781]  eta: 0:01:34  lr: 0.000018  loss: 1.2506 (1.4467)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.2506 (1.4459)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [520/781]  eta: 0:01:27  lr: 0.000018  loss: 1.3073 (1.4473)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [530/781]  eta: 0:01:24  lr: 0.000018  loss: 1.3305 (1.4471)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.3674 (1.4561)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [550/781]  eta: 0:01:17  lr: 0.000018  loss: 1.3761 (1.4566)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [560/781]  eta: 0:01:14  lr: 0.000018  loss: 1.3074 (1.4563)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.3406 (1.4582)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [580/781]  eta: 0:01:07  lr: 0.000018  loss: 1.3726 (1.4578)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [590/781]  eta: 0:01:04  lr: 0.000018  loss: 1.2967 (1.4569)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.2944 (1.4542)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [610/781]  eta: 0:00:57  lr: 0.000018  loss: 1.3000 (1.4526)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.3000 (1.4519)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3051 (1.4519)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [640/781]  eta: 0:00:47  lr: 0.000018  loss: 1.3123 (1.4508)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.3061 (1.4508)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.3296 (1.4535)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [670/781]  eta: 0:00:37  lr: 0.000018  loss: 1.2901 (1.4523)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.2811 (1.4528)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.3353 (1.4530)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [700/781]  eta: 0:00:27  lr: 0.000018  loss: 1.3252 (1.4522)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.3356 (1.4529)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.3356 (1.4506)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [730/781]  eta: 0:00:17  lr: 0.000018  loss: 1.2980 (1.4510)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.2894 (1.4513)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.2523 (1.4499)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [760/781]  eta: 0:00:07  lr: 0.000018  loss: 1.3260 (1.4532)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.4204 (1.4546)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [75]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.3591 (1.4546)  time: 0.3333  data: 0.0005  max mem: 6459\n",
            "Epoch: [75] Total time: 0:04:21 (0.3349 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.3591 (1.4546)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32850387692451477, 'lambda_convnext_base': 0.260731965303421, 'lambda_tf_efficientnetv2_l': 0.4107641279697418}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8261 (0.8261)  acc1: 84.3750 (84.3750)  acc5: 95.3125 (95.3125)  time: 0.8507  data: 0.8198  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9099 (0.9842)  acc1: 84.3750 (81.9129)  acc5: 94.7917 (93.7500)  time: 0.1723  data: 0.1416  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0516 (1.0354)  acc1: 77.6042 (80.9276)  acc5: 93.2292 (92.7331)  time: 0.1202  data: 0.0895  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1996 (1.0987)  acc1: 76.0417 (79.5531)  acc5: 91.1458 (92.0867)  time: 0.1197  data: 0.0890  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2550 (1.1452)  acc1: 74.4792 (78.6204)  acc5: 90.6250 (91.6667)  time: 0.1198  data: 0.0891  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.0902 (1.1439)  acc1: 75.5208 (78.3293)  acc5: 92.1875 (91.8811)  time: 0.1216  data: 0.0910  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2236 (1.1583)  acc1: 75.0000 (78.2100)  acc5: 92.7083 (91.9100)  time: 0.1026  data: 0.0728  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1284 s / it)\n",
            "* Acc@1 78.210 Acc@5 91.910 loss 1.158\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.21%\n",
            "Epoch: [76]  [  0/781]  eta: 0:14:52  lr: 0.000018  loss: 1.2224 (1.2224)  time: 1.1429  data: 0.7988  max mem: 6459\n",
            "Epoch: [76]  [ 10/781]  eta: 0:05:13  lr: 0.000018  loss: 1.2795 (1.3821)  time: 0.4071  data: 0.0729  max mem: 6459\n",
            "Epoch: [76]  [ 20/781]  eta: 0:04:43  lr: 0.000018  loss: 1.2795 (1.3267)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 30/781]  eta: 0:04:30  lr: 0.000018  loss: 1.2855 (1.3297)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 40/781]  eta: 0:04:21  lr: 0.000018  loss: 1.3028 (1.3805)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 50/781]  eta: 0:04:15  lr: 0.000018  loss: 1.2489 (1.3551)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 60/781]  eta: 0:04:09  lr: 0.000018  loss: 1.2489 (1.3732)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 70/781]  eta: 0:04:04  lr: 0.000018  loss: 1.2874 (1.3735)  time: 0.3327  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 80/781]  eta: 0:04:00  lr: 0.000018  loss: 1.2656 (1.3724)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [ 90/781]  eta: 0:03:56  lr: 0.000018  loss: 1.2536 (1.3771)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [100/781]  eta: 0:03:52  lr: 0.000018  loss: 1.2720 (1.3871)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [110/781]  eta: 0:03:48  lr: 0.000018  loss: 1.2720 (1.3851)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [120/781]  eta: 0:03:44  lr: 0.000018  loss: 1.2597 (1.4018)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [130/781]  eta: 0:03:41  lr: 0.000018  loss: 1.3076 (1.4072)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [140/781]  eta: 0:03:37  lr: 0.000018  loss: 1.3094 (1.4075)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [150/781]  eta: 0:03:33  lr: 0.000018  loss: 1.3249 (1.4150)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [160/781]  eta: 0:03:30  lr: 0.000018  loss: 1.3206 (1.4176)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [170/781]  eta: 0:03:26  lr: 0.000018  loss: 1.2420 (1.4219)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [180/781]  eta: 0:03:23  lr: 0.000018  loss: 1.2993 (1.4190)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [190/781]  eta: 0:03:19  lr: 0.000018  loss: 1.2867 (1.4114)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [200/781]  eta: 0:03:16  lr: 0.000018  loss: 1.2913 (1.4163)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [210/781]  eta: 0:03:12  lr: 0.000018  loss: 1.3207 (1.4202)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [220/781]  eta: 0:03:09  lr: 0.000018  loss: 1.2794 (1.4133)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [230/781]  eta: 0:03:05  lr: 0.000018  loss: 1.2578 (1.4081)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [240/781]  eta: 0:03:02  lr: 0.000018  loss: 1.2728 (1.4068)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [250/781]  eta: 0:02:58  lr: 0.000018  loss: 1.2817 (1.4046)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [260/781]  eta: 0:02:55  lr: 0.000018  loss: 1.2945 (1.4045)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [270/781]  eta: 0:02:51  lr: 0.000018  loss: 1.2993 (1.4080)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [280/781]  eta: 0:02:48  lr: 0.000018  loss: 1.2749 (1.4083)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [290/781]  eta: 0:02:45  lr: 0.000018  loss: 1.2502 (1.4083)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [300/781]  eta: 0:02:41  lr: 0.000018  loss: 1.2550 (1.4111)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [310/781]  eta: 0:02:38  lr: 0.000018  loss: 1.2939 (1.4112)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [320/781]  eta: 0:02:34  lr: 0.000018  loss: 1.2913 (1.4119)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [330/781]  eta: 0:02:31  lr: 0.000018  loss: 1.3166 (1.4108)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [340/781]  eta: 0:02:28  lr: 0.000018  loss: 1.3177 (1.4103)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [350/781]  eta: 0:02:24  lr: 0.000018  loss: 1.2708 (1.4056)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [360/781]  eta: 0:02:21  lr: 0.000018  loss: 1.2710 (1.4032)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [370/781]  eta: 0:02:17  lr: 0.000018  loss: 1.2962 (1.4018)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [380/781]  eta: 0:02:14  lr: 0.000018  loss: 1.3007 (1.4025)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [390/781]  eta: 0:02:11  lr: 0.000018  loss: 1.2786 (1.4007)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [400/781]  eta: 0:02:07  lr: 0.000018  loss: 1.3317 (1.3996)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [410/781]  eta: 0:02:04  lr: 0.000018  loss: 1.3015 (1.3991)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [420/781]  eta: 0:02:01  lr: 0.000018  loss: 1.2654 (1.3961)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [430/781]  eta: 0:01:57  lr: 0.000018  loss: 1.2755 (1.3952)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [440/781]  eta: 0:01:54  lr: 0.000018  loss: 1.2988 (1.3959)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [450/781]  eta: 0:01:50  lr: 0.000018  loss: 1.2988 (1.3947)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [460/781]  eta: 0:01:47  lr: 0.000018  loss: 1.3265 (1.3966)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [470/781]  eta: 0:01:44  lr: 0.000018  loss: 1.4504 (1.4057)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [480/781]  eta: 0:01:40  lr: 0.000018  loss: 1.3595 (1.4073)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [490/781]  eta: 0:01:37  lr: 0.000018  loss: 1.3517 (1.4107)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [500/781]  eta: 0:01:34  lr: 0.000018  loss: 1.3517 (1.4122)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [510/781]  eta: 0:01:30  lr: 0.000018  loss: 1.3301 (1.4169)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [520/781]  eta: 0:01:27  lr: 0.000018  loss: 1.3462 (1.4194)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [530/781]  eta: 0:01:24  lr: 0.000018  loss: 1.3919 (1.4203)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [540/781]  eta: 0:01:20  lr: 0.000018  loss: 1.3464 (1.4215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [550/781]  eta: 0:01:17  lr: 0.000018  loss: 1.3209 (1.4203)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [560/781]  eta: 0:01:13  lr: 0.000018  loss: 1.2875 (1.4212)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [570/781]  eta: 0:01:10  lr: 0.000018  loss: 1.2647 (1.4193)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [580/781]  eta: 0:01:07  lr: 0.000018  loss: 1.2647 (1.4196)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [590/781]  eta: 0:01:03  lr: 0.000018  loss: 1.2935 (1.4209)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [600/781]  eta: 0:01:00  lr: 0.000018  loss: 1.2895 (1.4215)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [610/781]  eta: 0:00:57  lr: 0.000018  loss: 1.3149 (1.4211)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [620/781]  eta: 0:00:53  lr: 0.000018  loss: 1.3139 (1.4214)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [630/781]  eta: 0:00:50  lr: 0.000018  loss: 1.3143 (1.4224)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [640/781]  eta: 0:00:47  lr: 0.000018  loss: 1.2941 (1.4208)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [650/781]  eta: 0:00:43  lr: 0.000018  loss: 1.2441 (1.4196)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [660/781]  eta: 0:00:40  lr: 0.000018  loss: 1.3062 (1.4201)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [670/781]  eta: 0:00:37  lr: 0.000018  loss: 1.2959 (1.4193)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [680/781]  eta: 0:00:33  lr: 0.000018  loss: 1.2613 (1.4177)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [690/781]  eta: 0:00:30  lr: 0.000018  loss: 1.2613 (1.4188)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [700/781]  eta: 0:00:27  lr: 0.000018  loss: 1.2992 (1.4203)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [710/781]  eta: 0:00:23  lr: 0.000018  loss: 1.2621 (1.4180)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [720/781]  eta: 0:00:20  lr: 0.000018  loss: 1.2621 (1.4181)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [730/781]  eta: 0:00:17  lr: 0.000018  loss: 1.2831 (1.4171)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [740/781]  eta: 0:00:13  lr: 0.000018  loss: 1.3359 (1.4174)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [750/781]  eta: 0:00:10  lr: 0.000018  loss: 1.3191 (1.4194)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [760/781]  eta: 0:00:07  lr: 0.000018  loss: 1.2839 (1.4189)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [770/781]  eta: 0:00:03  lr: 0.000018  loss: 1.2733 (1.4209)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [76]  [780/781]  eta: 0:00:00  lr: 0.000018  loss: 1.3486 (1.4211)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [76] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000018  loss: 1.3486 (1.4211)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32961568236351013, 'lambda_convnext_base': 0.25897446274757385, 'lambda_tf_efficientnetv2_l': 0.41141006350517273}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.7683 (0.7683)  acc1: 84.8958 (84.8958)  acc5: 95.3125 (95.3125)  time: 0.8045  data: 0.7735  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9227 (0.9785)  acc1: 83.8542 (81.0606)  acc5: 94.7917 (93.7027)  time: 0.1661  data: 0.1354  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0137 (1.0398)  acc1: 78.6458 (80.2827)  acc5: 93.2292 (92.5843)  time: 0.1217  data: 0.0911  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2241 (1.0967)  acc1: 75.5208 (79.0995)  acc5: 90.6250 (91.9859)  time: 0.1224  data: 0.0917  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2847 (1.1370)  acc1: 74.4792 (78.3028)  acc5: 89.5833 (91.5015)  time: 0.1228  data: 0.0922  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1499 (1.1384)  acc1: 74.4792 (77.9310)  acc5: 91.6667 (91.7790)  time: 0.1235  data: 0.0928  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2050 (1.1474)  acc1: 74.4792 (77.8200)  acc5: 91.6667 (91.8200)  time: 0.1040  data: 0.0743  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1291 s / it)\n",
            "* Acc@1 77.820 Acc@5 91.820 loss 1.147\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.21%\n",
            "Epoch: [77]  [  0/781]  eta: 0:14:40  lr: 0.000017  loss: 1.2561 (1.2561)  time: 1.1272  data: 0.7833  max mem: 6459\n",
            "Epoch: [77]  [ 10/781]  eta: 0:05:12  lr: 0.000017  loss: 1.3011 (1.4036)  time: 0.4054  data: 0.0715  max mem: 6459\n",
            "Epoch: [77]  [ 20/781]  eta: 0:04:42  lr: 0.000017  loss: 1.3257 (1.5243)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 30/781]  eta: 0:04:29  lr: 0.000017  loss: 1.3410 (1.4990)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 40/781]  eta: 0:04:21  lr: 0.000017  loss: 1.3349 (1.4768)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 50/781]  eta: 0:04:15  lr: 0.000017  loss: 1.2408 (1.4315)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 60/781]  eta: 0:04:09  lr: 0.000017  loss: 1.2392 (1.4273)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 70/781]  eta: 0:04:04  lr: 0.000017  loss: 1.2519 (1.4197)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 80/781]  eta: 0:04:00  lr: 0.000017  loss: 1.2718 (1.4036)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [ 90/781]  eta: 0:03:56  lr: 0.000017  loss: 1.2675 (1.3997)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [100/781]  eta: 0:03:52  lr: 0.000017  loss: 1.2513 (1.4115)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [110/781]  eta: 0:03:48  lr: 0.000017  loss: 1.2694 (1.4046)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [120/781]  eta: 0:03:44  lr: 0.000017  loss: 1.3174 (1.4185)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [130/781]  eta: 0:03:40  lr: 0.000017  loss: 1.3077 (1.4149)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [140/781]  eta: 0:03:37  lr: 0.000017  loss: 1.3154 (1.4262)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [150/781]  eta: 0:03:33  lr: 0.000017  loss: 1.3011 (1.4186)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [160/781]  eta: 0:03:30  lr: 0.000017  loss: 1.2462 (1.4179)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [170/781]  eta: 0:03:26  lr: 0.000017  loss: 1.2489 (1.4081)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [180/781]  eta: 0:03:22  lr: 0.000017  loss: 1.2740 (1.4212)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [190/781]  eta: 0:03:19  lr: 0.000017  loss: 1.3164 (1.4239)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [200/781]  eta: 0:03:15  lr: 0.000017  loss: 1.2984 (1.4301)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [210/781]  eta: 0:03:12  lr: 0.000017  loss: 1.3431 (1.4377)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [220/781]  eta: 0:03:09  lr: 0.000017  loss: 1.3367 (1.4345)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [230/781]  eta: 0:03:05  lr: 0.000017  loss: 1.3367 (1.4460)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [240/781]  eta: 0:03:02  lr: 0.000017  loss: 1.4042 (1.4499)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [250/781]  eta: 0:02:58  lr: 0.000017  loss: 1.2869 (1.4457)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [260/781]  eta: 0:02:55  lr: 0.000017  loss: 1.2876 (1.4494)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [270/781]  eta: 0:02:51  lr: 0.000017  loss: 1.3264 (1.4481)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [280/781]  eta: 0:02:48  lr: 0.000017  loss: 1.2626 (1.4504)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [290/781]  eta: 0:02:45  lr: 0.000017  loss: 1.2798 (1.4519)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [300/781]  eta: 0:02:41  lr: 0.000017  loss: 1.3143 (1.4580)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [310/781]  eta: 0:02:38  lr: 0.000017  loss: 1.3711 (1.4571)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [320/781]  eta: 0:02:34  lr: 0.000017  loss: 1.3532 (1.4620)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [330/781]  eta: 0:02:31  lr: 0.000017  loss: 1.2626 (1.4625)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [340/781]  eta: 0:02:28  lr: 0.000017  loss: 1.2529 (1.4573)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [350/781]  eta: 0:02:24  lr: 0.000017  loss: 1.2662 (1.4571)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [360/781]  eta: 0:02:21  lr: 0.000017  loss: 1.3111 (1.4525)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [370/781]  eta: 0:02:17  lr: 0.000017  loss: 1.2830 (1.4536)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [380/781]  eta: 0:02:14  lr: 0.000017  loss: 1.3069 (1.4524)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [390/781]  eta: 0:02:11  lr: 0.000017  loss: 1.3054 (1.4536)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [400/781]  eta: 0:02:07  lr: 0.000017  loss: 1.3376 (1.4605)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [410/781]  eta: 0:02:04  lr: 0.000017  loss: 1.3376 (1.4595)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [420/781]  eta: 0:02:01  lr: 0.000017  loss: 1.3217 (1.4581)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [430/781]  eta: 0:01:57  lr: 0.000017  loss: 1.3446 (1.4582)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [440/781]  eta: 0:01:54  lr: 0.000017  loss: 1.3531 (1.4599)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [450/781]  eta: 0:01:50  lr: 0.000017  loss: 1.2513 (1.4550)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [460/781]  eta: 0:01:47  lr: 0.000017  loss: 1.2436 (1.4514)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [470/781]  eta: 0:01:44  lr: 0.000017  loss: 1.2438 (1.4479)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [480/781]  eta: 0:01:40  lr: 0.000017  loss: 1.2781 (1.4465)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [490/781]  eta: 0:01:37  lr: 0.000017  loss: 1.2954 (1.4451)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [500/781]  eta: 0:01:34  lr: 0.000017  loss: 1.2954 (1.4462)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [510/781]  eta: 0:01:30  lr: 0.000017  loss: 1.2748 (1.4456)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [520/781]  eta: 0:01:27  lr: 0.000017  loss: 1.2817 (1.4446)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [530/781]  eta: 0:01:24  lr: 0.000017  loss: 1.2824 (1.4426)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [540/781]  eta: 0:01:20  lr: 0.000017  loss: 1.2969 (1.4405)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [550/781]  eta: 0:01:17  lr: 0.000017  loss: 1.3088 (1.4380)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [560/781]  eta: 0:01:13  lr: 0.000017  loss: 1.3080 (1.4396)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [570/781]  eta: 0:01:10  lr: 0.000017  loss: 1.3080 (1.4405)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [580/781]  eta: 0:01:07  lr: 0.000017  loss: 1.2889 (1.4403)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [590/781]  eta: 0:01:03  lr: 0.000017  loss: 1.3150 (1.4389)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [600/781]  eta: 0:01:00  lr: 0.000017  loss: 1.2652 (1.4368)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [610/781]  eta: 0:00:57  lr: 0.000017  loss: 1.3018 (1.4392)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [620/781]  eta: 0:00:53  lr: 0.000017  loss: 1.2754 (1.4378)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [630/781]  eta: 0:00:50  lr: 0.000017  loss: 1.2640 (1.4361)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [640/781]  eta: 0:00:47  lr: 0.000017  loss: 1.3276 (1.4379)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [650/781]  eta: 0:00:43  lr: 0.000017  loss: 1.2910 (1.4368)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [660/781]  eta: 0:00:40  lr: 0.000017  loss: 1.2910 (1.4354)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [670/781]  eta: 0:00:37  lr: 0.000017  loss: 1.2785 (1.4343)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [680/781]  eta: 0:00:33  lr: 0.000017  loss: 1.3184 (1.4369)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [690/781]  eta: 0:00:30  lr: 0.000017  loss: 1.3814 (1.4381)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [700/781]  eta: 0:00:27  lr: 0.000017  loss: 1.3184 (1.4381)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [710/781]  eta: 0:00:23  lr: 0.000017  loss: 1.3073 (1.4393)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [720/781]  eta: 0:00:20  lr: 0.000017  loss: 1.2890 (1.4367)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [730/781]  eta: 0:00:17  lr: 0.000017  loss: 1.2899 (1.4358)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [740/781]  eta: 0:00:13  lr: 0.000017  loss: 1.2970 (1.4373)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [750/781]  eta: 0:00:10  lr: 0.000017  loss: 1.2970 (1.4361)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [760/781]  eta: 0:00:07  lr: 0.000017  loss: 1.2592 (1.4366)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [770/781]  eta: 0:00:03  lr: 0.000017  loss: 1.2918 (1.4357)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [77]  [780/781]  eta: 0:00:00  lr: 0.000017  loss: 1.3131 (1.4352)  time: 0.3339  data: 0.0006  max mem: 6459\n",
            "Epoch: [77] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000017  loss: 1.3131 (1.4352)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3291614353656769, 'lambda_convnext_base': 0.2598098814487457, 'lambda_tf_efficientnetv2_l': 0.411028653383255}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8650 (0.8650)  acc1: 84.3750 (84.3750)  acc5: 93.2292 (93.2292)  time: 0.8198  data: 0.7887  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9024 (0.9885)  acc1: 84.3750 (81.6761)  acc5: 94.7917 (93.4186)  time: 0.1696  data: 0.1389  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0283 (1.0548)  acc1: 77.6042 (80.2083)  acc5: 93.2292 (92.4603)  time: 0.1224  data: 0.0917  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1956 (1.1108)  acc1: 75.0000 (78.9987)  acc5: 91.6667 (91.9691)  time: 0.1256  data: 0.0949  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2170 (1.1587)  acc1: 75.0000 (77.9853)  acc5: 90.1042 (91.4634)  time: 0.1241  data: 0.0934  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1545 (1.1496)  acc1: 76.5625 (77.9310)  acc5: 92.1875 (91.7892)  time: 0.1234  data: 0.0927  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1636 (1.1605)  acc1: 75.5208 (77.7900)  acc5: 92.7083 (91.8200)  time: 0.1076  data: 0.0779  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1308 s / it)\n",
            "* Acc@1 77.790 Acc@5 91.820 loss 1.161\n",
            "Accuracy of the network on the 10000 test images: 77.8%\n",
            "Max accuracy: 78.21%\n",
            "Epoch: [78]  [  0/781]  eta: 0:14:39  lr: 0.000017  loss: 1.2384 (1.2384)  time: 1.1256  data: 0.7876  max mem: 6459\n",
            "Epoch: [78]  [ 10/781]  eta: 0:05:12  lr: 0.000017  loss: 1.2950 (1.3396)  time: 0.4051  data: 0.0719  max mem: 6459\n",
            "Epoch: [78]  [ 20/781]  eta: 0:04:42  lr: 0.000017  loss: 1.2647 (1.3572)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 30/781]  eta: 0:04:29  lr: 0.000017  loss: 1.2647 (1.3630)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 40/781]  eta: 0:04:21  lr: 0.000017  loss: 1.2911 (1.3729)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 50/781]  eta: 0:04:14  lr: 0.000017  loss: 1.3131 (1.3781)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 60/781]  eta: 0:04:09  lr: 0.000017  loss: 1.3044 (1.4041)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 70/781]  eta: 0:04:04  lr: 0.000017  loss: 1.2943 (1.4107)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 80/781]  eta: 0:04:00  lr: 0.000017  loss: 1.2960 (1.3950)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [ 90/781]  eta: 0:03:56  lr: 0.000017  loss: 1.3246 (1.4134)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [100/781]  eta: 0:03:52  lr: 0.000017  loss: 1.3191 (1.4140)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [110/781]  eta: 0:03:48  lr: 0.000017  loss: 1.2814 (1.4149)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [120/781]  eta: 0:03:45  lr: 0.000017  loss: 1.2881 (1.4106)  time: 0.3437  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [130/781]  eta: 0:03:41  lr: 0.000017  loss: 1.2825 (1.4104)  time: 0.3436  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [140/781]  eta: 0:03:38  lr: 0.000017  loss: 1.2387 (1.4032)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [150/781]  eta: 0:03:34  lr: 0.000017  loss: 1.2667 (1.3973)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [160/781]  eta: 0:03:30  lr: 0.000017  loss: 1.2929 (1.3937)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [170/781]  eta: 0:03:27  lr: 0.000017  loss: 1.2660 (1.3916)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [180/781]  eta: 0:03:23  lr: 0.000017  loss: 1.2681 (1.3868)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [190/781]  eta: 0:03:19  lr: 0.000017  loss: 1.2658 (1.3805)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [200/781]  eta: 0:03:16  lr: 0.000017  loss: 1.2710 (1.3979)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [210/781]  eta: 0:03:12  lr: 0.000017  loss: 1.3350 (1.3981)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [220/781]  eta: 0:03:09  lr: 0.000017  loss: 1.3080 (1.3983)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [230/781]  eta: 0:03:05  lr: 0.000017  loss: 1.2810 (1.3966)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [240/781]  eta: 0:03:02  lr: 0.000017  loss: 1.2522 (1.3946)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [250/781]  eta: 0:02:59  lr: 0.000017  loss: 1.2970 (1.3954)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [260/781]  eta: 0:02:55  lr: 0.000017  loss: 1.2976 (1.3973)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [270/781]  eta: 0:02:52  lr: 0.000017  loss: 1.3069 (1.4030)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [280/781]  eta: 0:02:48  lr: 0.000017  loss: 1.2687 (1.4013)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [290/781]  eta: 0:02:45  lr: 0.000017  loss: 1.2432 (1.4000)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [300/781]  eta: 0:02:41  lr: 0.000017  loss: 1.2830 (1.3995)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [310/781]  eta: 0:02:38  lr: 0.000017  loss: 1.2931 (1.3982)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [320/781]  eta: 0:02:35  lr: 0.000017  loss: 1.2731 (1.4051)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [330/781]  eta: 0:02:31  lr: 0.000017  loss: 1.2990 (1.4051)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [340/781]  eta: 0:02:28  lr: 0.000017  loss: 1.2609 (1.4045)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [350/781]  eta: 0:02:24  lr: 0.000017  loss: 1.2450 (1.4002)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [360/781]  eta: 0:02:21  lr: 0.000017  loss: 1.2843 (1.3982)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [370/781]  eta: 0:02:18  lr: 0.000017  loss: 1.3340 (1.4015)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [380/781]  eta: 0:02:14  lr: 0.000017  loss: 1.2889 (1.4017)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [390/781]  eta: 0:02:11  lr: 0.000017  loss: 1.2713 (1.4018)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [400/781]  eta: 0:02:07  lr: 0.000017  loss: 1.2770 (1.4032)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [410/781]  eta: 0:02:04  lr: 0.000017  loss: 1.3091 (1.4088)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [420/781]  eta: 0:02:01  lr: 0.000017  loss: 1.2929 (1.4088)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [430/781]  eta: 0:01:57  lr: 0.000017  loss: 1.2713 (1.4091)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [440/781]  eta: 0:01:54  lr: 0.000017  loss: 1.2754 (1.4103)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [450/781]  eta: 0:01:51  lr: 0.000017  loss: 1.2754 (1.4089)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [460/781]  eta: 0:01:47  lr: 0.000017  loss: 1.3021 (1.4081)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [470/781]  eta: 0:01:44  lr: 0.000017  loss: 1.2926 (1.4056)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [480/781]  eta: 0:01:40  lr: 0.000017  loss: 1.2926 (1.4062)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [490/781]  eta: 0:01:37  lr: 0.000017  loss: 1.2910 (1.4077)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [500/781]  eta: 0:01:34  lr: 0.000017  loss: 1.2910 (1.4057)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [510/781]  eta: 0:01:30  lr: 0.000017  loss: 1.2722 (1.4038)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [520/781]  eta: 0:01:27  lr: 0.000017  loss: 1.2653 (1.4037)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [530/781]  eta: 0:01:24  lr: 0.000017  loss: 1.2921 (1.4069)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [540/781]  eta: 0:01:20  lr: 0.000017  loss: 1.2887 (1.4082)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [550/781]  eta: 0:01:17  lr: 0.000017  loss: 1.2842 (1.4087)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [560/781]  eta: 0:01:14  lr: 0.000017  loss: 1.2842 (1.4103)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [570/781]  eta: 0:01:10  lr: 0.000017  loss: 1.2956 (1.4107)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [580/781]  eta: 0:01:07  lr: 0.000017  loss: 1.2864 (1.4106)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [590/781]  eta: 0:01:03  lr: 0.000017  loss: 1.2790 (1.4096)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [600/781]  eta: 0:01:00  lr: 0.000017  loss: 1.2790 (1.4075)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [610/781]  eta: 0:00:57  lr: 0.000017  loss: 1.2676 (1.4057)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [620/781]  eta: 0:00:53  lr: 0.000017  loss: 1.3067 (1.4102)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [630/781]  eta: 0:00:50  lr: 0.000017  loss: 1.3238 (1.4092)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [640/781]  eta: 0:00:47  lr: 0.000017  loss: 1.2958 (1.4089)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [650/781]  eta: 0:00:43  lr: 0.000017  loss: 1.2454 (1.4093)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [660/781]  eta: 0:00:40  lr: 0.000017  loss: 1.2839 (1.4107)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [670/781]  eta: 0:00:37  lr: 0.000017  loss: 1.3485 (1.4121)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [680/781]  eta: 0:00:33  lr: 0.000017  loss: 1.2800 (1.4117)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [690/781]  eta: 0:00:30  lr: 0.000017  loss: 1.2423 (1.4137)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [700/781]  eta: 0:00:27  lr: 0.000017  loss: 1.3652 (1.4160)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [710/781]  eta: 0:00:23  lr: 0.000017  loss: 1.3652 (1.4171)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [720/781]  eta: 0:00:20  lr: 0.000017  loss: 1.2943 (1.4193)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [730/781]  eta: 0:00:17  lr: 0.000017  loss: 1.2620 (1.4188)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [740/781]  eta: 0:00:13  lr: 0.000017  loss: 1.2567 (1.4205)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [750/781]  eta: 0:00:10  lr: 0.000017  loss: 1.3124 (1.4242)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [760/781]  eta: 0:00:07  lr: 0.000017  loss: 1.3090 (1.4229)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [770/781]  eta: 0:00:03  lr: 0.000017  loss: 1.2942 (1.4234)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [78]  [780/781]  eta: 0:00:00  lr: 0.000017  loss: 1.2750 (1.4244)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [78] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000017  loss: 1.2750 (1.4244)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3294912576675415, 'lambda_convnext_base': 0.2597328722476959, 'lambda_tf_efficientnetv2_l': 0.4107763171195984}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8134 (0.8134)  acc1: 83.8542 (83.8542)  acc5: 95.8333 (95.8333)  time: 0.8556  data: 0.8247  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9455 (0.9786)  acc1: 83.8542 (81.9602)  acc5: 94.2708 (93.4659)  time: 0.1742  data: 0.1434  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0658 (1.0450)  acc1: 77.6042 (80.3819)  acc5: 93.7500 (92.4603)  time: 0.1192  data: 0.0885  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2057 (1.1006)  acc1: 76.5625 (79.3179)  acc5: 91.6667 (92.0531)  time: 0.1228  data: 0.0921  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2253 (1.1386)  acc1: 76.0417 (78.4172)  acc5: 90.6250 (91.6921)  time: 0.1213  data: 0.0906  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1136 (1.1354)  acc1: 75.5208 (78.1250)  acc5: 92.1875 (92.0241)  time: 0.1224  data: 0.0917  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2102 (1.1464)  acc1: 75.5208 (77.9600)  acc5: 92.7083 (92.0700)  time: 0.1076  data: 0.0779  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1303 s / it)\n",
            "* Acc@1 77.960 Acc@5 92.070 loss 1.146\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.21%\n",
            "Epoch: [79]  [  0/781]  eta: 0:14:30  lr: 0.000016  loss: 1.2874 (1.2874)  time: 1.1148  data: 0.7765  max mem: 6459\n",
            "Epoch: [79]  [ 10/781]  eta: 0:05:11  lr: 0.000016  loss: 1.3000 (1.5098)  time: 0.4044  data: 0.0709  max mem: 6459\n",
            "Epoch: [79]  [ 20/781]  eta: 0:04:42  lr: 0.000016  loss: 1.2947 (1.4555)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 30/781]  eta: 0:04:29  lr: 0.000016  loss: 1.2947 (1.4232)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 40/781]  eta: 0:04:21  lr: 0.000016  loss: 1.3375 (1.4773)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 50/781]  eta: 0:04:14  lr: 0.000016  loss: 1.2960 (1.4789)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 60/781]  eta: 0:04:09  lr: 0.000016  loss: 1.2823 (1.4806)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 70/781]  eta: 0:04:04  lr: 0.000016  loss: 1.2888 (1.4921)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 80/781]  eta: 0:04:00  lr: 0.000016  loss: 1.2832 (1.4808)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [ 90/781]  eta: 0:03:56  lr: 0.000016  loss: 1.2486 (1.4635)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [100/781]  eta: 0:03:52  lr: 0.000016  loss: 1.2998 (1.4995)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [110/781]  eta: 0:03:48  lr: 0.000016  loss: 1.2970 (1.4808)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [120/781]  eta: 0:03:44  lr: 0.000016  loss: 1.2687 (1.4681)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.3038 (1.4694)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [140/781]  eta: 0:03:37  lr: 0.000016  loss: 1.3104 (1.4597)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [150/781]  eta: 0:03:33  lr: 0.000016  loss: 1.3104 (1.4530)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [160/781]  eta: 0:03:30  lr: 0.000016  loss: 1.2734 (1.4531)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [170/781]  eta: 0:03:26  lr: 0.000016  loss: 1.2794 (1.4603)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [180/781]  eta: 0:03:23  lr: 0.000016  loss: 1.2768 (1.4530)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [190/781]  eta: 0:03:19  lr: 0.000016  loss: 1.2626 (1.4446)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [200/781]  eta: 0:03:16  lr: 0.000016  loss: 1.2675 (1.4376)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [210/781]  eta: 0:03:12  lr: 0.000016  loss: 1.2886 (1.4336)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [220/781]  eta: 0:03:09  lr: 0.000016  loss: 1.2962 (1.4363)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [230/781]  eta: 0:03:05  lr: 0.000016  loss: 1.2841 (1.4369)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [240/781]  eta: 0:03:02  lr: 0.000016  loss: 1.2915 (1.4343)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [250/781]  eta: 0:02:58  lr: 0.000016  loss: 1.2915 (1.4283)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [260/781]  eta: 0:02:55  lr: 0.000016  loss: 1.2893 (1.4312)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.2864 (1.4355)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [280/781]  eta: 0:02:48  lr: 0.000016  loss: 1.2544 (1.4324)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [290/781]  eta: 0:02:45  lr: 0.000016  loss: 1.2819 (1.4353)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [300/781]  eta: 0:02:41  lr: 0.000016  loss: 1.3016 (1.4309)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [310/781]  eta: 0:02:38  lr: 0.000016  loss: 1.3016 (1.4333)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.3197 (1.4341)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [330/781]  eta: 0:02:31  lr: 0.000016  loss: 1.3335 (1.4381)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [340/781]  eta: 0:02:28  lr: 0.000016  loss: 1.2920 (1.4372)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.2898 (1.4325)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [360/781]  eta: 0:02:21  lr: 0.000016  loss: 1.2723 (1.4276)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.2775 (1.4279)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [380/781]  eta: 0:02:14  lr: 0.000016  loss: 1.2944 (1.4297)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [390/781]  eta: 0:02:11  lr: 0.000016  loss: 1.3081 (1.4311)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.2883 (1.4300)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [410/781]  eta: 0:02:04  lr: 0.000016  loss: 1.2445 (1.4312)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [420/781]  eta: 0:02:01  lr: 0.000016  loss: 1.2801 (1.4299)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.2975 (1.4284)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [440/781]  eta: 0:01:54  lr: 0.000016  loss: 1.3473 (1.4268)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.3473 (1.4290)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.3903 (1.4336)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [470/781]  eta: 0:01:44  lr: 0.000016  loss: 1.3850 (1.4344)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.2812 (1.4336)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.2740 (1.4312)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [500/781]  eta: 0:01:34  lr: 0.000016  loss: 1.3118 (1.4308)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.2740 (1.4287)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.2617 (1.4262)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [530/781]  eta: 0:01:24  lr: 0.000016  loss: 1.2985 (1.4240)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.2941 (1.4241)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [550/781]  eta: 0:01:17  lr: 0.000016  loss: 1.2634 (1.4237)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [560/781]  eta: 0:01:14  lr: 0.000016  loss: 1.2657 (1.4250)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.3097 (1.4243)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [580/781]  eta: 0:01:07  lr: 0.000016  loss: 1.2670 (1.4245)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.2609 (1.4227)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.2609 (1.4221)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [610/781]  eta: 0:00:57  lr: 0.000016  loss: 1.2959 (1.4257)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.3348 (1.4252)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.2264 (1.4219)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [640/781]  eta: 0:00:47  lr: 0.000016  loss: 1.2478 (1.4219)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.2616 (1.4207)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.2616 (1.4220)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [670/781]  eta: 0:00:37  lr: 0.000016  loss: 1.2904 (1.4207)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.3060 (1.4243)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.3638 (1.4262)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [700/781]  eta: 0:00:27  lr: 0.000016  loss: 1.3638 (1.4272)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.3366 (1.4272)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.3385 (1.4293)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [730/781]  eta: 0:00:17  lr: 0.000016  loss: 1.2807 (1.4267)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.2416 (1.4273)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.2900 (1.4263)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [760/781]  eta: 0:00:07  lr: 0.000016  loss: 1.3096 (1.4280)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.2944 (1.4274)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [79]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.2675 (1.4271)  time: 0.3337  data: 0.0005  max mem: 6459\n",
            "Epoch: [79] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.2675 (1.4271)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32883572578430176, 'lambda_convnext_base': 0.2597050070762634, 'lambda_tf_efficientnetv2_l': 0.41145917773246765}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8067 (0.8067)  acc1: 86.4583 (86.4583)  acc5: 95.8333 (95.8333)  time: 0.8489  data: 0.8180  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9807 (0.9613)  acc1: 83.3333 (82.3390)  acc5: 94.7917 (93.5606)  time: 0.1724  data: 0.1417  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0384 (1.0367)  acc1: 80.2083 (80.8780)  acc5: 93.2292 (92.5347)  time: 0.1205  data: 0.0898  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2168 (1.0988)  acc1: 76.0417 (79.4187)  acc5: 90.6250 (91.9523)  time: 0.1221  data: 0.0914  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2531 (1.1451)  acc1: 75.5208 (78.4172)  acc5: 90.6250 (91.5142)  time: 0.1250  data: 0.0943  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1107 (1.1377)  acc1: 78.1250 (78.3088)  acc5: 91.6667 (91.7790)  time: 0.1232  data: 0.0925  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1430 (1.1463)  acc1: 76.0417 (78.1900)  acc5: 92.1875 (91.8200)  time: 0.1038  data: 0.0741  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1301 s / it)\n",
            "* Acc@1 78.190 Acc@5 91.820 loss 1.146\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.21%\n",
            "Epoch: [80]  [  0/781]  eta: 0:12:52  lr: 0.000016  loss: 1.2573 (1.2573)  time: 0.9897  data: 0.6494  max mem: 6459\n",
            "Epoch: [80]  [ 10/781]  eta: 0:05:03  lr: 0.000016  loss: 1.2302 (1.2980)  time: 0.3934  data: 0.0593  max mem: 6459\n",
            "Epoch: [80]  [ 20/781]  eta: 0:04:37  lr: 0.000016  loss: 1.2386 (1.3160)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 30/781]  eta: 0:04:26  lr: 0.000016  loss: 1.2773 (1.3303)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 40/781]  eta: 0:04:18  lr: 0.000016  loss: 1.2880 (1.3341)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 50/781]  eta: 0:04:12  lr: 0.000016  loss: 1.2607 (1.3623)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 60/781]  eta: 0:04:08  lr: 0.000016  loss: 1.2620 (1.3549)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 70/781]  eta: 0:04:03  lr: 0.000016  loss: 1.2733 (1.3544)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 80/781]  eta: 0:03:59  lr: 0.000016  loss: 1.2890 (1.3557)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [ 90/781]  eta: 0:03:55  lr: 0.000016  loss: 1.2890 (1.3592)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [100/781]  eta: 0:03:51  lr: 0.000016  loss: 1.3092 (1.3644)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [110/781]  eta: 0:03:47  lr: 0.000016  loss: 1.3029 (1.3559)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [120/781]  eta: 0:03:43  lr: 0.000016  loss: 1.2369 (1.3555)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [130/781]  eta: 0:03:40  lr: 0.000016  loss: 1.2456 (1.3559)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [140/781]  eta: 0:03:36  lr: 0.000016  loss: 1.2895 (1.3575)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [150/781]  eta: 0:03:33  lr: 0.000016  loss: 1.2895 (1.3609)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [160/781]  eta: 0:03:29  lr: 0.000016  loss: 1.2732 (1.3621)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [170/781]  eta: 0:03:26  lr: 0.000016  loss: 1.2864 (1.3654)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [180/781]  eta: 0:03:22  lr: 0.000016  loss: 1.2871 (1.3661)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [190/781]  eta: 0:03:19  lr: 0.000016  loss: 1.2678 (1.3627)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [200/781]  eta: 0:03:15  lr: 0.000016  loss: 1.2678 (1.3629)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [210/781]  eta: 0:03:12  lr: 0.000016  loss: 1.3132 (1.3598)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [220/781]  eta: 0:03:08  lr: 0.000016  loss: 1.3036 (1.3666)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [230/781]  eta: 0:03:05  lr: 0.000016  loss: 1.3192 (1.3674)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [240/781]  eta: 0:03:01  lr: 0.000016  loss: 1.3092 (1.3668)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [250/781]  eta: 0:02:58  lr: 0.000016  loss: 1.2681 (1.3665)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [260/781]  eta: 0:02:54  lr: 0.000016  loss: 1.2609 (1.3674)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [270/781]  eta: 0:02:51  lr: 0.000016  loss: 1.2955 (1.3696)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [280/781]  eta: 0:02:48  lr: 0.000016  loss: 1.2932 (1.3717)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [290/781]  eta: 0:02:44  lr: 0.000016  loss: 1.2820 (1.3737)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [300/781]  eta: 0:02:41  lr: 0.000016  loss: 1.2918 (1.3759)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [310/781]  eta: 0:02:38  lr: 0.000016  loss: 1.3246 (1.3789)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [320/781]  eta: 0:02:34  lr: 0.000016  loss: 1.2715 (1.3788)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [330/781]  eta: 0:02:31  lr: 0.000016  loss: 1.2678 (1.3852)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [340/781]  eta: 0:02:27  lr: 0.000016  loss: 1.2887 (1.3863)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [350/781]  eta: 0:02:24  lr: 0.000016  loss: 1.2445 (1.3839)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [360/781]  eta: 0:02:21  lr: 0.000016  loss: 1.2899 (1.3846)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [370/781]  eta: 0:02:17  lr: 0.000016  loss: 1.3087 (1.3826)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [380/781]  eta: 0:02:14  lr: 0.000016  loss: 1.2953 (1.3843)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [390/781]  eta: 0:02:11  lr: 0.000016  loss: 1.3192 (1.3849)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [400/781]  eta: 0:02:07  lr: 0.000016  loss: 1.3424 (1.3917)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [410/781]  eta: 0:02:04  lr: 0.000016  loss: 1.3203 (1.3896)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [420/781]  eta: 0:02:00  lr: 0.000016  loss: 1.3104 (1.3882)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [430/781]  eta: 0:01:57  lr: 0.000016  loss: 1.3104 (1.3903)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [440/781]  eta: 0:01:54  lr: 0.000016  loss: 1.2569 (1.3941)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [450/781]  eta: 0:01:50  lr: 0.000016  loss: 1.2751 (1.3934)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [460/781]  eta: 0:01:47  lr: 0.000016  loss: 1.2751 (1.3937)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [470/781]  eta: 0:01:44  lr: 0.000016  loss: 1.2770 (1.3965)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [480/781]  eta: 0:01:40  lr: 0.000016  loss: 1.3000 (1.3961)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [490/781]  eta: 0:01:37  lr: 0.000016  loss: 1.2924 (1.3972)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [500/781]  eta: 0:01:34  lr: 0.000016  loss: 1.2898 (1.3960)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [510/781]  eta: 0:01:30  lr: 0.000016  loss: 1.2826 (1.3975)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [520/781]  eta: 0:01:27  lr: 0.000016  loss: 1.2829 (1.4006)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [530/781]  eta: 0:01:24  lr: 0.000016  loss: 1.2903 (1.4031)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [540/781]  eta: 0:01:20  lr: 0.000016  loss: 1.3054 (1.4042)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [550/781]  eta: 0:01:17  lr: 0.000016  loss: 1.2816 (1.4032)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [560/781]  eta: 0:01:13  lr: 0.000016  loss: 1.2675 (1.4014)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [570/781]  eta: 0:01:10  lr: 0.000016  loss: 1.2657 (1.4010)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [580/781]  eta: 0:01:07  lr: 0.000016  loss: 1.2407 (1.3997)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [590/781]  eta: 0:01:03  lr: 0.000016  loss: 1.2785 (1.3986)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [600/781]  eta: 0:01:00  lr: 0.000016  loss: 1.2981 (1.3984)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [610/781]  eta: 0:00:57  lr: 0.000016  loss: 1.2966 (1.3968)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [620/781]  eta: 0:00:53  lr: 0.000016  loss: 1.2532 (1.3977)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [630/781]  eta: 0:00:50  lr: 0.000016  loss: 1.2578 (1.3974)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [640/781]  eta: 0:00:47  lr: 0.000016  loss: 1.2578 (1.3951)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [650/781]  eta: 0:00:43  lr: 0.000016  loss: 1.3087 (1.3981)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [660/781]  eta: 0:00:40  lr: 0.000016  loss: 1.3391 (1.3971)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [670/781]  eta: 0:00:37  lr: 0.000016  loss: 1.2804 (1.3979)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [680/781]  eta: 0:00:33  lr: 0.000016  loss: 1.2525 (1.3974)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [690/781]  eta: 0:00:30  lr: 0.000016  loss: 1.2394 (1.3951)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [700/781]  eta: 0:00:27  lr: 0.000016  loss: 1.2518 (1.3938)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [710/781]  eta: 0:00:23  lr: 0.000016  loss: 1.2993 (1.3938)  time: 0.3337  data: 0.0004  max mem: 6459\n",
            "Epoch: [80]  [720/781]  eta: 0:00:20  lr: 0.000016  loss: 1.2459 (1.3941)  time: 0.3334  data: 0.0004  max mem: 6459\n",
            "Epoch: [80]  [730/781]  eta: 0:00:17  lr: 0.000016  loss: 1.2869 (1.3960)  time: 0.3437  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [740/781]  eta: 0:00:13  lr: 0.000016  loss: 1.2869 (1.3949)  time: 0.3439  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [750/781]  eta: 0:00:10  lr: 0.000016  loss: 1.2731 (1.3957)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [760/781]  eta: 0:00:07  lr: 0.000016  loss: 1.2662 (1.3944)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [770/781]  eta: 0:00:03  lr: 0.000016  loss: 1.3026 (1.3962)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [80]  [780/781]  eta: 0:00:00  lr: 0.000016  loss: 1.3102 (1.3971)  time: 0.3337  data: 0.0005  max mem: 6459\n",
            "Epoch: [80] Total time: 0:04:21 (0.3348 s / it)\n",
            "Averaged stats: lr: 0.000016  loss: 1.3102 (1.3971)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290824294090271, 'lambda_convnext_base': 0.2587907314300537, 'lambda_tf_efficientnetv2_l': 0.412127286195755}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8192 (0.8192)  acc1: 84.8958 (84.8958)  acc5: 96.3542 (96.3542)  time: 0.8401  data: 0.8092  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8670 (0.9589)  acc1: 84.8958 (82.5284)  acc5: 95.3125 (94.0341)  time: 0.1699  data: 0.1392  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0768 (1.0237)  acc1: 79.6875 (81.1756)  acc5: 93.2292 (92.7827)  time: 0.1222  data: 0.0915  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1742 (1.0883)  acc1: 77.0833 (79.7883)  acc5: 91.1458 (92.2715)  time: 0.1224  data: 0.0918  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3052 (1.1340)  acc1: 75.0000 (78.7348)  acc5: 91.1458 (91.7429)  time: 0.1230  data: 0.0923  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1644 (1.1346)  acc1: 75.5208 (78.4722)  acc5: 91.6667 (91.9118)  time: 0.1239  data: 0.0932  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1715 (1.1438)  acc1: 75.0000 (78.3400)  acc5: 91.6667 (91.9500)  time: 0.1045  data: 0.0748  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1298 s / it)\n",
            "* Acc@1 78.340 Acc@5 91.950 loss 1.144\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [81]  [  0/781]  eta: 0:14:56  lr: 0.000015  loss: 1.1964 (1.1964)  time: 1.1484  data: 0.7997  max mem: 6459\n",
            "Epoch: [81]  [ 10/781]  eta: 0:05:14  lr: 0.000015  loss: 1.2875 (1.5434)  time: 0.4078  data: 0.0730  max mem: 6459\n",
            "Epoch: [81]  [ 20/781]  eta: 0:04:43  lr: 0.000015  loss: 1.2664 (1.4268)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 30/781]  eta: 0:04:30  lr: 0.000015  loss: 1.2357 (1.4057)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 40/781]  eta: 0:04:21  lr: 0.000015  loss: 1.2875 (1.4918)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 50/781]  eta: 0:04:15  lr: 0.000015  loss: 1.2885 (1.4678)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 60/781]  eta: 0:04:09  lr: 0.000015  loss: 1.2439 (1.4539)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 70/781]  eta: 0:04:05  lr: 0.000015  loss: 1.2616 (1.4461)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 80/781]  eta: 0:04:00  lr: 0.000015  loss: 1.3230 (1.4679)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [ 90/781]  eta: 0:03:56  lr: 0.000015  loss: 1.3230 (1.4685)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [100/781]  eta: 0:03:52  lr: 0.000015  loss: 1.2396 (1.4555)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [110/781]  eta: 0:03:48  lr: 0.000015  loss: 1.2646 (1.4557)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [120/781]  eta: 0:03:44  lr: 0.000015  loss: 1.2729 (1.4519)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [130/781]  eta: 0:03:41  lr: 0.000015  loss: 1.2786 (1.4411)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [140/781]  eta: 0:03:37  lr: 0.000015  loss: 1.2763 (1.4332)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [150/781]  eta: 0:03:33  lr: 0.000015  loss: 1.2763 (1.4300)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [160/781]  eta: 0:03:30  lr: 0.000015  loss: 1.2987 (1.4316)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [170/781]  eta: 0:03:26  lr: 0.000015  loss: 1.2817 (1.4292)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [180/781]  eta: 0:03:23  lr: 0.000015  loss: 1.2817 (1.4240)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [190/781]  eta: 0:03:19  lr: 0.000015  loss: 1.3277 (1.4283)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [200/781]  eta: 0:03:16  lr: 0.000015  loss: 1.3105 (1.4324)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [210/781]  eta: 0:03:12  lr: 0.000015  loss: 1.3157 (1.4309)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [220/781]  eta: 0:03:09  lr: 0.000015  loss: 1.3193 (1.4282)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [230/781]  eta: 0:03:05  lr: 0.000015  loss: 1.2569 (1.4260)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [240/781]  eta: 0:03:02  lr: 0.000015  loss: 1.2846 (1.4271)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [250/781]  eta: 0:02:58  lr: 0.000015  loss: 1.2846 (1.4209)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [260/781]  eta: 0:02:55  lr: 0.000015  loss: 1.2590 (1.4156)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [270/781]  eta: 0:02:52  lr: 0.000015  loss: 1.2988 (1.4150)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [280/781]  eta: 0:02:48  lr: 0.000015  loss: 1.2788 (1.4191)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [290/781]  eta: 0:02:45  lr: 0.000015  loss: 1.2616 (1.4213)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [300/781]  eta: 0:02:41  lr: 0.000015  loss: 1.2826 (1.4219)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [310/781]  eta: 0:02:38  lr: 0.000015  loss: 1.2826 (1.4235)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.2953 (1.4296)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [330/781]  eta: 0:02:31  lr: 0.000015  loss: 1.3338 (1.4287)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [340/781]  eta: 0:02:28  lr: 0.000015  loss: 1.2931 (1.4290)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [350/781]  eta: 0:02:24  lr: 0.000015  loss: 1.3102 (1.4315)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [360/781]  eta: 0:02:21  lr: 0.000015  loss: 1.3019 (1.4330)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [370/781]  eta: 0:02:18  lr: 0.000015  loss: 1.2626 (1.4290)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [380/781]  eta: 0:02:14  lr: 0.000015  loss: 1.2061 (1.4261)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [390/781]  eta: 0:02:11  lr: 0.000015  loss: 1.2358 (1.4237)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.2782 (1.4274)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [410/781]  eta: 0:02:04  lr: 0.000015  loss: 1.3322 (1.4288)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [420/781]  eta: 0:02:01  lr: 0.000015  loss: 1.3087 (1.4255)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.2726 (1.4268)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [440/781]  eta: 0:01:54  lr: 0.000015  loss: 1.2601 (1.4292)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [450/781]  eta: 0:01:51  lr: 0.000015  loss: 1.2537 (1.4260)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.2471 (1.4257)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [470/781]  eta: 0:01:44  lr: 0.000015  loss: 1.2552 (1.4245)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.3072 (1.4270)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.2402 (1.4227)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [500/781]  eta: 0:01:34  lr: 0.000015  loss: 1.2303 (1.4209)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.2829 (1.4247)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.2542 (1.4215)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [530/781]  eta: 0:01:24  lr: 0.000015  loss: 1.2482 (1.4226)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.2638 (1.4197)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [550/781]  eta: 0:01:17  lr: 0.000015  loss: 1.3058 (1.4237)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [560/781]  eta: 0:01:14  lr: 0.000015  loss: 1.3629 (1.4246)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.3323 (1.4259)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [580/781]  eta: 0:01:07  lr: 0.000015  loss: 1.3000 (1.4253)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.2728 (1.4252)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.2788 (1.4246)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [610/781]  eta: 0:00:57  lr: 0.000015  loss: 1.2783 (1.4270)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.2290 (1.4242)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.2971 (1.4231)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [640/781]  eta: 0:00:47  lr: 0.000015  loss: 1.3064 (1.4249)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.3064 (1.4233)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.2827 (1.4218)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [670/781]  eta: 0:00:37  lr: 0.000015  loss: 1.2931 (1.4216)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.2884 (1.4198)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.2884 (1.4198)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [700/781]  eta: 0:00:27  lr: 0.000015  loss: 1.2575 (1.4193)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.2650 (1.4199)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.2650 (1.4199)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [730/781]  eta: 0:00:17  lr: 0.000015  loss: 1.2881 (1.4210)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.3069 (1.4226)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.3383 (1.4237)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [760/781]  eta: 0:00:07  lr: 0.000015  loss: 1.3258 (1.4226)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.2816 (1.4226)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [81]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.2820 (1.4239)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [81] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.2820 (1.4239)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32969316840171814, 'lambda_convnext_base': 0.25974375009536743, 'lambda_tf_efficientnetv2_l': 0.4105633795261383}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8915 (0.8915)  acc1: 82.8125 (82.8125)  acc5: 93.7500 (93.7500)  time: 0.8116  data: 0.7807  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8915 (0.9801)  acc1: 82.8125 (81.5341)  acc5: 94.7917 (93.6080)  time: 0.1689  data: 0.1382  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0474 (1.0378)  acc1: 80.2083 (80.5308)  acc5: 94.2708 (92.7331)  time: 0.1237  data: 0.0931  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2070 (1.1043)  acc1: 76.5625 (79.2843)  acc5: 90.1042 (91.9691)  time: 0.1263  data: 0.0956  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3041 (1.1365)  acc1: 75.0000 (78.5188)  acc5: 90.1042 (91.7556)  time: 0.1262  data: 0.0955  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1531 (1.1364)  acc1: 77.0833 (78.2271)  acc5: 92.7083 (91.9526)  time: 0.1247  data: 0.0940  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1682 (1.1457)  acc1: 76.5625 (78.1100)  acc5: 93.2292 (91.9900)  time: 0.1088  data: 0.0791  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1315 s / it)\n",
            "* Acc@1 78.110 Acc@5 91.990 loss 1.146\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [82]  [  0/781]  eta: 0:14:30  lr: 0.000015  loss: 1.1955 (1.1955)  time: 1.1143  data: 0.7737  max mem: 6459\n",
            "Epoch: [82]  [ 10/781]  eta: 0:05:11  lr: 0.000015  loss: 1.2768 (1.3686)  time: 0.4040  data: 0.0706  max mem: 6459\n",
            "Epoch: [82]  [ 20/781]  eta: 0:04:41  lr: 0.000015  loss: 1.2768 (1.3798)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 30/781]  eta: 0:04:29  lr: 0.000015  loss: 1.2662 (1.3764)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 40/781]  eta: 0:04:20  lr: 0.000015  loss: 1.2662 (1.3517)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 50/781]  eta: 0:04:14  lr: 0.000015  loss: 1.2969 (1.4279)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 60/781]  eta: 0:04:09  lr: 0.000015  loss: 1.2606 (1.3968)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 70/781]  eta: 0:04:04  lr: 0.000015  loss: 1.2500 (1.3782)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 80/781]  eta: 0:04:00  lr: 0.000015  loss: 1.2749 (1.3937)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [ 90/781]  eta: 0:03:56  lr: 0.000015  loss: 1.3245 (1.3924)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [100/781]  eta: 0:03:52  lr: 0.000015  loss: 1.3107 (1.3903)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [110/781]  eta: 0:03:48  lr: 0.000015  loss: 1.2671 (1.3852)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [120/781]  eta: 0:03:44  lr: 0.000015  loss: 1.2134 (1.3803)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [130/781]  eta: 0:03:40  lr: 0.000015  loss: 1.2279 (1.3927)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [140/781]  eta: 0:03:37  lr: 0.000015  loss: 1.2938 (1.3918)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [150/781]  eta: 0:03:33  lr: 0.000015  loss: 1.2771 (1.4028)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [160/781]  eta: 0:03:29  lr: 0.000015  loss: 1.3068 (1.4029)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [170/781]  eta: 0:03:26  lr: 0.000015  loss: 1.3068 (1.4101)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [180/781]  eta: 0:03:22  lr: 0.000015  loss: 1.2894 (1.4122)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [190/781]  eta: 0:03:19  lr: 0.000015  loss: 1.2696 (1.4041)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [200/781]  eta: 0:03:15  lr: 0.000015  loss: 1.2764 (1.4054)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [210/781]  eta: 0:03:12  lr: 0.000015  loss: 1.2784 (1.4013)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [220/781]  eta: 0:03:08  lr: 0.000015  loss: 1.2331 (1.4003)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [230/781]  eta: 0:03:05  lr: 0.000015  loss: 1.2744 (1.4009)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [240/781]  eta: 0:03:02  lr: 0.000015  loss: 1.3010 (1.3988)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [250/781]  eta: 0:02:58  lr: 0.000015  loss: 1.3010 (1.4039)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [260/781]  eta: 0:02:55  lr: 0.000015  loss: 1.2956 (1.4041)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [270/781]  eta: 0:02:51  lr: 0.000015  loss: 1.2868 (1.4073)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [280/781]  eta: 0:02:48  lr: 0.000015  loss: 1.2866 (1.4062)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [290/781]  eta: 0:02:44  lr: 0.000015  loss: 1.2636 (1.4053)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [300/781]  eta: 0:02:41  lr: 0.000015  loss: 1.2256 (1.3988)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [310/781]  eta: 0:02:38  lr: 0.000015  loss: 1.2297 (1.4017)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [320/781]  eta: 0:02:34  lr: 0.000015  loss: 1.2724 (1.4003)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [330/781]  eta: 0:02:31  lr: 0.000015  loss: 1.2503 (1.3959)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [340/781]  eta: 0:02:27  lr: 0.000015  loss: 1.2503 (1.3928)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [350/781]  eta: 0:02:24  lr: 0.000015  loss: 1.2471 (1.3911)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [360/781]  eta: 0:02:21  lr: 0.000015  loss: 1.2353 (1.3917)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [370/781]  eta: 0:02:17  lr: 0.000015  loss: 1.2822 (1.3919)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [380/781]  eta: 0:02:14  lr: 0.000015  loss: 1.2991 (1.3932)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [390/781]  eta: 0:02:11  lr: 0.000015  loss: 1.3153 (1.3971)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [400/781]  eta: 0:02:07  lr: 0.000015  loss: 1.3064 (1.4007)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [410/781]  eta: 0:02:04  lr: 0.000015  loss: 1.2625 (1.3999)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [420/781]  eta: 0:02:00  lr: 0.000015  loss: 1.2830 (1.4038)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [430/781]  eta: 0:01:57  lr: 0.000015  loss: 1.3231 (1.4061)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [440/781]  eta: 0:01:54  lr: 0.000015  loss: 1.2838 (1.4060)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [450/781]  eta: 0:01:50  lr: 0.000015  loss: 1.2158 (1.4026)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [460/781]  eta: 0:01:47  lr: 0.000015  loss: 1.2063 (1.3990)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [470/781]  eta: 0:01:44  lr: 0.000015  loss: 1.2443 (1.4014)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [480/781]  eta: 0:01:40  lr: 0.000015  loss: 1.2960 (1.4025)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [490/781]  eta: 0:01:37  lr: 0.000015  loss: 1.2569 (1.4021)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [500/781]  eta: 0:01:34  lr: 0.000015  loss: 1.2577 (1.4029)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [510/781]  eta: 0:01:30  lr: 0.000015  loss: 1.2681 (1.4010)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [520/781]  eta: 0:01:27  lr: 0.000015  loss: 1.2048 (1.4030)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [530/781]  eta: 0:01:24  lr: 0.000015  loss: 1.2599 (1.4005)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [540/781]  eta: 0:01:20  lr: 0.000015  loss: 1.2599 (1.4010)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [550/781]  eta: 0:01:17  lr: 0.000015  loss: 1.2387 (1.3984)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [560/781]  eta: 0:01:13  lr: 0.000015  loss: 1.2563 (1.3969)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [570/781]  eta: 0:01:10  lr: 0.000015  loss: 1.2575 (1.3950)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [580/781]  eta: 0:01:07  lr: 0.000015  loss: 1.2575 (1.3950)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [590/781]  eta: 0:01:03  lr: 0.000015  loss: 1.2823 (1.3936)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [600/781]  eta: 0:01:00  lr: 0.000015  loss: 1.3347 (1.3984)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [610/781]  eta: 0:00:57  lr: 0.000015  loss: 1.3554 (1.4008)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [620/781]  eta: 0:00:53  lr: 0.000015  loss: 1.2825 (1.4006)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [630/781]  eta: 0:00:50  lr: 0.000015  loss: 1.2825 (1.4009)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [640/781]  eta: 0:00:47  lr: 0.000015  loss: 1.3038 (1.4003)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [650/781]  eta: 0:00:43  lr: 0.000015  loss: 1.2634 (1.3992)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [660/781]  eta: 0:00:40  lr: 0.000015  loss: 1.2995 (1.3988)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [670/781]  eta: 0:00:37  lr: 0.000015  loss: 1.3072 (1.3986)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [680/781]  eta: 0:00:33  lr: 0.000015  loss: 1.3195 (1.3973)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [690/781]  eta: 0:00:30  lr: 0.000015  loss: 1.2676 (1.3987)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [700/781]  eta: 0:00:27  lr: 0.000015  loss: 1.2897 (1.4003)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [710/781]  eta: 0:00:23  lr: 0.000015  loss: 1.3144 (1.4033)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [720/781]  eta: 0:00:20  lr: 0.000015  loss: 1.3144 (1.4024)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [730/781]  eta: 0:00:17  lr: 0.000015  loss: 1.2888 (1.4051)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [740/781]  eta: 0:00:13  lr: 0.000015  loss: 1.3134 (1.4071)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [750/781]  eta: 0:00:10  lr: 0.000015  loss: 1.3134 (1.4069)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [760/781]  eta: 0:00:07  lr: 0.000015  loss: 1.3270 (1.4068)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [770/781]  eta: 0:00:03  lr: 0.000015  loss: 1.3270 (1.4063)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [82]  [780/781]  eta: 0:00:00  lr: 0.000015  loss: 1.2745 (1.4087)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [82] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000015  loss: 1.2745 (1.4087)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3288130760192871, 'lambda_convnext_base': 0.25966718792915344, 'lambda_tf_efficientnetv2_l': 0.41151973605155945}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8338 (0.8338)  acc1: 83.8542 (83.8542)  acc5: 94.2708 (94.2708)  time: 0.8498  data: 0.8189  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8779 (0.9655)  acc1: 83.8542 (82.0076)  acc5: 94.7917 (93.5133)  time: 0.1746  data: 0.1439  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 0.9779 (1.0331)  acc1: 81.2500 (80.6300)  acc5: 93.2292 (92.4851)  time: 0.1242  data: 0.0935  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1917 (1.0964)  acc1: 76.0417 (79.4691)  acc5: 91.6667 (91.8683)  time: 0.1228  data: 0.0922  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2574 (1.1385)  acc1: 75.5208 (78.5696)  acc5: 90.1042 (91.4253)  time: 0.1231  data: 0.0925  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1558 (1.1350)  acc1: 77.6042 (78.3395)  acc5: 92.1875 (91.8096)  time: 0.1229  data: 0.0923  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1862 (1.1467)  acc1: 75.0000 (78.2300)  acc5: 92.7083 (91.8400)  time: 0.1035  data: 0.0738  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1308 s / it)\n",
            "* Acc@1 78.230 Acc@5 91.840 loss 1.147\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [83]  [  0/781]  eta: 0:14:37  lr: 0.000014  loss: 1.3958 (1.3958)  time: 1.1231  data: 0.7827  max mem: 6459\n",
            "Epoch: [83]  [ 10/781]  eta: 0:05:12  lr: 0.000014  loss: 1.2369 (1.3641)  time: 0.4052  data: 0.0714  max mem: 6459\n",
            "Epoch: [83]  [ 20/781]  eta: 0:04:42  lr: 0.000014  loss: 1.2252 (1.3738)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 30/781]  eta: 0:04:29  lr: 0.000014  loss: 1.2864 (1.3610)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 40/781]  eta: 0:04:21  lr: 0.000014  loss: 1.2887 (1.3441)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.2605 (1.3676)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 60/781]  eta: 0:04:09  lr: 0.000014  loss: 1.2605 (1.3833)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.2501 (1.3715)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 80/781]  eta: 0:04:00  lr: 0.000014  loss: 1.2418 (1.3587)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [ 90/781]  eta: 0:03:56  lr: 0.000014  loss: 1.2619 (1.3621)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [100/781]  eta: 0:03:52  lr: 0.000014  loss: 1.2740 (1.3906)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [110/781]  eta: 0:03:48  lr: 0.000014  loss: 1.2894 (1.3850)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [120/781]  eta: 0:03:44  lr: 0.000014  loss: 1.3280 (1.3986)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.2989 (1.3884)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [140/781]  eta: 0:03:37  lr: 0.000014  loss: 1.2631 (1.3896)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [150/781]  eta: 0:03:33  lr: 0.000014  loss: 1.2631 (1.3829)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [160/781]  eta: 0:03:29  lr: 0.000014  loss: 1.2703 (1.3874)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [170/781]  eta: 0:03:26  lr: 0.000014  loss: 1.3201 (1.3979)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2714 (1.3918)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [190/781]  eta: 0:03:19  lr: 0.000014  loss: 1.2888 (1.3987)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.3091 (1.4071)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [210/781]  eta: 0:03:12  lr: 0.000014  loss: 1.3375 (1.4162)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.3077 (1.4184)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [230/781]  eta: 0:03:05  lr: 0.000014  loss: 1.2718 (1.4171)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [240/781]  eta: 0:03:02  lr: 0.000014  loss: 1.2287 (1.4162)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.2651 (1.4108)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [260/781]  eta: 0:02:55  lr: 0.000014  loss: 1.2538 (1.4068)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.2538 (1.4027)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [280/781]  eta: 0:02:48  lr: 0.000014  loss: 1.3254 (1.4122)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.2878 (1.4073)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.2878 (1.4111)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [310/781]  eta: 0:02:38  lr: 0.000014  loss: 1.3103 (1.4113)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.3205 (1.4122)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [330/781]  eta: 0:02:31  lr: 0.000014  loss: 1.3205 (1.4146)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.2925 (1.4112)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.2763 (1.4142)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [360/781]  eta: 0:02:21  lr: 0.000014  loss: 1.2656 (1.4107)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.2754 (1.4173)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.2680 (1.4162)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [390/781]  eta: 0:02:11  lr: 0.000014  loss: 1.2680 (1.4179)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.2782 (1.4197)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [410/781]  eta: 0:02:04  lr: 0.000014  loss: 1.2782 (1.4182)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.2743 (1.4158)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.2812 (1.4165)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [440/781]  eta: 0:01:54  lr: 0.000014  loss: 1.3253 (1.4218)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.2502 (1.4199)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2301 (1.4200)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [470/781]  eta: 0:01:44  lr: 0.000014  loss: 1.2467 (1.4174)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2719 (1.4164)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.2719 (1.4152)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [500/781]  eta: 0:01:34  lr: 0.000014  loss: 1.2576 (1.4110)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.2258 (1.4092)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.3145 (1.4102)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [530/781]  eta: 0:01:24  lr: 0.000014  loss: 1.3024 (1.4120)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.2771 (1.4119)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.2748 (1.4126)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [560/781]  eta: 0:01:14  lr: 0.000014  loss: 1.2729 (1.4112)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.2648 (1.4106)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2813 (1.4111)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2813 (1.4115)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.2865 (1.4131)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2902 (1.4140)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.3267 (1.4145)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.2979 (1.4140)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.2267 (1.4184)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.2456 (1.4157)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.2419 (1.4159)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.3036 (1.4170)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.2805 (1.4167)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.3041 (1.4196)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.3041 (1.4203)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.2997 (1.4215)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.2939 (1.4210)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.3153 (1.4243)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.2777 (1.4239)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.2649 (1.4242)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [760/781]  eta: 0:00:07  lr: 0.000014  loss: 1.3084 (1.4242)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.2948 (1.4241)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [83]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.2763 (1.4232)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [83] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.2763 (1.4232)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32849907875061035, 'lambda_convnext_base': 0.25964102149009705, 'lambda_tf_efficientnetv2_l': 0.4118601977825165}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7973 (0.7973)  acc1: 82.8125 (82.8125)  acc5: 95.8333 (95.8333)  time: 0.8548  data: 0.8239  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9294 (0.9635)  acc1: 83.8542 (82.1970)  acc5: 94.7917 (93.5606)  time: 0.1711  data: 0.1405  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0386 (1.0259)  acc1: 79.6875 (81.0268)  acc5: 93.2292 (92.6835)  time: 0.1214  data: 0.0907  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1951 (1.0971)  acc1: 76.0417 (79.4019)  acc5: 90.6250 (92.0699)  time: 0.1216  data: 0.0910  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.3296 (1.1363)  acc1: 74.4792 (78.5950)  acc5: 90.6250 (91.7556)  time: 0.1199  data: 0.0892  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1605 (1.1376)  acc1: 74.4792 (78.1965)  acc5: 92.1875 (92.0445)  time: 0.1200  data: 0.0893  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.2206 (1.1548)  acc1: 73.9583 (78.0200)  acc5: 92.7083 (92.0600)  time: 0.1029  data: 0.0732  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1284 s / it)\n",
            "* Acc@1 78.020 Acc@5 92.060 loss 1.155\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [84]  [  0/781]  eta: 0:14:25  lr: 0.000014  loss: 2.4033 (2.4033)  time: 1.1087  data: 0.7624  max mem: 6459\n",
            "Epoch: [84]  [ 10/781]  eta: 0:05:11  lr: 0.000014  loss: 1.2779 (1.4637)  time: 0.4039  data: 0.0696  max mem: 6459\n",
            "Epoch: [84]  [ 20/781]  eta: 0:04:41  lr: 0.000014  loss: 1.2610 (1.3992)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 30/781]  eta: 0:04:29  lr: 0.000014  loss: 1.2299 (1.3436)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 40/781]  eta: 0:04:20  lr: 0.000014  loss: 1.2412 (1.3360)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 50/781]  eta: 0:04:14  lr: 0.000014  loss: 1.3236 (1.3714)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 60/781]  eta: 0:04:09  lr: 0.000014  loss: 1.3236 (1.3760)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 70/781]  eta: 0:04:04  lr: 0.000014  loss: 1.2894 (1.3911)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 80/781]  eta: 0:04:00  lr: 0.000014  loss: 1.2894 (1.4158)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [ 90/781]  eta: 0:03:56  lr: 0.000014  loss: 1.2822 (1.4243)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [100/781]  eta: 0:03:52  lr: 0.000014  loss: 1.2822 (1.4222)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [110/781]  eta: 0:03:48  lr: 0.000014  loss: 1.3244 (1.4267)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [120/781]  eta: 0:03:44  lr: 0.000014  loss: 1.3438 (1.4263)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [130/781]  eta: 0:03:40  lr: 0.000014  loss: 1.3438 (1.4384)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [140/781]  eta: 0:03:37  lr: 0.000014  loss: 1.3160 (1.4437)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [150/781]  eta: 0:03:33  lr: 0.000014  loss: 1.3068 (1.4491)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [160/781]  eta: 0:03:29  lr: 0.000014  loss: 1.2741 (1.4470)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [170/781]  eta: 0:03:26  lr: 0.000014  loss: 1.2640 (1.4412)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [180/781]  eta: 0:03:22  lr: 0.000014  loss: 1.2363 (1.4314)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [190/781]  eta: 0:03:19  lr: 0.000014  loss: 1.2243 (1.4260)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [200/781]  eta: 0:03:15  lr: 0.000014  loss: 1.2105 (1.4215)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [210/781]  eta: 0:03:12  lr: 0.000014  loss: 1.2510 (1.4197)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [220/781]  eta: 0:03:08  lr: 0.000014  loss: 1.2482 (1.4186)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [230/781]  eta: 0:03:05  lr: 0.000014  loss: 1.2506 (1.4139)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [240/781]  eta: 0:03:01  lr: 0.000014  loss: 1.2951 (1.4151)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [250/781]  eta: 0:02:58  lr: 0.000014  loss: 1.2243 (1.4106)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [260/781]  eta: 0:02:55  lr: 0.000014  loss: 1.2428 (1.4166)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [270/781]  eta: 0:02:51  lr: 0.000014  loss: 1.2519 (1.4146)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [280/781]  eta: 0:02:48  lr: 0.000014  loss: 1.3018 (1.4154)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [290/781]  eta: 0:02:44  lr: 0.000014  loss: 1.3026 (1.4166)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [300/781]  eta: 0:02:41  lr: 0.000014  loss: 1.2661 (1.4191)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [310/781]  eta: 0:02:38  lr: 0.000014  loss: 1.2481 (1.4158)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [320/781]  eta: 0:02:34  lr: 0.000014  loss: 1.2481 (1.4114)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [330/781]  eta: 0:02:31  lr: 0.000014  loss: 1.2811 (1.4083)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [340/781]  eta: 0:02:27  lr: 0.000014  loss: 1.2856 (1.4064)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [350/781]  eta: 0:02:24  lr: 0.000014  loss: 1.2748 (1.4064)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [360/781]  eta: 0:02:21  lr: 0.000014  loss: 1.2405 (1.4070)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [370/781]  eta: 0:02:17  lr: 0.000014  loss: 1.2324 (1.4061)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [380/781]  eta: 0:02:14  lr: 0.000014  loss: 1.2683 (1.4074)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [390/781]  eta: 0:02:11  lr: 0.000014  loss: 1.3188 (1.4079)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [400/781]  eta: 0:02:07  lr: 0.000014  loss: 1.2780 (1.4096)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [410/781]  eta: 0:02:04  lr: 0.000014  loss: 1.3116 (1.4090)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [420/781]  eta: 0:02:00  lr: 0.000014  loss: 1.3267 (1.4092)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [430/781]  eta: 0:01:57  lr: 0.000014  loss: 1.2929 (1.4113)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [440/781]  eta: 0:01:54  lr: 0.000014  loss: 1.3019 (1.4124)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [450/781]  eta: 0:01:50  lr: 0.000014  loss: 1.3102 (1.4183)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [460/781]  eta: 0:01:47  lr: 0.000014  loss: 1.2457 (1.4174)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [470/781]  eta: 0:01:44  lr: 0.000014  loss: 1.2356 (1.4131)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [480/781]  eta: 0:01:40  lr: 0.000014  loss: 1.2471 (1.4102)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [490/781]  eta: 0:01:37  lr: 0.000014  loss: 1.2745 (1.4165)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [500/781]  eta: 0:01:34  lr: 0.000014  loss: 1.3041 (1.4155)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [510/781]  eta: 0:01:30  lr: 0.000014  loss: 1.2982 (1.4135)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [520/781]  eta: 0:01:27  lr: 0.000014  loss: 1.2612 (1.4107)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [530/781]  eta: 0:01:24  lr: 0.000014  loss: 1.2739 (1.4115)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [540/781]  eta: 0:01:20  lr: 0.000014  loss: 1.2798 (1.4107)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [550/781]  eta: 0:01:17  lr: 0.000014  loss: 1.2620 (1.4086)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [560/781]  eta: 0:01:13  lr: 0.000014  loss: 1.2605 (1.4088)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [570/781]  eta: 0:01:10  lr: 0.000014  loss: 1.2962 (1.4092)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [580/781]  eta: 0:01:07  lr: 0.000014  loss: 1.2962 (1.4103)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [590/781]  eta: 0:01:03  lr: 0.000014  loss: 1.2406 (1.4112)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [600/781]  eta: 0:01:00  lr: 0.000014  loss: 1.2239 (1.4087)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [610/781]  eta: 0:00:57  lr: 0.000014  loss: 1.2777 (1.4119)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [620/781]  eta: 0:00:53  lr: 0.000014  loss: 1.2416 (1.4097)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [630/781]  eta: 0:00:50  lr: 0.000014  loss: 1.2361 (1.4084)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [640/781]  eta: 0:00:47  lr: 0.000014  loss: 1.2483 (1.4083)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [650/781]  eta: 0:00:43  lr: 0.000014  loss: 1.2663 (1.4062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [660/781]  eta: 0:00:40  lr: 0.000014  loss: 1.2746 (1.4082)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [670/781]  eta: 0:00:37  lr: 0.000014  loss: 1.3042 (1.4078)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [680/781]  eta: 0:00:33  lr: 0.000014  loss: 1.3026 (1.4079)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [690/781]  eta: 0:00:30  lr: 0.000014  loss: 1.3016 (1.4077)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [700/781]  eta: 0:00:27  lr: 0.000014  loss: 1.2650 (1.4063)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [710/781]  eta: 0:00:23  lr: 0.000014  loss: 1.2687 (1.4080)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [720/781]  eta: 0:00:20  lr: 0.000014  loss: 1.2687 (1.4059)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [730/781]  eta: 0:00:17  lr: 0.000014  loss: 1.2498 (1.4096)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [740/781]  eta: 0:00:13  lr: 0.000014  loss: 1.3899 (1.4122)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [750/781]  eta: 0:00:10  lr: 0.000014  loss: 1.3260 (1.4116)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [760/781]  eta: 0:00:07  lr: 0.000014  loss: 1.2623 (1.4126)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [770/781]  eta: 0:00:03  lr: 0.000014  loss: 1.2896 (1.4155)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [84]  [780/781]  eta: 0:00:00  lr: 0.000014  loss: 1.2967 (1.4151)  time: 0.3337  data: 0.0005  max mem: 6459\n",
            "Epoch: [84] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000014  loss: 1.2967 (1.4151)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3289838433265686, 'lambda_convnext_base': 0.25979483127593994, 'lambda_tf_efficientnetv2_l': 0.41122132539749146}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8086 (0.8086)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8587  data: 0.8278  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8521 (0.9622)  acc1: 83.3333 (82.0076)  acc5: 94.7917 (93.7027)  time: 0.1694  data: 0.1387  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0562 (1.0398)  acc1: 79.6875 (80.4067)  acc5: 93.2292 (92.7083)  time: 0.1239  data: 0.0932  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2359 (1.1007)  acc1: 75.5208 (79.3179)  acc5: 92.1875 (91.9691)  time: 0.1253  data: 0.0947  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2881 (1.1418)  acc1: 75.0000 (78.3664)  acc5: 90.6250 (91.6159)  time: 0.1218  data: 0.0912  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1491 (1.1386)  acc1: 76.5625 (78.0944)  acc5: 91.6667 (91.9424)  time: 0.1219  data: 0.0913  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1809 (1.1577)  acc1: 73.9583 (77.9500)  acc5: 92.1875 (91.9600)  time: 0.1030  data: 0.0733  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1302 s / it)\n",
            "* Acc@1 77.950 Acc@5 91.960 loss 1.158\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [85]  [  0/781]  eta: 0:14:40  lr: 0.000013  loss: 1.3455 (1.3455)  time: 1.1269  data: 0.7740  max mem: 6459\n",
            "Epoch: [85]  [ 10/781]  eta: 0:05:12  lr: 0.000013  loss: 1.2463 (1.4294)  time: 0.4058  data: 0.0706  max mem: 6459\n",
            "Epoch: [85]  [ 20/781]  eta: 0:04:42  lr: 0.000013  loss: 1.2709 (1.4532)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 30/781]  eta: 0:04:29  lr: 0.000013  loss: 1.2583 (1.3799)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 40/781]  eta: 0:04:21  lr: 0.000013  loss: 1.2583 (1.4123)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 50/781]  eta: 0:04:15  lr: 0.000013  loss: 1.2683 (1.3872)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 60/781]  eta: 0:04:09  lr: 0.000013  loss: 1.2411 (1.3747)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 70/781]  eta: 0:04:05  lr: 0.000013  loss: 1.2411 (1.4051)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 80/781]  eta: 0:04:00  lr: 0.000013  loss: 1.3074 (1.3916)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [ 90/781]  eta: 0:03:56  lr: 0.000013  loss: 1.3025 (1.4096)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [100/781]  eta: 0:03:52  lr: 0.000013  loss: 1.2508 (1.3966)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [110/781]  eta: 0:03:48  lr: 0.000013  loss: 1.2762 (1.3926)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [120/781]  eta: 0:03:44  lr: 0.000013  loss: 1.2961 (1.3895)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.2621 (1.3829)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [140/781]  eta: 0:03:37  lr: 0.000013  loss: 1.2447 (1.3841)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [150/781]  eta: 0:03:33  lr: 0.000013  loss: 1.2400 (1.3850)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [160/781]  eta: 0:03:30  lr: 0.000013  loss: 1.2972 (1.3964)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [170/781]  eta: 0:03:26  lr: 0.000013  loss: 1.3044 (1.3900)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [180/781]  eta: 0:03:22  lr: 0.000013  loss: 1.2600 (1.3950)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [190/781]  eta: 0:03:19  lr: 0.000013  loss: 1.2508 (1.4040)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [200/781]  eta: 0:03:15  lr: 0.000013  loss: 1.2508 (1.3974)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [210/781]  eta: 0:03:12  lr: 0.000013  loss: 1.2276 (1.3956)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [220/781]  eta: 0:03:09  lr: 0.000013  loss: 1.2510 (1.3981)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [230/781]  eta: 0:03:05  lr: 0.000013  loss: 1.2691 (1.3978)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [240/781]  eta: 0:03:02  lr: 0.000013  loss: 1.2684 (1.3916)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [250/781]  eta: 0:02:58  lr: 0.000013  loss: 1.2739 (1.3917)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [260/781]  eta: 0:02:55  lr: 0.000013  loss: 1.2778 (1.3947)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.2523 (1.3895)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [280/781]  eta: 0:02:48  lr: 0.000013  loss: 1.2554 (1.3884)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [290/781]  eta: 0:02:45  lr: 0.000013  loss: 1.3225 (1.3966)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [300/781]  eta: 0:02:41  lr: 0.000013  loss: 1.2988 (1.3929)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [310/781]  eta: 0:02:38  lr: 0.000013  loss: 1.2848 (1.3991)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [320/781]  eta: 0:02:34  lr: 0.000013  loss: 1.3177 (1.3998)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [330/781]  eta: 0:02:31  lr: 0.000013  loss: 1.2771 (1.3988)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [340/781]  eta: 0:02:28  lr: 0.000013  loss: 1.2351 (1.3952)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [350/781]  eta: 0:02:24  lr: 0.000013  loss: 1.2174 (1.3923)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [360/781]  eta: 0:02:21  lr: 0.000013  loss: 1.2332 (1.3884)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [370/781]  eta: 0:02:17  lr: 0.000013  loss: 1.2470 (1.3868)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [380/781]  eta: 0:02:14  lr: 0.000013  loss: 1.2344 (1.3840)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [390/781]  eta: 0:02:11  lr: 0.000013  loss: 1.2344 (1.3902)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.2830 (1.3918)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [410/781]  eta: 0:02:04  lr: 0.000013  loss: 1.2890 (1.3905)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [420/781]  eta: 0:02:01  lr: 0.000013  loss: 1.2890 (1.3929)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2740 (1.3943)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [440/781]  eta: 0:01:54  lr: 0.000013  loss: 1.4638 (1.3994)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [450/781]  eta: 0:01:50  lr: 0.000013  loss: 1.3490 (1.3998)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.3210 (1.3991)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [470/781]  eta: 0:01:44  lr: 0.000013  loss: 1.3210 (1.4001)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2708 (1.3984)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.2955 (1.3997)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [500/781]  eta: 0:01:34  lr: 0.000013  loss: 1.3231 (1.3991)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2734 (1.3967)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.2533 (1.3973)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [530/781]  eta: 0:01:24  lr: 0.000013  loss: 1.2665 (1.3976)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.2480 (1.3961)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.2348 (1.3956)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [560/781]  eta: 0:01:13  lr: 0.000013  loss: 1.2800 (1.3958)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.2806 (1.3959)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2806 (1.3994)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.3032 (1.4004)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.2757 (1.3995)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.2682 (1.4011)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.3136 (1.3996)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.3136 (1.4020)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.3385 (1.4059)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2677 (1.4048)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2559 (1.4046)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [670/781]  eta: 0:00:37  lr: 0.000013  loss: 1.2813 (1.4063)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.2462 (1.4053)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.2473 (1.4034)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [700/781]  eta: 0:00:27  lr: 0.000013  loss: 1.2693 (1.4055)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.3053 (1.4055)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.2815 (1.4071)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [730/781]  eta: 0:00:17  lr: 0.000013  loss: 1.2505 (1.4061)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.2583 (1.4073)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.2670 (1.4064)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [760/781]  eta: 0:00:07  lr: 0.000013  loss: 1.2864 (1.4069)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.2700 (1.4064)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [85]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2976 (1.4070)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [85] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2976 (1.4070)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32921409606933594, 'lambda_convnext_base': 0.2595621645450592, 'lambda_tf_efficientnetv2_l': 0.4112235903739929}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8163 (0.8163)  acc1: 83.8542 (83.8542)  acc5: 95.3125 (95.3125)  time: 0.8182  data: 0.7873  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9155 (0.9663)  acc1: 83.8542 (82.1023)  acc5: 94.7917 (93.6080)  time: 0.1752  data: 0.1445  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0844 (1.0278)  acc1: 77.0833 (80.6548)  acc5: 93.2292 (92.5347)  time: 0.1307  data: 0.1000  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1484 (1.0839)  acc1: 76.5625 (79.4691)  acc5: 91.6667 (92.1035)  time: 0.1307  data: 0.1001  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2540 (1.1278)  acc1: 75.5208 (78.4680)  acc5: 90.6250 (91.6921)  time: 0.1306  data: 0.1000  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1049 (1.1290)  acc1: 76.5625 (78.1148)  acc5: 92.1875 (91.8811)  time: 0.1346  data: 0.1039  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1668 (1.1414)  acc1: 75.0000 (77.9900)  acc5: 92.7083 (91.9100)  time: 0.1152  data: 0.0854  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1380 s / it)\n",
            "* Acc@1 77.990 Acc@5 91.910 loss 1.141\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [86]  [  0/781]  eta: 0:14:05  lr: 0.000013  loss: 1.4913 (1.4913)  time: 1.0821  data: 0.7427  max mem: 6459\n",
            "Epoch: [86]  [ 10/781]  eta: 0:05:09  lr: 0.000013  loss: 1.2813 (1.3980)  time: 0.4020  data: 0.0678  max mem: 6459\n",
            "Epoch: [86]  [ 20/781]  eta: 0:04:41  lr: 0.000013  loss: 1.2813 (1.4389)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 30/781]  eta: 0:04:28  lr: 0.000013  loss: 1.3047 (1.4720)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 40/781]  eta: 0:04:20  lr: 0.000013  loss: 1.2602 (1.4420)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 50/781]  eta: 0:04:14  lr: 0.000013  loss: 1.2502 (1.4201)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 60/781]  eta: 0:04:09  lr: 0.000013  loss: 1.2532 (1.4461)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 70/781]  eta: 0:04:04  lr: 0.000013  loss: 1.2816 (1.4355)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 80/781]  eta: 0:04:00  lr: 0.000013  loss: 1.2855 (1.4235)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [ 90/781]  eta: 0:03:56  lr: 0.000013  loss: 1.2052 (1.4012)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [100/781]  eta: 0:03:52  lr: 0.000013  loss: 1.2070 (1.3843)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [110/781]  eta: 0:03:48  lr: 0.000013  loss: 1.2567 (1.3776)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [120/781]  eta: 0:03:44  lr: 0.000013  loss: 1.2365 (1.3674)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [130/781]  eta: 0:03:40  lr: 0.000013  loss: 1.2778 (1.3669)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [140/781]  eta: 0:03:37  lr: 0.000013  loss: 1.2976 (1.3732)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [150/781]  eta: 0:03:33  lr: 0.000013  loss: 1.2976 (1.3830)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [160/781]  eta: 0:03:29  lr: 0.000013  loss: 1.3026 (1.4035)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [170/781]  eta: 0:03:26  lr: 0.000013  loss: 1.2415 (1.3974)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [180/781]  eta: 0:03:22  lr: 0.000013  loss: 1.2187 (1.3879)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [190/781]  eta: 0:03:19  lr: 0.000013  loss: 1.2315 (1.3854)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [200/781]  eta: 0:03:15  lr: 0.000013  loss: 1.3182 (1.3921)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [210/781]  eta: 0:03:12  lr: 0.000013  loss: 1.3188 (1.3880)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [220/781]  eta: 0:03:08  lr: 0.000013  loss: 1.2750 (1.3888)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [230/781]  eta: 0:03:05  lr: 0.000013  loss: 1.2750 (1.3962)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [240/781]  eta: 0:03:02  lr: 0.000013  loss: 1.2439 (1.3948)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [250/781]  eta: 0:02:58  lr: 0.000013  loss: 1.2465 (1.3931)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [260/781]  eta: 0:02:55  lr: 0.000013  loss: 1.2584 (1.3969)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [270/781]  eta: 0:02:51  lr: 0.000013  loss: 1.2880 (1.3986)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [280/781]  eta: 0:02:48  lr: 0.000013  loss: 1.3185 (1.4023)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [290/781]  eta: 0:02:44  lr: 0.000013  loss: 1.3200 (1.4021)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [300/781]  eta: 0:02:41  lr: 0.000013  loss: 1.2972 (1.3983)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [310/781]  eta: 0:02:38  lr: 0.000013  loss: 1.2638 (1.4013)  time: 0.3433  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [320/781]  eta: 0:02:35  lr: 0.000013  loss: 1.2826 (1.4061)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [330/781]  eta: 0:02:31  lr: 0.000013  loss: 1.2773 (1.4032)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [340/781]  eta: 0:02:28  lr: 0.000013  loss: 1.2459 (1.3986)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [350/781]  eta: 0:02:24  lr: 0.000013  loss: 1.2553 (1.3949)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [360/781]  eta: 0:02:21  lr: 0.000013  loss: 1.2667 (1.3945)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [370/781]  eta: 0:02:18  lr: 0.000013  loss: 1.2912 (1.3942)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [380/781]  eta: 0:02:14  lr: 0.000013  loss: 1.2912 (1.3954)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [390/781]  eta: 0:02:11  lr: 0.000013  loss: 1.2948 (1.3994)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [400/781]  eta: 0:02:07  lr: 0.000013  loss: 1.3513 (1.4072)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [410/781]  eta: 0:02:04  lr: 0.000013  loss: 1.2651 (1.4047)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [420/781]  eta: 0:02:01  lr: 0.000013  loss: 1.2105 (1.4013)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [430/781]  eta: 0:01:57  lr: 0.000013  loss: 1.2686 (1.4012)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [440/781]  eta: 0:01:54  lr: 0.000013  loss: 1.3031 (1.4030)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [450/781]  eta: 0:01:51  lr: 0.000013  loss: 1.3084 (1.4024)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [460/781]  eta: 0:01:47  lr: 0.000013  loss: 1.2809 (1.4014)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [470/781]  eta: 0:01:44  lr: 0.000013  loss: 1.2433 (1.3981)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [480/781]  eta: 0:01:40  lr: 0.000013  loss: 1.2053 (1.3942)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [490/781]  eta: 0:01:37  lr: 0.000013  loss: 1.2599 (1.3945)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [500/781]  eta: 0:01:34  lr: 0.000013  loss: 1.2792 (1.3969)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [510/781]  eta: 0:01:30  lr: 0.000013  loss: 1.2719 (1.4000)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [520/781]  eta: 0:01:27  lr: 0.000013  loss: 1.2780 (1.4011)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [530/781]  eta: 0:01:24  lr: 0.000013  loss: 1.2832 (1.4028)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [540/781]  eta: 0:01:20  lr: 0.000013  loss: 1.3131 (1.4053)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [550/781]  eta: 0:01:17  lr: 0.000013  loss: 1.2648 (1.4022)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [560/781]  eta: 0:01:14  lr: 0.000013  loss: 1.2391 (1.4008)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [570/781]  eta: 0:01:10  lr: 0.000013  loss: 1.2352 (1.3984)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [580/781]  eta: 0:01:07  lr: 0.000013  loss: 1.2806 (1.3998)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [590/781]  eta: 0:01:03  lr: 0.000013  loss: 1.2806 (1.3983)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [600/781]  eta: 0:01:00  lr: 0.000013  loss: 1.2614 (1.3969)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [610/781]  eta: 0:00:57  lr: 0.000013  loss: 1.3207 (1.3984)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [620/781]  eta: 0:00:53  lr: 0.000013  loss: 1.3025 (1.3975)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [630/781]  eta: 0:00:50  lr: 0.000013  loss: 1.2690 (1.3953)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [640/781]  eta: 0:00:47  lr: 0.000013  loss: 1.2518 (1.3933)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [650/781]  eta: 0:00:43  lr: 0.000013  loss: 1.2525 (1.3927)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [660/781]  eta: 0:00:40  lr: 0.000013  loss: 1.2986 (1.3939)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [670/781]  eta: 0:00:37  lr: 0.000013  loss: 1.2989 (1.3938)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [680/781]  eta: 0:00:33  lr: 0.000013  loss: 1.2656 (1.3953)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [690/781]  eta: 0:00:30  lr: 0.000013  loss: 1.2801 (1.3955)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [700/781]  eta: 0:00:27  lr: 0.000013  loss: 1.3238 (1.3980)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [710/781]  eta: 0:00:23  lr: 0.000013  loss: 1.3151 (1.3992)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [720/781]  eta: 0:00:20  lr: 0.000013  loss: 1.2795 (1.3994)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [730/781]  eta: 0:00:17  lr: 0.000013  loss: 1.3117 (1.3989)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [740/781]  eta: 0:00:13  lr: 0.000013  loss: 1.3033 (1.3995)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [750/781]  eta: 0:00:10  lr: 0.000013  loss: 1.2642 (1.3998)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [760/781]  eta: 0:00:07  lr: 0.000013  loss: 1.2810 (1.4026)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [770/781]  eta: 0:00:03  lr: 0.000013  loss: 1.2853 (1.4030)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [86]  [780/781]  eta: 0:00:00  lr: 0.000013  loss: 1.2810 (1.4068)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [86] Total time: 0:04:21 (0.3346 s / it)\n",
            "Averaged stats: lr: 0.000013  loss: 1.2810 (1.4068)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32864078879356384, 'lambda_convnext_base': 0.2596803307533264, 'lambda_tf_efficientnetv2_l': 0.4116789698600769}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8507 (0.8507)  acc1: 83.3333 (83.3333)  acc5: 94.7917 (94.7917)  time: 0.8459  data: 0.8150  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9310 (0.9928)  acc1: 83.3333 (81.0133)  acc5: 94.2708 (93.1818)  time: 0.1737  data: 0.1430  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0536 (1.0535)  acc1: 77.6042 (79.7371)  acc5: 92.7083 (92.3115)  time: 0.1219  data: 0.0912  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1852 (1.0976)  acc1: 76.0417 (79.0491)  acc5: 91.6667 (92.0363)  time: 0.1283  data: 0.0976  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2034 (1.1451)  acc1: 76.0417 (78.2647)  acc5: 90.6250 (91.5523)  time: 0.1229  data: 0.0922  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1787 (1.1423)  acc1: 76.0417 (78.1046)  acc5: 91.1458 (91.8301)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1916 (1.1544)  acc1: 75.0000 (78.0100)  acc5: 92.7083 (91.8700)  time: 0.1105  data: 0.0808  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1324 s / it)\n",
            "* Acc@1 78.010 Acc@5 91.870 loss 1.154\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [87]  [  0/781]  eta: 0:14:22  lr: 0.000012  loss: 1.2714 (1.2714)  time: 1.1038  data: 0.7608  max mem: 6459\n",
            "Epoch: [87]  [ 10/781]  eta: 0:05:11  lr: 0.000012  loss: 1.3102 (1.4292)  time: 0.4038  data: 0.0694  max mem: 6459\n",
            "Epoch: [87]  [ 20/781]  eta: 0:04:41  lr: 0.000012  loss: 1.3114 (1.4713)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 30/781]  eta: 0:04:29  lr: 0.000012  loss: 1.3416 (1.4634)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 40/781]  eta: 0:04:20  lr: 0.000012  loss: 1.2606 (1.4074)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2677 (1.3995)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2789 (1.4154)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.3109 (1.4197)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 80/781]  eta: 0:04:00  lr: 0.000012  loss: 1.3109 (1.4360)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [ 90/781]  eta: 0:03:56  lr: 0.000012  loss: 1.2645 (1.4343)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [100/781]  eta: 0:03:52  lr: 0.000012  loss: 1.2745 (1.4433)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [110/781]  eta: 0:03:48  lr: 0.000012  loss: 1.3107 (1.4551)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [120/781]  eta: 0:03:44  lr: 0.000012  loss: 1.3083 (1.4397)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.3083 (1.4408)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [140/781]  eta: 0:03:37  lr: 0.000012  loss: 1.3235 (1.4579)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [150/781]  eta: 0:03:33  lr: 0.000012  loss: 1.2851 (1.4508)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [160/781]  eta: 0:03:30  lr: 0.000012  loss: 1.2818 (1.4555)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [170/781]  eta: 0:03:26  lr: 0.000012  loss: 1.2691 (1.4538)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2365 (1.4470)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.3064 (1.4560)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.3528 (1.4604)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.2876 (1.4576)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [220/781]  eta: 0:03:09  lr: 0.000012  loss: 1.2706 (1.4549)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.2562 (1.4457)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [240/781]  eta: 0:03:02  lr: 0.000012  loss: 1.2445 (1.4380)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.2597 (1.4336)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [260/781]  eta: 0:02:55  lr: 0.000012  loss: 1.2800 (1.4332)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2528 (1.4274)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2035 (1.4233)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [290/781]  eta: 0:02:45  lr: 0.000012  loss: 1.2485 (1.4187)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2617 (1.4205)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [310/781]  eta: 0:02:38  lr: 0.000012  loss: 1.2620 (1.4210)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.3208 (1.4275)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.3208 (1.4271)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [340/781]  eta: 0:02:28  lr: 0.000012  loss: 1.2426 (1.4212)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2349 (1.4161)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.2620 (1.4173)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.3294 (1.4250)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.2586 (1.4217)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [390/781]  eta: 0:02:11  lr: 0.000012  loss: 1.2140 (1.4173)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2076 (1.4128)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.2439 (1.4151)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [420/781]  eta: 0:02:01  lr: 0.000012  loss: 1.2310 (1.4104)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2731 (1.4125)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.3046 (1.4130)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.2873 (1.4101)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.3893 (1.4163)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.4178 (1.4197)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.3318 (1.4216)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.3214 (1.4239)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [500/781]  eta: 0:01:34  lr: 0.000012  loss: 1.2709 (1.4228)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2764 (1.4209)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.3622 (1.4229)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [530/781]  eta: 0:01:24  lr: 0.000012  loss: 1.3782 (1.4249)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.2466 (1.4243)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.2466 (1.4255)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2518 (1.4286)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2509 (1.4297)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2664 (1.4281)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2648 (1.4255)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2663 (1.4233)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2663 (1.4235)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.2328 (1.4205)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2547 (1.4206)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.3024 (1.4183)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.3024 (1.4166)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.3239 (1.4170)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.3067 (1.4159)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2889 (1.4165)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.2889 (1.4188)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.2857 (1.4184)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2906 (1.4173)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2906 (1.4156)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.2412 (1.4152)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.2536 (1.4135)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.3274 (1.4133)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [760/781]  eta: 0:00:07  lr: 0.000012  loss: 1.2676 (1.4116)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2132 (1.4110)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [87]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.3417 (1.4138)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [87] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.3417 (1.4138)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3289774954319, 'lambda_convnext_base': 0.25926342606544495, 'lambda_tf_efficientnetv2_l': 0.4117591083049774}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8373 (0.8373)  acc1: 82.8125 (82.8125)  acc5: 94.2708 (94.2708)  time: 0.8298  data: 0.7988  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9184 (0.9753)  acc1: 83.3333 (81.5341)  acc5: 94.2708 (93.2765)  time: 0.1765  data: 0.1458  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0278 (1.0487)  acc1: 79.1667 (80.4067)  acc5: 93.2292 (92.4603)  time: 0.1307  data: 0.1001  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1683 (1.1077)  acc1: 76.0417 (79.2171)  acc5: 90.6250 (91.8851)  time: 0.1302  data: 0.0996  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2751 (1.1509)  acc1: 75.0000 (78.3156)  acc5: 89.0625 (91.4253)  time: 0.1282  data: 0.0976  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1238 (1.1445)  acc1: 76.5625 (78.1761)  acc5: 92.1875 (91.7892)  time: 0.1282  data: 0.0976  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1696 (1.1583)  acc1: 75.0000 (78.0300)  acc5: 92.7083 (91.8300)  time: 0.1074  data: 0.0777  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1358 s / it)\n",
            "* Acc@1 78.030 Acc@5 91.830 loss 1.158\n",
            "Accuracy of the network on the 10000 test images: 78.0%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [88]  [  0/781]  eta: 0:14:42  lr: 0.000012  loss: 1.1793 (1.1793)  time: 1.1298  data: 0.7903  max mem: 6459\n",
            "Epoch: [88]  [ 10/781]  eta: 0:05:12  lr: 0.000012  loss: 1.2904 (1.3147)  time: 0.4058  data: 0.0721  max mem: 6459\n",
            "Epoch: [88]  [ 20/781]  eta: 0:04:42  lr: 0.000012  loss: 1.2717 (1.2791)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 30/781]  eta: 0:04:29  lr: 0.000012  loss: 1.2340 (1.2881)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 40/781]  eta: 0:04:21  lr: 0.000012  loss: 1.3017 (1.3460)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2978 (1.3547)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2309 (1.3371)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.2508 (1.3570)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 80/781]  eta: 0:04:00  lr: 0.000012  loss: 1.2853 (1.3704)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [ 90/781]  eta: 0:03:56  lr: 0.000012  loss: 1.3270 (1.3749)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [100/781]  eta: 0:03:52  lr: 0.000012  loss: 1.3270 (1.3901)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [110/781]  eta: 0:03:48  lr: 0.000012  loss: 1.3185 (1.3924)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [120/781]  eta: 0:03:44  lr: 0.000012  loss: 1.2652 (1.3839)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.2642 (1.3926)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [140/781]  eta: 0:03:37  lr: 0.000012  loss: 1.2453 (1.3926)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [150/781]  eta: 0:03:33  lr: 0.000012  loss: 1.2665 (1.3870)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [160/781]  eta: 0:03:30  lr: 0.000012  loss: 1.2665 (1.3871)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [170/781]  eta: 0:03:26  lr: 0.000012  loss: 1.2759 (1.3985)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2905 (1.3999)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.2663 (1.3966)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.2271 (1.3924)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.3022 (1.4025)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.3147 (1.4058)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.2807 (1.4033)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [240/781]  eta: 0:03:02  lr: 0.000012  loss: 1.2807 (1.4091)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.3304 (1.4106)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [260/781]  eta: 0:02:55  lr: 0.000012  loss: 1.3214 (1.4113)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.2841 (1.4116)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2598 (1.4180)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2382 (1.4161)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2504 (1.4148)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [310/781]  eta: 0:02:38  lr: 0.000012  loss: 1.2728 (1.4212)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.2728 (1.4190)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.2723 (1.4155)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.2593 (1.4114)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2722 (1.4162)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.2685 (1.4141)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.2685 (1.4121)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.2816 (1.4145)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [390/781]  eta: 0:02:11  lr: 0.000012  loss: 1.2401 (1.4120)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2979 (1.4140)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.3014 (1.4166)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2439 (1.4159)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2439 (1.4154)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.2495 (1.4124)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.2923 (1.4148)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.2779 (1.4136)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.2512 (1.4129)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.2434 (1.4106)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.2602 (1.4097)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [500/781]  eta: 0:01:34  lr: 0.000012  loss: 1.2748 (1.4069)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2499 (1.4082)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.2489 (1.4062)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [530/781]  eta: 0:01:24  lr: 0.000012  loss: 1.2454 (1.4053)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.2968 (1.4073)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.2800 (1.4087)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2680 (1.4069)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2568 (1.4082)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2568 (1.4134)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.3837 (1.4170)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2538 (1.4144)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2447 (1.4140)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.2768 (1.4124)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2941 (1.4144)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.2790 (1.4132)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2902 (1.4166)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2881 (1.4145)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.2758 (1.4144)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.3118 (1.4203)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.3053 (1.4180)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.3227 (1.4224)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.3163 (1.4202)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2408 (1.4180)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.2747 (1.4185)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.3079 (1.4181)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.2749 (1.4162)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [760/781]  eta: 0:00:07  lr: 0.000012  loss: 1.2402 (1.4138)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2517 (1.4129)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [88]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.2439 (1.4119)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [88] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.2439 (1.4119)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3293393850326538, 'lambda_convnext_base': 0.2593823969364166, 'lambda_tf_efficientnetv2_l': 0.4112781584262848}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7884 (0.7884)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8518  data: 0.8209  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8917 (0.9524)  acc1: 84.8958 (82.4337)  acc5: 94.2708 (93.5606)  time: 0.1696  data: 0.1389  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0371 (1.0262)  acc1: 79.1667 (80.6796)  acc5: 93.2292 (92.6587)  time: 0.1167  data: 0.0860  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1927 (1.0896)  acc1: 76.5625 (79.4019)  acc5: 91.6667 (92.0531)  time: 0.1221  data: 0.0914  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2399 (1.1328)  acc1: 75.0000 (78.5950)  acc5: 91.1458 (91.6921)  time: 0.1227  data: 0.0918  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1203 (1.1319)  acc1: 75.0000 (78.2476)  acc5: 92.1875 (91.9935)  time: 0.1222  data: 0.0914  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1807 (1.1439)  acc1: 75.0000 (78.1200)  acc5: 92.7083 (92.0000)  time: 0.1065  data: 0.0768  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1290 s / it)\n",
            "* Acc@1 78.120 Acc@5 92.000 loss 1.144\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [89]  [  0/781]  eta: 0:14:36  lr: 0.000012  loss: 1.2907 (1.2907)  time: 1.1221  data: 0.7815  max mem: 6459\n",
            "Epoch: [89]  [ 10/781]  eta: 0:05:12  lr: 0.000012  loss: 1.2860 (1.3841)  time: 0.4049  data: 0.0713  max mem: 6459\n",
            "Epoch: [89]  [ 20/781]  eta: 0:04:41  lr: 0.000012  loss: 1.2536 (1.3192)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 30/781]  eta: 0:04:29  lr: 0.000012  loss: 1.2536 (1.3055)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 40/781]  eta: 0:04:21  lr: 0.000012  loss: 1.2579 (1.3046)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2683 (1.3095)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2764 (1.3213)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.2398 (1.3141)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 80/781]  eta: 0:04:02  lr: 0.000012  loss: 1.2506 (1.3291)  time: 0.3438  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [ 90/781]  eta: 0:03:57  lr: 0.000012  loss: 1.3015 (1.3516)  time: 0.3438  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [100/781]  eta: 0:03:53  lr: 0.000012  loss: 1.2684 (1.3504)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [110/781]  eta: 0:03:49  lr: 0.000012  loss: 1.2625 (1.3436)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [120/781]  eta: 0:03:45  lr: 0.000012  loss: 1.2886 (1.3542)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [130/781]  eta: 0:03:41  lr: 0.000012  loss: 1.2781 (1.3707)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [140/781]  eta: 0:03:38  lr: 0.000012  loss: 1.2884 (1.3790)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [150/781]  eta: 0:03:34  lr: 0.000012  loss: 1.2636 (1.3723)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [160/781]  eta: 0:03:30  lr: 0.000012  loss: 1.2560 (1.3704)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [170/781]  eta: 0:03:27  lr: 0.000012  loss: 1.2553 (1.3684)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [180/781]  eta: 0:03:23  lr: 0.000012  loss: 1.2580 (1.3661)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [190/781]  eta: 0:03:20  lr: 0.000012  loss: 1.2390 (1.3712)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [200/781]  eta: 0:03:16  lr: 0.000012  loss: 1.2473 (1.3728)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [210/781]  eta: 0:03:13  lr: 0.000012  loss: 1.2887 (1.3789)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [220/781]  eta: 0:03:09  lr: 0.000012  loss: 1.2696 (1.3789)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [230/781]  eta: 0:03:06  lr: 0.000012  loss: 1.2696 (1.3823)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [240/781]  eta: 0:03:02  lr: 0.000012  loss: 1.2637 (1.3769)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [250/781]  eta: 0:02:59  lr: 0.000012  loss: 1.2347 (1.3827)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [260/781]  eta: 0:02:55  lr: 0.000012  loss: 1.2607 (1.3843)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [270/781]  eta: 0:02:52  lr: 0.000012  loss: 1.2467 (1.3905)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2614 (1.3917)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [290/781]  eta: 0:02:45  lr: 0.000012  loss: 1.2875 (1.3883)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2875 (1.3874)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [310/781]  eta: 0:02:38  lr: 0.000012  loss: 1.2990 (1.3901)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [320/781]  eta: 0:02:35  lr: 0.000012  loss: 1.2890 (1.3889)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.2965 (1.3929)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [340/781]  eta: 0:02:28  lr: 0.000012  loss: 1.3367 (1.3918)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2558 (1.3910)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.2373 (1.3911)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [370/781]  eta: 0:02:18  lr: 0.000012  loss: 1.2373 (1.3905)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.2798 (1.3879)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [390/781]  eta: 0:02:11  lr: 0.000012  loss: 1.2696 (1.3884)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2700 (1.3906)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.3053 (1.3930)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [420/781]  eta: 0:02:01  lr: 0.000012  loss: 1.2848 (1.3936)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2315 (1.3912)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.2366 (1.3957)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [450/781]  eta: 0:01:51  lr: 0.000012  loss: 1.2438 (1.3994)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.3006 (1.4006)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.3031 (1.4030)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.2667 (1.4016)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.2667 (1.4015)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [500/781]  eta: 0:01:34  lr: 0.000012  loss: 1.2915 (1.4050)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.3128 (1.4037)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.3128 (1.4108)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [530/781]  eta: 0:01:24  lr: 0.000012  loss: 1.3075 (1.4114)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.2811 (1.4165)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.3014 (1.4155)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [560/781]  eta: 0:01:14  lr: 0.000012  loss: 1.2534 (1.4161)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2628 (1.4177)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2674 (1.4178)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2229 (1.4176)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2227 (1.4152)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2683 (1.4156)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.3024 (1.4150)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2932 (1.4146)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.3006 (1.4170)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.3014 (1.4199)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2885 (1.4196)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.2493 (1.4189)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2637 (1.4185)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.2665 (1.4183)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.2702 (1.4164)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2677 (1.4163)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2709 (1.4155)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.2438 (1.4149)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.2362 (1.4139)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.2518 (1.4157)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [760/781]  eta: 0:00:07  lr: 0.000012  loss: 1.3347 (1.4170)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2674 (1.4159)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [89]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.2440 (1.4177)  time: 0.3332  data: 0.0005  max mem: 6459\n",
            "Epoch: [89] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.2440 (1.4177)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32860898971557617, 'lambda_convnext_base': 0.2605615556240082, 'lambda_tf_efficientnetv2_l': 0.41082924604415894}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.8077 (0.8077)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8550  data: 0.8242  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9117 (0.9576)  acc1: 83.8542 (82.0549)  acc5: 94.2708 (93.4659)  time: 0.1686  data: 0.1380  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0088 (1.0295)  acc1: 80.7292 (80.6796)  acc5: 93.2292 (92.6587)  time: 0.1200  data: 0.0893  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1923 (1.0907)  acc1: 77.0833 (79.5531)  acc5: 92.1875 (92.0531)  time: 0.1227  data: 0.0921  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2717 (1.1372)  acc1: 76.5625 (78.4934)  acc5: 90.1042 (91.6032)  time: 0.1225  data: 0.0918  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1565 (1.1343)  acc1: 76.0417 (78.2373)  acc5: 92.1875 (91.9016)  time: 0.1253  data: 0.0946  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1708 (1.1472)  acc1: 75.0000 (78.0700)  acc5: 92.1875 (91.9400)  time: 0.1057  data: 0.0759  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1302 s / it)\n",
            "* Acc@1 78.070 Acc@5 91.940 loss 1.147\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [90]  [  0/781]  eta: 0:14:12  lr: 0.000012  loss: 1.1770 (1.1770)  time: 1.0912  data: 0.7312  max mem: 6459\n",
            "Epoch: [90]  [ 10/781]  eta: 0:05:10  lr: 0.000012  loss: 1.2426 (1.2958)  time: 0.4029  data: 0.0667  max mem: 6459\n",
            "Epoch: [90]  [ 20/781]  eta: 0:04:41  lr: 0.000012  loss: 1.2426 (1.3963)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 30/781]  eta: 0:04:28  lr: 0.000012  loss: 1.2628 (1.4067)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 40/781]  eta: 0:04:20  lr: 0.000012  loss: 1.2775 (1.4034)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 50/781]  eta: 0:04:14  lr: 0.000012  loss: 1.2619 (1.3868)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 60/781]  eta: 0:04:09  lr: 0.000012  loss: 1.2523 (1.3982)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 70/781]  eta: 0:04:04  lr: 0.000012  loss: 1.2523 (1.3890)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 80/781]  eta: 0:04:00  lr: 0.000012  loss: 1.2458 (1.3869)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [ 90/781]  eta: 0:03:55  lr: 0.000012  loss: 1.2389 (1.3850)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [100/781]  eta: 0:03:52  lr: 0.000012  loss: 1.2877 (1.3864)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [110/781]  eta: 0:03:48  lr: 0.000012  loss: 1.3182 (1.4001)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [120/781]  eta: 0:03:44  lr: 0.000012  loss: 1.2362 (1.3890)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [130/781]  eta: 0:03:40  lr: 0.000012  loss: 1.2362 (1.3841)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [140/781]  eta: 0:03:37  lr: 0.000012  loss: 1.2618 (1.3841)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [150/781]  eta: 0:03:33  lr: 0.000012  loss: 1.2744 (1.3769)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [160/781]  eta: 0:03:29  lr: 0.000012  loss: 1.2870 (1.3901)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [170/781]  eta: 0:03:26  lr: 0.000012  loss: 1.3344 (1.3893)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [180/781]  eta: 0:03:22  lr: 0.000012  loss: 1.2438 (1.3888)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [190/781]  eta: 0:03:19  lr: 0.000012  loss: 1.2674 (1.3894)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [200/781]  eta: 0:03:15  lr: 0.000012  loss: 1.3334 (1.3941)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [210/781]  eta: 0:03:12  lr: 0.000012  loss: 1.3005 (1.3943)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [220/781]  eta: 0:03:08  lr: 0.000012  loss: 1.2903 (1.3935)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [230/781]  eta: 0:03:05  lr: 0.000012  loss: 1.2840 (1.3917)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [240/781]  eta: 0:03:01  lr: 0.000012  loss: 1.2840 (1.4006)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [250/781]  eta: 0:02:58  lr: 0.000012  loss: 1.2469 (1.4003)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [260/781]  eta: 0:02:55  lr: 0.000012  loss: 1.2724 (1.4044)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [270/781]  eta: 0:02:51  lr: 0.000012  loss: 1.3307 (1.4074)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [280/781]  eta: 0:02:48  lr: 0.000012  loss: 1.2689 (1.4058)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [290/781]  eta: 0:02:44  lr: 0.000012  loss: 1.2461 (1.4001)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [300/781]  eta: 0:02:41  lr: 0.000012  loss: 1.2733 (1.3981)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [310/781]  eta: 0:02:38  lr: 0.000012  loss: 1.2215 (1.3971)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [320/781]  eta: 0:02:34  lr: 0.000012  loss: 1.2295 (1.3976)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [330/781]  eta: 0:02:31  lr: 0.000012  loss: 1.2591 (1.3968)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [340/781]  eta: 0:02:27  lr: 0.000012  loss: 1.2513 (1.3952)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [350/781]  eta: 0:02:24  lr: 0.000012  loss: 1.2513 (1.3915)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [360/781]  eta: 0:02:21  lr: 0.000012  loss: 1.2390 (1.3880)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [370/781]  eta: 0:02:17  lr: 0.000012  loss: 1.2424 (1.3867)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [380/781]  eta: 0:02:14  lr: 0.000012  loss: 1.2523 (1.3845)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [390/781]  eta: 0:02:11  lr: 0.000012  loss: 1.2589 (1.3891)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [400/781]  eta: 0:02:07  lr: 0.000012  loss: 1.2979 (1.3887)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [410/781]  eta: 0:02:04  lr: 0.000012  loss: 1.2770 (1.3918)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [420/781]  eta: 0:02:00  lr: 0.000012  loss: 1.2661 (1.3899)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [430/781]  eta: 0:01:57  lr: 0.000012  loss: 1.2955 (1.3899)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [440/781]  eta: 0:01:54  lr: 0.000012  loss: 1.3448 (1.3909)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [450/781]  eta: 0:01:50  lr: 0.000012  loss: 1.3142 (1.3942)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [460/781]  eta: 0:01:47  lr: 0.000012  loss: 1.2610 (1.3912)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [470/781]  eta: 0:01:44  lr: 0.000012  loss: 1.2491 (1.3875)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [480/781]  eta: 0:01:40  lr: 0.000012  loss: 1.2055 (1.3895)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [490/781]  eta: 0:01:37  lr: 0.000012  loss: 1.3408 (1.3912)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [500/781]  eta: 0:01:34  lr: 0.000012  loss: 1.2784 (1.3900)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [510/781]  eta: 0:01:30  lr: 0.000012  loss: 1.2514 (1.3871)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [520/781]  eta: 0:01:27  lr: 0.000012  loss: 1.2514 (1.3879)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [530/781]  eta: 0:01:23  lr: 0.000012  loss: 1.2973 (1.3899)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [540/781]  eta: 0:01:20  lr: 0.000012  loss: 1.2826 (1.3899)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [550/781]  eta: 0:01:17  lr: 0.000012  loss: 1.2771 (1.3923)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [560/781]  eta: 0:01:13  lr: 0.000012  loss: 1.2165 (1.3939)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [570/781]  eta: 0:01:10  lr: 0.000012  loss: 1.2574 (1.3951)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [580/781]  eta: 0:01:07  lr: 0.000012  loss: 1.2589 (1.3933)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [590/781]  eta: 0:01:03  lr: 0.000012  loss: 1.2589 (1.3921)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [600/781]  eta: 0:01:00  lr: 0.000012  loss: 1.2640 (1.3928)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [610/781]  eta: 0:00:57  lr: 0.000012  loss: 1.2640 (1.3914)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [620/781]  eta: 0:00:53  lr: 0.000012  loss: 1.2790 (1.3922)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [630/781]  eta: 0:00:50  lr: 0.000012  loss: 1.2957 (1.3913)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [640/781]  eta: 0:00:47  lr: 0.000012  loss: 1.2443 (1.3905)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [650/781]  eta: 0:00:43  lr: 0.000012  loss: 1.2268 (1.3897)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [660/781]  eta: 0:00:40  lr: 0.000012  loss: 1.2618 (1.3881)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [670/781]  eta: 0:00:37  lr: 0.000012  loss: 1.2725 (1.3895)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [680/781]  eta: 0:00:33  lr: 0.000012  loss: 1.2894 (1.3905)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [690/781]  eta: 0:00:30  lr: 0.000012  loss: 1.2777 (1.3891)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [700/781]  eta: 0:00:27  lr: 0.000012  loss: 1.2566 (1.3875)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [710/781]  eta: 0:00:23  lr: 0.000012  loss: 1.2428 (1.3863)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [720/781]  eta: 0:00:20  lr: 0.000012  loss: 1.2418 (1.3845)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [730/781]  eta: 0:00:17  lr: 0.000012  loss: 1.2592 (1.3838)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [740/781]  eta: 0:00:13  lr: 0.000012  loss: 1.2703 (1.3851)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [750/781]  eta: 0:00:10  lr: 0.000012  loss: 1.2560 (1.3870)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [760/781]  eta: 0:00:07  lr: 0.000012  loss: 1.2698 (1.3880)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [770/781]  eta: 0:00:03  lr: 0.000012  loss: 1.2778 (1.3877)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [90]  [780/781]  eta: 0:00:00  lr: 0.000012  loss: 1.2678 (1.3890)  time: 0.3336  data: 0.0005  max mem: 6459\n",
            "Epoch: [90] Total time: 0:04:21 (0.3343 s / it)\n",
            "Averaged stats: lr: 0.000012  loss: 1.2678 (1.3890)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32919377088546753, 'lambda_convnext_base': 0.25967109203338623, 'lambda_tf_efficientnetv2_l': 0.41113534569740295}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.8217 (0.8217)  acc1: 84.8958 (84.8958)  acc5: 93.7500 (93.7500)  time: 0.8203  data: 0.7894  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9268 (0.9588)  acc1: 84.3750 (82.3864)  acc5: 94.2708 (93.5133)  time: 0.1753  data: 0.1446  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0520 (1.0298)  acc1: 79.6875 (80.9772)  acc5: 93.2292 (92.6835)  time: 0.1318  data: 0.1011  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1881 (1.0866)  acc1: 77.0833 (79.9059)  acc5: 91.6667 (92.1203)  time: 0.1355  data: 0.1048  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2543 (1.1342)  acc1: 76.5625 (78.8745)  acc5: 91.1458 (91.6286)  time: 0.1354  data: 0.1047  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1243 (1.1343)  acc1: 76.0417 (78.4314)  acc5: 91.6667 (91.8199)  time: 0.1326  data: 0.1020  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1760 (1.1435)  acc1: 75.0000 (78.3100)  acc5: 91.6667 (91.8500)  time: 0.1111  data: 0.0814  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1392 s / it)\n",
            "* Acc@1 78.310 Acc@5 91.850 loss 1.143\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [91]  [  0/781]  eta: 0:14:14  lr: 0.000011  loss: 1.1510 (1.1510)  time: 1.0947  data: 0.7500  max mem: 6459\n",
            "Epoch: [91]  [ 10/781]  eta: 0:05:10  lr: 0.000011  loss: 1.2955 (1.5453)  time: 0.4033  data: 0.0685  max mem: 6459\n",
            "Epoch: [91]  [ 20/781]  eta: 0:04:42  lr: 0.000011  loss: 1.2889 (1.4802)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 30/781]  eta: 0:04:29  lr: 0.000011  loss: 1.2776 (1.4376)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 40/781]  eta: 0:04:21  lr: 0.000011  loss: 1.2469 (1.4552)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 50/781]  eta: 0:04:14  lr: 0.000011  loss: 1.2469 (1.4713)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 60/781]  eta: 0:04:09  lr: 0.000011  loss: 1.2369 (1.4465)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 70/781]  eta: 0:04:04  lr: 0.000011  loss: 1.2486 (1.4220)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 80/781]  eta: 0:04:00  lr: 0.000011  loss: 1.2541 (1.4311)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [ 90/781]  eta: 0:03:56  lr: 0.000011  loss: 1.2699 (1.4441)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [100/781]  eta: 0:03:52  lr: 0.000011  loss: 1.2439 (1.4370)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [110/781]  eta: 0:03:48  lr: 0.000011  loss: 1.2092 (1.4172)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [120/781]  eta: 0:03:44  lr: 0.000011  loss: 1.2144 (1.4197)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [130/781]  eta: 0:03:40  lr: 0.000011  loss: 1.2380 (1.4160)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [140/781]  eta: 0:03:37  lr: 0.000011  loss: 1.2646 (1.4067)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [150/781]  eta: 0:03:33  lr: 0.000011  loss: 1.2670 (1.3983)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [160/781]  eta: 0:03:29  lr: 0.000011  loss: 1.2392 (1.3884)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [170/781]  eta: 0:03:26  lr: 0.000011  loss: 1.2421 (1.3880)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [180/781]  eta: 0:03:22  lr: 0.000011  loss: 1.2637 (1.3922)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [190/781]  eta: 0:03:19  lr: 0.000011  loss: 1.2796 (1.4026)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [200/781]  eta: 0:03:15  lr: 0.000011  loss: 1.3406 (1.4133)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [210/781]  eta: 0:03:12  lr: 0.000011  loss: 1.3024 (1.4159)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [220/781]  eta: 0:03:08  lr: 0.000011  loss: 1.2486 (1.4124)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [230/781]  eta: 0:03:05  lr: 0.000011  loss: 1.2472 (1.4169)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [240/781]  eta: 0:03:02  lr: 0.000011  loss: 1.2624 (1.4137)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [250/781]  eta: 0:02:58  lr: 0.000011  loss: 1.2939 (1.4086)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [260/781]  eta: 0:02:55  lr: 0.000011  loss: 1.3057 (1.4129)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.2835 (1.4123)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [280/781]  eta: 0:02:48  lr: 0.000011  loss: 1.2503 (1.4076)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [290/781]  eta: 0:02:44  lr: 0.000011  loss: 1.2637 (1.4080)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [300/781]  eta: 0:02:41  lr: 0.000011  loss: 1.3140 (1.4174)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [310/781]  eta: 0:02:38  lr: 0.000011  loss: 1.3376 (1.4139)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.2686 (1.4147)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [330/781]  eta: 0:02:31  lr: 0.000011  loss: 1.2636 (1.4178)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [340/781]  eta: 0:02:27  lr: 0.000011  loss: 1.3006 (1.4210)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [350/781]  eta: 0:02:24  lr: 0.000011  loss: 1.3343 (1.4246)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [360/781]  eta: 0:02:21  lr: 0.000011  loss: 1.2428 (1.4221)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2468 (1.4225)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [380/781]  eta: 0:02:14  lr: 0.000011  loss: 1.2514 (1.4234)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [390/781]  eta: 0:02:11  lr: 0.000011  loss: 1.2518 (1.4203)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.2335 (1.4241)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [410/781]  eta: 0:02:04  lr: 0.000011  loss: 1.2553 (1.4238)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [420/781]  eta: 0:02:00  lr: 0.000011  loss: 1.2326 (1.4197)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.2742 (1.4222)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [440/781]  eta: 0:01:54  lr: 0.000011  loss: 1.2660 (1.4187)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.2319 (1.4187)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2931 (1.4206)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [470/781]  eta: 0:01:44  lr: 0.000011  loss: 1.2931 (1.4175)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2056 (1.4138)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2097 (1.4176)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [500/781]  eta: 0:01:34  lr: 0.000011  loss: 1.2749 (1.4196)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2462 (1.4164)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [520/781]  eta: 0:01:27  lr: 0.000011  loss: 1.2300 (1.4156)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [530/781]  eta: 0:01:24  lr: 0.000011  loss: 1.3051 (1.4162)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.3051 (1.4155)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [550/781]  eta: 0:01:17  lr: 0.000011  loss: 1.2660 (1.4146)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.3070 (1.4163)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.3070 (1.4150)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [580/781]  eta: 0:01:07  lr: 0.000011  loss: 1.2408 (1.4160)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2878 (1.4153)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2955 (1.4149)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [610/781]  eta: 0:00:57  lr: 0.000011  loss: 1.2862 (1.4181)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.2862 (1.4171)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2868 (1.4155)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [640/781]  eta: 0:00:47  lr: 0.000011  loss: 1.2868 (1.4161)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2830 (1.4162)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2691 (1.4155)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [670/781]  eta: 0:00:37  lr: 0.000011  loss: 1.2506 (1.4131)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2521 (1.4113)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2785 (1.4125)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [700/781]  eta: 0:00:27  lr: 0.000011  loss: 1.2768 (1.4114)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2456 (1.4099)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2432 (1.4075)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [730/781]  eta: 0:00:17  lr: 0.000011  loss: 1.2483 (1.4058)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2760 (1.4073)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.3054 (1.4086)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [760/781]  eta: 0:00:07  lr: 0.000011  loss: 1.2886 (1.4092)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2706 (1.4077)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [91]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2711 (1.4072)  time: 0.3335  data: 0.0005  max mem: 6459\n",
            "Epoch: [91] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2711 (1.4072)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3292854130268097, 'lambda_convnext_base': 0.25971484184265137, 'lambda_tf_efficientnetv2_l': 0.41100016236305237}\n",
            "Test:  [ 0/53]  eta: 0:00:38  loss: 0.7848 (0.7848)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.7180  data: 0.6871  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9246 (0.9452)  acc1: 83.8542 (82.0549)  acc5: 94.2708 (93.7974)  time: 0.1713  data: 0.1406  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0229 (1.0249)  acc1: 78.6458 (80.4564)  acc5: 93.7500 (92.7579)  time: 0.1253  data: 0.0946  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1797 (1.0847)  acc1: 77.0833 (79.4691)  acc5: 91.1458 (92.2715)  time: 0.1203  data: 0.0896  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2701 (1.1377)  acc1: 76.5625 (78.5442)  acc5: 90.1042 (91.6667)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1092 (1.1326)  acc1: 77.0833 (78.3190)  acc5: 92.1875 (91.9526)  time: 0.1237  data: 0.0930  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1569 (1.1456)  acc1: 75.0000 (78.2000)  acc5: 92.1875 (91.9800)  time: 0.1057  data: 0.0760  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1294 s / it)\n",
            "* Acc@1 78.200 Acc@5 91.980 loss 1.146\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [92]  [  0/781]  eta: 0:14:32  lr: 0.000011  loss: 1.1953 (1.1953)  time: 1.1174  data: 0.7734  max mem: 6459\n",
            "Epoch: [92]  [ 10/781]  eta: 0:05:12  lr: 0.000011  loss: 1.2653 (1.3632)  time: 0.4049  data: 0.0706  max mem: 6459\n",
            "Epoch: [92]  [ 20/781]  eta: 0:04:42  lr: 0.000011  loss: 1.2641 (1.4773)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 30/781]  eta: 0:04:29  lr: 0.000011  loss: 1.2546 (1.4397)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 40/781]  eta: 0:04:21  lr: 0.000011  loss: 1.2681 (1.4302)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 50/781]  eta: 0:04:15  lr: 0.000011  loss: 1.2934 (1.3979)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 60/781]  eta: 0:04:09  lr: 0.000011  loss: 1.2420 (1.3651)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 70/781]  eta: 0:04:04  lr: 0.000011  loss: 1.2454 (1.3661)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 80/781]  eta: 0:04:00  lr: 0.000011  loss: 1.2939 (1.3857)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [ 90/781]  eta: 0:03:56  lr: 0.000011  loss: 1.3170 (1.3797)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [100/781]  eta: 0:03:52  lr: 0.000011  loss: 1.2893 (1.3750)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [110/781]  eta: 0:03:48  lr: 0.000011  loss: 1.2701 (1.3839)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [120/781]  eta: 0:03:44  lr: 0.000011  loss: 1.2013 (1.3815)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [130/781]  eta: 0:03:41  lr: 0.000011  loss: 1.2467 (1.3806)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [140/781]  eta: 0:03:37  lr: 0.000011  loss: 1.2467 (1.3777)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [150/781]  eta: 0:03:33  lr: 0.000011  loss: 1.2463 (1.3736)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [160/781]  eta: 0:03:30  lr: 0.000011  loss: 1.2318 (1.3642)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [170/781]  eta: 0:03:26  lr: 0.000011  loss: 1.2368 (1.3659)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [180/781]  eta: 0:03:23  lr: 0.000011  loss: 1.2368 (1.3604)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [190/781]  eta: 0:03:19  lr: 0.000011  loss: 1.2564 (1.3636)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [200/781]  eta: 0:03:16  lr: 0.000011  loss: 1.2623 (1.3641)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [210/781]  eta: 0:03:12  lr: 0.000011  loss: 1.2498 (1.3728)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [220/781]  eta: 0:03:09  lr: 0.000011  loss: 1.2498 (1.3716)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [230/781]  eta: 0:03:05  lr: 0.000011  loss: 1.2756 (1.3701)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [240/781]  eta: 0:03:02  lr: 0.000011  loss: 1.2947 (1.3715)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [250/781]  eta: 0:02:58  lr: 0.000011  loss: 1.2457 (1.3651)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [260/781]  eta: 0:02:55  lr: 0.000011  loss: 1.2316 (1.3643)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.2654 (1.3606)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [280/781]  eta: 0:02:48  lr: 0.000011  loss: 1.2672 (1.3678)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [290/781]  eta: 0:02:45  lr: 0.000011  loss: 1.2715 (1.3709)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [300/781]  eta: 0:02:41  lr: 0.000011  loss: 1.2624 (1.3699)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [310/781]  eta: 0:02:38  lr: 0.000011  loss: 1.2661 (1.3709)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.2675 (1.3716)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [330/781]  eta: 0:02:31  lr: 0.000011  loss: 1.2532 (1.3747)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [340/781]  eta: 0:02:28  lr: 0.000011  loss: 1.2799 (1.3751)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [350/781]  eta: 0:02:24  lr: 0.000011  loss: 1.2799 (1.3730)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [360/781]  eta: 0:02:21  lr: 0.000011  loss: 1.2566 (1.3721)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2597 (1.3721)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [380/781]  eta: 0:02:14  lr: 0.000011  loss: 1.2763 (1.3714)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [390/781]  eta: 0:02:11  lr: 0.000011  loss: 1.2771 (1.3734)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.3045 (1.3731)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [410/781]  eta: 0:02:04  lr: 0.000011  loss: 1.2400 (1.3732)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [420/781]  eta: 0:02:01  lr: 0.000011  loss: 1.2529 (1.3809)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.3762 (1.3806)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [440/781]  eta: 0:01:54  lr: 0.000011  loss: 1.2859 (1.3787)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [450/781]  eta: 0:01:50  lr: 0.000011  loss: 1.2632 (1.3798)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2403 (1.3786)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [470/781]  eta: 0:01:44  lr: 0.000011  loss: 1.2377 (1.3755)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2638 (1.3753)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2569 (1.3736)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [500/781]  eta: 0:01:34  lr: 0.000011  loss: 1.2373 (1.3714)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2697 (1.3736)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [520/781]  eta: 0:01:27  lr: 0.000011  loss: 1.2757 (1.3730)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [530/781]  eta: 0:01:24  lr: 0.000011  loss: 1.2748 (1.3749)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2748 (1.3746)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [550/781]  eta: 0:01:17  lr: 0.000011  loss: 1.2952 (1.3767)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [560/781]  eta: 0:01:13  lr: 0.000011  loss: 1.2548 (1.3770)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2565 (1.3787)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [580/781]  eta: 0:01:07  lr: 0.000011  loss: 1.3063 (1.3777)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2422 (1.3813)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2747 (1.3847)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [610/781]  eta: 0:00:57  lr: 0.000011  loss: 1.3677 (1.3905)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.4183 (1.3947)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2833 (1.3955)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [640/781]  eta: 0:00:47  lr: 0.000011  loss: 1.2734 (1.3942)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2662 (1.3921)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2352 (1.3911)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [670/781]  eta: 0:00:37  lr: 0.000011  loss: 1.2724 (1.3931)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2797 (1.3932)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2512 (1.3936)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [700/781]  eta: 0:00:27  lr: 0.000011  loss: 1.2512 (1.3918)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2550 (1.3918)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2934 (1.3920)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [730/781]  eta: 0:00:17  lr: 0.000011  loss: 1.3306 (1.3943)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.3240 (1.3948)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2926 (1.3949)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [760/781]  eta: 0:00:07  lr: 0.000011  loss: 1.2460 (1.3931)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2392 (1.3925)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [92]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2182 (1.3915)  time: 0.3335  data: 0.0006  max mem: 6459\n",
            "Epoch: [92] Total time: 0:04:21 (0.3345 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2182 (1.3915)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3292343020439148, 'lambda_convnext_base': 0.2591608762741089, 'lambda_tf_efficientnetv2_l': 0.41160503029823303}\n",
            "Test:  [ 0/53]  eta: 0:00:44  loss: 0.8009 (0.8009)  acc1: 85.4167 (85.4167)  acc5: 95.3125 (95.3125)  time: 0.8457  data: 0.8148  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9494 (0.9550)  acc1: 83.3333 (82.2443)  acc5: 93.7500 (93.4659)  time: 0.1682  data: 0.1375  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:04  loss: 1.0065 (1.0359)  acc1: 79.6875 (80.6300)  acc5: 93.7500 (92.4851)  time: 0.1159  data: 0.0852  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2251 (1.0990)  acc1: 76.0417 (79.5363)  acc5: 91.1458 (91.9691)  time: 0.1200  data: 0.0894  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2679 (1.1435)  acc1: 75.5208 (78.4172)  acc5: 90.6250 (91.5269)  time: 0.1217  data: 0.0910  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1322 (1.1380)  acc1: 77.0833 (78.2578)  acc5: 91.1458 (91.7892)  time: 0.1248  data: 0.0941  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1416 (1.1510)  acc1: 75.0000 (78.1600)  acc5: 92.1875 (91.8300)  time: 0.1083  data: 0.0786  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1290 s / it)\n",
            "* Acc@1 78.160 Acc@5 91.830 loss 1.151\n",
            "Accuracy of the network on the 10000 test images: 78.2%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [93]  [  0/781]  eta: 0:15:10  lr: 0.000011  loss: 1.3251 (1.3251)  time: 1.1664  data: 0.8182  max mem: 6459\n",
            "Epoch: [93]  [ 10/781]  eta: 0:05:15  lr: 0.000011  loss: 1.2818 (1.3241)  time: 0.4097  data: 0.0747  max mem: 6459\n",
            "Epoch: [93]  [ 20/781]  eta: 0:04:44  lr: 0.000011  loss: 1.2415 (1.3601)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 30/781]  eta: 0:04:30  lr: 0.000011  loss: 1.2237 (1.3541)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 40/781]  eta: 0:04:22  lr: 0.000011  loss: 1.2796 (1.4216)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 50/781]  eta: 0:04:15  lr: 0.000011  loss: 1.4813 (1.4485)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 60/781]  eta: 0:04:10  lr: 0.000011  loss: 1.3403 (1.4435)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 70/781]  eta: 0:04:05  lr: 0.000011  loss: 1.2639 (1.4129)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 80/781]  eta: 0:04:01  lr: 0.000011  loss: 1.2411 (1.4157)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [ 90/781]  eta: 0:03:56  lr: 0.000011  loss: 1.2411 (1.4100)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [100/781]  eta: 0:03:52  lr: 0.000011  loss: 1.2789 (1.4158)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [110/781]  eta: 0:03:48  lr: 0.000011  loss: 1.2538 (1.4127)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [120/781]  eta: 0:03:45  lr: 0.000011  loss: 1.2440 (1.4136)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [130/781]  eta: 0:03:41  lr: 0.000011  loss: 1.2495 (1.4129)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [140/781]  eta: 0:03:37  lr: 0.000011  loss: 1.2920 (1.4250)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [150/781]  eta: 0:03:34  lr: 0.000011  loss: 1.3343 (1.4406)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [160/781]  eta: 0:03:30  lr: 0.000011  loss: 1.2802 (1.4315)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [170/781]  eta: 0:03:26  lr: 0.000011  loss: 1.2657 (1.4248)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [180/781]  eta: 0:03:23  lr: 0.000011  loss: 1.2478 (1.4165)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [190/781]  eta: 0:03:19  lr: 0.000011  loss: 1.2605 (1.4198)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [200/781]  eta: 0:03:16  lr: 0.000011  loss: 1.2497 (1.4229)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [210/781]  eta: 0:03:12  lr: 0.000011  loss: 1.2497 (1.4189)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [220/781]  eta: 0:03:09  lr: 0.000011  loss: 1.3000 (1.4152)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [230/781]  eta: 0:03:05  lr: 0.000011  loss: 1.2792 (1.4098)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [240/781]  eta: 0:03:02  lr: 0.000011  loss: 1.2787 (1.4082)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [250/781]  eta: 0:02:58  lr: 0.000011  loss: 1.2979 (1.4111)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [260/781]  eta: 0:02:55  lr: 0.000011  loss: 1.2855 (1.4096)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [270/781]  eta: 0:02:52  lr: 0.000011  loss: 1.2729 (1.4142)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [280/781]  eta: 0:02:48  lr: 0.000011  loss: 1.2998 (1.4237)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [290/781]  eta: 0:02:45  lr: 0.000011  loss: 1.3312 (1.4209)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [300/781]  eta: 0:02:41  lr: 0.000011  loss: 1.3312 (1.4226)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [310/781]  eta: 0:02:38  lr: 0.000011  loss: 1.3086 (1.4275)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.3086 (1.4291)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [330/781]  eta: 0:02:31  lr: 0.000011  loss: 1.3112 (1.4337)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [340/781]  eta: 0:02:28  lr: 0.000011  loss: 1.2689 (1.4283)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [350/781]  eta: 0:02:24  lr: 0.000011  loss: 1.2586 (1.4252)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [360/781]  eta: 0:02:21  lr: 0.000011  loss: 1.2614 (1.4276)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [370/781]  eta: 0:02:18  lr: 0.000011  loss: 1.2436 (1.4233)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [380/781]  eta: 0:02:14  lr: 0.000011  loss: 1.2431 (1.4209)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [390/781]  eta: 0:02:11  lr: 0.000011  loss: 1.2692 (1.4233)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.3281 (1.4243)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [410/781]  eta: 0:02:04  lr: 0.000011  loss: 1.2918 (1.4209)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [420/781]  eta: 0:02:01  lr: 0.000011  loss: 1.2304 (1.4186)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.2546 (1.4174)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [440/781]  eta: 0:01:54  lr: 0.000011  loss: 1.2671 (1.4158)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [450/781]  eta: 0:01:51  lr: 0.000011  loss: 1.2315 (1.4121)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2031 (1.4083)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [470/781]  eta: 0:01:44  lr: 0.000011  loss: 1.2397 (1.4097)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2760 (1.4129)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2798 (1.4133)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [500/781]  eta: 0:01:34  lr: 0.000011  loss: 1.3063 (1.4141)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.3519 (1.4194)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [520/781]  eta: 0:01:27  lr: 0.000011  loss: 1.2824 (1.4161)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [530/781]  eta: 0:01:24  lr: 0.000011  loss: 1.2596 (1.4156)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2789 (1.4185)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [550/781]  eta: 0:01:17  lr: 0.000011  loss: 1.2789 (1.4180)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [560/781]  eta: 0:01:14  lr: 0.000011  loss: 1.2641 (1.4176)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2641 (1.4176)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [580/781]  eta: 0:01:07  lr: 0.000011  loss: 1.3014 (1.4178)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2698 (1.4174)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2881 (1.4181)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [610/781]  eta: 0:00:57  lr: 0.000011  loss: 1.2881 (1.4163)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.2158 (1.4191)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2068 (1.4161)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [640/781]  eta: 0:00:47  lr: 0.000011  loss: 1.1962 (1.4139)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2308 (1.4139)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2610 (1.4115)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [670/781]  eta: 0:00:37  lr: 0.000011  loss: 1.2610 (1.4128)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2358 (1.4104)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2134 (1.4110)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [700/781]  eta: 0:00:27  lr: 0.000011  loss: 1.2575 (1.4139)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2282 (1.4127)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2282 (1.4117)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [730/781]  eta: 0:00:17  lr: 0.000011  loss: 1.2584 (1.4115)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2326 (1.4117)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2535 (1.4124)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [760/781]  eta: 0:00:07  lr: 0.000011  loss: 1.2535 (1.4110)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2370 (1.4095)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [93]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2370 (1.4091)  time: 0.3338  data: 0.0006  max mem: 6459\n",
            "Epoch: [93] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2370 (1.4091)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32830020785331726, 'lambda_convnext_base': 0.2600000500679016, 'lambda_tf_efficientnetv2_l': 0.4116996228694916}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7813 (0.7813)  acc1: 84.8958 (84.8958)  acc5: 95.3125 (95.3125)  time: 0.8545  data: 0.8236  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8455 (0.9498)  acc1: 84.8958 (82.2917)  acc5: 94.7917 (93.6080)  time: 0.1710  data: 0.1403  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0797 (1.0384)  acc1: 79.6875 (80.6796)  acc5: 92.7083 (92.4107)  time: 0.1213  data: 0.0907  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1818 (1.0899)  acc1: 76.0417 (79.6875)  acc5: 91.6667 (91.8179)  time: 0.1218  data: 0.0911  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2459 (1.1321)  acc1: 76.0417 (78.8110)  acc5: 90.1042 (91.5650)  time: 0.1241  data: 0.0934  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1492 (1.1321)  acc1: 76.5625 (78.4212)  acc5: 91.6667 (91.8199)  time: 0.1255  data: 0.0948  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1708 (1.1450)  acc1: 76.0417 (78.3000)  acc5: 92.1875 (91.8500)  time: 0.1062  data: 0.0764  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1306 s / it)\n",
            "* Acc@1 78.300 Acc@5 91.850 loss 1.145\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [94]  [  0/781]  eta: 0:14:23  lr: 0.000011  loss: 1.2583 (1.2583)  time: 1.1061  data: 0.7535  max mem: 6459\n",
            "Epoch: [94]  [ 10/781]  eta: 0:05:11  lr: 0.000011  loss: 1.2758 (1.3739)  time: 0.4040  data: 0.0688  max mem: 6459\n",
            "Epoch: [94]  [ 20/781]  eta: 0:04:41  lr: 0.000011  loss: 1.2537 (1.2984)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 30/781]  eta: 0:04:29  lr: 0.000011  loss: 1.2310 (1.3114)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 40/781]  eta: 0:04:21  lr: 0.000011  loss: 1.2574 (1.3341)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 50/781]  eta: 0:04:15  lr: 0.000011  loss: 1.2692 (1.3209)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 60/781]  eta: 0:04:09  lr: 0.000011  loss: 1.2436 (1.3145)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 70/781]  eta: 0:04:05  lr: 0.000011  loss: 1.2849 (1.3472)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 80/781]  eta: 0:04:00  lr: 0.000011  loss: 1.2706 (1.3399)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [ 90/781]  eta: 0:03:56  lr: 0.000011  loss: 1.2635 (1.3630)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [100/781]  eta: 0:03:52  lr: 0.000011  loss: 1.2702 (1.3557)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [110/781]  eta: 0:03:48  lr: 0.000011  loss: 1.2889 (1.3859)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [120/781]  eta: 0:03:44  lr: 0.000011  loss: 1.3398 (1.3849)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [130/781]  eta: 0:03:40  lr: 0.000011  loss: 1.2561 (1.3877)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [140/781]  eta: 0:03:37  lr: 0.000011  loss: 1.2299 (1.3938)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [150/781]  eta: 0:03:33  lr: 0.000011  loss: 1.2974 (1.4040)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [160/781]  eta: 0:03:30  lr: 0.000011  loss: 1.2886 (1.4042)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [170/781]  eta: 0:03:26  lr: 0.000011  loss: 1.2799 (1.4178)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [180/781]  eta: 0:03:22  lr: 0.000011  loss: 1.2362 (1.4082)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [190/781]  eta: 0:03:19  lr: 0.000011  loss: 1.2184 (1.4044)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [200/781]  eta: 0:03:15  lr: 0.000011  loss: 1.2691 (1.4028)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [210/781]  eta: 0:03:12  lr: 0.000011  loss: 1.2691 (1.3962)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [220/781]  eta: 0:03:08  lr: 0.000011  loss: 1.2495 (1.3984)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [230/781]  eta: 0:03:05  lr: 0.000011  loss: 1.2622 (1.4027)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [240/781]  eta: 0:03:02  lr: 0.000011  loss: 1.2533 (1.3995)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [250/781]  eta: 0:02:58  lr: 0.000011  loss: 1.2492 (1.3970)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [260/781]  eta: 0:02:55  lr: 0.000011  loss: 1.2492 (1.3913)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [270/781]  eta: 0:02:51  lr: 0.000011  loss: 1.2577 (1.3889)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [280/781]  eta: 0:02:48  lr: 0.000011  loss: 1.2496 (1.3886)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [290/781]  eta: 0:02:44  lr: 0.000011  loss: 1.2883 (1.3947)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [300/781]  eta: 0:02:41  lr: 0.000011  loss: 1.3106 (1.4015)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [310/781]  eta: 0:02:38  lr: 0.000011  loss: 1.2732 (1.3994)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [320/781]  eta: 0:02:34  lr: 0.000011  loss: 1.2651 (1.4034)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [330/781]  eta: 0:02:31  lr: 0.000011  loss: 1.2297 (1.4011)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [340/781]  eta: 0:02:28  lr: 0.000011  loss: 1.2457 (1.3989)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [350/781]  eta: 0:02:24  lr: 0.000011  loss: 1.2461 (1.3990)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [360/781]  eta: 0:02:21  lr: 0.000011  loss: 1.2410 (1.3968)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [370/781]  eta: 0:02:17  lr: 0.000011  loss: 1.2386 (1.3927)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [380/781]  eta: 0:02:14  lr: 0.000011  loss: 1.2399 (1.3909)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [390/781]  eta: 0:02:11  lr: 0.000011  loss: 1.2643 (1.3889)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [400/781]  eta: 0:02:07  lr: 0.000011  loss: 1.2457 (1.3892)  time: 0.3430  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [410/781]  eta: 0:02:04  lr: 0.000011  loss: 1.2362 (1.3859)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [420/781]  eta: 0:02:01  lr: 0.000011  loss: 1.2403 (1.3863)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [430/781]  eta: 0:01:57  lr: 0.000011  loss: 1.2479 (1.3868)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [440/781]  eta: 0:01:54  lr: 0.000011  loss: 1.2572 (1.3857)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [450/781]  eta: 0:01:51  lr: 0.000011  loss: 1.2572 (1.3852)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [460/781]  eta: 0:01:47  lr: 0.000011  loss: 1.2522 (1.3817)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [470/781]  eta: 0:01:44  lr: 0.000011  loss: 1.2452 (1.3818)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [480/781]  eta: 0:01:40  lr: 0.000011  loss: 1.2471 (1.3798)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [490/781]  eta: 0:01:37  lr: 0.000011  loss: 1.2646 (1.3787)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [500/781]  eta: 0:01:34  lr: 0.000011  loss: 1.3090 (1.3806)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [510/781]  eta: 0:01:30  lr: 0.000011  loss: 1.2636 (1.3841)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [520/781]  eta: 0:01:27  lr: 0.000011  loss: 1.2614 (1.3813)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [530/781]  eta: 0:01:24  lr: 0.000011  loss: 1.2614 (1.3796)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [540/781]  eta: 0:01:20  lr: 0.000011  loss: 1.2412 (1.3768)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [550/781]  eta: 0:01:17  lr: 0.000011  loss: 1.2353 (1.3744)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [560/781]  eta: 0:01:14  lr: 0.000011  loss: 1.2353 (1.3740)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [570/781]  eta: 0:01:10  lr: 0.000011  loss: 1.2286 (1.3739)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [580/781]  eta: 0:01:07  lr: 0.000011  loss: 1.2750 (1.3749)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [590/781]  eta: 0:01:03  lr: 0.000011  loss: 1.2750 (1.3748)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [600/781]  eta: 0:01:00  lr: 0.000011  loss: 1.2719 (1.3769)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [610/781]  eta: 0:00:57  lr: 0.000011  loss: 1.3046 (1.3777)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [620/781]  eta: 0:00:53  lr: 0.000011  loss: 1.2527 (1.3755)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [630/781]  eta: 0:00:50  lr: 0.000011  loss: 1.2474 (1.3761)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [640/781]  eta: 0:00:47  lr: 0.000011  loss: 1.2573 (1.3761)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [650/781]  eta: 0:00:43  lr: 0.000011  loss: 1.2647 (1.3758)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [660/781]  eta: 0:00:40  lr: 0.000011  loss: 1.2720 (1.3755)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [670/781]  eta: 0:00:37  lr: 0.000011  loss: 1.2706 (1.3752)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [680/781]  eta: 0:00:33  lr: 0.000011  loss: 1.2454 (1.3747)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [690/781]  eta: 0:00:30  lr: 0.000011  loss: 1.2678 (1.3738)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [700/781]  eta: 0:00:27  lr: 0.000011  loss: 1.2627 (1.3736)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [710/781]  eta: 0:00:23  lr: 0.000011  loss: 1.2011 (1.3722)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [720/781]  eta: 0:00:20  lr: 0.000011  loss: 1.2044 (1.3708)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [730/781]  eta: 0:00:17  lr: 0.000011  loss: 1.2546 (1.3729)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [740/781]  eta: 0:00:13  lr: 0.000011  loss: 1.2316 (1.3742)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [750/781]  eta: 0:00:10  lr: 0.000011  loss: 1.2492 (1.3736)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [760/781]  eta: 0:00:07  lr: 0.000011  loss: 1.2634 (1.3748)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [770/781]  eta: 0:00:03  lr: 0.000011  loss: 1.2550 (1.3748)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [94]  [780/781]  eta: 0:00:00  lr: 0.000011  loss: 1.2779 (1.3753)  time: 0.3339  data: 0.0006  max mem: 6459\n",
            "Epoch: [94] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000011  loss: 1.2779 (1.3753)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3290729224681854, 'lambda_convnext_base': 0.2588343918323517, 'lambda_tf_efficientnetv2_l': 0.41209250688552856}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7823 (0.7823)  acc1: 84.8958 (84.8958)  acc5: 94.7917 (94.7917)  time: 0.8565  data: 0.8257  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9266 (0.9512)  acc1: 84.8958 (82.0549)  acc5: 94.7917 (93.9394)  time: 0.1683  data: 0.1376  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0431 (1.0346)  acc1: 78.6458 (80.4812)  acc5: 93.7500 (92.6587)  time: 0.1223  data: 0.0916  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2019 (1.0899)  acc1: 76.0417 (79.4187)  acc5: 91.1458 (92.2043)  time: 0.1268  data: 0.0961  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2196 (1.1365)  acc1: 76.0417 (78.5315)  acc5: 90.6250 (91.6794)  time: 0.1256  data: 0.0949  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1478 (1.1334)  acc1: 76.5625 (78.2578)  acc5: 91.6667 (92.0139)  time: 0.1230  data: 0.0924  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1755 (1.1441)  acc1: 75.0000 (78.1400)  acc5: 92.7083 (92.0300)  time: 0.1034  data: 0.0737  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1308 s / it)\n",
            "* Acc@1 78.140 Acc@5 92.030 loss 1.144\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [95]  [  0/781]  eta: 0:14:08  lr: 0.000010  loss: 1.2438 (1.2438)  time: 1.0868  data: 0.7399  max mem: 6459\n",
            "Epoch: [95]  [ 10/781]  eta: 0:05:09  lr: 0.000010  loss: 1.2438 (1.4625)  time: 0.4018  data: 0.0675  max mem: 6459\n",
            "Epoch: [95]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2507 (1.3659)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2807 (1.3774)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2555 (1.3576)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 50/781]  eta: 0:04:14  lr: 0.000010  loss: 1.2555 (1.3607)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 60/781]  eta: 0:04:09  lr: 0.000010  loss: 1.2670 (1.3619)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 70/781]  eta: 0:04:04  lr: 0.000010  loss: 1.2692 (1.3800)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 80/781]  eta: 0:04:00  lr: 0.000010  loss: 1.2977 (1.3813)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [ 90/781]  eta: 0:03:55  lr: 0.000010  loss: 1.2670 (1.3857)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [100/781]  eta: 0:03:52  lr: 0.000010  loss: 1.2529 (1.3827)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [110/781]  eta: 0:03:48  lr: 0.000010  loss: 1.2249 (1.3677)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [120/781]  eta: 0:03:44  lr: 0.000010  loss: 1.2191 (1.3596)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [130/781]  eta: 0:03:40  lr: 0.000010  loss: 1.2447 (1.3587)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [140/781]  eta: 0:03:37  lr: 0.000010  loss: 1.2499 (1.3517)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [150/781]  eta: 0:03:33  lr: 0.000010  loss: 1.2499 (1.3538)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2652 (1.3679)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [170/781]  eta: 0:03:26  lr: 0.000010  loss: 1.2855 (1.3608)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2584 (1.3546)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [190/781]  eta: 0:03:19  lr: 0.000010  loss: 1.2944 (1.3607)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2421 (1.3536)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [210/781]  eta: 0:03:12  lr: 0.000010  loss: 1.2135 (1.3531)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2789 (1.3640)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [230/781]  eta: 0:03:05  lr: 0.000010  loss: 1.3023 (1.3709)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [240/781]  eta: 0:03:02  lr: 0.000010  loss: 1.2694 (1.3718)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [250/781]  eta: 0:02:58  lr: 0.000010  loss: 1.2513 (1.3667)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [260/781]  eta: 0:02:55  lr: 0.000010  loss: 1.2638 (1.3802)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [270/781]  eta: 0:02:51  lr: 0.000010  loss: 1.2655 (1.3746)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [280/781]  eta: 0:02:48  lr: 0.000010  loss: 1.2492 (1.3715)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2559 (1.3738)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [300/781]  eta: 0:02:41  lr: 0.000010  loss: 1.2354 (1.3706)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [310/781]  eta: 0:02:38  lr: 0.000010  loss: 1.2207 (1.3684)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2681 (1.3704)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [330/781]  eta: 0:02:31  lr: 0.000010  loss: 1.2359 (1.3689)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2359 (1.3712)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [350/781]  eta: 0:02:24  lr: 0.000010  loss: 1.2795 (1.3760)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [360/781]  eta: 0:02:21  lr: 0.000010  loss: 1.3175 (1.3785)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2835 (1.3752)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2166 (1.3745)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [390/781]  eta: 0:02:11  lr: 0.000010  loss: 1.2557 (1.3713)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2369 (1.3730)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [410/781]  eta: 0:02:04  lr: 0.000010  loss: 1.2413 (1.3760)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2661 (1.3746)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2784 (1.3761)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [440/781]  eta: 0:01:54  lr: 0.000010  loss: 1.3278 (1.3826)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.4062 (1.3838)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2757 (1.3833)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [470/781]  eta: 0:01:44  lr: 0.000010  loss: 1.2323 (1.3820)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2314 (1.3807)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.2408 (1.3782)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [500/781]  eta: 0:01:34  lr: 0.000010  loss: 1.2662 (1.3785)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2476 (1.3772)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2512 (1.3812)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [530/781]  eta: 0:01:24  lr: 0.000010  loss: 1.2460 (1.3783)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2460 (1.3795)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2953 (1.3823)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2657 (1.3872)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.3384 (1.3894)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2287 (1.3873)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2287 (1.3879)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2487 (1.3905)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [610/781]  eta: 0:00:57  lr: 0.000010  loss: 1.2286 (1.3883)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2286 (1.3898)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2469 (1.3914)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [640/781]  eta: 0:00:47  lr: 0.000010  loss: 1.2620 (1.3921)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2899 (1.3940)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2899 (1.3946)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [670/781]  eta: 0:00:37  lr: 0.000010  loss: 1.2832 (1.3976)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2822 (1.4002)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2821 (1.3999)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [700/781]  eta: 0:00:27  lr: 0.000010  loss: 1.2574 (1.4011)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2405 (1.4007)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2405 (1.4044)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [730/781]  eta: 0:00:17  lr: 0.000010  loss: 1.2675 (1.4054)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2559 (1.4059)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2332 (1.4048)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [760/781]  eta: 0:00:07  lr: 0.000010  loss: 1.2519 (1.4049)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2808 (1.4035)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [95]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2581 (1.4055)  time: 0.3331  data: 0.0005  max mem: 6459\n",
            "Epoch: [95] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2581 (1.4055)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32813993096351624, 'lambda_convnext_base': 0.26001134514808655, 'lambda_tf_efficientnetv2_l': 0.41184836626052856}\n",
            "Test:  [ 0/53]  eta: 0:00:47  loss: 0.7748 (0.7748)  acc1: 86.4583 (86.4583)  acc5: 94.7917 (94.7917)  time: 0.8869  data: 0.8560  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9615 (0.9428)  acc1: 84.3750 (82.2443)  acc5: 94.7917 (93.7027)  time: 0.1757  data: 0.1450  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0088 (1.0194)  acc1: 80.2083 (80.7044)  acc5: 93.2292 (92.6587)  time: 0.1231  data: 0.0924  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2011 (1.0764)  acc1: 75.5208 (79.5531)  acc5: 91.6667 (92.1707)  time: 0.1237  data: 0.0930  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2490 (1.1276)  acc1: 75.0000 (78.6966)  acc5: 90.6250 (91.7556)  time: 0.1236  data: 0.0929  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1400 (1.1255)  acc1: 76.0417 (78.3803)  acc5: 91.1458 (92.0343)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1408 (1.1385)  acc1: 75.5208 (78.2600)  acc5: 91.1458 (92.0500)  time: 0.1031  data: 0.0734  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1311 s / it)\n",
            "* Acc@1 78.260 Acc@5 92.050 loss 1.138\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [96]  [  0/781]  eta: 0:14:38  lr: 0.000010  loss: 2.0592 (2.0592)  time: 1.1242  data: 0.7765  max mem: 6459\n",
            "Epoch: [96]  [ 10/781]  eta: 0:05:12  lr: 0.000010  loss: 1.2654 (1.4909)  time: 0.4059  data: 0.0709  max mem: 6459\n",
            "Epoch: [96]  [ 20/781]  eta: 0:04:42  lr: 0.000010  loss: 1.2130 (1.3613)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 30/781]  eta: 0:04:29  lr: 0.000010  loss: 1.2117 (1.3412)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 40/781]  eta: 0:04:21  lr: 0.000010  loss: 1.2545 (1.3292)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 50/781]  eta: 0:04:15  lr: 0.000010  loss: 1.3046 (1.3382)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 60/781]  eta: 0:04:09  lr: 0.000010  loss: 1.3046 (1.3378)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 70/781]  eta: 0:04:05  lr: 0.000010  loss: 1.3055 (1.3918)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 80/781]  eta: 0:04:00  lr: 0.000010  loss: 1.3223 (1.4042)  time: 0.3345  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [ 90/781]  eta: 0:03:56  lr: 0.000010  loss: 1.2751 (1.4029)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [100/781]  eta: 0:03:52  lr: 0.000010  loss: 1.2596 (1.4267)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [110/781]  eta: 0:03:48  lr: 0.000010  loss: 1.3559 (1.4348)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [120/781]  eta: 0:03:44  lr: 0.000010  loss: 1.3360 (1.4349)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [130/781]  eta: 0:03:41  lr: 0.000010  loss: 1.2524 (1.4297)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [140/781]  eta: 0:03:37  lr: 0.000010  loss: 1.2542 (1.4290)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [150/781]  eta: 0:03:33  lr: 0.000010  loss: 1.2762 (1.4279)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [160/781]  eta: 0:03:30  lr: 0.000010  loss: 1.2777 (1.4189)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [170/781]  eta: 0:03:26  lr: 0.000010  loss: 1.2661 (1.4257)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [180/781]  eta: 0:03:23  lr: 0.000010  loss: 1.2807 (1.4263)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [190/781]  eta: 0:03:19  lr: 0.000010  loss: 1.2807 (1.4210)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [200/781]  eta: 0:03:16  lr: 0.000010  loss: 1.2547 (1.4229)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [210/781]  eta: 0:03:12  lr: 0.000010  loss: 1.2547 (1.4228)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [220/781]  eta: 0:03:09  lr: 0.000010  loss: 1.2566 (1.4204)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [230/781]  eta: 0:03:05  lr: 0.000010  loss: 1.3235 (1.4352)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [240/781]  eta: 0:03:02  lr: 0.000010  loss: 1.3276 (1.4364)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [250/781]  eta: 0:02:58  lr: 0.000010  loss: 1.3276 (1.4415)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [260/781]  eta: 0:02:55  lr: 0.000010  loss: 1.2816 (1.4415)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [270/781]  eta: 0:02:52  lr: 0.000010  loss: 1.2459 (1.4389)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [280/781]  eta: 0:02:48  lr: 0.000010  loss: 1.2517 (1.4377)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [290/781]  eta: 0:02:45  lr: 0.000010  loss: 1.2586 (1.4319)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [300/781]  eta: 0:02:41  lr: 0.000010  loss: 1.2458 (1.4265)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [310/781]  eta: 0:02:38  lr: 0.000010  loss: 1.2392 (1.4214)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2056 (1.4151)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [330/781]  eta: 0:02:31  lr: 0.000010  loss: 1.2056 (1.4140)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [340/781]  eta: 0:02:28  lr: 0.000010  loss: 1.2177 (1.4114)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [350/781]  eta: 0:02:24  lr: 0.000010  loss: 1.2177 (1.4079)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [360/781]  eta: 0:02:21  lr: 0.000010  loss: 1.2634 (1.4084)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [370/781]  eta: 0:02:18  lr: 0.000010  loss: 1.2808 (1.4090)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2946 (1.4149)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [390/781]  eta: 0:02:11  lr: 0.000010  loss: 1.2943 (1.4133)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2700 (1.4103)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [410/781]  eta: 0:02:04  lr: 0.000010  loss: 1.2463 (1.4126)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [420/781]  eta: 0:02:01  lr: 0.000010  loss: 1.2243 (1.4113)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2388 (1.4116)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [440/781]  eta: 0:01:54  lr: 0.000010  loss: 1.3326 (1.4156)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [450/781]  eta: 0:01:51  lr: 0.000010  loss: 1.2643 (1.4153)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2850 (1.4183)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [470/781]  eta: 0:01:44  lr: 0.000010  loss: 1.3457 (1.4195)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2256 (1.4153)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.1924 (1.4141)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [500/781]  eta: 0:01:34  lr: 0.000010  loss: 1.2238 (1.4134)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2749 (1.4128)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2925 (1.4117)  time: 0.3341  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [530/781]  eta: 0:01:24  lr: 0.000010  loss: 1.2727 (1.4129)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2972 (1.4151)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2984 (1.4162)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [560/781]  eta: 0:01:14  lr: 0.000010  loss: 1.2774 (1.4154)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2434 (1.4138)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2519 (1.4147)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2709 (1.4155)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2929 (1.4166)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [610/781]  eta: 0:00:57  lr: 0.000010  loss: 1.2858 (1.4172)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2650 (1.4168)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2635 (1.4150)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [640/781]  eta: 0:00:47  lr: 0.000010  loss: 1.2635 (1.4162)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2688 (1.4148)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2776 (1.4149)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [670/781]  eta: 0:00:37  lr: 0.000010  loss: 1.2716 (1.4124)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2716 (1.4127)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2765 (1.4118)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [700/781]  eta: 0:00:27  lr: 0.000010  loss: 1.2882 (1.4147)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.3896 (1.4154)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2986 (1.4158)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [730/781]  eta: 0:00:17  lr: 0.000010  loss: 1.2951 (1.4162)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.3031 (1.4182)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2577 (1.4173)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [760/781]  eta: 0:00:07  lr: 0.000010  loss: 1.2205 (1.4150)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2383 (1.4149)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [96]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2559 (1.4143)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [96] Total time: 0:04:21 (0.3347 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2559 (1.4143)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32868754863739014, 'lambda_convnext_base': 0.26011982560157776, 'lambda_tf_efficientnetv2_l': 0.4111928641796112}\n",
            "Test:  [ 0/53]  eta: 0:00:42  loss: 0.7795 (0.7795)  acc1: 84.3750 (84.3750)  acc5: 94.7917 (94.7917)  time: 0.8017  data: 0.7707  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.9242 (0.9475)  acc1: 83.3333 (82.3390)  acc5: 94.7917 (93.8447)  time: 0.1695  data: 0.1388  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0506 (1.0357)  acc1: 79.6875 (80.6052)  acc5: 92.1875 (92.4603)  time: 0.1279  data: 0.0972  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2180 (1.0944)  acc1: 75.5208 (79.2675)  acc5: 91.6667 (92.0195)  time: 0.1320  data: 0.1013  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2461 (1.1401)  acc1: 75.0000 (78.3156)  acc5: 90.6250 (91.5777)  time: 0.1369  data: 0.1062  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1885 (1.1355)  acc1: 75.5208 (78.2271)  acc5: 91.6667 (91.8709)  time: 0.1347  data: 0.1040  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1966 (1.1473)  acc1: 75.5208 (78.1000)  acc5: 91.6667 (91.8900)  time: 0.1146  data: 0.0849  max mem: 6459\n",
            "Test: Total time: 0:00:07 (0.1374 s / it)\n",
            "* Acc@1 78.100 Acc@5 91.890 loss 1.147\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [97]  [  0/781]  eta: 0:14:29  lr: 0.000010  loss: 1.2655 (1.2655)  time: 1.1134  data: 0.7727  max mem: 6459\n",
            "Epoch: [97]  [ 10/781]  eta: 0:05:11  lr: 0.000010  loss: 1.2457 (1.2659)  time: 0.4045  data: 0.0705  max mem: 6459\n",
            "Epoch: [97]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2523 (1.2853)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 30/781]  eta: 0:04:29  lr: 0.000010  loss: 1.2649 (1.3031)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 40/781]  eta: 0:04:21  lr: 0.000010  loss: 1.2360 (1.3267)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 50/781]  eta: 0:04:14  lr: 0.000010  loss: 1.2981 (1.3524)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 60/781]  eta: 0:04:09  lr: 0.000010  loss: 1.3000 (1.3495)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 70/781]  eta: 0:04:04  lr: 0.000010  loss: 1.2375 (1.3508)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 80/781]  eta: 0:04:00  lr: 0.000010  loss: 1.2235 (1.3408)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [ 90/781]  eta: 0:03:56  lr: 0.000010  loss: 1.2429 (1.3358)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [100/781]  eta: 0:03:52  lr: 0.000010  loss: 1.2430 (1.3367)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [110/781]  eta: 0:03:48  lr: 0.000010  loss: 1.3134 (1.3430)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [120/781]  eta: 0:03:44  lr: 0.000010  loss: 1.2753 (1.3520)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [130/781]  eta: 0:03:40  lr: 0.000010  loss: 1.2593 (1.3652)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [140/781]  eta: 0:03:37  lr: 0.000010  loss: 1.2612 (1.3691)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [150/781]  eta: 0:03:33  lr: 0.000010  loss: 1.2639 (1.3699)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2639 (1.3754)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [170/781]  eta: 0:03:26  lr: 0.000010  loss: 1.2616 (1.3718)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2652 (1.3735)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [190/781]  eta: 0:03:19  lr: 0.000010  loss: 1.2541 (1.3769)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2541 (1.3771)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [210/781]  eta: 0:03:12  lr: 0.000010  loss: 1.2569 (1.3725)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [220/781]  eta: 0:03:09  lr: 0.000010  loss: 1.2456 (1.3665)  time: 0.3431  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [230/781]  eta: 0:03:05  lr: 0.000010  loss: 1.2409 (1.3638)  time: 0.3434  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [240/781]  eta: 0:03:02  lr: 0.000010  loss: 1.2474 (1.3618)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [250/781]  eta: 0:02:59  lr: 0.000010  loss: 1.2722 (1.3580)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [260/781]  eta: 0:02:55  lr: 0.000010  loss: 1.2886 (1.3579)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [270/781]  eta: 0:02:52  lr: 0.000010  loss: 1.2542 (1.3553)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [280/781]  eta: 0:02:48  lr: 0.000010  loss: 1.2491 (1.3651)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [290/781]  eta: 0:02:45  lr: 0.000010  loss: 1.2603 (1.3621)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [300/781]  eta: 0:02:41  lr: 0.000010  loss: 1.2408 (1.3571)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [310/781]  eta: 0:02:38  lr: 0.000010  loss: 1.1865 (1.3556)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [320/781]  eta: 0:02:35  lr: 0.000010  loss: 1.2478 (1.3622)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [330/781]  eta: 0:02:31  lr: 0.000010  loss: 1.3969 (1.3744)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [340/781]  eta: 0:02:28  lr: 0.000010  loss: 1.3031 (1.3741)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [350/781]  eta: 0:02:24  lr: 0.000010  loss: 1.2856 (1.3790)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [360/781]  eta: 0:02:21  lr: 0.000010  loss: 1.2459 (1.3762)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [370/781]  eta: 0:02:18  lr: 0.000010  loss: 1.2496 (1.3751)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2724 (1.3727)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [390/781]  eta: 0:02:11  lr: 0.000010  loss: 1.2724 (1.3716)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2790 (1.3720)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [410/781]  eta: 0:02:04  lr: 0.000010  loss: 1.2961 (1.3714)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [420/781]  eta: 0:02:01  lr: 0.000010  loss: 1.2640 (1.3687)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2489 (1.3661)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [440/781]  eta: 0:01:54  lr: 0.000010  loss: 1.2535 (1.3681)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [450/781]  eta: 0:01:51  lr: 0.000010  loss: 1.2679 (1.3710)  time: 0.3342  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2197 (1.3703)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [470/781]  eta: 0:01:44  lr: 0.000010  loss: 1.2197 (1.3714)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2735 (1.3739)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.3161 (1.3773)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [500/781]  eta: 0:01:34  lr: 0.000010  loss: 1.2874 (1.3745)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2190 (1.3785)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2647 (1.3792)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [530/781]  eta: 0:01:24  lr: 0.000010  loss: 1.2562 (1.3770)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2562 (1.3786)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2303 (1.3812)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [560/781]  eta: 0:01:14  lr: 0.000010  loss: 1.2556 (1.3821)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.3006 (1.3843)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2786 (1.3860)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [590/781]  eta: 0:01:04  lr: 0.000010  loss: 1.2635 (1.3871)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2773 (1.3882)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [610/781]  eta: 0:00:57  lr: 0.000010  loss: 1.2879 (1.3877)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2758 (1.3892)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2681 (1.3889)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [640/781]  eta: 0:00:47  lr: 0.000010  loss: 1.2621 (1.3917)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2327 (1.3911)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.2250 (1.3927)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [670/781]  eta: 0:00:37  lr: 0.000010  loss: 1.2877 (1.3951)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.2791 (1.3934)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2729 (1.3952)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [700/781]  eta: 0:00:27  lr: 0.000010  loss: 1.2691 (1.3955)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2993 (1.3961)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2967 (1.3941)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [730/781]  eta: 0:00:17  lr: 0.000010  loss: 1.2434 (1.3922)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2851 (1.3945)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2861 (1.3940)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [760/781]  eta: 0:00:07  lr: 0.000010  loss: 1.2776 (1.3944)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2776 (1.3941)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [97]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2698 (1.3966)  time: 0.3334  data: 0.0006  max mem: 6459\n",
            "Epoch: [97] Total time: 0:04:21 (0.3349 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2698 (1.3966)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.3285941481590271, 'lambda_convnext_base': 0.2597082555294037, 'lambda_tf_efficientnetv2_l': 0.41169798374176025}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7867 (0.7867)  acc1: 83.3333 (83.3333)  acc5: 95.3125 (95.3125)  time: 0.8572  data: 0.8262  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8983 (0.9476)  acc1: 83.3333 (82.1023)  acc5: 94.2708 (93.5606)  time: 0.1709  data: 0.1402  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0422 (1.0248)  acc1: 78.6458 (80.6548)  acc5: 93.2292 (92.6587)  time: 0.1218  data: 0.0911  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.1492 (1.0865)  acc1: 76.5625 (79.4523)  acc5: 91.6667 (92.1875)  time: 0.1227  data: 0.0920  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2488 (1.1351)  acc1: 74.4792 (78.5569)  acc5: 90.6250 (91.7048)  time: 0.1235  data: 0.0928  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1608 (1.1301)  acc1: 76.0417 (78.4110)  acc5: 90.6250 (91.9220)  time: 0.1240  data: 0.0933  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1757 (1.1400)  acc1: 75.5208 (78.3200)  acc5: 92.1875 (91.9500)  time: 0.1045  data: 0.0747  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1304 s / it)\n",
            "* Acc@1 78.320 Acc@5 91.950 loss 1.140\n",
            "Accuracy of the network on the 10000 test images: 78.3%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [98]  [  0/781]  eta: 0:14:11  lr: 0.000010  loss: 1.1730 (1.1730)  time: 1.0898  data: 0.7478  max mem: 6459\n",
            "Epoch: [98]  [ 10/781]  eta: 0:05:09  lr: 0.000010  loss: 1.2337 (1.2927)  time: 0.4020  data: 0.0683  max mem: 6459\n",
            "Epoch: [98]  [ 20/781]  eta: 0:04:41  lr: 0.000010  loss: 1.2337 (1.4158)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2328 (1.4069)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2693 (1.4638)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 50/781]  eta: 0:04:14  lr: 0.000010  loss: 1.2984 (1.4588)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 60/781]  eta: 0:04:09  lr: 0.000010  loss: 1.2879 (1.4373)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 70/781]  eta: 0:04:04  lr: 0.000010  loss: 1.2672 (1.4402)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 80/781]  eta: 0:04:00  lr: 0.000010  loss: 1.2672 (1.4443)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [ 90/781]  eta: 0:03:56  lr: 0.000010  loss: 1.2196 (1.4262)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [100/781]  eta: 0:03:52  lr: 0.000010  loss: 1.2549 (1.4296)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [110/781]  eta: 0:03:48  lr: 0.000010  loss: 1.2929 (1.4337)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [120/781]  eta: 0:03:44  lr: 0.000010  loss: 1.2897 (1.4477)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [130/781]  eta: 0:03:40  lr: 0.000010  loss: 1.3883 (1.4497)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [140/781]  eta: 0:03:37  lr: 0.000010  loss: 1.2166 (1.4367)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [150/781]  eta: 0:03:33  lr: 0.000010  loss: 1.2184 (1.4303)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2474 (1.4255)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [170/781]  eta: 0:03:26  lr: 0.000010  loss: 1.2505 (1.4246)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2461 (1.4215)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [190/781]  eta: 0:03:19  lr: 0.000010  loss: 1.2608 (1.4133)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2544 (1.4063)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [210/781]  eta: 0:03:12  lr: 0.000010  loss: 1.2965 (1.4122)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2571 (1.4055)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [230/781]  eta: 0:03:05  lr: 0.000010  loss: 1.2391 (1.3990)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [240/781]  eta: 0:03:01  lr: 0.000010  loss: 1.2353 (1.3932)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [250/781]  eta: 0:02:58  lr: 0.000010  loss: 1.2218 (1.3876)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [260/781]  eta: 0:02:55  lr: 0.000010  loss: 1.2435 (1.3893)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [270/781]  eta: 0:02:51  lr: 0.000010  loss: 1.2822 (1.3916)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [280/781]  eta: 0:02:48  lr: 0.000010  loss: 1.3321 (1.4012)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.3528 (1.4016)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [300/781]  eta: 0:02:41  lr: 0.000010  loss: 1.2757 (1.4071)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [310/781]  eta: 0:02:38  lr: 0.000010  loss: 1.2757 (1.4072)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2715 (1.4061)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [330/781]  eta: 0:02:31  lr: 0.000010  loss: 1.2727 (1.4064)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2735 (1.4086)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [350/781]  eta: 0:02:24  lr: 0.000010  loss: 1.2752 (1.4149)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [360/781]  eta: 0:02:21  lr: 0.000010  loss: 1.2581 (1.4104)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2486 (1.4064)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2372 (1.4050)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [390/781]  eta: 0:02:11  lr: 0.000010  loss: 1.2390 (1.4062)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2701 (1.4069)  time: 0.3340  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [410/781]  eta: 0:02:04  lr: 0.000010  loss: 1.2464 (1.4075)  time: 0.3338  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2464 (1.4047)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.2350 (1.4013)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [440/781]  eta: 0:01:54  lr: 0.000010  loss: 1.2758 (1.4049)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.3137 (1.4068)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.2721 (1.4081)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [470/781]  eta: 0:01:44  lr: 0.000010  loss: 1.2466 (1.4042)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2254 (1.4040)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.2533 (1.4026)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [500/781]  eta: 0:01:34  lr: 0.000010  loss: 1.2493 (1.3993)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2524 (1.3979)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2532 (1.4007)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [530/781]  eta: 0:01:24  lr: 0.000010  loss: 1.2466 (1.3997)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2139 (1.3965)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2139 (1.3967)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2095 (1.3938)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2058 (1.3911)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2778 (1.3979)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2778 (1.3961)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2432 (1.3953)  time: 0.3328  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [610/781]  eta: 0:00:57  lr: 0.000010  loss: 1.2444 (1.3944)  time: 0.3329  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2371 (1.3957)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.2462 (1.3982)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [640/781]  eta: 0:00:47  lr: 0.000010  loss: 1.2627 (1.3960)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2688 (1.3993)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.3247 (1.3994)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [670/781]  eta: 0:00:37  lr: 0.000010  loss: 1.3247 (1.4015)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.3139 (1.4014)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.2489 (1.4004)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [700/781]  eta: 0:00:27  lr: 0.000010  loss: 1.2298 (1.4015)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2600 (1.4002)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2423 (1.3986)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [730/781]  eta: 0:00:17  lr: 0.000010  loss: 1.2423 (1.3986)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2502 (1.3967)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2472 (1.4002)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [760/781]  eta: 0:00:07  lr: 0.000010  loss: 1.2951 (1.4015)  time: 0.3344  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2951 (1.4012)  time: 0.3343  data: 0.0003  max mem: 6459\n",
            "Epoch: [98]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2555 (1.4019)  time: 0.3339  data: 0.0005  max mem: 6459\n",
            "Epoch: [98] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2555 (1.4019)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32889676094055176, 'lambda_convnext_base': 0.2597246468067169, 'lambda_tf_efficientnetv2_l': 0.41137805581092834}\n",
            "Test:  [ 0/53]  eta: 0:00:45  loss: 0.7934 (0.7934)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 0.8536  data: 0.8227  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8815 (0.9565)  acc1: 84.3750 (82.1023)  acc5: 94.2708 (93.8447)  time: 0.1702  data: 0.1395  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0131 (1.0347)  acc1: 79.1667 (80.5308)  acc5: 93.2292 (92.7331)  time: 0.1174  data: 0.0867  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2073 (1.0930)  acc1: 75.5208 (79.4019)  acc5: 90.6250 (92.2211)  time: 0.1252  data: 0.0945  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2474 (1.1363)  acc1: 75.0000 (78.5696)  acc5: 90.1042 (91.7175)  time: 0.1243  data: 0.0936  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1831 (1.1378)  acc1: 76.0417 (78.2169)  acc5: 92.1875 (91.9833)  time: 0.1255  data: 0.0949  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1979 (1.1467)  acc1: 75.0000 (78.0900)  acc5: 92.1875 (92.0200)  time: 0.1110  data: 0.0813  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1316 s / it)\n",
            "* Acc@1 78.090 Acc@5 92.020 loss 1.147\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Epoch: [99]  [  0/781]  eta: 0:14:11  lr: 0.000010  loss: 1.2985 (1.2985)  time: 1.0899  data: 0.7464  max mem: 6459\n",
            "Epoch: [99]  [ 10/781]  eta: 0:05:09  lr: 0.000010  loss: 1.2985 (1.5088)  time: 0.4021  data: 0.0681  max mem: 6459\n",
            "Epoch: [99]  [ 20/781]  eta: 0:04:40  lr: 0.000010  loss: 1.2723 (1.4594)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 30/781]  eta: 0:04:28  lr: 0.000010  loss: 1.2356 (1.4088)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 40/781]  eta: 0:04:20  lr: 0.000010  loss: 1.2784 (1.3998)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 50/781]  eta: 0:04:14  lr: 0.000010  loss: 1.2803 (1.3744)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 60/781]  eta: 0:04:09  lr: 0.000010  loss: 1.2477 (1.3595)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 70/781]  eta: 0:04:04  lr: 0.000010  loss: 1.2520 (1.3715)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 80/781]  eta: 0:04:00  lr: 0.000010  loss: 1.2884 (1.3958)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [ 90/781]  eta: 0:03:56  lr: 0.000010  loss: 1.2804 (1.3940)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [100/781]  eta: 0:03:52  lr: 0.000010  loss: 1.2508 (1.3947)  time: 0.3330  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [110/781]  eta: 0:03:48  lr: 0.000010  loss: 1.2571 (1.4014)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [120/781]  eta: 0:03:44  lr: 0.000010  loss: 1.2434 (1.4007)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [130/781]  eta: 0:03:40  lr: 0.000010  loss: 1.2830 (1.4088)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [140/781]  eta: 0:03:37  lr: 0.000010  loss: 1.3003 (1.4088)  time: 0.3336  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [150/781]  eta: 0:03:33  lr: 0.000010  loss: 1.2768 (1.4117)  time: 0.3339  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [160/781]  eta: 0:03:29  lr: 0.000010  loss: 1.2520 (1.4165)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [170/781]  eta: 0:03:26  lr: 0.000010  loss: 1.2360 (1.4104)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [180/781]  eta: 0:03:22  lr: 0.000010  loss: 1.2360 (1.4161)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [190/781]  eta: 0:03:19  lr: 0.000010  loss: 1.3146 (1.4128)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [200/781]  eta: 0:03:15  lr: 0.000010  loss: 1.2489 (1.4079)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [210/781]  eta: 0:03:12  lr: 0.000010  loss: 1.2255 (1.4023)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [220/781]  eta: 0:03:08  lr: 0.000010  loss: 1.2484 (1.4001)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [230/781]  eta: 0:03:05  lr: 0.000010  loss: 1.2585 (1.3935)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [240/781]  eta: 0:03:02  lr: 0.000010  loss: 1.2806 (1.3902)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [250/781]  eta: 0:02:58  lr: 0.000010  loss: 1.2431 (1.3867)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [260/781]  eta: 0:02:55  lr: 0.000010  loss: 1.2120 (1.3873)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [270/781]  eta: 0:02:51  lr: 0.000010  loss: 1.2359 (1.3867)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [280/781]  eta: 0:02:48  lr: 0.000010  loss: 1.2456 (1.3908)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [290/781]  eta: 0:02:44  lr: 0.000010  loss: 1.2693 (1.3876)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [300/781]  eta: 0:02:41  lr: 0.000010  loss: 1.2788 (1.3869)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [310/781]  eta: 0:02:38  lr: 0.000010  loss: 1.2783 (1.3918)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [320/781]  eta: 0:02:34  lr: 0.000010  loss: 1.2098 (1.3906)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [330/781]  eta: 0:02:31  lr: 0.000010  loss: 1.2808 (1.3973)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [340/781]  eta: 0:02:27  lr: 0.000010  loss: 1.2620 (1.3912)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [350/781]  eta: 0:02:24  lr: 0.000010  loss: 1.2076 (1.3907)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [360/781]  eta: 0:02:21  lr: 0.000010  loss: 1.2076 (1.3885)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [370/781]  eta: 0:02:17  lr: 0.000010  loss: 1.2070 (1.3889)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [380/781]  eta: 0:02:14  lr: 0.000010  loss: 1.2196 (1.3931)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [390/781]  eta: 0:02:11  lr: 0.000010  loss: 1.2856 (1.3893)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [400/781]  eta: 0:02:07  lr: 0.000010  loss: 1.2879 (1.3920)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [410/781]  eta: 0:02:04  lr: 0.000010  loss: 1.2940 (1.3947)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [420/781]  eta: 0:02:00  lr: 0.000010  loss: 1.2782 (1.3977)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [430/781]  eta: 0:01:57  lr: 0.000010  loss: 1.3122 (1.3972)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [440/781]  eta: 0:01:54  lr: 0.000010  loss: 1.3001 (1.3953)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [450/781]  eta: 0:01:50  lr: 0.000010  loss: 1.2526 (1.4044)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [460/781]  eta: 0:01:47  lr: 0.000010  loss: 1.3228 (1.4047)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [470/781]  eta: 0:01:44  lr: 0.000010  loss: 1.2701 (1.4054)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [480/781]  eta: 0:01:40  lr: 0.000010  loss: 1.2319 (1.4060)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [490/781]  eta: 0:01:37  lr: 0.000010  loss: 1.2444 (1.4035)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [500/781]  eta: 0:01:34  lr: 0.000010  loss: 1.2444 (1.4053)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [510/781]  eta: 0:01:30  lr: 0.000010  loss: 1.2770 (1.4034)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [520/781]  eta: 0:01:27  lr: 0.000010  loss: 1.2492 (1.4020)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [530/781]  eta: 0:01:24  lr: 0.000010  loss: 1.2381 (1.4003)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [540/781]  eta: 0:01:20  lr: 0.000010  loss: 1.2463 (1.4046)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [550/781]  eta: 0:01:17  lr: 0.000010  loss: 1.2857 (1.4065)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [560/781]  eta: 0:01:13  lr: 0.000010  loss: 1.2857 (1.4085)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [570/781]  eta: 0:01:10  lr: 0.000010  loss: 1.2720 (1.4080)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [580/781]  eta: 0:01:07  lr: 0.000010  loss: 1.2487 (1.4098)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [590/781]  eta: 0:01:03  lr: 0.000010  loss: 1.2287 (1.4076)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [600/781]  eta: 0:01:00  lr: 0.000010  loss: 1.2515 (1.4059)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [610/781]  eta: 0:00:57  lr: 0.000010  loss: 1.2900 (1.4092)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [620/781]  eta: 0:00:53  lr: 0.000010  loss: 1.2931 (1.4066)  time: 0.3337  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [630/781]  eta: 0:00:50  lr: 0.000010  loss: 1.3036 (1.4096)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [640/781]  eta: 0:00:47  lr: 0.000010  loss: 1.2309 (1.4066)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [650/781]  eta: 0:00:43  lr: 0.000010  loss: 1.2266 (1.4068)  time: 0.3331  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [660/781]  eta: 0:00:40  lr: 0.000010  loss: 1.3082 (1.4083)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [670/781]  eta: 0:00:37  lr: 0.000010  loss: 1.2606 (1.4071)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [680/781]  eta: 0:00:33  lr: 0.000010  loss: 1.1833 (1.4040)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [690/781]  eta: 0:00:30  lr: 0.000010  loss: 1.1986 (1.4039)  time: 0.3335  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [700/781]  eta: 0:00:27  lr: 0.000010  loss: 1.2128 (1.4027)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [710/781]  eta: 0:00:23  lr: 0.000010  loss: 1.2163 (1.4022)  time: 0.3334  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [720/781]  eta: 0:00:20  lr: 0.000010  loss: 1.2501 (1.3996)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [730/781]  eta: 0:00:17  lr: 0.000010  loss: 1.2370 (1.4003)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [740/781]  eta: 0:00:13  lr: 0.000010  loss: 1.2540 (1.4019)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [750/781]  eta: 0:00:10  lr: 0.000010  loss: 1.2541 (1.4014)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [760/781]  eta: 0:00:07  lr: 0.000010  loss: 1.2737 (1.4004)  time: 0.3333  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [770/781]  eta: 0:00:03  lr: 0.000010  loss: 1.2763 (1.4005)  time: 0.3332  data: 0.0003  max mem: 6459\n",
            "Epoch: [99]  [780/781]  eta: 0:00:00  lr: 0.000010  loss: 1.2569 (1.3999)  time: 0.3332  data: 0.0006  max mem: 6459\n",
            "Epoch: [99] Total time: 0:04:21 (0.3344 s / it)\n",
            "Averaged stats: lr: 0.000010  loss: 1.2569 (1.3999)\n",
            "λ means: {'lambda_swin_base_patch4_window7_224': 0.32900360226631165, 'lambda_convnext_base': 0.2606245279312134, 'lambda_tf_efficientnetv2_l': 0.4103720486164093}\n",
            "Test:  [ 0/53]  eta: 0:00:43  loss: 0.7785 (0.7785)  acc1: 84.8958 (84.8958)  acc5: 95.8333 (95.8333)  time: 0.8302  data: 0.7911  max mem: 6459\n",
            "Test:  [10/53]  eta: 0:00:07  loss: 0.8806 (0.9483)  acc1: 84.8958 (82.3390)  acc5: 95.3125 (93.7500)  time: 0.1746  data: 0.1432  max mem: 6459\n",
            "Test:  [20/53]  eta: 0:00:05  loss: 1.0356 (1.0335)  acc1: 78.1250 (80.5556)  acc5: 92.7083 (92.6091)  time: 0.1249  data: 0.0942  max mem: 6459\n",
            "Test:  [30/53]  eta: 0:00:03  loss: 1.2044 (1.0914)  acc1: 76.0417 (79.3179)  acc5: 91.1458 (92.1035)  time: 0.1220  data: 0.0913  max mem: 6459\n",
            "Test:  [40/53]  eta: 0:00:01  loss: 1.2866 (1.1321)  acc1: 76.0417 (78.4934)  acc5: 90.1042 (91.6286)  time: 0.1223  data: 0.0916  max mem: 6459\n",
            "Test:  [50/53]  eta: 0:00:00  loss: 1.1479 (1.1311)  acc1: 76.5625 (78.2067)  acc5: 90.6250 (91.8607)  time: 0.1232  data: 0.0925  max mem: 6459\n",
            "Test:  [52/53]  eta: 0:00:00  loss: 1.1826 (1.1383)  acc1: 76.5625 (78.1000)  acc5: 91.6667 (91.9000)  time: 0.1037  data: 0.0739  max mem: 6459\n",
            "Test: Total time: 0:00:06 (0.1304 s / it)\n",
            "* Acc@1 78.100 Acc@5 91.900 loss 1.138\n",
            "Accuracy of the network on the 10000 test images: 78.1%\n",
            "Max accuracy: 78.34%\n",
            "Training time 7:27:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Layer 2: Base Environment — Teacher Models & Multi-Teacher Adaptations**"
      ],
      "metadata": {
        "id": "ck_VO0908kCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer 2 extends the baseline DeiT environment to support knowledge distillation from one or more teacher models. This layer is additive: it does not modify the baseline DeiT training loop unless explicitly stated.\n",
        "It includes\n",
        "1. Teacher Model Support (Single & Multiple)\n",
        "2. Teacher Registry / Configuration\n",
        "3. Multi-Teacher Fusion Mechanism (Adaptation Layer)\n",
        "4. Distillation Loss Integration"
      ],
      "metadata": {
        "id": "0ZO3MUL88nog"
      }
    }
  ]
}